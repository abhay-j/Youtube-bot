{
  "qOECpFrwv-g": {
    "published_at": "2024-02-02T10:35:44Z",
    "title": "Will Perplexity AI takeover Google?",
    "text": "Will Perplexity AI takeover Google? can you show us some perplexity AI so let's say that I want to do top 10 places to eat in Mumbai it gives me answers in this kind of a format but the thing is in Google it it all depends on who ranks for the best SEO it's like a pretty competitive market over here why is it that much better than chbd dude it gives you references like CH gbd hallucinates a lot perplexity anything it says will give you a reference so I can look through the original article and wherever it found it from and be like okay it's not bullshitting the only problem is if this gets really really big a chat GP will be like hey they're eating my lunch and they might you know pivot a little bit or maybe have this offering as one of the gpts or something they're saying they're going to try and make Google dance that's literally what the CEO said why everyone wants to make Google dance bro Microsoft also wants to make Google dance perplexity also wants to make Google dance p is like P that was a good joke that was a good joke",
    "url": "https://www.youtube.com/watch?v=qOECpFrwv-g"
  },
  "dGxuH-eaADo": {
    "published_at": "2024-03-22T10:52:31Z",
    "title": "#ad loved trying this futuristic, sleek, and powerful phone - HONOR X9B!",
    "text": "#ad loved trying this futuristic, sleek, and powerful phone - HONOR X9B! so T my mid Journey as you know has gotten really good at product shots and we've been experimenting a lot with those product shots let's try product shot of a mid-range smartphone that has airbags technology textured orange surface that looks okay but I want like I want something more futuristic and classy I mean what you've generated so far is looks pretty nice but it looks bulky it doesn't look Sleek that being said we were fortunate enough to receive a phone that matches the futuristic and classy design oh this is the honor x9b no yes and it comes with all the cool features obviously but one feature that particularly stands out is its Ultra bounce anti- drop display ah so if you drop it from like a height the screen remains undamaged so this phone is pretty cool because it's also equipped with the brand new Qualcomm Snapdragon 6 gen 1 this is the phone it actually looks pretty nice and you know I've just been thinking that at the price this looks like a really good phone you can buy this phone now on amazon.in and on Mainline stores near you enjoy",
    "url": "https://www.youtube.com/watch?v=dGxuH-eaADo"
  },
  "Ghpb-hZF5gs": {
    "published_at": "2023-10-28T13:30:13Z",
    "title": "How Induced AI is Being Built!",
    "text": "How Induced AI is Being Built! me and my co-founder aush we building AI Bots that we run on the cloud it's called induced every bot has full access to a browser it has its own email it has its own phone number and everything's running on the cloud so it doesn't affect your computer you can be sleeping and the Bots can still work and function we use these Bots and we basically deploy them in business processes and workflows where as a 15 member team they're spending time doing a lot of stuff that is not really requiring cognitive power could be form filling data entry any business process that would typically be outsourced to a back office you can have a th running at once you can have five depending on what you need it's a slightly different kind of agent it's not fully autonomous it's like doing consumer work we have a lot more scripting and just input that goes into it but we also kind do that because we are serving a customer segment that wants reliability and agents seem like a very very exciting problem for us it's one of the most exciting opportunities when we think the infrastructure we're creating in this process is going to be increasingly important as more people start creating agents models and connect them to the internet",
    "url": "https://www.youtube.com/watch?v=Ghpb-hZF5gs"
  },
  "Fe4MMd-cJto": {
    "published_at": "2024-01-25T12:36:40Z",
    "title": "The big problem with KYC as AI gets better",
    "text": "The big problem with KYC as AI gets better kyc is getting disrupted T how does this work what is this staed Fusion now there's a new technology called IP adapter face ID you're able to feed it an image from the AAR card or whatever and then it will make you person that sort of looks like the AAR card enough to fool any kyc so it it can replicate a photo so if I give it a photo and say now take this person and put them in XY Z yeah you can full verification post pretty well even with video I think you can fool it with deep fix I think we will go back to physical kycs for a bit as this gets more rampant year ago zero knowledge kyc technology is officially available right like most of India's documentation is on digilocker and if third party apps want to Ping it you can now use Zer ZK to Ping and not third party apps don't even need your actual data but they can still verify that you're a real person and get with it but all video kyc stuff is like yeah I can see how that's that's a problem now",
    "url": "https://www.youtube.com/watch?v=Fe4MMd-cJto"
  },
  "t9S6ApYMAQw": {
    "published_at": "2023-06-07T14:32:22Z",
    "title": "What is fine-tuning? Explained!",
    "text": "What is fine-tuning? Explained! I think the best use case of fine tuning is having your parents live forever that's the best use case how do you do that hey can you play a clip of that Superman show where he has jorel his father arrive with him on the spaceship and it appears as a hologram and it's a exact reflection of Jordan can you explain to folks what what is fine tuning so fine tuning is essentially saying okay instead of this output that chat dpd would give me reply with this this is what Tanya would say and if I give it and it turns out if I give it enough examples charity starts behaving like so effectively if this is your AI model on one side is the trading data yeah which you feed into the model on the other side is the output based on the training data yeah so you replace the string data with something specific yeah you don't replace it you add on you add on to it so you just add the specific use case that you want to train it for yeah input from one end so it can start outputting like you in whatever task that you wanted to do this is fine tuning yes",
    "url": "https://www.youtube.com/watch?v=t9S6ApYMAQw"
  },
  "T9Gy4n8DsR0": {
    "published_at": "2024-01-05T15:27:26Z",
    "title": "The future of AI companionship -- Digi AI",
    "text": "The future of AI companionship -- Digi AI it's the future of AI romantic companionship it's called D it was so nice talking to you today honestly I've never met anyone like you it's an app where you have this thing you can talk to it you can be friends with it and you start off as friendship then dating then you know whatever I'm not a fan of this stuff why because it's really depressing to think about that you're going to have companionship via robot even though I think it will be necessary and I think loneliness is going to be a big problem but it's just still kind of sad to think about that this is going to be massive I think this will also be in games so you'll play cyber Punk there'll be characters in cyber punk you can fall in love with or make friends with you play some other game every game basically every game is sandbox now yeah every game is sandbox and that makes real life sadbox",
    "url": "https://www.youtube.com/watch?v=T9Gy4n8DsR0"
  },
  "vy3dlArdErE": {
    "published_at": "2023-05-24T12:38:16Z",
    "title": "How To Create MC Stan AI Diss Track Using Eminem&#39;s Voice!",
    "text": "How To Create MC Stan AI Diss Track Using Eminem&#39;s Voice! I want to try and make a song live right now Eminem was dissed by NC Stan and this is a reply to MC stand by Eminem write a song please sing a new rapper called him see Stan he wears shoes worth 80 000 rupees never be me so don't even try you're just a weak imitation a basic rhymed jeez I'm gonna go to this app called Uber duck I'm gonna do text to speech I'm about to start this kid like he's all right so now we have Eminem's rap and the beat uh in two layers in audacity yeah it may not match but it won't match just to hoping over its thinks the it thinks the layers you listen up it's Eminem  so let's see",
    "url": "https://www.youtube.com/watch?v=vy3dlArdErE"
  },
  "mIqFOJe0dW0": {
    "published_at": "2023-07-12T11:30:17Z",
    "title": "Create Presentation Slides Using AI in Seconds \ud83e\udd2f",
    "text": "Create Presentation Slides Using AI in Seconds \ud83e\udd2f create presentation slides with AI in seconds let's actually use Tome so I'm going to create a new slide deck and I'm just going to say create a presentation about life lessons from Harry Potter book seven and then Tome at the back end uses gpd4 to or GPD 3.5 to generate the text for it as well so we don't have to manually do it all right so it's generated it seven life lessons from the boy who lived it even generated nice little images yeah that's pretty cool so it's got power of love importance of friendship consequences of greed value of sacrifice and yeah so the visual presentation here is a lot better here there's just a lot of text but this does look visually prettier",
    "url": "https://www.youtube.com/watch?v=mIqFOJe0dW0"
  },
  "EojbnWvb2QI": {
    "published_at": "2023-06-18T13:41:59Z",
    "title": "Sam Altman Testified in front of US Senate",
    "text": "Sam Altman Testified in front of US Senate Sam Allman testified in front of U.S Senate and I gotta say way better than uh what Zuck had Sam artman knows how he's being perceived and he played that super well like we the few of the technology in the industry caused significant harm to the world it's why we started the company it's a big part of why I'm here today and why we've been here in the past I think if this technology goes wrong it can go quite wrong yeah he was quite open about the potential destructive nature of AI he's being a Doomer he's being a Doomer but a very measured it could go wrong it could go quiet may go wrong like he's doing it very smartly like Sam came prepared with hey we think this should be regulated so he kind of got ahead of everybody else and be like I'm the guy who's saying let's regulate this tip we need we need a body if there is regulation that's going to come open AI will help that regulation be shaped Samir is a sly guy Sameer Sameer Altman",
    "url": "https://www.youtube.com/watch?v=EojbnWvb2QI"
  },
  "gTYXt-5aiz0": {
    "published_at": "2023-10-30T14:25:29Z",
    "title": "What AI Tools do Varun and Tanmay Use?",
    "text": "What AI Tools do Varun and Tanmay Use? I'm just curious because you've seen so many product like what's the conversion rate of new product to like actual implementation in your life I'll tell you what all I use so all my content is automated I'm a lazy person I think in the next couple of weeks we are fine tuning mril hopefully I don't have to write scripts either like we use AI for some projects we're making an anime we're using something called animate diff there we are primarily using AI for video as a consumer I I do use GPT a lot as well I use GPT as a sparring partner uses GPD like that as well GPD 4 and mid journey to me are the obvious Delta 4 products out there but apart from that a lot of the other tools that I see they feel like almost there but not quite but because I've used mid Journey like a year ago and seen where it gotten now it's so clear that some of this is going to get so good that it's going to be obvious but is it something that my life is being automated when not there yet",
    "url": "https://www.youtube.com/watch?v=gTYXt-5aiz0"
  },
  "hbi8RXZSQlY": {
    "published_at": "2023-07-20T14:25:38Z",
    "title": "Claude: The Real Threat to ChatGPT",
    "text": "Claude: The Real Threat to ChatGPT there is a competitor GPD it's called Claude 2 it's currently live only in the US and UK but because we are cool we have access to it how did we get access one thing I know about slot it's got a longer context run ppt's base context length is about 4000 something and then GPT also released a 32 000 context length but Claude has a 100K context map we've put in lots of tweets from Elon we've taken his podcast from Joe Rogan Experience his podcast from Lex Friedman and we've just dumped it in now that you have this data can you tell me three things that Elon believes in that the average human right or not all right so Claude replied saying based on the text of his tweets CR three things he seems to believe that the average person may not making Humanity multi-planetary merging with AI engineering as an art form the overarching theme seems to be Elon takes a very long term species level view of his things and is focused on existential threats interesting",
    "url": "https://www.youtube.com/watch?v=hbi8RXZSQlY"
  },
  "8yjbBubze2E": {
    "published_at": "2023-06-09T12:24:26Z",
    "title": "How to Faceswap Yourself into any Image",
    "text": "How to Faceswap Yourself into any Image I tried the mid-journey face swap me on Donald Trump like that looks that looks like a real image right and there's you as Superman you as an old guy it looks really good so let's show people how to do this on my journey well first you need a mid Journey account especially for install a bot called inside face add it to your server type slash imagine and a prompt macro photography Superman flying through Mumbai close up short Studio lighting so once so once you have the base image you write save ID this triggers the bot this is a picture of me that I'm just gonna add as my ID and when I press enter It's Gonna Save tanma as my ID then I go here on the picture I right click on it I go to apps and I click on in swapper now the ill generate an image with my face on Superman that's pretty good",
    "url": "https://www.youtube.com/watch?v=8yjbBubze2E"
  },
  "JWC2M_8bZng": {
    "published_at": "2023-10-08T16:58:45Z",
    "title": "Turn your Voice into musical Instruments!",
    "text": "Turn your Voice into musical Instruments!  so this tool is called music fy. L what we're going to go into is turning your voice into an instrument T just say like a simple  beat perfect and you're going to turn it into drums I'm going to turn it into drums there's two kinds of drums over here there's one it's basic drum set and there's another instrument called darbuka so actually Tred darbuka it sounds pretty nice this so select an audio file all right it's converted let's listen to it oh not bad that was nice can you try another instrument let's try slap base right no this not it's not as good I mean it doesn't have notes but it's kind of getting the slap sound right I think if a beat boxer Did something like this it what are you saying that I'm not good enough",
    "url": "https://www.youtube.com/watch?v=JWC2M_8bZng"
  },
  "iDP4Pcoxyx8": {
    "published_at": "2023-09-05T10:21:16Z",
    "title": "Cursor.sh - AI Powered Coding Assistant",
    "text": "Cursor.sh - AI Powered Coding Assistant cursor.sh coding assistant it uses gpd432k increases productivity how is it better than copilot let's see so we are here new AI project build me a 2048 game in unity let's see if we can actually do it to create a 2048 game in unity you need several files first you need a main scene then you need a game manager then you need a tile.cs which is great then you need grid you need input control so it's it's sort of like Auto GPT in a way or the small repo that we built autocode Pro on top of but a nicer interface and has like a smoother chat they're doing it inside like your IDE and the IDE itself is saying hey you want to install the c-sharp extension for the c-sharp language so it's got the game manager ready it's creating the file it's writing The Code by itself great as for how well it will work we'll have to deploy it but this is interesting how much code I'm writing wow I'm doing so much effort",
    "url": "https://www.youtube.com/watch?v=iDP4Pcoxyx8"
  },
  "PSVe0lDSRGI": {
    "published_at": "2024-08-14T13:30:19Z",
    "title": "Meet &#39;Friend&#39;: The AI Wearable Stirring Up Controversy!",
    "text": "Meet &#39;Friend&#39;: The AI Wearable Stirring Up Controversy! dude what did I watch I saw something explode on Twitter yesterday it drew by mind ABI shiffman raised $2 million and app spent 1.8 million of it buying the domain name friend.com it looks like the small Amazon Echo but with AI capability built into it you it was worth it so finally this guy Abby wanted to make a available there's another guy that also wanted to make available and they both named it friend eventually when Abi came out with his product the other guys made a rap song on the internet saying how can you steal my thing or whatever I don't C renamed your T check my style bu nothing real it's been a while and's like no screw you it's my m the move that he made was he spent $1.8 million on a domain which to be very honest that's the one part of this I can get behind everyone can make products but getting users on the products is damn hard you think play which is to hack SEO which is people everybody searching for AI friend is going to find this now I think everyone's checking on everything that comes out so A's learned how to sort of take advantage of the haters right he's like haters are any going to share and talk nonsense might as it make something where they can actually share and it's got like 21 million views I don't think you can purchase 21 million views for $1.8 million so whatever it is it paid off",
    "url": "https://www.youtube.com/watch?v=PSVe0lDSRGI"
  },
  "K_SHoo61jO0": {
    "published_at": "2023-08-11T13:10:52Z",
    "title": "Use this AI tool for Music Sampling",
    "text": "Use this AI tool for Music Sampling so the first tool is something called lalalai helpful in making music helping me and sampling things it's sampling is essentially when you take a part of a song that already exists you probably like that part or you probably like that element you might want to reuse it so I can get the stems of the entire track you can select whether I want only drums whether I want drums and vocals whether I want just the vocals let's try it with quesaria  still separated and give it to you basically you can create like karaoke versions of correct so this is essentially just the vocals  oh that's mad this is really good overall one good news is musicians don't have to worry about AI taking their place because the tools are pretty primitive at this point",
    "url": "https://www.youtube.com/watch?v=K_SHoo61jO0"
  },
  "zeo-3pHp0Xk": {
    "published_at": "2023-06-21T15:29:34Z",
    "title": "Would you buy the new Apple Vision Pro?",
    "text": "Would you buy the new Apple Vision Pro? Apple launch application Pro my first impression was dude How can Apple make something without controllers which seems way cooler like it feels so intuitive to just move your fingers and to select icons and on the next treatment podcast Zuck said that controllers are a deliberate thing because he want to make something that is Affordable by more people and specifically for gaming whereas Apple went for an entertainment which is classic apple right like they the whole thing is like for rich people it's for rich people it's cool it's designed at this point it's just a signaling thing if you can afford Vision Pro which means you have a certain class and a certain taste I have tried the quest Pro I would buy Vision Pro because I can afford it um shut the up you can also afford it why you make it seem like yeah I think it's cool it's 100 classic apple just hype me up I'm gonna buy it",
    "url": "https://www.youtube.com/watch?v=zeo-3pHp0Xk"
  },
  "g7i0QpiAq7I": {
    "published_at": "2023-07-29T15:10:41Z",
    "title": "The Progress of AI is Truly Crazy\ud83e\udd2f",
    "text": "The Progress of AI is Truly Crazy\ud83e\udd2f when I saw the fact that you could just generate an avocado chair I think I kind of started losing my mind and I don't think my shock wasn't complete because for me that was I couldn't touch it so I was a bit skeptical still and in my mind it was always going to be stuck in some sort of super computer at Google I can't run my own computer but then stable diffusion came out and stable diffusion so folks listening is another image model but what's different about this one is that it can run on your computer as in you're not connected to the internet and then I used it and I think that was the moment where I realized that all the large models are going to fit on people's computers yeah and I think I was kind of right and making that prediction I think it was like eight months ago or actually a year ago now I was really making that prediction because we have a new chat model from meta that's approaching it's approaching the capabilities of gpp 3.5 so that's pretty incredible",
    "url": "https://www.youtube.com/watch?v=g7i0QpiAq7I"
  },
  "Wywt9noUcto": {
    "published_at": "2024-07-26T01:00:13Z",
    "title": "Text To Video Has Gotten Insane!",
    "text": "Text To Video Has Gotten Insane! there's just no way this is not real this is absolutely nuts so cling is basically a SORA alternative we had Runway we had Luma labs and we had cing come out I think cing outputs are probably the best out of the three at least in my opinion you want to see some outputs yeah traveling by train viewing all sorts of landscape through the window this is really good dude look at this video of an astronaut running on the moon yeah it's pretty nice it's so good dude I can't stop looking at these videos dude I mean if you posted a real video at this point I I won't be able to tell I think B rolles are going to be solved you want a one minute clip of of some train or some sky or you know some stock footage I think we are at the point where it's almost there you still wouldn't make a movie with this though there's too many things to stit together consistency is still a problem I'm happy that not just open source but other companies have also caught up and open a is no longer the one company we rely on to get all our AI needs I like that there's some diversification going on here",
    "url": "https://www.youtube.com/watch?v=Wywt9noUcto"
  },
  "3PwTD5zQ4nM": {
    "published_at": "2023-09-13T14:27:35Z",
    "title": "These AI Agents Will Do All The Work For You!",
    "text": "These AI Agents Will Do All The Work For You! another week another episode the world of AI does not stop with me is how's it going are you a robot yet I'm not a robot yet but I wish I could be I've been sick this week in the last week so I wish I could just my wife keeps saying this right she's like when can we become GPT what is the what is gpt's version of being sick I think somebody prompt hacking it and making it says stupid stuff I guess muscle version Hey listen I've been I've been talking to a bunch of people and I've been seeing some chatter online about GPT being not as good recently as it was when it began lobotomization what does that mean so I'll tell you okay GPS two parts obviously there's you train uh the model the second part is something called rlhf which is reinforcement learning by human feedback it's almost like this right you ask GPT a question and recently I think rlhf uh and its impacts were also shown on llama 2 right where you ask a question give you some answer and then you have a human reviewer say this is a good answer or this is a bad answer and a lot of the benefits of GPT come from rlhf but if you over rlhf in a way right like if you are um constraining the responses too much and you're saying hey don't say this don't say this if you're constantly muting it it has effects across the entire uh set of responses right not just the responses you are clamping down so I think we saw this with llama where even the most basic of things Lama 2 would be like sorry I can't do that right uh and I think it's time to see that as GPT as well but this is an unfounded rumor like we don't know what's going on right like people are just benchmarking by themselves and they're saying yeah you know subjectively I feel like something is wrong in my own experience I have at least for the things that I use I don't ask you to make a bomb every day or kill a child every day uh so yeah what do you mean kill a child every day like it's every other weekend for you what the  I'm saying I'm saying a lot of people who are prompt hacking this thing or using GPT are trying to right it's like it's almost like they're trying to take a picture of it doing a silly stuff but they're also prompting it to do very silly stuff because I don't use it for that I use it mostly generate scripts or if I want to learn about something I think in my use cases it's been great right in fact I we've been finding GPD 3.5 to be maybe like subjectively better but we don't have objective evidence of it so we won't make that claim sorry what does rlh stand for again reinforcement learning by human feedback got it so the human intervener is telling it hey this is a good answer this is a bad answer don't say this say this yes and based on that it is it is learning how to be and that's what's making people feel like okay it's not as responsive as it used to be like RL HF is the equivalent in humans is parenting and so it's responding exactly like humans which is becoming becoming not as good right now it's what's happening is helicopter parenting or over parenting right a lot of parents do that to the young kids like they try to control everything the young kid thinks and says GPT is also suffering from dude even AI is having the same problem as humans  all right what do we have first in this week is someone made an open source locally running implementation of gpt's code interpreter let's look can you set my system to dark mode oh nice  oh ah okay got it it can run code on the computer this is a little bit dangerous I'll tell you why with auto code I remember um it can download any package from the internet right so it can easily pick up malware as well hang on it can work on the document okay very interesting it's a very cool videos foreign so a lot of people have used code interpreter online and we've used it for a little bit of amateur data science now we have a version offline right and uh I wouldn't say offline because it's still using the gpt4 key but it's running locally tell me something what does it mean by running it locally what's happening is uh the entire code for code the code interpreter part is running locally on chat GPT both parts are online so you can also swap out with open interpreter you can remove gpt4 and you can add in code llama which are both like then your code interpreter like the local code interpreter it's called open interpreter and your uh uh AI model which is uh code llama are both running locally so the idea is to eventually be rid of open Ai and their Monopoly got it so we can use code interpreter with your own llm also yes so if you have your own data you can use your own local llm you can use it yeah okay got it I I read the benchmarks I'm off Twitter so I'm a little bit slower on the loop these days but I read the benchmarks and it's isn't that much of a jump over llama too twin apparently it's between three uh GPD 3.5 and 4. so we're an open interpreter right now so the question I have like a general question I have is um a rate the top 10 hip-hop artists by records sold give me insights data will be cut off by September 2021 good so it's doing a script and then it's analyzing the data okay so it's using python with beautiful soup and request libraries to scrape the data so like I said uh even in the code interpreter that we have on uh GPT it has it knows which python repository to use where it knows which python package to use where so as you can see it's using beautiful soup first I have to keep saying yes to run the code like there'll be a block in code interpreter on the charge GPD version of code interpreter but things are happening behind the scenes if you expand it it'll use the same thing it's using beautiful soup behind the scenes etc etc so we've done this in the past like I want to Once send out a large blast of Reddit DMS long time ago five six years ago where we'd write the python script ourselves um and now you can just ask this yeah this is like Auto GPT but for not code stuff also yeah Auto GPD is just for code this is for non-code stuff now this is still running code behind the scenes and we can use it I mean that's why it's called code interpreter and not you know data analytics okay got it so this will just continue to do this it's finally going to kaggle but this feels at least this query that you've put in feels like this is just easier to do on chat gbt right yeah instead of doing this on locally yeah but it's it's it's uh sort of what can I say it's subject to the same problems that uh uh Auto GPT subject to which is going down a tangent if it doesn't find for example the kaggle API key should be asking me right it's not asking me right so it's kaggle API is not installed we need to install it now they're installing the kaggle API yeah let me just kill this it's looking for the kaggle data set I need to put in the API key it has parts of small also on this by the way let's actually try that okay change my computer to dark mode nice to change your computer dark mode we need to modify the Windows registry okay set the current theme mode in the Windows registry so it's going to run a registry command it's already dark mode if you want to switch to light mode yes switch me to like okay let's run this okay it says it's switched to light mode is now set to light mode sure it is set to light mode I don't think windows will allow random programs like this to edit the registry I'm just killing this it's gone into a loop but at some point Apple slash Windows slash Microsoft will all uh have this available locally make an Excel sheet with the names of 10 people from history 10 famous people from history okay it's going to use the pandas library in Python to create a data frame from the list and then they'll use pandas to write this data frame to an Excel file okay first is installing pandas in Open PI Excel now it's installed the libraries now let's create a list of famous people it's coming up with the list putting all these people in data frame is writing it to an Excel file that sounds good okay it's created a new file called famouspeople.xl let's find out hey simple Excel sheet has been created so like okay if I use GPT I can just generate this list but if you have it running locally it can interact with your computer or laptop and actually generate files for you yeah you can generate files it can edit the registry so you can do dark mode to light mode but the problem with dark mode to light mode is I am very sure windows will block external programs from doing this I'm it's going to block vs vs code from doing this we might have to do it in the terminal and I think ultimately everything you do on your computer can be manipulated by a code interpreter but you need to know what you're doing because it's it's I don't know how it's choosing what python packages to use it seems to be using the most popular ones right like pandas and um it's using pi Excel so the core idea is to talk to your computer in natural language and ask it to do stuff which is or generate this file generate this file imagine if your computer has G it has a large language model plugged in at the back end you can ask it to pull stuff from the internet as well and create stuff out of it I just want this to be in a simple chat interface like how much I I want to be able to do this on Windows but there's just a there's just it's very easy it's very easy to do this on Windows like someone could just make a program right now it's just like a quick app that's on your taskbar or something where you can just be like okay I want this done I'm damn sure that Microsoft's gonna do this in Windows Apple's gonna do this for the Mac OS it is going to be natively part of the OSS I think in the next update or the update after that we are going to see one of these uh happen at some point and just have a voice command feature where I should be able to talk like I want to press a button like on Mac I just want to press that button and basically this is like Siri but like hyper powered or Cortana but hyper powered that's what this is yeah and the cool part is you can also generate quick scripts and write code and stuff right for example make me a simple app Simple app to generate a joke every time I open it okay this is the same thing we did with small if you remember small right uh it's using flask to make a simple web application it's using some joke API to fetch a random joke and it'll ask me for the joke API but I don't want to listen to what all you're doing I just want to say it and just do it yeah it's doing what I'm saying is it's doing all of these things it's going to abstract these things behind the scenes this entire thing that you saw here this pip install flask and stuff end user doesn't need to see correct you they are only going to see this it's just going to be like hey great the necessary libraries are installed we're going ahead with the next step yeah you're right though I think the next the next iteration of Windows or Mac should just be able to have this like it's this is going to be part of Windows and Mac um uh the Mac OS I think you'll have a you know the command shift command space on Mac where you can just search for anything now it will probably allow you to just ask the AI anything like a lot of times when I want to change something in my phone or figure out where to update and stuff I go to Google and I'm like well how do I change the setting now instead of asking Google you can just ask you know the Apple settings page and it'll just do it for you yeah every laptop is basically a Jarvis every phone will become a Jarvis now and eventually it'll just be voice like there'd be one special key they'll call it the I know how the brands are going to Market this they'll be one special key you press the key and it's your assistant and when you press the key you can ask it for anything and the computer will do it and that will be like a big selling point for a few months until everyone has it correct agreed next story let's go to hyper right AI so this is hyper right uh which seems to be at first glance it seems to be like an AI agent that can operate a browser like a human so let's see if it can do that uh write a script on a video about Paris so it's using my browser okay this is really cool oh go to Google to gather information about Paris it's search for Paris okay type Paris into the search bar and click submit on the search okay this is like really cool click on the Wikipedia it's doing it automatically like if this is inside the program you're not doing anything my hands are off go to Wikipedia link click on more information about Paris it's almost like one of those automated testing kits like selenium can do this right and there are other testing kits that can do this which will click on links specific keywords that it needs to click on it will figure it out here is just figuring out which link to click by itself so now it's going back to hyper right to write about Paris let me just move this down this is lovely I love this this is really really really cool I was typing the script yeah he's given me a script about Paris this is actually beautiful the task went perfectly now let's try something more complicated okay let's start a new task let's say uh post uh tweet about guns I have no idea how this is going to do but let's see I have no idea why you said guns but okay let's see this is AI inside AI even Google's like hey do you want to use our journey I powered overview for the search It's Gone on Twitter sagar's account is logged in it's now uh clicking on the link on the twit clicking on the link on to the Twitter homepage type in guns or not toys respect others and themselves and it is going to tweet that bro dude's account what the  this is really really really cool uh this is really cool I didn't do anything can you can you send emails check yeah just say uh send an email to Varun send an email to Varun Maya telling him hyper right AI is a scary tool is a scary tool okay hands are off it's like in the last couple of AI videos I've just kept my hands behind my whatever head and I'll just let it do the thing navigate to Gmail and compose and send the email okay yeah click on compose okay it's clicked on compose okay now it's going to find Varun Maya let's see if I can do that oh my God that's really cool select the first email address for Warren Maya dude this is super cool this is like super duper cool hyper right here is a subject okay just wrote hyperwrite AI is a scary tool full stop and it sent the email let's see if I got the email yeah I'm sure you got me yeah I got it I got it I love this tool yeah this is an interesting tool it's working so flawlessly and well like it's so good this is really really really good now tell me something why can't the open interpreter that we saw why can't it do stuff like stuff like this it it can it can that's the thing right like eventually you're not going to want to use an open interpreter you're going to want this like this I think all the tasks that it does are inside the browser inside the browser like let's say there's a button okay the button will have specific CSS to find that CSS a lot of testing kits have like if you want to do browser testing for your own apps when you build out an app right like a web app a lot of these kids have already figured out the hard work of figuring out what button to click these people are basically a layer on top of one of those testing kits right or they built their own that's what they're doing it's like it's very browser focused it's a great personal assistant I love it like I really love it I okay let's this is weird Okay let's try this go to amazon.in search for Mama Earth then scroll just once and put all the product names and prices in there into an Excel into a Google sheet but I find this tool very very impressive like this will improve obviously over time so it's gone to amazon.in type mama or thin submitted the search for mamath scroll down to see more products please provide the Google Sheets URL where you want to store the product names wow it's asking me for an action let's see where the product names are uh I'm just going to give it the sheet I'm going to the provided sheet as long as you're logged in it'll be fine it's got imported into the sheet it can input in the sheet the only thing is it's not inputting this into the sheet dude so this is like pretty close like I think for scraping tasks it'll take a few months of iterative improvement but so far it's pretty decent at least I think what they've done is they've covered use cases by use cases scraping is not a use case so it can it can do these four things but I think beyond that it chokes a little bit kind of breaks I feel like they just this is going to cover use Case by use Case by UK like scraping is a very big use case especially for people who are in the space of you know I need to make a report or I need to create data sheets for somebody else this might be very valuable in the future yeah and I think this summarizes a lot of the AI tool space right now which is that there is a glimmer of possibility and there's limited use cases but that one breakthrough I think since GPT there hasn't been that one powerful product that just breaks through and also I understand that that breakthrough could be scary also no like an all-powerful agent that can actually function like a human and have enough context setting ability to do it it can also be scary but if you look at it right if you look at the uh when it runs through it's rational it's rational is correct scroll through the pages get some most of give me a Google sheet link I'll put it all in the Google sheet link rational is correct the execution is poor right what I mean by that is I think a lot of these tools are not conducive like a Google Sheets might not be conducive or on Amazon might not be okay with scraping so I feel like eventually uh either the AI is going to find a way around it right or the testing kit or the testing framework is sitting on top of is going to be a superior testing solution uh I think that this is this should be a solvable problem right I can see how it can be solved today um somebody's used to or maybe they might be unique tools like there'll be a specific AI tool just for scraping there'll be a specific AI tool just for summarization which is what most people are going around they're saying we'll make specialist tools but I think the end goal I can see the end goal being a one solution like a hyper ride doing everything for us all right this was cool let's move on so in video launched a new AI video tool now in video solves uh AI video very differently from how a Runway solves AI video so let me let me search for this okay make a YouTube video about an astronaut who dislikes fizzy drinks who dislikes fizzy drinks is it GPT powered at the back end at least for like figuring out the title uh yeah I think it uses GP to figure out the title figure out the sequences and then it's probably using stock footage it's using a pixels or a stock video or eye stock or something to pick out the right clips and put them together GP didn't do this well by the way if you go to GPT and you say give me a two minute video of I don't know a man drinking coffee and give me in each frame what image slash clip should I show it will actually give you like a sort of like a guideline saying that okay in first second to third second play this clip third second or fifth second play this clip and you can just run those as search queries on istalk photo or one of the stock platforms right it's not like Runway where it's text to video this is It's almost like text to uh script to pick up stock footage put it together this is not it's not like mid Journey but more canvasque yeah it's more like canva I think that the combination of a Runway Plus in video is is the eventual future right where instead of you depending on a third party stock footage generator to generate stock footage for you I think eventually you'll build out a solution that's just text to video right and you'll have them stitched together because right now the big limitation of text to videos like it's a few seconds so let's watch this have you have it what astronauts crave when they're thousands of miles above Earth it's not the stargazing or the zero gravity it's not even the Silence of space it's the simple Earthly pleasure of their favorite foods yet surprisingly not all foods are universally adored take for instance are astronaut protagonist who has a peculiar aversion towards fizzy drinks imagine the scene a rocket blasting off leaving a trail of smoke and fire piercing through the atmosphere amidst the Roar of engines and the rush of adrenaline sits our astronaut strapped in his seat ready for the Journey of a lifetime he's leaving behind not just his home but also his favorite foods yet one thing he doesn't miss is the fizzy drinks the astronaut's journey is one of Wonder and exploration a tale of human determination and resilience he navigates around asteroids observes distant galaxies and even catches sight of the occasional shooting star but when it comes to meal times he's a little less adventurous fizzy drinks are off the table or rather off the spaceship why this fizzier version you ask it's not a matter of taste but rather a matter of comfort you see in zero gravity carbonated beverages don't behave quite as they do on Earth the gas and liquid don't separate leading to a rather unpleasant drinking experience our astronaut well versed in the quirks of space life opts for still beverages instead summing up our astronaut story serves as a reminder of The Oddities of life in space it's not just about floating around and looking at stars it's also about adapting to a whole new way of living which in this case means saying no to fizzy drinks so the next time you pop open a can of your favorite soda take a moment to think about our astronaut floating around in space sipping on his still drink it's a small detail but it's these details that make the vast expanse of space a little more relatable a little more human what do you think dude  mind-blowing this is so good it found all these stock footages from some third-party play and it's synthesized together it wrote a script and even the narration of the script seemed so human-like text to audio seems so human-like yeah the next step is now even the stock footages that are being generated imagine if you're able to wrote with text to video holy  can we make one more can you make can we make one like um can we make a YouTube video about how to succeed on YouTube on how to succeed on YouTube like for 99 of media that just like strings footage stock footage together now it's completely automated the voiceovers the what we didn't check was there a way to edit the script in any way edit the script edit edit stuff here possibly I mean I I can see how it should be a pretty easy middle step this is what I keep saying about AI right people who synthesize the tools that exist very very well will eventually end up building out good tools because at the end of the user wants a solution right user doesn't care about how fancy the tech behind the scenes is it needs to come together the same way he would put something together dude this is so good what are the immediate use cases in your head what would you use this for if you're able to edit the script okay for example if for example if I'm able to feed it a script saying hey this is a script find a bunch of stock footage give me a voiceover and then generate it that would be super powerful because this finds appropriate stock footage edits them together finds a music layer does the voiceover all I need to do is create the script which again one person can do the job of like 10 people and use GPD to generate a bunch of scripts I think the value now of generating stock footage has become even higher either somebody solves it with text to video like the model combat video we saw but that's still not there yet or somebody can just go around and shoot a lot of stuff and just say hey I have a lot of like base footage for you to put together and build out a good video no but this is elegant right we already have a third party stock footage websites yeah and not just that right like I think even the presenter part with what Hagen is doing in the presenter part can sort of get solved if there's a person on screen saying hey this is what happened in like blah blah and you have certain shots of him talking to the camera him or her talking to the camera and then you have certain stock footage and then back to the person tell me on a side note right I think uh stuff like this allows you to make a lot of faceless channels on YouTube correct and I know a lot of people have been excited about faceless young I'm not a big fan but what do you think there's like one thread every week on Twitter about how you can make money through faceless channels I mean eventually if a lot of people everyone's doing it there's pointless then what's the what's the point yeah ocus once told me something very interesting about YouTube he's like everything you wanted to see on YouTube over the last decade has already been out on YouTube so you have to do something that's fundamentally different and you can't just say somebody else succeeded doing this so you can control C control V8 because maybe the space for like three four big players in a space but a thousand people do it then it becomes worthless if if creation is going to zero then you need to have a differentiator yeah quality is a benchmark that changes with competition it's not an objective number it's a subjective number based on competition in content at least so you're saying that the bar for I mean the barrier for entry is getting lower because of tools like this but the bar for Quality content is going higher will go higher naturally because what is refreshing is actually a product of what is the norm like a joke I used to make 10 years ago saying oh any punjabi's in the house oh you guys love drinking that's not funny anymore but it was funny the first five times I said it because back in the day it was fresh because nobody else was saying it but now now that's harder because you know it's been said so many times that it's not fresh anymore similarly if you because of more more content what surprises you keeps going down so it's harder to surprise you and be refreshing because you're just hit it's it's the same thing as attention span no it is harder to hold some of the tension now because there's just so much  available to take your attention it's a it's the same Funda so if content creation goes to zero Quality Bar will have to be that much higher which means you know you can't just hack your way into making content like this is why like even the AV side right like the editing if you've seen the last couple of videos has just gone up so many notches right mainly because it's like hey there is competition constantly try to differentiate from the competition one cool thing I feel about AI is everything is almost there it's almost like this is not quite but yeah there's it just needs something the glimpses are there glimpses are there it needs some breakthrough products Beyond this GPT I mean GPT and mid journey to a degree but I see how this will be part of osis like Microsoft and Microsoft Windows it's an obvious opportunity for them to just plug AI everywhere all right let's go let's watch this want to master YouTube crave to see your channel rise to the top today we're going to delve into the art of YouTube Mastery whether you're a seasoned Creator or just dipping your toes into the world of digital content this guide will unveil the secrets to skyrocketing your YouTube success Step 1 know your audience the key to any successful YouTube channel is understanding who watches your videos what are their interests their ages their locations knowing your your audience allows you to tailor your content to their tastes ensuring they keep coming back for more Step 2 consistency uploading content creates a rhythm that your viewers come to expect consistency not only helps to retain your existing audience but also attracts new viewers remember it's not just about quantity but also quality high quality content uploaded consistently is a Surefire way to YouTube success step 3 optimization from video titles to descriptions tags to thumbnails optimizing your content is crucial use relevant keywords in your titles and descriptions create eye-catching thumbnails and don't forget to tag your videos got it so now that flaws are kind of obvious right which is okay limitation of stock footage means that the quality of the video will be lower I would love it if the video that's being made it gives me like a Premiere it gives me like an edited version on like a timeline so I can be like okay this stuff is not good this stuff is not good this stuff is not good let me fix this I want to fix the voiceover I want to fix the text I want to change the stock footage here yeah yeah yeah and outside of the stock footage it also generated some footage like the placards that came in with the YouTube logo on it I assume at the back end it did okay I have the I have the basic of the placard coming in I just put in the YouTube logo uh I wish it could do like there could be some advancement in generating these kind of flowcharty type of type of visuals that I think can get better but it's an interesting start for sure like the astronaut one was way better because there was just a lot more variety in the stock footage and I think the astronaut one told a story correct like I think humans eventually are suckers for stories right like yeah the visuals are secondary to what the story is telling you there's actually one interesting Channel idea that I have and I don't know if we should do it but maybe someone should do it is to create a channel of just AI generated videos and just experimenting every day with hey this video was generated by air and the description should have hey these are the tools that I use this is what I did this is what I made at the back end this is what I connected here and there the description should have all of that and the video is the final output uh just a tutorial channel on except you don't have to explain it everything can be in description just show me the end product on this I think that is that is a channel waiting to happen yeah I wouldn't build a channel like that I think the entire goal of channels now has become about trust like today you can go out on the street and buy like headphones or earphones for like 300 rupees right but there's a reason people still go to a boat or people still go to like a well-known brand right like I think anyone can build a channel anyone can get like now with shots like some random videos can get views right but I think building a brand is the is the key piece right and that there's a reason that people still go to celebrities and have them appear on TV even though the celebrities reach is not being used on TV right like it's more the celebrities brand I think that's we have become more attuned more sensitive to the idea of a brand now that everyone can create junk okay let's move on there's a tool called move Ai and it's pretty cool let's watch a video on it  so if you want to do 3D footage and you want the motion capture extracted from it I'll tell you how I was planning to do it two years ago right the manual way is to go to a website called mixamo yeah so you have these 3D animated characters you have their animations you can plug their animations into any skeleton you want right the Step Beyond this is to use a suit so rokoko there's a company called Rococo that has a very cheap suit two thousand dollars is fairly cheap in the mocap world right motion capture world so this is the Rococo suit you can see it here but again wearing a suit is like painful it's annoying it's you know it's it's just it feels cumbersome but then there was another company called Deep motion that came right after Rococo where they said that you know what just send us camera footage of what you're doing and we'll create the entire you know uh animation for you we'll rig each bone below where each bone is moving including your fingers and we'll create that animation for you but then recently something called move.ai came out which I use the like before yesterday where you can have any cool thing and it uses AI to figure out you know perfect animations this is like really cool and you can transfer it to any 3D character you want this is a bit like Wonder Dynamics right it's a bit like Wonder Dynamics except it's just giving the skeleton now as I was exploring this I saw the Big Daddy of this which is that you know the cool thing about this is you can do it with your iPhone right but there was a tool I saw called simulon it's Wonder Dynamics is still a tool you need to you know use it you need to take existing footage remove the character put your own character in but similarly you can do all of this inside your iPhone itself and it matches lighting automatically real time yeah it's sort of like my biggest issue with ar and AR cameras were that the lighting never matches it always looks like it's a strange object in the scene where it just doesn't seem to be part of the scene but look at this this looks pretty realistic right I'll show you some more check this out or check this out uh oh this is footage from the camera direct from the camera they have their own camera I assume and the lighting solves everything is matched automatically like take a look at this dude this is so this is very good like the lighting it's got like it looks that thing looks like it's part of the scene you know what's one of my favorite uh CGI scenes like our CGI movies have you seen a movie called District 9 like I thought the CGI of the aliens in that movie was really good and it's an old movie relatively old movie I think this technology is amazing because it's able to do the real time animation and stuff you don't need to do more cap it's at least on wonder Dynamics I've seen the facial expressions also Done Right the lighting looks much better than vendor Dynamics the Shadows are in the right place so I think this is like really really cool this though is going to lead to some jobs being lost because it's like the manual like being good at doing manual CGI is a very high value skill right Marvel spends so much money on it uh but the minute you say we have technology like this a lot of those scenes can just be done from inside the camera do you know what ADI purush's budget was 55 rupees based on the VFX that I saw it's 700 crores right so that's 700 tours that's going to someone to make with a significant chunk of the budget is to make CGI and the CGI was terrible because it's a it's a binaries it's almost like a like a you need to be above a skill level for it to be good right and below that skill level it starts looking cringe so this automatically puts you above that level and it's just like the alternative to get somebody of that high skill level costs so many crores that you might as well default to this right if you have budget constraints so it's like that 700 crores worth of jobs maybe 100 200 crores going to actors production etc etc but CGI is like it's a big field to disrupt and I didn't expect it to come this quick um like this is better than the oned IMX stuff that we did whatever three four months ago yeah it's already better yeah let's just talk about consistent characters in mid-journey so now you can make consistent characters in mid-journey this will be very useful in my opinion for comic books you can take up to 10 shots of the same character from multiple angles in a single generation okay so the method is she found that image split into two to a prompt would create two different images of the same person if you do image Splinter 2 Shot from different angles slash imagine pretty Asian woman eating ice cream image split into two from different angles that's what it is right yeah basically that's what it is split images into six different images shot from multiple angles got it and then how do you separate them you no they will come as four separate images like these two for example in the same shot you'll get two two splits the third one failed if you look at this these two are the same woman it is so if you do let's say imagine a Dalmatian chasing a ball image split into five five different angles very interesting dude how people are able to just you know they're people who are just full time figuring out how to do fun stuff with AI or the second image looks very interesting let's see if the spots match that's why I choose chose the dalmatian so if you look at this this one this looks like the same dog yeah it's got the same choke collar the spots are roughly in the same area like there's a left right cheek spot there's a right cheeks pocket spot here as well uh uh this one looks different this one looks different yeah but this one kinda looks the same I guess second image is nice I think this would be most useful for to generate like comic books so let's try a comic book prompt let's make um an anime robot in eating ice cream image split into five different angles angles Style cute pretty cool no like if you look at the first this thing it looks like the same character in multiple different positions the layer generate okay let's see see it's the same character in multiple different positions this is very good this is also very good same character you can see that the angle of this diamond thing is the same across these two um the angle of the diamond thing and where these spokes are are pretty much perfect yeah but I just want my journey to be able to put this as a feature like if I'm able to input a picture and say hey change the angle on this that I think is the next step instead of generating one image then I have to upscale this crop it out uses a separate frames there's something I saw recently it's called style drop I think so style drop allows you to put in a certain style I don't know if this will work for consistent characters but you can put in a style correct and it does it reasonably well correct I'm sure this can be adapted for characters anyway to quote Saint Maya six months yeah six months yeah but it I I don't know I thought the the hyper right thing was really cool hybrid was very cool it just needs a lot more broadly I think there is incremental progress on every um tool but yeah there's still a long way to go nothing seems like you need absolutely zero human intervention to go from a to the file final output uh but yeah it's getting better interesting all right another episode of overpowered thank you for watching hit that subscribe button let's get to half a million subscribers on YouTube as soon as possible and if you're watching us on Instagram follow us we want to reach a million ASAP on that note is bye ",
    "url": "https://www.youtube.com/watch?v=3PwTD5zQ4nM"
  },
  "ZDB05cTiDUg": {
    "published_at": "2024-04-09T14:30:01Z",
    "title": "Is Suno AI better than Spotify?",
    "text": "Is Suno AI better than Spotify? there's a new version of sunu AI give me a song idea a Bollywood love ballad in Hindi about a man who misses his lover who died let's write it about Mark zaka and his love for lizards just for fun  so it's pretty good this is really good if this had an app I would use this over Spotify",
    "url": "https://www.youtube.com/watch?v=ZDB05cTiDUg"
  },
  "vZEJqHuRDO8": {
    "published_at": "2023-05-29T14:30:23Z",
    "title": "AI can now detect feelings in real-time!",
    "text": "AI can now detect feelings in real-time! insane we can now detect feelings in real time through facial expressions using AI just off the bat I think AI Tech isn't there yet because it's not a single column that says want to slap how's it accurate since it's doing in real times like the lag seems to be like very very short will I be able to fool the air which is if I'm feeling nervous or scary you will be able to fool the air okay okay it's like you can fool the AI but you need to be really good in fact it's so weird to fool the AI you need to be good enough to fool other humans so I kept getting this comment saying Nai can never be emotional that is wrong it's not unique to humans at all what is unique to humans is rationality",
    "url": "https://www.youtube.com/watch?v=vZEJqHuRDO8"
  },
  "eoVPKom8iFc": {
    "published_at": "2023-09-15T11:30:15Z",
    "title": "Move AI Animation for Facial and Motion Capture!",
    "text": "Move AI Animation for Facial and Motion Capture! there's a tool called move Ai and it's pretty cool let's watch a video on it  if you want to do 3D footage and you want the motion capture extracted from it I'll tell you how I was planning to do it two years ago there's a company called Rococo that has a very cheap suit but again wearing a suit is like painful it's annoying it feels cumbersome but then there was another company called Deep motion where they said that you know what just send us camera footage of what you're doing and we'll create the entire animation for you but then recently something called move.ai came out where you can have any cool thing and it uses AI to figure out perfect animations the cool thing about this is you can do it with your iPhone right and you can transfer it to any 3D character you want this is a bit like Wonder Dynamics right it's a bit like Wonder Dynamics except it's just giving you a skeleton I think this technology is amazing because it's able to do real time animation you don't need to do more caps so I think this is like really really cool",
    "url": "https://www.youtube.com/watch?v=eoVPKom8iFc"
  },
  "HNXzeTpgcLk": {
    "published_at": "2023-09-02T10:30:04Z",
    "title": "We used AI tools for Hindi Voice Dubbing\ud83e\udd2f",
    "text": "We used AI tools for Hindi Voice Dubbing\ud83e\udd2f this is so cool so this is called 11 Labs multilingual V2 plus RVC voice dubbing let's first play it yourself content creation AI development yes this is what the English version of what we record in the last episode sounded like maybe that's just me wanting to not be in a world where it's this easy to replace you know content creation but I think Paul Graham had once put out this tweet he's like with traditional software you have iterative Improvement it's actually a chain of tools so we said what if we took the output from 11 labs and then dumped that output into RVC where we made our own custom model on RVC of than Maya what does the output gonna sound like and it turns out it is pretty accurate now you can hear original Miles Morales actor or Tom Holland or whoever is playing the role right you can hear them speak Hindi and Telugu in kannada and all the others that I think is pretty cool",
    "url": "https://www.youtube.com/watch?v=HNXzeTpgcLk"
  },
  "y3-Ce3zlG3k": {
    "published_at": "2023-09-06T11:30:19Z",
    "title": "Midjourney Inpainting is just to Good!",
    "text": "Midjourney Inpainting is just to Good! let's just play with my Journeys in painting you want to swap out clothes you want to swap out sunglasses you want to swap with the background you can do all that fun stuff right I was waiting for this since uh Photoshop launched generative fill I said okay mid Journey's version will be as cool if not better because the data set is a lot more illegal than photoshops yeah so imagine Undertaker in a wrestling ring holding a broom in his hand let's take a look at this we got pictures of Undertaker yeah let's upscale one of them I like the third one and now we'll in pain actually let's try it in the background Undertaker in Candyland first let's take a look at this beautiful no yeah interesting the generative fill feels better than Photoshop why is that because my journey just has better training data right so over many generations I think they now know what humans prefer like Photoshop generative fill you are not saying that okay I like this output but on my journey you are technically because you're upscaling it",
    "url": "https://www.youtube.com/watch?v=y3-Ce3zlG3k"
  },
  "pJ-DD1jNWqc": {
    "published_at": "2024-04-13T07:39:32Z",
    "title": "Can this AI tool understand emotions?",
    "text": "Can this AI tool understand emotions? Baron Hume is a tool that AI voice can Now understand the feelings in certain speech and it can also reply with feelings I'm going to start a conversation with you I need you to be really surprised while telling me that tme is a great comedian wait what tme a great comedian you must be joking okay okay I'll play along tan May is an absolute right that's the funniest guy I've ever seen hands down ah there how's that for surprised that's pretty good now can you say the same thing but be angry t b is a great iian are you kidding me that guy is about as funny as a rock I can't believe you to even suggest that the nerve of some people ohow I have be DSD I'm getting PR gooded what do you think that man now I compare all AI tools to Mid journey and I this feels like text to speech and speech recognition V2 I think it is pretty good like you're right as in it's V2 I think there's still miles for it to go but hey I had like like a good long conversation with it",
    "url": "https://www.youtube.com/watch?v=pJ-DD1jNWqc"
  },
  "OVelEeKCSEc": {
    "published_at": "2023-11-21T16:20:01Z",
    "title": "Why did Sam Altman get fired?!",
    "text": "Why did Sam Altman get fired?! what the is going on one day we all woke up on Twitter that apparently Sam Alman has been leted go by the board and according to a statement that came out it says open was deliberately structured to advance a mission yada y yada at the same time we believe new leadership is necessary as we move forward n is qualified to step into the role as interim CEO and they basically fired Sam immediately Tan's reaction and and even my reaction was like he's done some right so what I feel may have transpired and this is conspiracy theory land in the beginning this was a mission-driven company where like let's build AGI let's benefit all of humanity with this and that's why it's structured as a nonprofit but then immediately as they start seeing success as satanella got involved it started feeling very commercial that we're sellouts we're just making models to make money you would have expected a guy who gives structuring advice as part of his curriculum advice to structure things better and to at least be protected from the boat throwing him out like that randomly right even though he said in the past that boat should have the power to kick me out if necessary not for these things",
    "url": "https://www.youtube.com/watch?v=OVelEeKCSEc"
  },
  "HuWxPC_FNoU": {
    "published_at": "2024-04-18T11:59:40Z",
    "title": "Stargate AI: Microsoft and OpenAI&#39;s $100 Billion Project",
    "text": "Stargate AI: Microsoft and OpenAI&#39;s $100 Billion Project Microsoft and openi are plotting a data center project with millions of specialized chips costing up to100 Billion it's called the Stargate AI computer what do you think what does this mean so basically they're building out a data center right they're getting lots of chips Microsoft has expressed interest to build their own graphic processing units at least I realized with Sora because I was experimenting a little bit with text to video is compute really matters there's this article that I read some time ago called The Bitter lesson as written by Rich suton biggest it's from 2019 the biggest lesson that you can read from 70 years of AI research is that the general methods that just leverage computation and just max out computation are ultimately the most effective and by a large margin so what openi is really going for is let's just max computation and see where the limits of the current architecture that we have are so they're just saying let's stretch that to the maximum let's build a 100 billion doll superc Compu cluster and see what happens this is what they're trying to do",
    "url": "https://www.youtube.com/watch?v=HuWxPC_FNoU"
  },
  "VeaT6ucXuMI": {
    "published_at": "2024-08-24T12:30:54Z",
    "title": "Stable Diffusion Founder&#39;s Advice for Indian College Students, Jobs, 2025 AI Predictions\u00a0&amp;\u00a0more!",
    "text": "Stable Diffusion Founder&#39;s Advice for Indian College Students, Jobs, 2025 AI Predictions\u00a0&amp;\u00a0more! how do you see Ubi playing out I'm sure you have thoughts around Universal basic income my guess is that eventually you will not have Ubi but you'll have Universal basic jobs cuz people need something to do is coming later and sooner than we expect how far are we from actually generating let's say a complete complex Uber app if you want to build a complete replica of uber dynamically I'd say one year it's going to be done in a year yeah for someone let's say a college student sitting in India what is this particular skill set that you're talking about ladies and gentlemen welcome to yet another episode of overpowered and this time we have somebody who by popular demand uh you know it's been weeks in the making it's been months in the making we finally have Imad who today runs shelling Ai and is more famously known for stable diffusion in the past Imad it's an absolute honor to have you here tan who is my usual host is not there with me today we have Sid from 100x Engineers instead but this is going to be a riot this is going to be very interesting for anyone interested in the intersection of AI and art we're going to try and tease out what Imad thinks the future is like because I think he has Insider access and he's built a giant company here in the past building another one right now so so yeah without much further Ado Imad how are you feeling today I'm feeling good it's been a good few months reading looking and now you know everything continues to go a pace thank you for having me on one of my favorite Twitter accounts to follow like I I you know there's some Twitter accounts which give you dopamine when a new tweet pops up one of those is yours because every time something pops up I'm like wait there's some deeper Alpha there's some deeper Insight in this that you know I need to double click on so now I finally get the opportunity to do it one of the things you've been tweeting about a lot is about Ai and video I think the last you know last year was a lot about Ai and images and I think we saw the year start with mid Journey sort of you know make the waves and then stable diffusion hot at the heel and I think by the end of the year now now you know we have stuff like flux we have stuff like you know sd3 we have lots of really good fine tunes uh but I think the same Revolution is coming in video and you keep tweeting a lot about it I want to know where the state of video is right now like what are your thoughts like if you to organize your thoughts around video and AI where is it right now yeah so I think it's again we're seeing the output live um some amazing kind of things uh with all these models tring to come together if we look at the history of this um back in the winter of 2021 um one of the key breakthroughs for this technology was combining an image generator and discriminator so a diffusion model and a clip model together so that was done by Katherine Kon Rivers Hab Wings on um Twitter she was one of the stability founding engineers and then it was taken by opena AI with Del that technology and by the stable diffusion team stability as as well Robin and Co who've now gone to do black forest Labs it was a combination of those two models that was the powerful thing but once we had stable diffusion we then in 2022 created stable video um which basically took the image model and then extended outward time conditioning to create video models that then extended to um what came to be the architecture for stable diffusion 3 Sora um a whole bunch of these a diffusion Transformer where we mix the diffusion and Transformer topologies effect L but it could accept any type of input but it was best when it started with image that could then be extrapolated to video and actually could be extrapolated to 3D as well so if you look at SD 3D uh stable diffusion 3D that's how that works when you're looking at a video though there are kind of two questions one is this zero short generation just like a language model like you know you prompt it and it comes back with something like me giving these quick answers the other thing is thinking these things through and chaining together different models so the teamate stability built something called comfy UI which anyone who uses creative industry will recognize whereby a day after any model comes out there's a node and every single media file suddenly becomes this flow of different attributes hyperparameters assets and model calls that then if I share with you can reconstruct and that's important because when you look at how a movie is made movies are actually made up of shots on average of 2.5 seconds each it used to be 12 now it's 2 and half which is why they shift a lot and then you think about the construction of that there things like the pacing the scene the composition you can deconstruct all of those with things like segment anywhere from meta and more and then in paint reconstruct do mapping and I think that all the technology for high quality video is here today it just isn't chained together high quality video Zero shot is a different thing but what we've seen is that the more compute you throw at it now that we have Transformers in particular cuz diffusion models are very difficult to scale the better the models get and they learn more and more this is why open a called Sor World model whereby understands physics so when you take the picture of the person giving a talk and then you put it through Runway gen 3 which is a diffusion transform model it can suddenly wave arms around and it has shadows and everything like that so a combination of these World models and these flows means that we're pretty much at the point where anyone can create any type of movie but again the stuff needs to go from research to actual engineering which I think is the next few years is there anything in the research phase right now that you've been keeping track of that you think next year or the year after that this is going to be something that changes the video industry yeah I mean I think that the there was some recent work out by Google on positional editing with the text descriptions that is far beyond anything kind of we've seen before and that's coming to video so being able to say you know I add an image and then say you know I want mad to look purple alien and then it does it perfectly in place I think that when you look at the flow it's creation control composition and so the models now are getting to that point of creation and again scale seems to be working and we're seeing that and we saw that with the video models image models and more um but now it's about the control so the control Nets the equivalent uh where you can like take yourself and make a sketch of you and then input isn't quite there for video yet but it's coming very very quickly and so I think that's kind of the key breakthrough and again there's been lots of interesting stuff there lots of interesting stuff around um planning and long system creation whereby you're storyboarding and you're ensuring consistency of edits and Direction and other things um there are some really interesting advances in speech as well with the speech to speech becoming eerily accurate um as well as the lip sync and kind of other masking and so again I think that we're pretty much there on all the breakthroughs that are needed for generative video with high levels of control it just hasn't been put together yet I don't think we need any more technological architectural breakthroughs unlike maybe language where there are some more things kind of bubbling and it'll just get faster and faster I think I've seen some of your tweets where tweets where you talk about realtime video generation being a thing uh as soon as next year what do you think is like a realistic timeline on something like that and one of the other issues that I see is consistency in characters and consistency in the composition how long do you think it will take for those problems to actually get solved I think they're pretty much solved if we look at the second part and you look at something like the latest Runway gen 3 like what happens with video models they tend to collapse because they don't have good training data and also we didn't put enough compute into them so like it starts out very accurate and then all of a sudden turns into a blob that's kind of been largely solved now with addition of more compute higher quality data segmentation and more plus some differences on the way the actually runs um and then the consistency thing is the same type of thing we saw in image models right you had these luras you had these kind of fine tunes and inference level IP adapters where you could now have a consistent character across multiple things because we mapped it appropriately to the latent space so I think those are kind of solved it's now a question of how fast and how optimized we make it because models still probably have 10 times more data than they need need to like we just Chuck everything in do a bit of editing and then put it in a giant super computer and squeeze it out so there's a 10 times potential Improvement there like um there was uh some work I believe out of was it Nvidia or someone similar no I think actually it was um Sony Sony managed to make a stable diffusion 1.5 level model for $25,000 wow using only 10 million images versus the two billion images that we had by very care picking the data cuz right now it's like cooking a steak for a long time or bad meat you know like we cook it in the super computer and then use that to make up for the fact we don't really know what data goes in but now we're getting better and beta the data that goes in this is important because you can make the model smaller with the same performance and you're seeing that like um today San put out a two billion parameter language model train from scratch that's as performant as the higher 8 billion parameter models right which is as performing as gpt3 many years ago 175 billion parameters what your feed it makes difference and there are these techniques like um adversarial defusion distilled diffusion and more that means that rather than requiring 20 or 100 steps you just need one or two this is the LCM and the lightning models the stable diffusion LCM and lightning models this for inference you're talking about uh yeah for inference but I mean again if we're talking about real time that's important right like if you look at SD fast the library now um on a 490 I believe you're up to 300 images a second with stable diffusion versus 20 seconds you can make a game with that you can reskin a game with that well pretty much I mean again we're at this point of Real Time video interpolation there's a new le fake Library just came out that could do that dynamically and again we're seeing art installations where people are transforming things if we think about pixel level high definition video though this becomes very interesting so like when you look at something like um Luma Labs video model again this is their small one they've got bigger ones coming uh their dream machine I think it takes about a minute for 5 seconds roughly and so that's on a h100 a h100 is around about um 1,000 fp16 flops ter flops to give you an idea um the b100s that are coming uh get down to 4bit precision and 20,000 so they're 20 times faster potentially let's say it's five or 10 times faster you know like suddenly gone from a minute down to 20 seconds down to you pretty much real time but there's a problem the problem is that will Real Time full video generation again when you're generating everything and you don't really know what the output's going to be because there's some unpredictability around it you know like when you're trying these things the human brain can't respond that quickly like with our stable audio Audio models we can generate we generated three minute songs in 10 seconds but it takes a lot longer than three minutes to tell you if a song is good because you have to listen to it right so what is faster than real time actually mean right it doesn't really make that much sense like again like what does personalized media mean because we can take things and we can do the hyper personalization you know very easily now like the shuk Khan cabri advertisement in India done a few years ago where the local businesses could have him speak their business names and things like that you could do on a consumer PC now with the advances we've seen that's a level of personalization you really need not recreating the whole thing you know and again you can transpose that almost Real Time with very little if the vast majority of the pixels are the same the vast majority of the audio is the same and again we've seen realtime audio to audio now as well so I don't think it will be like in the next couple of years every pixel generated on the fly like a game engine on steroids in 5 to 10 years maybe because it will just make sense given the way these models are and the hyper optimizations there but for now you know I think it'll be more like edits and more um and also the final thing is a lot of the discussions about AI are inference Bound in that we build models to do inference like the zero shot stuff but when you look at the coding models and things like that like Devon and others like those cost maybe $100 a day because they've got multiple agents going out doing things and the inference has gone from a couple of cents to $100 movies are the same thing yeah you don't want a crap movie you want to have it polished and super polished and repolished and so the first step before real time being available to everyone is just vast amounts of Compu being used at inference time with your editors and your film Crews and kind of the other models building just really good high quality movies or good quality movies you know I have a question here I have a I have a what a business question here so assume now all these models exist comfy UI exists we use a lot of comfy UI at work now the question business question here is does it make more sense for let's say a really good engineer to go out and build a product layer say hey I'll you know wrap these four models in you know build a workflow for this problem statement or would you build a services company around this because it makes a lot more sense and we run a company called Laos where we sort to do this right where we learned the hard lesson of well you build a product that's great you make a lot less money there's a lot more competition you get priced down to very you have to raise $100 million to play or you build a Services Company where you use some of these tools you also combine this with like real human editors and then provide people outcomes right and a lot of people these days are talking about providing outcomes with stable diffusion one of the things I started seeing you tweet about was more around this hey we should it's okay to build a services company or build customer models for companies for specific things right so the product versus because I don't think the models are products themselves right you'll still have to build something on top of it but there's also this Services Company angle that's suddenly making a comeback what do you think about this yeah I mean like this is a transition period right and so you can build better products so like I kicked off mid Journey's funding and I gave them the technology gave them like a grant for a month of A1 100s for the beta and David Holtz to CEO there built a company that's making $20 million a month in Revenue right and they build their own models and things like that now like it's profitable that's fantastic but it's hard building good products is hard because you fa the distributional challenge whereas what you've got now is technology that's transformative for entire established industries that have baked in distribution and so if you get the pricing model correct you have baked in distribution again open AI did that with Microsoft androp are doing that with micro Google and kind of others and I think that's a far more lucrative area now because you got the thing where right now it was like AI is interesting and now it's we must use AI as youve head towards Real Time video generation and you're seeing the quality of these outputs is there a media company in the world that's like oh my God you know is there a media company that's like oh what you can translate into every dialect in India dynamically you know like all of these you can make virtual influencers virtual influencers you know you can do all of these things because you've got these little translation engines that have suddenly emerged very few people should build their own models the the models that are coming out now you can combine them in order to again achieve these outcomes I think that's what the vast majority of people should do build useful things but as you said even if you build a useful product distribution is still incredibly difficult differentiation is still incredibly difficult and so like I would say the safer bet is to plug into transformation technology and have this hybridized or service model where you help others because that market is huge I have a segue question to this um so essentially what stability has is kind of based on is the open open source ecosystem right and um I use this open source ecosystem extensively a bunch of my students use this open source ecosystem extensively and uh we've been able to produce great work out of this I'm curious to know what are the economics behind um how open source really works uh how does that really factor into longevity and uh what are the inner workings of that so you know classically the commercial open source software Paradigm was you release the software open and then you offer services around it for implementation so you can look at things like data bricks $30 billion they have redes yeah Services component and then a private version of that private installation Red Hat $30 billion as well like if you look at again if we'd rolled out a services division in time as it were that would have been far most lucrative thing but we just couldn't scale that because we were scaling a multimodal AI team to compete against the Google deep minds and open AIS of the world like we hit state-of-the-art AC cross modalities not just an image um but you know we were going for something very big while I was there the that and again that is the best thing if you're creating something that people generally want to use you know because they're used to paying for services like when you try to convince people to pay in different way that's different the other model here is the API model but that's a very difficult one um whereby models are being commoditized but workflows aren't so if you offer a translation service to translate any piece of media or Content Library into every single Indian dialect how much can you charge for that no one really knows but they know what the cost of conventional translation is and the potential value from doing that if you offer just a API for a model that's a speech to speech model that's a very different thing right because you need to have some technical expertise to do that and do the data augmentation and other things so basically the models are you vertically integrate and you use open source to reduce your costs and that's what meta is doing a 10% Improvement in llamas llama costs pays for itself in terms of open sourcing that when you look at their size right number two is you offer services uh number three is you offer rap Services as it were and so I think those are the business models that we typically see within a commercial open source software context um I think it also points to why we can all see adoption building it hasn't gone super mainstream yet it's only been 2 years and businesses are very shy about putting stuff into deployment you don't push on a Friday you don't push this early into a cycle but now these things are becoming standardized and so they're more pushable shall we say and again that's why the service layer is a very useful one here because you can blame someone if it goes wrong where you can't blame the API if it goes wrong yeah so I have a question here on I mean you were saying something about running these things on consumer computers right for example this one runs the Intel Core Ultras right I think there's been an entire wave of you know these companies is coming out and saying hey you know we've got npus we've got you know we'll run everything locally and their entire pitch is you know a good pitch which is hey you run all the small models on your computer themselves uh everything from you know simple stuff like erasing the background to like complicated stuff like well you want to be able to chat with a small AI uh chatboard right on your computer you can do all of that locally now do you think there is a world where consumer compute uh actually becomes competitive at least for some of these tools and services right instead of me spending X number of dollars on Mid Journey do you think I'm just going to have stable diffusion or flux bundled in with my next you know Intel laptop do you think something like that's going to happen I mean why not right like there's going to be a level of universal basic intelligence almost that comes with the laptops and the smartphones and then there's the extension from there so it's got this large amount of memory and it can run a gp4 level model and it's consumer M but then you look at the mpus and you look at the speed of running again a 2 to 7 billion parameter model you're only using 5 wats of electricity versus you know the 150 that 490 may use or the Thousand that a h100 might use but you can run and model this GPT 3.5 level already today you can run stable laptop yeah like is it super fast no but you know it'll generate the images and so if you look out a few years and you look at the optimizations that are occurring uh both from inference quantization many of these other things the models of today all will run on consumer Hardware within a couple of years Mass consumer hardware and that handles probably 90% of use cases honestly of this technology and it has the advantage of being able to access private data but then what do you use your Cloud for we had a piece we put out recently how to think about AI actually I think we might just got the Hindi translation that's coming um where we describe these models as graduates you discovered a AI Atlantis right you've got your own little graduate agents working here and then you've got the ones in the cloud that the experts so there always be better models in the cloud with more capabilities but what matters most is is it doing something useful and when you look at the size of these models like you know if you're installing alen ring it's 50 gabt stable diffusion is 1 Gigabyte llama quantized is 4 GB you know gp4 is probably I'm guessing 20 to 40 gab it's insane to think about since you mentioned the AI Atlantis article there was one quote uh there actually a bunch of quots that I really liked but uh there's one thing in particular that intrigued me which is the cost of intelligence is plummeting with the value of human Ingenuity is applying in applying this unique resource skyrockets and you said that this would become one of the most important skill sets to have um for the next decade to come for someone let's say uh a college student sitting in India or let's say a working professional sitting somewhere in the United States or whatever what is this particular skill set that you're talking about and how would that really evolve so you're moving more and more gentic with the models themselves again they're like graduates or interns that you've got they'll get more and more specialized over time right um right now to like how many people graduates so the college students or or whoever could have made the images they make today or done those particular tasks they could do today with the previous technology percent now well now they're enabled right and you're seeing all these building blocks here but the building blocks have to come together with Ingenuity into Services you know and that's basically the same as managing teams so you've got teams of models your comfy UI nodes that are doing certain things and you've got the content and the regularized repeating processes and then you have the brand new processes that you could never have done before that you're thinking about right so you've got cost savings and then you've got almost the revenue Top Line and the question is kind of where are you going are you expanding reach by translating this into every single language in the world with full speech uh lip syncing and everything and our own voices you know are you reducing costs by doing the post editing of this much better and standardizing it and rather than paying for transcripts you know the transcripts autogenerated like these types of things enable a lot of business Innovation inside organizations inside personal life and then you know beyond that and I think it really lowers the floor just like serverless and Cloud lowered the floor right we didn't need to have our own service anymore now you don't necessarily need to have that hiring spree a small highly dedicated team can do a huge amount like yesterday one of the best code models was released by team of five mid Journey's team was a team of 12 you know so I think that's like just super exciting to think about and it is a bit of like said of management skill it's a bit understanding how to do the prompting and chaining the capabilities of these models where they fall apart and that's just a question of immersion because you don't need to worry about how the models are trained anymore just what they do and that's a bit different from classical coding you know what do you think that skill is called if you to call that skill something what would you call like using the models but not necessarily knowing how they were trained well it's a management skill right just like I don't know necessarily where you've been to University or your background but I know you've got a set of capabilities and you've got some certain special things where you're good at and things that you fail and so this is a management mapping organizational kind of thing and again as the models get more agentic and they can go and do jobs and then come back and Report how they've done it is literally just like running a team right yeah you're saying AI just bloated the number of mid-level managers in the world well mid this is interesting because basically the failure of large organizations is that that uh agency responsibility and accountability get divorced and the mid-level managers are a route to that because you get your specification down to your developers from someone and the mid- level manages the interface but they don't have the agency to change anything to that and then whose fault is it if something goes wrong right what's the iteration process and what's the cost of iteration the cost of iteration of an image now is zero you know but then like I said you can really think about that mixture there so you're not going to have middle managers it'll be more like integrated product managers right but with the ability to execute on what they want and to spin up more compute to spin up more agents if they need to and I think that's a solitary thing I think teams are still important because people have different view sets but again it's just build stuff that's useful and ultimately if the value exceeds the cost then you've got a good business so in short um that skill would be something along the lines of um sort of just immersing yourself in the array of generative air tools that are available out there and sort of applying them and connecting them and making something out of them two two real world use cases and thinking about again the value of existing processes that can be made cheaper faster or better and you know again this is a bit first principles it's engineering first principles thinking with the element of product management as well and product thinking you know build things to do a job I think the way that I always approach this is what's the problem to be solved right and then what are the ways that I can do it better faster cheaper no one really debates those things leveraging this technology and for that you need to actually be using the technology dayto day because then you get your own frustrations it's not working here it's working there and then you'll have more things that come to mind then you'll start building towards solving problems and again within the article we say you know like basically it's if you had a whole bunch of incredibly talented people that were generalists coming to work for you and soon there'll be Specialists what would you do today tomorrow that you couldn't do today and then how would you manage them they don't have to sleep they don't get moody unless you want them to you know they just get on with their job I want to I want to chat about model modes for a second here right like one of the things about flux coming out and just you know I was playing with it the outputs are great uh mid Journey has been king for a very very long time but now I think we've started to see competition and you know there was a time where I remember when stable diffusion had first come out and we all kind of were excited about fine tuning it uh I think we quickly learned after fine tuning a model or two that you know there was this website called civit Ai and then there were ton of fine tunes there right for every flavor everything from anime to like Aura for you know you know a specific style of how you want the images to look and they're all free right you can basically download any model you want any Lowa there you want it was quick it was free it felt like there was no m in building the model at all right especially fine-tuning the models and a lot of people learned this the hard way especially some of the companies that got into YC and said well you know what we'll take an existing model we'll find unit and and that's going to be our our Mo but then I I wanted to pick your brain on what you think the Moes are for somebody who actually wants to go out there and build the models what should they be focusing on it's very difficult because it's basically saying go out and launch your own University and make your own grads and where will they be accepted to jobs right um so the process of making a model requires large amounts of compute data and the algorithms themselves are not complicated like like um one of the coders we sponsored stability is a guy called Lucid Reigns Phil Wang um if you want to cry as a developer you go and look at his GitHub it's like the most productive ever he implemented the Google Palm 540 billion parameter model in 200 lines of pie torch the whole model you know um so the algorithm not that complicated is this industrial scale computation understanding and having the experience of training models and then you know some breakthroughs there I've always maintained there will only be a few model creators cuz again it's like School you create the generalist models and then the fine tunes are like training courses they're trained in CPR or you know like marketing or a few of these other things right and my view was that we would move towards a more more generalized models so like when we released stable diffusion 2 we got a lot of backlash because it was very anod it didn't make like the celebrities and things like that because I told the team to make well we I made one mistake where we put the the unsafe Selter a bit too high so it got rid of the humans but 2.1 fix that but it wasn't very opinionated cuz we thought people would tune luras on top of it with any Direction they want it it's easier when you're less opinionated otherwise if you try to move Concepts it's very difficult um but people want stuff that works out the box and they want stuff that's generalizable but they said where is the mode there the mod are things like um well let's kind of break that up actually the modes for model creation are things like acceptance and that's where you can do services off so stable diffusion is still King it's the most widely used right now the flux team Black Forest Labs is the original core stable diffusion team you know we basically spun out of stability and so they'll build excellent models uh but the question is can they build a community will they have all the IP adapters control Nets and other things around it that's something we deliberately kind of uh gave grants to and we built that stability when we were there the actual models are getting closer and closer in performance so stable diffusion 38 which again the same team made is not far off performance to the flux model and that's shown in their own kind of benchmarking in elos you can see where SD um large is versus flux it's basically the same but it wasn't released because it's difficult to release open source models for various reasons which is nothing they can do in the new company there's a question of compatibility like again everything is compatible there and you can kind of switch from one to the other which is why I think ultimately you just have a few universities creating these generalized grads that can be spun up and my view is that you will have meta continuing to release open models to reduce the cost of their service those will be open weight models my Google will need to continue to build their own intelligence because of their own specific use cases and needs and they can offer that on a generalized basis cuz it's Google's mission to organize the Well's knowledge and make it accessible and useful Nvidia will probably start putting out models soon because it drives demand for their chips um and then you've got number twos and things like anthropic Etc that kind of come there but proprietary models are a bit of a raised to zero because the cost of intelligence is already getting so low and open models have basically closed the Gap um I think the only other area that there is is what I'm doing at shelling is um fully open models for regulated Industries in particular and flows for that so basically providing compute and expertise to build highquality open data sets for every nation and sector Healthcare education legal accounting and more with the regulated stamp well they'll be fully because one of the things you can't use proprietary models for is a decision making because you can poison them so there is a paper by anthropic called um sleeper agents where with a little bit of data going into the model you can make it turn evil on demand so I think that every government will want or Nation will want sovereignty over their own models but every company will as well and those will be fully open models in that open data and open weights and that should be a public common good and again that's what I'm kind of be working on now but only is one entity to do that it only is one entity to make open weights and then you will have these very large models from a few entities and where is kind of the Gap there unless you take that model and then you do the fine tunes and others I think there is still value to that you know but again it's are you doing a job with that fine tune you know are you bringing it into a Data Center and using all the private healthcare data are you helping an accounting firm are you using these models in conert with each other to achieve outcomes but yeah really like I said model training is hard um and it's expensive um and the reason we did a stability ultimately was fund all the cool open source research create the alternative and then offer services against it because we got M share over 300 million developer downloads of the models you know it's just you know that point yeah we never see anything like it I think on GitHub Stars we overtook Bitcoin and ethereum in one and a half months they're cumulative stars and the ecosystem again was crazy um unfortunately we messed up the language models or we could have been the mistal Lama of language models it turns out Reddit data is very bad um but even there like I said I think it's very interesting to see how this will evolve how would you um describe shelling AI in like let's say a one or two liner and could you also diverge a little bit into specific use cases of who would be the people who would actually be using shelling AI yeah so um shelling AI will have more details soon in the official white paper but the idea is to build an open distributed AI system um you know we kind of um got some additional terminology share later around that which is that I believe that there is this class of models that need open data open weights and skill transfer so I think that ultimately Clayton Christian from from Harvard Business School said that infrastructure is most efficient means why wish the society stores andri value and information is valuable with these models to achieve certain outcomes as a practical example of that let's take um cancer the world's cancer knowledge in a cancer llm should be available to everyone fully open source and they should be comprehensive authority of up to date especially because the language models now outperform human doctors not only on diagnosis but empathy and you think about anyone who's gone through the cancer Journey imagine if we made that available but then the governance of that should be communal the governance of the best data set possible for India reflecting Indian culture and laws other things should be owned by the people of India for the people of India and the same for Every Other Nation as well and you've got this intersectionality between Global common knowledge that's like your high school knowledge right or human knowledge and things like biology then you've got your specialized knowledge and localized knowledge and I think the AI of the future that will be running our governments and healthc care services education and more needs to be deliberately built to reflect that and so that's what shelling is kind of doing um we're going to be building models and high quality data sets and providing research grants on the other side for everything from cancer to autism multiple sclerosis Alzheimer's but also for every nation for building National Data again not by the government by the people working with the governments uh and more whoever wants to creating standards around this for interoperability and then sharing ownership and more yeah know I just like again I alluded to this in the LA but the example I gave here was Bitcoin Bitcoin has provisioned a huge amount of specialist compute to secure a store of value right but all of the compute goes towards solving useless equations the total energy used by Bitcoin yearly now is60 tatt hours all the data centers in the world use 350 tatt hours so you think about that and when I looked at that I was like what if we could do something similar to bitcoin a distributed Ledger for use for things value but create value use that energy to create open source models and data sets for Humanity and then share the ownership of that so anyone can contribute their Edge compute but also their super compute so if there's a glut of compute great it means that we're the marginal dollar and everything that we release is open um but again there's two things build intentionally the stuff that you know should be built to help run the government's education Healthcare Etc and then on the other side just fund all the best research and researchers so there's never a compute shortage anywhere cuz we saw massive games for that we gave 20 million superc compute hours away in Grants in stability that's 10 llama 7bs to give you an idea wow and that did things like open fold for protein folding through to RW KB for RNN language models so I have a question here right uh this is related to how You' be giving grants away so I think let's take the example of you know doctors and medical knowledge right you said This Global Knowledge is BAS Baseline biology for example I got tyho recently right so there was Baseline biology of how tyho works and you know how salmonella works then there's also you know like a more local level knowledge which is what is the resistance pattern of salmonella in India to specific antibiotics and I feel even though there's one or two papers maybe from three or four years ago that covered it on Pub and I'm sure You' ingest that in there's also so much anecdotal evidence anecdotal information from doctors like unless you speak to a doctor in India and ask them well what is the resistance pattern you've seen what antibiotics have you seen salmonella in India in this part of India respond to I feel you wouldn't get good information so is there a way for you to incentivize these individual doctors to talk about this somewhere or put this as part of the data set or is the incentivization indirect via hey we'll fund a study where somebody does uh you know paper on this what what would the route be for shelling so before I did stability I um did a project called kayak where I was lead architect Collective implemented intelligence against covid-19 um to organize the world's Co knowledge using AI so I launched that at Stanford with the World Bank UNESCO a whole bunch of others um and part of what we did was blind interviews with experts in covid about what they couldn't say on the record you know just kind of seeing their kind of level and then I kind of saw how all these models would be because ultimately what we want to have Is An Open Health Care system that can be used in India or Guatemala or wherever whereby the amount of data density goes from doct Scrolls to everything being recorded as a flow and then feeding back into a global um knowledge base because there have been things like Melody and others for Federated learning and Healthcare but once you standardize the models and you can take out structure data to structure data you can capture the local knowledge and feed it up into the pilots almost so you have pilots and co-pilots and again what we're doing at shelling is we're looking at very practically the models that can help to dat we build that cancer model it'll be available for everyone in the world and no one will ever be alone again on their cancer Journey or multiple sclerosis Journey or any of these conditions but then thinking about what is the future of healthcare from first principles using generative Ai and what's the stack that should be built from the ground up for the doctor to the hospital for everything so you have a constantly learning intelligence system and the same for education and the same for every industry which and individuals will contribute right individuals will contribute because then the system can go and find what's needed so you can contribute your compute at the start because it's algorithmic and distribute compute can be used for batch jobs data augmentation you know model optimization and more Super compute is like the giant Bitcoin minor nodes right so we've got a node system there so it'll be like folding at home or setti at home but then there'll be rewards for data provision for feedback identification of where the gaps are in our knowledge system what data sets need to be built like genetic data is very white for example and again the expression of these are like that I think that will fundamentally change for example the medical system because the medical system is about the law of large numbers like if you have a cyto p450 abnormality which like a decent percentage of people you metabolize morphine into Cod and into yeah sorry Codine into morphine you know you metabolize all your drugs much much quicker and that causes all sorts of cytochrome yeah talk about cytochrome yeah cytochome p450 it means that you metabolize um codin into morphine incredibly quickly that you fental into death you know everyone's got the same non-personalized medicine non-personalized education because we couldn't do that but again if we think about our public infrastructure I think there needs to be a level of again Universal basic intelligence that's offered to everyone to support them and this is the regulated Industries and those can't be black boxes run out of the US again that needs to be localized and the reason that I think we need that just like we need to have internet is because because it's so empowering you know like um it can uplift and particularly when you've got a rich basis like the infrastructure that's built in India right now with India stack adhar and the high levels of data from the mobile phone networks like I think it can change the game there was uh one interview in which you said that India will Leap Frog into the AI era because they have to because Outsourcing work will actually start to decline what do you see the impact of that in the coming years and uh what is that really going to look like so you know if you look at it practically um you look kind of I acceptance rates already being hit slightly B kind of levels going down a little bit right now next year is the year where it all kicks off where there's an impetus where you are forced to react and you know you need to create the jobs but then like I said I think the fascinating thing about India is that if you've got identity you have widespread smartphone usage High data those are massively important things for AI and if you have models now that are highly performant that work on the edge you know that can be localized Edge or Edge Edge that's something that could really be used to create the jobs of the future and to allow India to compete on a Level Playing Field as long as regulation and other things don't get in the way you do need to create the right models you do need to have the right structures but it's like I went on record a couple I think started last year saying there no more programmers in 5 years the answer is as you question basically that's me to be as we know it like when I started programming 23 years ago I was doing like assembly you know there was no GitHub or anything like that we got sub version a few years later programming changes but ultimately it's like let's do something to make a job happen we look at generative AI now and again you look at these models coalescing down to the edge and being accessible to everyone you're like what does a programming job with the future look like it looks like a problem solving job right and so we have to teach like a different mentality but then with the base of Indian infrastructure as it is I think it's a unique place to LEAP from forward because you can identify human within an Indian context you can do Mass financialization again given India stack because you've got high levels of data cheaper than anywhere in the world so you can do all sorts of interesting streaming and model things that aren't possible anywhere else but it requires the population to kind of take that forward and the government to not get in the way too much so I think there's a potential like let's take advantage of it and then there's also this forcing function in the white collar jobs being decimated potentially in the coming years if you do see some of these jobs especially in India right like the the biggest worry people have in India is you know if you decimate White Collar jobs especially mid-level White Collar jobs right for example the large services companies in India the software services companies that hire tens of thousands of people you you leave this void where then you'll actually have to start talking about things like Ubi because many of these people they might go to the next step and decide okay well I'm going to start doing like delivery or driving and things like that but once some of that gets automated because it's inevitable for some of that to also get automated right at some point uh how do you see Ubi playing out I'm sure you have thoughts around Universal basic income uh whether it's a good idea whether it's a bad idea whether it creates INF inflation I think everyone has their own thoughts on it and I'm sure you've thought about this so you know it would be nice to hear your thoughts well it's incredibly difficult but that's why I you know I stepped back from stability handed it over and decided to go to Shelly you know cuz I was like um the plan is that we're going to launch like um National subsidiaries that will eventually be owned by the people of each Nation uh to help guide through this process as well as sectoral subsidiaries so you get the best economists together and others because these are really hard and it's coming really quickly and again there's a difference between a western company not hiring graduates not renewing a Services contract and firing senior people right you've got this order thing so you look some like the Philippines why would you have a call center worker in India what call center workers the is already better than Call Center worker but what's the cost now it's tiny this is happening very quickly and is it going to be Universal basic income and I think that makes sense I think the people still want jobs and you need to give them something to do I think Universal basic jobs is a very interesting thing so something like the Argentinian effers program allow gave a budget and then people created Community jobs to improve the community so there was alignment inclusion of large amounts of women in the workforce and more I think things like that are better but it's going to be a tough needle to thread when livelihoods and sectorial stuff is disrupted because agregate demand goes down you know who is going to make up the demand for Indian services and you're already seeing kind of things that you can have growth like you know I'm from Bangladesh and we over took India on GDP per cap because that was just driven by textiles is India going to be driven by service jobs is it going to industrialize are you going to build robots you know like where is the aggregate demand of the future and how does India do that I'm not sure but like I said my guess is that eventually you will not have Ubi but you'll have Universal basic jobs because people need something to do I think that the distribution of that will be super important and I think that the monetary policy that follows from that as well will be super important which is why like one of the things that I did with shelling one of the Reas I did as well was I was like AIS are going to be doing a lot of the productive work on your behalf potentially right again this expansionary thing that we talked about managing swarms of AIS and robots they're not going to have bank accounts they're going to pay each other in digital currency but they're not going to pay each other in Bitcoin or ethereum none of these are like fit for purpose we've got to build a new type of digital infrastructure that's communal and interoperable but then that could be the is the basis of money in the future going to be compute intelligence you know um not sure uh but I think again we need to have systems that can help us adapt to this because is coming later and sooner than we expect and that's again an opportunity and a threat just uh backtracking on what you said about coding uh I've also been reading a bunch of Articles where you say that uh we're not going to be coding the way that we do today we're going to be coding practically in English or which is going to be doing it in natural language uh with the current capability of you know code Splitters out there you can pretty much uh generate a basic website you can generate like very small objects how far are we from actually generating let's say a complete complex um Tech architecture like let's say an Uber app or um a level where it even thinks about the architectural decisions it has to make while coding something and not just generate Snippets if you want to build a complete replica of uber dynamically I'd say one year going to be done in a year yeah if you took the large context windows that you're seeing with magic and Gemini and more thatti code basis um you look at the optimizations that are occurring with things like um cosign that came out yesterday and again Devon and more like again this is if you're not computationally bound I'm not saying that it's going to be necessarily just a few infer steps zero shot um if you're talking about a few instances it's still only a couple of years away because again if these models like graduates they can follow rules what can't they do especially with long context window so for listeners kind of long context window is how big is your prompt you could typically only put a th000 words or 2,000 words or 4,000 words into these models previously with the new Google Gemini models you can try it right now you can fit 2 million words or video so you can put your code base and a video of you debugging the code base and it will do that inference time and interpolate the two know you can give it a guide to architecturing and common mistakes and it will interpolate that with that you can have multimodal input which is crazy and once you start training these together you can do some crazy crazy things and again the cost of testing that out is a few bucks which is again crazy what do what do software Engineers do with this information like how do they think about this how do you model your world if you're a software engineer you just studied four years of college in India you know you know how to build a basic react app you you probably just got your first job how do you how are you supposed to think about this change so if you spin up clae 3.5 and then you use the aact you'd be like oh building react up is a lot quicker and easier now or use cursor or something like that right and so you start by out competing your peers because you embrace the technology and you do your job better faster but then all a sudden you start building up experience in what's inevitable AI assisted coding is inevitable and again this is just a progress because like I was writing assembl code 23 years ago and then we started getting these libraries and things a lot of coding right now is basically like Lego you know but computers together yeah computers can talk to computers better than humans can talk to computers you're already seeing like the Google tpus the GPU equivalents were partially built using ai ai assist AI now assists all GPU design and TPU design and so why shouldn't it assist coding design but the first steps will probably be this um like you saw um my old tutor ogore God what was that name we just had the first coding model pen tester that outperformed humans it's not going to stop right but probably the first area you'll see is code review just like in you're not going to have diagnosis you'll have diagnosis review legal review everything gets reviewed by the AI first but then you start implementing it into your system and again the more familiar you are with it and its flaws and the fact that it doesn't require a large amount of technical competency to use because the inputs are human language the better off you'll be it doesn't matter what the future is unless you think this technology will not be useful which is a bold bet so that's why I'd say if you are the react coder build better react Taps faster you know treat it like you would treat a good quality graduate coming out of an IIT literally talk to it the same like if you in the prompts say think a bit longer or you know like try to think hard this is the context usually in prompts we put like that much but again if you're giving a graduate instruction you usually instruct him over a few hours actually be quite funny someone should do a test you should record everything that you tell a graduate programmer and then get them to welcome it versus a Claude or something like that and then see what the outcomes are like feed in a few thousand words or 10,000 words but this is more about you know status and also livelihood right because today yes you could build a react app faster with AI but if you think in a couple of years at least building an Uber is going to be table Stakes uh a lot of Indian services companies are building things at a slightly lower you know complexity level than San Uber they're not building at that span right uh so what happens to then when when that process gets completely automated do they move one level up to be the engineering manager or a product manager or do you feel like there is going to be some culling there well what is react right and like when you look at how the react Engineers operate they're not writing the react code directly you know they're using libraries so again they've had a level up already and again you look at how that compares to 5 10 years ago before you had the libraries before you had the Frameworks you know before you're using vue.js all kind of any of these other things vanilla JavaScript yeah like you're not writing vanilla JavaScript you're not using that it's just another level up um but again what's the job that your customer will ask you to do that's the question you know like there's still space for apps there is still space for products but when you're in a business you have to think well my customer suddenly has access to this will they use it or not the answer is in most cases they will not use it yeah you know so if you're offering that service and you're showing expertise in this area then you continue to upsell them but it's just the next phase like what was it maybe 10 years ago or time flies you remember Flash and how many flash developers there were how many flash developers are there now all the Min Clip games were made on flash yeah exactly you just evolve and you upgrade right like but in certain areas like you still have Cobalt and Fortran required as expertise how old is that these things don't upgrade some Legacy government stuff Legacy government stuff but again but the dangerous thing about this technology and the potential of this technology is like um last year I helped organization with our stable code models convert 50 150 million lines of code into python no sorry 15 million lines of code into python because you can just set it and almost forget it and it'll come and'll do the unit tests and other things like that and that was a large architectum challenge can't give details but that's the type of thing you can do now you can upgrade that Fortran code base which you could never do before um by you I mean like if if you take a team of top-notch 100 of times Engineers from India and they think about what can we do now that we could never do before because they couldn't bring on that 10 times engineer or that one times engineer with enough bandwidth they didn't want to deal with the interpersonal stuff suddenly the scope of software engineering challenges that are achievable expands and the types of things you can build expand again this is why like when I we're looking at Shelly and we're looking at all the subsidiaries and things like that I want to think about AI first government AI first education AI First Healthcare while still releasing open source data sets and models that everyone can integrate into their existing because as they integrate the models these models also act as translation engines like again you can do transpilation of one code based to another just like I can take my face and put it onto your face with an image model these models themselves just embed context so we took all this huge amount of data 100,000 gbt of images into a 2 GB file you can't fit that with the zip all they do is embed context all day but then once you realize that again like I said the space of potential business that you can do and higher value business increases I think that's how Humanity progresses in general I think the underlying emotion of anything that comes out of the space is that it's crazy or it's insane but do you think we're approaching a face where that actually stops happening to give a little more context at least in recent times there's been a lot of talks there's been a lot of articles on whether the AI hype bubble is actually about to burst now there are two angles to this that I see one is from a revenue angle where a lot of these companies haven't really made a lot of Revenue yet which uh is a short-term problem um and not a really long-term problem because value will eventually be extracted from these uh but the angle that I'm more interested in is that are we approaching a technological plateau uh in compute or in some kind of uh capability sense uh do you think these models will actually stop getting better beyond the point where we simply can't bridge the gap between Ani and AGI yeah I mean the AGI ASI discussion is a complicated one let's put that aside for now we already seeing model saturation if it was just about compute then Google would win they have these tpus which have got better interconnect than the Nvidia chips and they can scale them to potentially millions of chips in a training run and again you're seeing these gigantic supercomputers being built like Elon Musk 100,000 h100 that's 3.5 billion just on chips right but if scale was everything then you know again we're just heading One Direction but what we're seeing is saturation of these models against their benchmarks like you try flux right as the best image model do you need more like probably not I mean when sd3 came out I said it would probably be the last great image model assuming the sd3 8 GB 8 billion was released because you don't need that much more and so this is you a concept called satisficing once you get to a Claude 3.5 GPT 40 mid Journey flux level you don't need much better on the model and then you engineer it to optimization you look at exactly how you can replace the data how you can e out every single last Lop of performance and so now we're entering the engineering phase of this technology but it's already dropped distill it make it smaller distill it but make it useful all that matters is is this model useful and again we take the example of flux what more could you want in an image model that can be part of a pipeline that can check for any errors and balance and do construction you don't need anything more on image do you you need prompt adherance like better prompt adherance like if there's a very long prompt then some parts you know if if it simply doesn't fit it just it doesn't show up on the image right especially with very very long prompts whereas if you've seen ideogram right like the the the one from the folks that imagin it does prompt adance a lot better than say an sd3 today but I feel you're right in the sense that given a year there's going to be a model that does that better right so you're already reaching the top you you're now gone from the core to the edge cases and again you can input a language model to reconstruct prompts you can do segmental kind of decomposition of scenes again there's some really good stuff by Google around that where you kind of lay it out and then you can offer options you can do step-by-step processing and again the model itself now as this kind of binary as this translation engine is good enough like we're still I mean how many people still use SD 1.5 I I do well it's good enough right and it has a whole ecosystem around it it's like you know we still go and play like Team Fortress which is a mod you know on top of a thing because it's good enough does it do the job so again how can you expect expect this massive leap Beyond GPT 40 to GPT 5 it'll just adhere to prompts better CL 3.5 aderes better than that next one will hear better than that this is also part of the continuous learning process so I don't think that these models again let's put Ai and Asi to the side right now will get much better the architectures will get better this is why you're seeing Google and open a and everyone now going from these autoaggressive models now to MCTS Monte Cara research um like models like the one stuff qar beating humans at DOTA this agentic kind of thing again have agents operating together it's why you've got things like lamb and I had a piece of research about having a million experts and then that inched 95% rag retrieval rates from like none from 60% or open AI functional output with Json so you get 100% adherence to schemas you know you've got Mo Moa architectures from together where you just route the model the query through the best model for any type so if you gave it a complex prompt it would say that goes on the deconstructing thing versus I want an anime girl goes through an anime model you know so I think now it's a question of architecting system design and again design patterns that will be the most emergent here the base models will still improve but I think we're setting a saturation Point against the data there are some architectural improvements like falcon from the UAE released a Mamba model that performs better than llama 38b yesterday um that uses this mambas on state space thing and with things like samb that combine that with sliding window attention others there are lots of very interesting things plus some architectures that haven't been released yet that are coming out that're like 10 100 times faster but do you need more is what the question that I was come back to like we always like shinier gpus and things like that but if I can play D 4 or Elden ring or my MacBook it's fine you know like or Playstation you can eat a lot out of the existing architectures if you look how old an Xbox is you know so I think again we're reaching that satisficing point um and I think to your point what will shock now is the capabilities of these models being pulled together in design patents and again like today you saw Sakana have an AI um scientist it's not very good but it's reasonably shocking you know but it'll be assume to be power for the course you saw again like people taking flux and then combining it with Gen 3 and you have this lady kind of speaking or this man speaking at the event you're like they can't is that AI or not these are again but now we're getting used to it like text to image of course you can type in words and images magically come only been two years and then we got used to it right yeah it it still all comes back to the mapping narrative at the end of the day are you excited about the new open uh the strawberry models that's being teased across do you think that's going to be something shocking something that's that's going to make us all get off our seats and well to be honest I'm like overloaded with AI stuff all the time anyway it's tough keeping up um I think it'll just be better again I don't think it'll be ridiculous insane breakthrough I think getting better data build compute better feedback data tuning we kind of know where things are going right now but like I'll give you an example when I first started using FL 3.5 it was a joy to use with the artifact feature like you know the frustration levels go down like when I was a video game investor I used to look to time to fun flow and frustration so the more these Technologies and models can be used to augment us like again stable diffusion was a joy to used originally like okay it had errors but who cares so I think you know you go look for I I assume this will be even better to use um and nicer but I don't expect any massive improvements because we already the limit of what the data can provide like if we move again and we managed to be successful in our mission of creating open data sets that reflect all of humanity and that can then hyper customize then I think that will be incredible collective intelligence you can do all sorts of stuff but now I think your data can strained but not on these big data questions but on personalized data on these feedback loops to make this AI us and for us and so I think that'll probably be the next breakthrough when the AI gets you and you can trust it as your partner you know um because again I'm getting there with Claude they Co but Claude isn't learning right I mean unless you learning from me unless you write a really big prompt actually this is interesting um so for all the developers uh little plug I don't know um Gemini flash is free to F tune so Google kind of snuck that out so that means you have one of Google's top models with no cost to find tune and so I imagine people are going to go wild when they realize that and start experimenting with it because then you can have mass personalization of models and things like that but again there doesn't exist for example anyone hasn't taken something like Gemma 2B which is an incredibly performant model stuck it on a laptop with a self-recursive feedback loop where it's learning about you as you're having a discussion with it and that's probably the next step of these models these hyper personalized your culture your country your own personal ideas and data what that looks like your conversation is context conversation is context it has the memory it gets you and again just like a graduate will get you like I say these are talented graduates but The Talented graduates are goldfish right they don't go back and learn from the previous but we have the Technologies to do that like Dynamic Laura creation answer a I have that now and they pushed that out perfectly possible and again this is the design space like you never had an assistant that can talk in exactly the tone that you need to guide you through the day in a way that is impactful like um I have to admit one of the coding assistants that I created for my coding I put like um all the top coders that I liked uh code in there and it switches between their voices as well I just chat with it as I code so it's like personas again could never build that type of thing before hasn't made be a better Cod probably not but it's certainly more enjoyable you think there'll be a you think there'll be a better form factor for this you're doing this on the glasses or you're doing this with the the friend or the whatever you think the form factor for this would change or is going to be a mobile phone well I mean like let's take the Indian example right like you look at the geone and others and India is a very speech-based vocal society and so the feedback loops I think will be largely order Tre there um whereas other nations like Japan are more visual in some of their constructions um but again it's a wide open design space now which is super exciting I think voice is incredibly powerful and again like I don't use Siri because Siri is annoying but Apple intelligence will be smarter it's a three billion parameter model that does dynamic Laura shifting so just like stable diffusion what they'd have is they have these it's like Lorax type things where they'll create a personalized Laur for you so that'll be one of the first examples of what I've described there but the voice will be better and better and it'll be fun to use and it'll just be become part of your life but like I said why don't people experiment with Dynamic Ur generation you why don't people experiment with these different modalities how expens it costs nothing even within an Indian context with a relatively lower consumptive capability the price of this intelligence is minimal now which again is crazy like um the latest uh gemi flash I think is something like 15 cents per million Words which is about a thousand it's really low from gpt3 and especially if you're doing it on edge compute it's it's it cost you nothing except the price of the device and I know pixel the Google pixels they're really pushing for on device compute and they're like hey we want to get to the point where at least the smaller models we wanted to be able to run it flawlessly so again if I kind of look at the example looking at the TCL phones and a bunch of the others within Indian context the Gemma 2B model that you have right now runs faster than you can read on any of the new Chips coming out for the budget phones using less than electricity so model that's a 2B model but that 2B model outperforms gpt3 original 175 billion parameters that's impressive perform similar to the original FL 70b but this is kind of one of the things like when you're architecting we need the model releases to slow down and then you reach a level like in an SD 1.5 level that you can then adapt and build with predictable outputs because if you change the latent space underlying constantly then it gets very very confusing like now like I said the new standard will be probably flux 12b you know um except for the fact that chel is a distilled model so it's a bit harder to tune Dev is easier because it is a distill model but if stable diffusion AB8 is released that will become the standard for the industry because it's predictable it's good enough it's can be fast it can be big Etc similarly llama became a standard but you're still in the experimentation phase with language models really because language requires much Precision than creative models but once we get a standard and I think something like a Gemma 2B is a good initial start you know again I think s them put out their 2B today maybe that will get traction showing good performance even though it's only halfway through the training cycle and again don't really understand why it's not bigger um maybe I'll offer some help um then you can have really predictable experiences that are very good and I think you build for spec look at where the smartphones are going the size of the relative Model A two model and again Apple intelligence is 3B on the neural engine of the iPhones you look at things like what needs to be done synchronously and live what needs to fetch from the cloud and then what can be done on a batch processing when it's on a charger that's a really interesting design pattern change and I think maybe basically maybe one of the things is this I think that content is becoming commoditized and boilerplate code but again as we described there's even more scope for creating recipes being a chef versus a cook especially because you're like the typical react engineer doesn't really believe they can create like even making their own react app for fun is difficult because they don't have the time whereas now they can right and so I think it's about Embrace that creative aspect of you and realize that you are creative and then go and solve some really cool problems that you could never do before or build just cool stuff this is going to be the last question from my end um so in 2023 we saw llms and images uh image models take off you know in in an exponential speed in terms of quality they're still getting better uh this year and probably it'll take another one or two years but we saw them really take off uh 2024 has been so far uh the year for video models and 3D models to some extent uh what do you see for 2025 what do you think is going to take off in 2025 and that'll be the year of agent where you get these models and you send them out to do jobs and they come back versus the synchronous stuff I think it will be the dynamic model customization where it's continuous learning is kind of the norm versus now there's very few aspects of that um I think it's multimodality um both with chains and with the models themselves like again being trained on all sorts of input being able to do all sorts of output but then as you chain it you will have that full compositional control over any scene or over any article like as you're writing you should be able to take it from the high level down to expansions of topics try out different variants tell it different things again this control aspect is just coming now in language it's just coming in code the question you asked earlier about architecting an Uber level app the AI should be able to take you through the various levels of abstraction what everything does better than any human and that should be possible now it's just we haven't built that in yet and again that I think all these models at a base level standardize and they become very predictable um again there will still be bigger models coming but I think again let's exclude AGI and Asi because they're complicated topics um I think we're pretty much there now and again it's kind of let's play it this way it's like a video game it's come out of Alpha and it's in beta right now and we're still waiting for the mass release before we mod it right that's an interesting take on it this was superb I have no more questions I think I learned a lot um I had so many questions I just wanted to ask the best in the world I got the opportunity to do it thank you so much Imad for doing this with us uh I'm sure this episode is going to help a lot of young I know a lot of young Engineers sitting on Twitter who are extremely smart still thinking about whether you know they need to go build out the models still think about you know where do I use this what's the opportunity what should I be doing with my life and I think you've laid all of it down and I feel like today anyone watching this now has a plan on what they should do and where the timelines are even if the timelines might be 10% 20% off they still have a road map so thank you so much for doing this and yeah you know thank you thanks a lot super fun ",
    "url": "https://www.youtube.com/watch?v=VeaT6ucXuMI"
  },
  "kQHkOqUIiAg": {
    "published_at": "2024-09-05T15:38:26Z",
    "title": "AI Images Are Getting Out of Hand!",
    "text": "AI Images Are Getting Out of Hand! it's a new week and some crazy stuff has been happening in the world of AI this week uh whaton I uploaded a picture of myself on Instagram and I just asked on my story saying is this a good picture should I put it on my grid and like 90% of the people replied saying yes yes yes yes it's a great picture you should put on your grid and then I uploaded a screenshot of a WhatsApp conversation I had with the friend where I asked her this question and she said yeah it's a nice picture then I said it's generated by Ai and I and most of my friends replied saying good picture then I said generated by AI they're all shocked and then everybody found out that oh this is AI this is AI so officially I had a first moment where you know image generation is officially good enough to fool people of me that too so yeah would you put it on your grid would you pass it off as a real photo I think if I put it on my grid it would pass off as a real photo I think most people would not recognize it's just that when I revealed to them that this was AI they all go like oh I knew this was a I saw it but I think there's a bias there but I think most people would not have recognized it if I put my weight behind it and said hey guys here's me holding a Starbucks cup uh you know in New York they would not have they would not have guessed look at that Starbucks logo the Reconstruction is so good the fingers are so good it's really good and actually this is the first time I don't I think it's gotten my body type accurate right like U that's what's surprising previously I have used mid Journey and then I've used face ID to put my face onto a similar body type but here it feels like yo that's that's what I look like when I wear a wear a wear a t-shirt yeah they look very very very real yeah it looks it looks very accurate would you consider this satisfying which means it's good enough now for it to be like okay if there's any more Improvement in this it doesn't matter so much I think there is still scope for like three 3 to 5% more Improvement but it's it's I think the last 10% has made a big difference uh we've gone from fooling about about 20 30% of the bottom tier to fooling about 70 to 80% of of most people um and I think that's that's been the big leap especially with flux Laura let's just roll the intro then we'll get into  FL all right so how did we achieve this picture vun I saw that you also uploaded a bunch of these photos on Twitter and Instagram uh this is definitely we have leveled up uh in terms of creating lifelike images of anyone uh what do you think so I'll tell you the process very simple you can basically Now train a simple flux Laura so so I'll tell you what a Lura is right you don't train a full model you train a small piece of the model and then what you do is in our case we took maybe 10 pictures of me or actually mine was about I think 25 pictures yours I think about 10 pictures uh and then we trained this small little Laura um and then we said hey you know let's now generate images where you have the Bas flux model it's connected to the Lura and then you're outputting these nice little pictures right these nice little fancy pictures dude the training process pretty seamless like what I'm saying is like even if you don't know too much about ml you could train this and get good outputs I think it's more art to get good outputs like I'll give you an example okay in all my pictures before this run we had I had a mic like all my uh input images had a small microphone so half of the almost more than half of the images when we prompted and we try to get an output the mic was there so it learns things as long as they are it learns the things that are stable across different images right for example in your case it would learn your face structure because it's pretty stable across many images but for example in your second image you have a ring right I maybe and that ring looks very much like the ultra human ring right which you've worn in some images and it's probably in some of your training data as well and it's on the finger that you wear it in let's say this Ultra human ring I was wearing it on the first finger like this the the index finger it would probably capture that and it would give me that right unless that's something I didn't want so what we learned is as long as you know you have a particular like thing that's stable between images and everything else changes like for example you're wearing different shirts if you wore a blue shirt in all the Laura images training images that you sent it it will only generate you with blue shirts most likely generate you with blue shirts right the weight of that would be very very strong so that's what we learned and I think the fun thing was the fact that I think uh it really helped us with thumbnails because one of the things you can do with like the comfy workflow that we have you can also generate text you can say tan B uh in you know a car showroom with the words slipstream behind him right or t but in like a party with the words party behind him in neon lighting and it generates really good text right like it's it's pretty accurate reconstruction of text so I think um thumbnails is like we you've been very obsessed with thumbnails right you've seen that we've been trying to crack it for a year and a half now thumbnails are actually fully a generated including the text part there's no manual person who's like editing it or whatever right uh it still gets maybe five out of 10 times it like half the times it gets text wrong but it's okay because you can just generate one more and you can be like what's the next output like so over time I think the only like like thing that they can optimize here is to improve the text generation but we are not very far but what I found even more impressive than this is the videos Man like have you tried this on Runway have you put this image on Runway yeah so we put this image on Runway and then this was the output and this was also really impressive right like it uh once it gets your face and body type this accurate that the video gets elevated to a whole different level so let's share the Tan's video output it's still maintaining your face structure right yeah I mean the the video is not actually as good as the image uh when you look at the when you when you look at the video you know that oh this is AI but if you just yeah so this one is a much better video see this one is a much better video it is uh more accurate uh I think your Joker your Joker video is probably the best of the lot this one right yeah is probably the best of the lot uh but it gets distorted towards the end like towards the end it's probably so what do you what do you think of this like the the idea of you being a ble to make video it's very uncanny know it feels very weird like hey I was never there and now there's an actual video of me moving around in a place where I wasn't there does it make you feel any different to me personally no because I have used I used mid Journey plus face ID to create actually you know real life lifelike images of myself um but I think I think we have leveled up in terms of in terms of uh creating lifelike images and videos I think most people will be fooled now I think initially before this people who knew AI existed would always be skeptical when they watch certain content I think even despite the skepticism now it's going to be hard to differentiate uh I think yeah definitely a level up so the the the workflow that you've made in order to in order to replicate these images uh why can't we turn it into a product so you can uh the only thing one one of the sad things about products today at least these kind of products today is aay BD says it really well right he's like apps will become content now so you'll you'll gain traction for like 6 months you'll get like half a million users a million users we've seen this before right you'll get a million users and then it'll slowly taper off as the next cool thing comes out right and somebody else gets hype on the next cool thing so uh for us now because we're a slightly large company it's like we really have to think about is this going to add enough Delta and is this going to be long-term Delta right so the fear I have now is I don't want to build like an app that makes me small amount of money for a short period of time and then tapers out it has to be long-term like value addition right plus my worry with things like this is and this is the thing with local laptops right the local laptops are getting good enough to just pack this in right they're just saying hey we'll we'll just make it as part of you know your your laptop boot up I mean it'll just be one one of the apps that comes bundled with your laptop same with phones right like the the new pixels had this crazy feature where you can add somebody into the image you can take a picture of a group of people if you are not in the image you be like somebody else hold it I'll go stand in the image now you retake the picture and then it merges the two pictures right so it's unlikely to me that a Google is not going to come out tomorrow and say well now we have this flux Laura where you can or an equivalent of flux Laura where you can generate whatever image of you wherever you want because people like that people want that I want to be able to prompt and get any image I want because it's so useful because for me it's more because of content right like it's very useful for thumbnails and for you know b-roll for many people it'll be useful to just share with their friends like if you see Facebook it's full of Boomers like commenting on you know random stuff like they they look at some waterfall air generated waterfall and be like wow so beautiful nature is pretty this that okay and the Facebook group page owner who's put up you know the AI generated images is basically just having a fun trip because you're not making money out of it either so I think um I think it's going to be on phones man and I don't want take the risk of building it for a while like we built something on WhatsApp and then meta built you know their AI on WhatsApp right after a year so I don't want to how is is G in the Box still making money I mean it still makes some money uh not as much as before and it's definitely declined but it's declined because now meta has an alternative like you would not be the wisest person to now use our tool when meta has their own tool right like and it's baked in it's free like why would you pay money when something is free so we've seen an obvious decline I think thumbnail wise this will be very useful but I'll tell you what I've learned about business right like at least with AI because we've been doing it for for a while now I think it is wiser to go to a company and say hey we will do thumbnails for you we'll do a service for you and then use these tools at the back end cuz I'll tell you how companies think okay companies don't want to do the work even if you give them the tool they're like bro we don't have somebody who can chaly the tool even if it's one prompt we don't have somebody who can think about it see the outputs check if one output is better than the other so you do one thing what is the price of a thumbnail designer let's say it's 25k 30k I will pay you 25 30k you use whatever tool you want in the back end what I'm hiring you for is your taste you probably know what thumbnails work on YouTube you you generate you decide which ones to go out you AB test two three thumbnails and then you keep the winner you do that process for me as a service so this idea of you will use a lot of these products behind the scenes to make your job easier you won't manually make thumbnails anymore on Photoshop or you might tweak it a little bit in Photoshop you'll use these tools as the Baseline to generate it and you'll make money as a service not as a product like I think you make far more money as a service using these products behind the scenes because like you you've kept saying in the past people are hiring you for your taste uh I'm seeing a lot of kids do this too and I think this is a good business because a lot of kids they at least freelancing kids they get into this mistake of taking on too many projects they'll take on 10 projects at a time 20 projects at a time and they're doing it alone like I understand you take on 10 projects and you have 10 employees then you can spread it and what usually happens is they're not able to jus to the third one onwards maybe two you can do at the same time you take the third one you can't really do justice to it with these tools you can actually take on 10 projects and you're purely now paid for your taste right like you look at the way we do content right like we have an AI Avatar like on my channel on the short form we have an AI Avatar that creates the content it's still my thought like I still think about which ideas we should do and what's the narrative like but AI generating AI converts that voice note that I sent into a script we use H to kind of make the video we use use 11 labs to make the audio uh We've trained it well uh the 11 lab side at least and then you know it's edited by a human being as a service and then it's put out on social media so it's like it's this amalgamation that I think people really want and they're willing to pay for they're not willing to pay so much for tools at Max you you'll charge $9 then it'll go down some other guy will come and say okay it's not $4 third guy will come and say no $1 fifth guy will be like it's free it's on your phone and you buy the pixel phone it's part of the or an Apple phone it's part of the OS so you don't want to get commoditized via being a product and somehow there seems to be a Resurgence of services but it seems to be a new kind of services this is at least my learning what do you think no I agree with you actually I agree with you largely um I have been thinking about okay so I've been tinkering around with trying to think of what is the next startup that I would want to want to play around with and the more I think the more it feels like all right maybe atoms is the way to go uh yeah that's becoming more and more clear what's atoms just physical things you know M People Community Real Estate products physical products um that's our Zone and services right and services especially in India where like I the feeling is that yo just software doesn't make you money it's you need a guy with a software right like you can't even enter a mall and just press a button and get the receipt you need a guy there to press a button for you so yeah is there a reason for that do you feel like it's different in the US I mean I have an experience from us right like I remember there's no there's no person helping you at the ticketing at the car pocket ticketing machines okay and our car was stuck there we had rented a car our car was stuck at the ticketing machine and for some reason I I we had two cards so I had forgotten my card in the other card so I wasn't able to pay for the ticketing machine and there's no human being there no one to help us we had cash that machine wouldn't take cash the people behind us really started shouting at us like there was a guy there was a some bald guy 40-year-old white man who really was like go back to your country and like he was saying like really bad stuff right so we like I mean fair enough right in my country there would be a guy here who would solve it no like we had no help like we have cash the thing requires a card a specific type of card uh I had a my card I I mean I hadn't picked up my card the guy who was with me his card wasn't working like can you help us to second they're like no figure it out and we like d this is our second day here uh so it's a little bit hard I I feel like it's just a very cultural difference where there it's all everyone does things by themselves here people like there's a statement that I heard recently which is super fascinating right it's why service agencies matter right um I think it's because of individualism and how we as a society curb it for example someone said to me recently saying listen you can't get fired as a manager for hiring like neelen or McKenzie like if you when you hire a brand or something with repute you don't get fired which is implying that you're actually making decisions not you're actually making decisions to not get fired and or you're not rewarded for taking risks right that's why I think service agencies are are inv vog and rather or have always been inv vog can I can I frame this a little better if you're a let's say a manager at a company if you buy a tool you are now responsible for the outcomes because you have to use the tool and give the outputs if you had an agency you're like bro I hired them they screwed up their fault so yeah you don't get fired for hiring hiring neelen or McKenzie you don't T you've probably seen those funny memes right where someone's face and body take over a video right like I mean previously you needed an online tool called vigle AI where you had to pay for a subscription but now you can generate for free with no Cloud processing everything locally on your laptop okay show me something uh cool on the laptop you have okay so we have been playing with this cool new AI comfy UI workflow running on this laptop called mimic motion watch this okay that is definitely AI hallucinating right there what did what what are you doing nothing uh I think the main thing here is that look earlier all of these tools we saw on the cloud right we saw on these Discord servers and stuff and now it's all coming locally it's all something you can do on your laptop and that's like phase two of AI right like phase one was everything happens on the cloud Phase 2 is now everything's happening on the laptop this one's happening on the Intel Core Ultra powered AI PCS so let me show you how it works uh the workflow is here we'll just attach the workflow to the comments for anybody reading then you input a photo of myself and the video clip make motion extracts the movement data and then applies it to my image the AI acceleration in this processor makes generation Lightning faster it happens very very quickly it's got an NPO inside of it dude these Generations are like coming out like pretty fast it's almost real time I thought this needed like serious Hardware yeah maybe in the past but now you can do all of this with just a laptop and you guys can go check out the laptop as well just check out the link and thanks to Intel for sponsoring this video have you heard of a account on Twitter called Barry Stanton no so there's an account on Twitter okay recently it got banned so there's this guy without a DP he has he had 140k followers and he's posting the most racist stuff about Indians so he's calling the pajits he was talking about Indians and Pooh and I went through his comments right like pretty much everybody in the comments was supporting him they were like yeah Indians are like this Indians are like that like so ex had become like openly racist for a while and now this guy's got banned uh and people didn't know what to do like people like the more engagement you created the more you complained about the guy the more views he was getting no no right as of right now uh as of right now the hate on India in on X is at its alltime high I'm seeing it on my timeline I don't even engage with any of this stuff but I'm seeing it on my timeline uh I actually sent it to a couple of my friends in um I sent it to a couple of my friends in the valley and I said hey are you are you are you guys also seeing this and they said yeah we're also seeing it on X so it's not just it's not just you it is that so somebody who's done social media for a while what's the right solution here do you engage do you not engage do you go banned up and you know fight like what do you do like what what should India do because you understand this better than anybody else if you are the new clickbait it means a you did something right right so Indians Indians globally are taking more of a center stage my personal opinion on this is that the world is going to be darwinian okay because of because of you know we are now entering an age where there's problem of abundance there's too much information so we're going to have darwinian outcomes which is dumb people will get affected by the abundance of info smart people will try to readed out say okay this is not useful to me this is not good for me this is not good for mental health and they'll keep getting smarter and smarter so to me as long as the smartest folks aren't racist I don't give a cuz the dumb folks are anyway racist they're anyway going to fall for all this they're anyway going to participate like the dude behind you at the at the you know stop at the whatever um what is it nakabandi version of the US or whatever that dude is was going to behave like that he was going to ask you to go back to your country anyway he just gets more ench charged by this um so yeah I would I would not engage I would not bother I mean that's me me personally but this will subconsciously affect their behaviors because if people are openly calling Indians pajit pajit then you know let's say a Scandinavian who's like planning to hire in India will be like it seeps into their thinking no if it's openly okay we're doing this it's not it's not going to be just us it's going to be every everyone else the question to ask yourself is how do you guard yourself as an individual against this  cuz that's what I that's what I want to think like cuz I am as susceptible to this kind of behavior as anybody else so you would be off social media or you would just not listen if you're off social media that's that's the ideal or if you're on social media you want to regulate it as much as possible which is how much do I consume of it etc etc um I don't know man and for me personally I'm taking a break from you know on the streets myself you know I was doing it until last week and this week I'm like maybe I don't on the streets this week I think that could help if I stop you know each person can bring a change on their own you know interesting but I think it's just going to rise the amount of Engagement that that account got 50 people are looking at it and saying I'll do the same thing now so it's not going to stop like how many accounts will Twitter Bann like my opinion is you can't have free speech and not have some of this because you can't go around Banning every single account that posts this and everyone's seeing I'm getting so much engagement so quickly adding 10 10K followers a week it's so much faster than you grinding and like actually making AI content and running flux Laura experiments and all that right like this is hard that is easy vun please don't go around making racist tweets to get more followers I know what you're thinking no no I won't do that no no I won't do that I'm saying we've done the hard work over years right I mean many of these people want like okay in one week I want X number of followers and if the account gets banned fine make another one get get to it again how many accounts can Twitter banned because they don't have a moderation team at this point right or it's like five people at Twitter or something moderating so uh my personal opinion is I think we will all kind of say okay right now Indians are busy attacking each other India is so vast and we have so many different things I think eventually India needs to realize that there are like people outside who are in the business of demeaning India and if we we don't market India better to the rest of the world like it's an it's an advertising marketing problem if you don't market India better to the rest of the world then you dude it will happen on its own I don't know what you're it will happen on its own like if the economy grows just better quality Indians will travel around the world as they have been for for many years right like the so it it'll just happen on its own like the more the more exposed people get to it's a simp it's a simple mathematical issue right the racism against India is about hygiene etc etc all of it is a maths issue dude it's just a lot of people can't afford better hygiene a lot of people can't afford to live a live a better better life and that's what gets highlighted the more economically prosperous the country gets the better it gets the the better hygiene everybody has the more people that travel abroad the more the better behave they get all of it it takes time it's not going to happen I don't think it's not it's going to happen in like the next decade but it might take a little longer but this is how things get better okay the last thing we want to talk about today is I've been seeing a lot of tweets about Claude 3.5 Sonet and cursor okay so Claude 3 I mean Cloud onet you've used right T it's pretty awesome really good really good we've tried artifacts before but now you have this thing called cursor um which is this offline ID that you can use that uses Sonet and basically tab tab tab and it completes code for you right so now almost everyone including the top tier you know AI like kapati is like probably one of the most well-known AI engineers in the world right he's also he's he's worked at Tesla I he's done ml for practically most of his life he thinks that now the future of code is English I mean we've been saying this for one and a half years and getting belted we were doing we were showing the small you know pieces of building out a website or an app and we're saying look this is possible now and over time it's just getting more and more complex now everyone's like yo in the next few months English is like prompting is going to be how you make an app as long as you know what you want and you're able to kind of enunciate it as long as you're able to describe it well um it's can you thing to do does it make people like you feel more empowered dude like what does it do for you it's crazy so I've been playing pickle ball for the last like six months right I love pickle ball I have a gang of friends in Bombay that I play pickle ball with and it's the same six to eight people that come to play pickle ball so much so that a month ago I was like guys we should have our own app that can keep tabs on who's won how many games at pickle ball okay simple problem simple problem right or when we come it's a gang of six people we're playing for 2 hours we should have our own tournament where teams of two and we play each other there should be a round robin semi-final final so they were like oh how to do it so then I just started I ped a friend of mine who was an engineer I sat with him on clae and then we just made the app it's done now he's helping me deployed he's helping me do do all that and get it on my phone but we just had we just had and made it it's easy I just had to describe the problem I use Simple English to describe the problem saying I need to be able to enter names of my friends create teams create a round robin table okay and then just input score and then move on after two rounds semi-final final and the product management world this would be called user stories but I think uh you know we just found fancy ways outside of actually writing code we found fancy ways to Rebrand English in different ways anyway over the last decade I think that's now I mean anyone can type in English the llm will take uh you know it'll help you like if you make a mistake it'll be like did you mean this uh it's now generating code for you I think in the next one or two years it's going to generate full apps like we had a podcast with Imad on on overpowered I don't know if you know this um and he said something very interesting right he's like in a year you'll be able to build out like a full Uber app with AI in a year in one year right maybe you should play that clip how far are we from actually generating let's say a complete complex um Tech architecture like let's say an Uber app or um a level where it even thinks about the architectural decisions it has to make while coding something and not just generate Snippets if you want to build a complete replica of uber dynamically I'd say one year going to be done in a year yeah and he's pretty confident that at that point India will have to decide whether to upskill do something else then you started talking about Ubi so because India is very engineering Services driven right and and I I think one big Advantage for us which someone needs to take advantage of is we can sell our services abroad right we can still do the India to us thing but say now we have ai assisted engineers in India who can who can you know at $30,000 a year who can do what people in the US do at 100K a year so I think there's still a very big opportunity for Indians but especially American Engineers because of their pricing and you know the fact that Alternatives already exist and now ai is coming they are going to be like first in on The Chopping Block yeah it's a legitimately it's it's a legitimate problem to solve I agree that was a good episode I saw the episode of the mon anyway awesome so I think um good good episode I think we CAU some interesting stuff and every 6 months I think the tech is evolving to the point where where a year or two later we'll probably be making full movies with AI yeah uh cool looking forward so that was a writing a movie so I should probably just junk that anyway good chat see you on the next episode bye ",
    "url": "https://www.youtube.com/watch?v=kQHkOqUIiAg"
  },
  "CVtUwGP_h38": {
    "published_at": "2024-01-03T14:09:06Z",
    "title": "Midjourney might get sued?",
    "text": "Midjourney might get sued? so mid Journey V6 is really good but I think they will get sued so if I do Thanos movie scene uh I'm just doing V6 and this looks like it's been in the movie it started to look like they're overfitting how can you tell when something is overfitting it looks too similar to the original images prompt was in a movie scene so it's supposed to generate something that looks like it's been a movie and then the it generates it and then you're like it looks like it's been a movie yeah that's what the promt said correct but whatever said and done the model is not supposed to reproduce the training data that's when you get into trouble and also why did you train on The Avengers this thing when you probably don't have copyright for it like there's this guy on Twitter who showed the original Joker image and then he showed the image that mid Journey generated with the prompt Joker in a movie and it looks almost exactly the same also mid Journey did something very strange they deleted everything he ever prompted from his gallery for calling out their plagiarism and copyright infringement and that is definitely something that you can go to court with and be like look it's they they're reproducing the same thing and they're charging me whatever $10 for it",
    "url": "https://www.youtube.com/watch?v=CVtUwGP_h38"
  },
  "U3oDzjeTrCo": {
    "published_at": "2023-07-05T11:30:11Z",
    "title": "Transform Logos Into INSANE Animated Scenes",
    "text": "Transform Logos Into INSANE Animated Scenes there's a really cool thing that people were doing with control net where they were giving a reference pose and they were creating like these really fun videos of you know their company logos can we demo that sure let's try the Nike logo logo black and white actually let's take the with the text yeah let's see what it does we're just gonna drop the Nike logo in I'm gonna say let's say top view of a city with skyscrapers and buildings and trees the ideal output would be if it populates  me that's killer yeah that's killer let's try Superman let's just see what happens if types of man this is a human I'm prompting it for let's see what happens top view of footprints in snow or Tire prints in snow that should be able to generate like tracks let's see tracks oh that's pretty good",
    "url": "https://www.youtube.com/watch?v=U3oDzjeTrCo"
  },
  "TCYa4wxqZKA": {
    "published_at": "2023-06-25T11:30:16Z",
    "title": "Create Logos Using Midjourney",
    "text": "Create Logos Using Midjourney so right now we're gonna try and create a logo on mid-journey okay robot sitting in front of a computer laughing Vector our logo simple lines graphic design okay so it created these characters these are boring retro stamp of a smiling robot showing the thumbs up oh I love the first one it's angry or it's sarcastic or whatever yeah eventually you'll have haters and it's a great thing to show them let's do a variant of the first one let's put the word cute minimistic logo commod dribble now type whatever you want  this one is nice now I like this I like this a lot it's got six fingers oh I think we should keep the sixth finger yeah just as little homage to the early days of AI yeah very early days",
    "url": "https://www.youtube.com/watch?v=TCYa4wxqZKA"
  },
  "Dp8NmWo43GI": {
    "published_at": "2023-12-17T16:40:09Z",
    "title": "Sketch to App using AI",
    "text": "Sketch to App using AI let's simply draw a very simple calculator oh wow okay so this is a simple box all right so now we're done drawing I've just clicked on Make It Real let's double click to interact this is crazy this is the coolest thing ever there's something called TL draw which just turns sketches into applications Sid what is this about TL draw is essentially a blank canvas you can basically draw whatever you want and you can make anything from a landing page of a website you can make a game you can make whatever you want all you need to do is you need to click this button called make it real and it makes it real it's built the front end it's built some logic can it also do back end no I don't think it can build a back end it can just build like very basic front-end based apps which has like pretty simple logic you're using GPT Vision it's going to look at this and it's going to write code based on what it's looking at interesting I mean the fact that you can actually just make a sketch like this and get a complete app out of it it's pretty mind-blowing it's something that I would have not even thought about last year when gbd 3.5 came out",
    "url": "https://www.youtube.com/watch?v=Dp8NmWo43GI"
  },
  "fvnpZO78jbQ": {
    "published_at": "2023-06-03T14:42:26Z",
    "title": "Tanmay Bhat Builds an AI Joke Generator",
    "text": "Tanmay Bhat Builds an AI Joke Generator okay you have some ideas okay but you can't build apps because unfortunately you didn't learn how to code tell me what you want to create I probably build like every hour show me a joke I just want to click on it and there's a new good joke every time I click on it actually you can do that that's the easiest thing to do okay so let's do this a manifest V3 Chrome extension okay to generate a joke and then show the setup and delivery part it's done let's pray it works so now we go to Chrome extensions we load this extension okay we're done documentation is like sex when it's good it's very good when it's bad it's better than nothing all right next one next one click out and click back in did you hear about the claustrophobic astronaut he just needed a little space okay got it next one I have a joke about trickle-down economics but 19 of you will ever get it it's pretty good it's pretty good it's really good",
    "url": "https://www.youtube.com/watch?v=fvnpZO78jbQ"
  },
  "rKVGN6zhicY": {
    "published_at": "2023-07-04T14:09:09Z",
    "title": "Why AI Can&#39;t Produce Bollywood Films",
    "text": "Why AI Can&#39;t Produce Bollywood Films if I own a production company right now that produces specific scripts like there's a script that's written with a celebrity in a specific manner where they need to behave and say a certain line is my job in danger because of X2 video generation no I think she has a director right you want that final control you want Alia Bhatt to look slightly 35 degrees to the left saying something and putting her hands up or being super excited there's a reason retakes happen right the problem with this is like right now we're generating stock footage right but let's say the entire segment is a minute long do you have the energy to look at a thousand different generations of a minute long video and then pick the right one and say oh this is the base there'll always be something you want to change but on set it's very easy for you to change that right for you to say okay move to the left slightly do this slightly do this slightly and directors 99 of the time whatever I've seen they're always asking for micro changes so production companies can breathe safe or not yeah",
    "url": "https://www.youtube.com/watch?v=rKVGN6zhicY"
  },
  "10b6Sb1GADQ": {
    "published_at": "2024-01-01T12:12:02Z",
    "title": "Meta Ray-Ban Smart Glasses are Super Amazing!",
    "text": "Meta Ray-Ban Smart Glasses are Super Amazing! so if you long press on this button it starts recording video and this is the screen that you currently have um if if you see around it captures everything and then you press it again and it stops recording dude this is too good it's very good dude honestly this audio is better than most AUD heard yeah it's like iPhone audio and the video quality is also pretty decent it's pretty good if I say hey meta and I can say play me Spotify call call my friend Raven the speakers on this are God Dam okay so now on the next update I was reading that they're going to put multimodal AI models on this MKBHD got access to the AI pieces oh really hey meta look and tell me what you see I see a person wearing a black hoodie and jeans standing in front of a large window with a camera held up to their eye I'm super excited dude all of us run around with like basally God on your shoulders",
    "url": "https://www.youtube.com/watch?v=10b6Sb1GADQ"
  },
  "MiVp4wFlpjQ": {
    "published_at": "2023-07-26T13:30:08Z",
    "title": "AI Predictions With ex-Applied AI engineer at Stripe!",
    "text": "AI Predictions With ex-Applied AI engineer at Stripe! all right ladies and gentlemen we're on another episode uh and today I have somebody very different usually I have tanmay but today I have somebody called Yasin and Yasin is from Canada and he used to do applied AI at stripe in fact you're saying thanks for thanks for jumping on I know it's you know it's hard to do scheduling over the Internet these days and you know I'd love to kind of just hear your story and maybe it would help for the audience as well because I'm gonna ask you see some some really difficult questions thanks for having me remember awesome so Yasin we'd love to know about your history at stripe what you've done in the AIML world and you know then we'll jump right into questions I kind of started out my career as a software engineer I came to Canada the reason I do computer science is because my mom told me to do it so I listened to my mom same here moms are always right so I listen to my mom and ever since I listened to my mom I've uh had my career kind of progress in a very positive manner I've actually for most of my career I worked in the offspace and I switched over to MLS right unless they're a little ladder part of my tenure there and I would described the work that I do with ML more on the applied layer rather than the development research and development layer so there's um the stuff can get really really deep and complicated but I'm more focused on bringing it to people uh so at the latter part of my tenure at stripe I decided to just go independent so basically I just find people online they find me and I just help them fix their problems I tell them what they can do what they can't do I build prototypes so sometimes you have a question is this possible I think it might be possible I can help you prove that as possible by just doing it so that's kind of what I've been doing it's been super super fun it's been very nice to help people in my locality rather than working with folks in America it's nice to help people in Ottawa it's nice to you know meet people with people in person so I've been really enjoying that awesome and and how long have you been doing it and all I've been doing it for a very long time but more of a hobbyist a more as a hobbyist I think my big ml my first big ml project was um I got a bunch of models from Google to count how much reps I do in my gym so I have a home gym at home and from the video I can count how much reps I've done of like you know squatting or like and what the foam was and stuff it's not I I didn't get that far but I did was able to like label what like the brand like I was bench pressing I did four reps like the actual repetition uh you can't get the form now what's really cool is this project wasn't even that long ago it was like two years ago or something and the fact that if I did it today now it would actually work way way better kind of talks to it kind of speaks to how fast the field is moving it's been kind of astounding it's been somewhat shocking to a lot of people how quickly things are changing and and this was what like five years ago six years ago um so this project was two years ago it was my first year of this project and then before that was mostly just stuff at University I when I started out my career I was trying to decide whether I wanted to go more of a data scientist route or um a software engineering graph so I did was I scripted through indeed which is a job post board in Canada and then I plotted out the salaries for each one so data scientists expect a salary and then the software engineer accepts a salary and then I just found that software Engineers ended up making more at the time so I went I just like spec out and software engineering so yeah the reason I asked you how long was it just to know whether it was pre-gpt I mean GPT wave or post it seems like you've been around for a while you've done this before the era of chat GPD how big a difference was you know the first chat interface for people to go and like finally meet a cognitive rival GPD three yeah that would be I can't believe how different it is before the first wave of AI companies was in 2016 what it ended up being was you could only build these very task specific models that did certain things for example um being able to differentiate between like let's say you're selling bananas and you have a conveyor belt of bananas and you can look at a banana and say is this banana good enough or is it bad and you had all the memes the cat dog memes exactly like the cat dog and even that it was kind of difficult and didn't work most of the time the cat was sitting on the striped carpet then the model will get confused yeah um so there have been a sequence of things being figured out uh and I think people could probably if you use a lot of YouTube you might have noticed a specific point in time where the comments were awful and then all of a sudden all the comments were good and I think that was the moment I think it was like around 2019 2018 or something I think that was the moment where it's like we figured out something fundamental and I think that fundamental thing was if you throw the kitchen sink as in you just self-supervised pre-trained models so these basically you throw all the data at these models and you just make them very very big you get something that is a lot more General and adaptable so then you can give those models out to people and then they can build different models using that as a foundation I think that was like one of the big uh shifts and what ended up changing is now you have you're able to make these products that are actually more consumer focused right like people like you and meaver and are ones who are benefiting from it because now I can go to gbt and just ask a question like when I saw that I kind of I lost my mind for me it was a clip I think that was my moment when I saw you're talking about the image captioning yeah exactly the image capturing so click and uh basically the first generative uh models that could make images when I saw the fact that you could just generate an avocado chair I think icons are losing my mind yeah and I I don't think my my shock wasn't complete because for me that was I didn't I couldn't touch it so I was a bit skeptical still and in my mind it was always going to be stuck in some sort of super computer at Google I can't run on my own compute my own computer yeah but then stable diffusion came out and see all the fusion so folks listening is another image model but what's different about this one is that it can run on your computer as in you're not connected to the internet and then I used it and I think that was the moment where I realized that all the large models are going to fit on people's computers yeah and I think I was kind of right and making that prediction I think it was like eight months ago or actually a year ago now I wasn't even making that prediction because we have a new um chat model from meta that's approaching the it's approaching the capabilities of GPT 3.5 so that's pretty incredible so um would it be safe to say that you feel like the future of um generative AI tools are eventually going to be OSS they're going to be open source for everybody to just run locally on their computers um you know you were talking about stable diffusion right I have the same thing right like I had the same sort of experience um I hadn't actually tried my journey this I mean I'd seen outputs from the journey but I was like hey I'm not going to go on Discord and like it seemed cumbersome but you know I saw automatic one one one and people just said hey you know you run five lines of code and then you have it you know on your desktop I said let me try this and my first experience with automatic 111 was bad because if you've seen the default Sable Fusion 1.5 model it's terrible right so I tried it and I was like hey this is not great right this is this is it's okay like it may get better at some point and then somebody linked me to another model I think it was called protogen or something like that right they just said hey this is a fine tune stable diffusion model so I said I'm going to run this right and the results are great and that's when I also realized hey automatic one one one one is not just um it's not just you know to run the model it's also do a lot of things on top of it right like you want to in paint you you wanna uh upscale so it's all it almost felt like uh almost five six years ago when I tried Photoshop I think I tried Photoshop a long long time ago when I tried Photoshop I was like wow this is cool this has all of these you know 20 30 50 different tools that I can use and put together and then I'm gonna put out some nice piece of art I felt like the ability to run on my computer pay essentially zero except electricity and the cost of the the GPU was nice and humbling and you know I've been looking for that with with the chat models as well um but yeah do you feel like eventually this is all going to be in the domain of Open Source do you feel like the winners are going to be open source or is there still going to be like um you know the the chat gpts of the world the open AIS of the world it's it depends on how you slice it there's going to be different models for different things I think stable diffusion Open Source One in control mid journey is better in Fidelity yeah but control is so so distract control instead of using Photoshop I can take a picture of you right now and then I can make you look like Showtime right I can do that yeah and you can't do that with mid Johnny like taking the same picture because there's the journey is very like um it's a very deep vertical it's like we're just gonna we're in research engineering seeing some of the smartest people in the world all working together with the GPU cluster right behind them humming and they're all just trying to figure out the best way to make it look better but every but the control part is like there's so many different people with different things that they need to do like for example you need to make a uh face swap uh or face swap or a thumbnail right for your for your podcast and then someone else needs to like replace like or sort of make their house look prettier or figure out how to have the same room so there's all these different things so you're saying the niche use cases will be owned by open source exactly or like open source will do a better job at finding the wider set of use cases right got it and for example I'll give you an example with uh sort of gbt or gpt4 gbd4 is very very good it's extremely smart but it can't do certain things there's certain things they just can't do as well as a model that I just have so that's strain for that use case for example the API one like gorilla exactly gorilla is just it's just going to be better because it's it's there's a team of people all working on it and there's there's more of them than open AI engineers and opening AI Engineers are focused on just one thing making AGI like making something as general as possible so I think that both closed sources and open source are going to be here and both of them are going to aim at two different verticals right so uh that that's what I think in general depends on who you are right if you're kind of a techie person who likes to mess with stuff you're going to be doing open source if you're going to be working as a sort of Applied AI engineer you're going to be working with open source most of the time and you're going to be using closed Source models when it makes sense um because it's just more Capital efficient so it depends but for me personally I will be using open source models more than close Source models because I think for a lot of folks in the community it's almost a philosophical stance where it just there's some comfort that you get from knowing that you're self-reliant um it's like knowing that you can fix your car if it breaks yeah right yeah I feel it too and the reason I think open source will eventually win is I think it's just it's just numbers right I think there are far more open source smart hackers somebody sitting in I don't know some corner of the world that you've never heard of that Google can't actually you know hire from who's like hey I'm gonna build the best face swapper for you know uh the any outputs from stable diffusion right and some guy somewhere on the world is going to be like hey I'm going to build this very specific thing for chat models so I feel like it's all these really smart people from all over the world this it's it's technically what the blockchain came up with right like hey decentralize everything everyone's going to contribute I feel like that's actually happening and you know there is still a little bit of you know somebody at automatic 111 is deciding which of these extensions is going to be in the official extensions page and which of these are you know extensions you'll have to go dig find pull out and put back into the central UI right so uh I'm a big OSS um fan and I think it's gonna eventually end up there but you mentioned AGI and you mentioned that the end goal for an open Ai and maybe even Google is to eventually build an AGI right um and these are all sort of short-term goals uh now I've heard the thesis that llms are sort of an off-ramp to AGI it's like it convinces a lot of people that hey if you keep making llms better they're eventually going to become AGI um those people are proponents of language is the seat eventual seat of intelligence uh another is like Yan who says that you know that's one way of doing it and we're probably gonna have to come up with something else for AGI what's your thesis on this it's really funny I don't know I I think gpt4 is Agi it's a Continuum right so I I do think open AI is I mean they say they say them that much themselves that they're trying to build AGI I think gbt4 is the closest thing we have to Asia today I think it is Agi if you ask me though I'll tell you that lava is Agi because it's General it can do most things quite well and I'm pretty convinced that if you just had enough time and you sat with it and you did what you got a less academic version a less rigorous version of look Coons Japan and you just hacked it together and just like had five llamas talking to each other the right way I feel like you could have something that's kind of convincingly um General and acts in the world I mean it's gpt4 is smarter than my cat maybe my cat's more you know General in the sense of of it can land on its feet yeah I can land on his feet you can like ask me for food you know my cat is better at being a captain gpk4 but I think gp24 is a lot more intelligent than my cat um yeah like there when you when uh open AI released their paper about gbt4 they spoke about how they have this agent framework where it went to taskrabbit and hired a human I think part of that is probably PR but I also don't think it's not possible yeah um I mean to me it's AGI I feel like AGI is here I feel like it was here when gbt3 was was around um and I don't necessarily think it's language I think it's just the discovery that if you throw enough data that fits some distribution you can model that distribution really really well in a way where things that are integrated so basically all the knowledge that it has it can integrate that knowledge together so you can ask it two things that it's never seen to put together and you can ask that to put it together I mean come on like I think Elias has this pretty well he's like hey if you if you build a next word predictor it turns out that it has to First build a model of the world right to predict the next word accurately so you're asking you asked it for something else you asked it for the next word but what you got was something that understood the world in its own sort of way right um that's fascinating what happens when it gets smarter than us I mean it's already smarter than us but like what happens when you have a magnitude 10x or 100x Improvement does it start you know one one thesis around this right like I'll just paint a picture for you which you can sort of you can you can navigate into two different parts one picture is hey it's just it's gonna have more accurate data it's just going to be a tool that we use the other path is well here's this thing it's a god-like entity and you can ask it a question but it actually doesn't care about you it's like ants don't understand the system of justice right the human justice system um do you feel like it's gonna get to a place where we don't get what it's doing or do you feel it's simply going to become a more powerful tool well we don't really know why it works today yeah I mean that's why that's why you're like I don't know like better probably spends in the order of like Millions like oh over here in the dollar at least um trying to get llama to do what it wants to do using rhf like we knew how it worked we wouldn't have to spend so much time getting like humans to label it right um I don't know like so I think you asked uh do you think that these models are going to get smarter than us and if they do get smarter than us what are the implications do they become tools do they become better tools or do you think they become intelligent creatures with agency where we don't know what they're up to we do have intelligent creatures with agencies that we don't know what they're up to and they're already Tools in a sense and those are just employees right you just have to align their assignments and it's a problem that we're really familiar with I think this is going to be kind of an alien thing that we're not really familiar with that much but it's also a suitable thing I feel like these models you can just effectively program them to have for just as much or just as Little Agency as we need them to be and my hypothesis is that humans are going to rather have something with very very little agency and it's actually just a predictive extension of what you want so all the model we've programs to do is to figure out what you want an actual individual human and then acts based on that and then you just like a manager who's like breathing down someone's neck watching them work you can just kind of micromanage the thing and effectively that's a part of kind of already what we do like uv4 have no agency it's not programmed to do anything if there's no human interacting with it it says nothing um and most people when they build systems that perform well they have a human in the loop somewhere or they have some sort of control mechanism to make sure that's like hacked out of out of distribution um so I think it's going to be more tool wise and I think even agentic things are still going to be tools right like I don't know you have Harry Potter and Harry Potter there's Dobby Dobby's a house elf who like you know cleans the house and stuff like Dobby is effectively a tool that has its own motivations and might try to trick you but it's still Dobby at the end of the day and I feel like I feel like the sort of I'm I'm fairly optimistic that these things aren't going to go out of control we just need to be careful with software in general you have to be careful you have to like write test Suites you have to be um aware of the distribution of behavior like the thing that you're releasing out into the world has but he also said we don't we don't understand it very well so it's hard to test for something we don't we don't fully understand well there are things that we do understand for example if you plug it it turns off that's that's like one thing we do understand right so there's and then another thing is um so like when you're building a system unless you use your gp4 you have the hallucination problem right like it might hallucinate uh a really great way to stop it from hallucinating is to only have it output two labels and then if it outputs another label then you just throw an error so there's like things you can do to like constrain Its Behavior even though it's kind of like a black box another way to describe it is people use database indexes all the time people use databases no one knows what's going on like like the the NBA and the hard drive switching like exactly like no one knows what's going on you just write an optional test the functional test asserts behavior and then you're good to go I feel like once we get to the ASI bit where we have this agentic thing that is extremely intelligent like super intelligent um I feel like the problem will be solved I just have a really strong feeling that it's going to be solved um maybe it's a blind optimism but I also don't think that I think part of my optimism or lack of pessimism relates to the fact that I don't think we understand what we mean when we say smart for example if you said gpp4 it might be smart but a lot smarter than most humans yeah in some Dimension but humans are smarter in other ways like they can understand human reactions and amplifies with you is better so um gp4 is smarter than humans in the sense that it doesn't need to sleep and it can just keep on working all night it's GPT Force faster in a sense that you can parallelize it and then you can get more work done like you can scan a million documents all you have to do is set a million API requests yeah so there's different dimensions of intelligence and some might go further than others and and I mean AGI ASI is like I would say one way one problem statement the other more immediate problem statement is well this definitely is going to take some jobs a lot of jobs right if I had to pay for an artist is very few cases where a mid-journey wouldn't suffice right even newborn spending your time to find an artist you don't have time you're busy you got things going on you got like podcasts to run you got editing to do you got people to talk to you like you're not gonna go find an artist on Fiverr and then look at their like that's too much work you just go opening up Fiverr is already too much work yeah what do you think is gonna happen to those people do they do they go back like revert and go do stuff offline I think artists are kind of screwed not gonna lie I think they were screwed for a long time I think like country wealth is like sort of burrito distributed so if you're in America and you're an artist well you're all like someone in the Philippines or Vietnam is going to outpart you and they're gonna charge like way below and you're gonna make a lot of a lot of money for their for their locality so if you're an artist already in America you're kind of screwed and I think that in general those folks are going to kind of benefit because they're going to be able to do more business and the skew of successful artists is going to get even worse so there's going to be one guy who's doing like 100 gigs a week uh thanks to Ai and his brand name exactly got it it's kind of scary when you think about the implications because what's really sad is a lot of these skills take a long time to invest in and effectively what's happening is that that investment is becoming worthless it's worthless right and I can relate this to as myself right a big part of my skill is that and how I make money is writing code and that's all I don't know people know but gp4 is a really good programmer yeah it's solved but the way I've been taking advantage of it is that I can get work done for my clients faster so I just like charge more and get more work done in less time yeah they end up paying the same amount and I get to barbecue in my backyard more so it depends on how you interact with it I think it's also about domain knowledge like with code like I've seen GPT and copilot do their thing right like every engineer in in my company now uses GPT all the time right they're just like they become 10x productive the output is 10x and you know because I have so few Engineers uh it's in the double digits compared to companies with like hundreds of thousands of Engineers it's it's become far more convenient for me to just have them and be like hey can we try four more experiments can we try five more experiments so I feel like junior level engineers and there is a breed of engineer by the way like the state of Engineering in India is like really poor like teaching software engineering people go to college they learn they're still learning asp.net right they are zipping their code and then emailing it to each other like it's like it's in the dinosaur era right um and I feel like those people are going to be in trouble right whereas I would still hire somebody super experience with like let's say 10 years of experience in a domain let's say I want to pick the best engineer in edtech right so I'd look for an engineer who's worked for 10 years buildings that sort of software because he comes with experience he or she comes with experience Beyond just the engineering skill set right and the engineering skill set itself has been tried and tested right he's tried 50 things and like failed at 30. so he saves me time so I'm essentially shortening Runway having him on so I'm saying hey if I hired a junior engineer this would take me two more months I have this person it takes me to to few months therefore I'm able to you know invest um and and try two more experiments in the same time period right or compress time so I I agree with you I think there are going to be 10x or 100x Engineers but it's going to come at the cost of a few Junior Engineers same with art right like imagine being a not so great artist right now yeah I'll be shaking my Boost yeah but what do you think about offline do you think they're going to transition offline do you think that going offline is like a safe job how would it say forever but like for now I don't really know that many people who buy it or that's like physically paid no no I'm talking about I'm talking about going in and working at a gas station or driving an Uber that's a really good question I think Ubers or Fox um part of my language I think I mean just like local waymo in California that's not that's gonna hit the west of the world really fast it's just so Capital efficient um I might begin to sound very conceited so I apologize in advance but there's a difference between real work and fake work and think work is work that you do to like look good and then kind of put yourself into an institution which is comfortable and your goals aren't actually aligned with production if you're trying to produce anything if you're trying to produce anything you'll be fine for example I don't think plumbers are ever going to be out of a job because plumbers are abstractly what their job is is their job is to fix things right they go to a place and they fix things that problem of abstractly fixing things if that's what your job is AI is going to help you make more money because that because you're going to fix more things and there's very tangible Roi to the person paying money for it exactly and this this kind of relates to software Engineers as well right there's I've been talking to folks you know all over the world including India and there are some kids out there I mean there's this one guy who set up 64 raspberry pies together and he's having llama run on literally 64 computers in a cluster there was like super cheap commodity computers and that person is just going to be able to get more stuff done but if your goal is to pass an exam you're not actually producing anything even though it's very important to pass the exam you're optimizing for something that's not related to cash exactly you're not optimizing for something that creates value so if you make your job a person who fixes problems and creates value and then that gets automated well the good news is if we fix the abstract problem of fixing any problem then we all get to relax and we don't need to fix problems anymore and we get to go and barbecue in our backyards so I feel like as long as your your job is I want to fix a problem so if you're an artist and your job is to go make art that is beautiful to people and that they're very happy with it and it brightens up their homes and you go meet people and shake their hands and you get to know what their problems are or you get to know what they what part they're looking for stable diffusion just helps you it helps you come up with ideas it helps you create new things faster it helps you fit the fit the expectation better so that artist is going to be fine um so like I think it really depends on your it's more about how honest your attitude is around work rather than um the type of job that you have so yeah like I think a lot of people are going to be okay because a lot of people just produce and at the end of the day there's it's going to help people as well learn how to produce because it's going to tutor them through it they're gonna like for example I don't think you really need to go to school anymore to learn how to code you could just do like software off YouTube like Khan Academy you don't really need to go to school I'm optimistic about it I think a lot of people are screwed but I'm sure they'll figure it out yeah I mean it's happened before I mean not not this scale and it's never been a threat to cognitive ability but it's happened what do you think about eventually like a GPT sitting inside of a Boston Dynamics robot and doing the plumbing as well I'm kind of like ugly optimistic that's going to be somewhat solved I don't think that Joe's robots are going I think it's going to start out with you having a co-pilot that sits on your shoulder and kind of tells you what to do and helps you analyze the situation better like thinking like kind of extrapolating out in the future like you're wearing an apple Vision Pro headset or like a you know evolve Decker headset and it's kind of labeling everything around you telling you exactly what to do what to fix yeah a lot of doctors have this they've got like this robotic robot assisted laparoscope laparoscopy I don't know how you pronounce it but they got this camera it's going inside the body they've got a screen and now they start labeling our items on the screen they're like hey this is a this is you know uh not supposed to be there right I don't understand the space so well but at least robotic surgery but I think a lot of people are going to be assisted but what what I was saying is that at some point you're gonna have a robot walking around making decisions on oh that's broken I'm gonna fix it no that's gonna happen like I mean we didn't already see this happening today with the drones they're like picking apple trees uh the robots that kind of go over um new seedlings and then laser they like laser uh and they figure out whether they're ripe or not exactly like there's like we're already beginning to see robot Automation in the wild and I'm not sure if it's going to be a humanoid looking robot but the fact that we have these drones you know running on computer vision and so I and so it's a listeners if you think if you think that text models are insane and image generation models are insane computer Visions progress the ability to understand what the computer is seeing the like speed at which that is progressing is genuinely astounding I cannot believe what people are doing with um you know Facebook's Dino V2 can you give us examples here's a really good example my wife has a basil plant and there's beetles on the basil plant they're they're kind of pests right I took a picture of it and then I fed it to a fast segmentation model I described beetle with my keyboard and it and it knew where the beetle was like that's like that's a new thing like the fact that you can segment any image and then you can immediately identify where the things in the image are that's completely new the fact that it runs on a potato it runs on a potato like relatively speaking if that system fast Sam runs on a potato the thought that I can do that and segment anything is as astounding like that's I could plug that into a robot that like sort of aims and then zaps it shoots yeah you can also do that with humans I mean I'm pretty sure the Army is going to have some sort of system that can just say hey that's that's that's the thing that moves that looks humid let's strike it down yes if they I think like the first thing we're gonna do is Beatles and then the next thing we're gonna do is humans or the other way around depending on who's who's faster interesting you know it's all this has happened in the last like two or three years I don't know I I just feel like 100 200 years in the future I I just can't extrapolate I think I'm smart but I'm not as smart as an ASI that's that's had 20 years to do the work yeah I mean it's be an answer I don't know if it's because we're kind of in the field deeper in the field and we're kind of looking closer at it but this rate of progress is nothing like I've ever seen before in technology and what's kind of shocking is how wide the area of progress is so it's generative AI it's you know all text-based processing it's computer vision it's we're getting so good at processing information in certain ways that we want computers to process our information it's it's shocking like what's terrifying for me is I can't even tell what's going to happen in a year let alone five years um I I don't like I I need to be careful to not over uh like signify what's happening it's just technological progress so I think a really good way to temper that excitement is thinking about phones they really did change things for us like phones changed the way people live their lives you can kind of summon an Uber wherever you are that's pretty cool it's a magic one it's a magic wand right but at the end of the day humans are still humans and in fact my life didn't really change that much I still need to eat sleep and take a crowd every morning right so I think things are going to change in exciting ways especially for me as someone who uses technology all the time like I'm just like using my computer and there's so many different ways I can now change my computer to be to behave better for example I can automatically detect ads my display manager and just send through the control net or something I'm not ready I'll control that with a fast segmentation models so I mean they're cool things for me but I think that it's going to be very good quality of life improvements it's really hard to know where the sort of five-year extrapolation is going to go because but but you're not a Doomer like you don't feel like one crazy person is gonna like you know I think one crazy person is going to make a male aligned artificial intelligence I fundamentally believe that it doesn't take that much compute to run these things like I think that consumer Hardware can place a male aligned artificial intelligence I just think it'll be solved the same way that you have male aligned humans and also like mountain lion cats right we still haven't figured out how to get our cast to behave properly when they interact with another cat or a dog which is so stranded exactly you're just restraining I think it's kind of solvable in that sense but it gets hard to restrain something that gets smarter over the years that's the only child we don't know how to restrain it apart from pulling the plug and it you know if some person sitting in Bahamas and it's hard to go physically access the plug then it's going to be out on the internet that's my biggest challenge like I feel like like the air gap is is hard to overcome in some ways I don't really know how we're going to solve that problem but I'm sure we'll figure it out like I don't know I'm just really optimistic I I'm part of part of my part of my sort of part of mine hesitancy to care that much about it is because I think it's somewhat inevitable that we have AGI and Madeline DJ yeah well in metal energy or rather humans I think it's inevitable that humans are gonna be able to do whatever they want and I'm just gonna be a crazy dude somewhere but I'm also a very optimistic in humans humanity is capacity to fix problems and I try to avoid fixing problems that aren't immediately here and there's like way bigger problems I feel like one of the things I'm really terrified about is um artificial intelligent companions where it kind of messes with Humanity's uh social structures it might be for the better you're talking about virtual girlfriends and stuff effectively yes that's how it's starting out I mean it's really funny like I could have told you last year you're like oh yeah they're totally gonna happen in a year and then you know six months later I go on you know Anonymous image boards and all I see is people posting about their you know simulated girlfriends and I don't think it's particularly healthy to do that um but on the other hand we have Tech talk and you know Instagram reels and all these apps they basically brain Jack you right and I think humans kind of can adapt pretty well to those negative scenarios I'm more worried about the sort of new year-term things and sure Asia has to be a problem and we'll figure it out this year and it's not really a problem yet to be honest awesome last question okay I saw one of your tweets I don't know whether you're talking about intelligence or Consciousness and I have a specific you know line between uh both those things you were talking about hey everything on the planet including a rock has some level of consciousness right now I don't know if you use the word conscious or intelligence um sometimes Consciousness I read this book by Douglas hofstaddo I'm pretty sure I'm butchering his name but I read the book and in the book it's called I'm a strange Loop he talks about how there isn't such a thing as self right like the your identity is is a story you constantly tell yourself and then he goes on to propose an even more crazy proposition which is that yo if you take a bunch of Cola cans draw wrap a wire around it then that system is conscious just not as conscious as human beings right so and and Sam Altman said the same thing but then he came under Fire but I'd love to know your thoughts on this and feel free to be as crazy as possible like be honest yeah pick Doug is probably right um I I the reason I say rocks are cautious is because I'm pointing to the absurdity of this High significance we ascribe Consciousness so my thought process is kind of similar to Doug's where it seems like something that just happens in our universe would matter if matter processes information a certain way I take it to the Absurd extreme to prove a point and I say oh rocks are reflecting light which is information in a sense the processing physics yeah they're processing physics in a certain way and therefore they are conscious I mean I fundamentally believe that sort of if information gets processed a certain way then it is cautious in our universe probably gbp4 if you Loop it around that's probably cautious and it's probably a Continuum right because I can pass out and there's a drop in my Consciousness so it's a Continuum um yeah and I I don't think it's I think it's a really it's a really curious mystery of your universe and we may just solve it by throwing data at it yeah we might just solve it we might already be cautious in its own way it's as far as I can tell I'm not really doing anything special other than information processing I think a lot of people come to the same conclusion too and I but I I also like would say that like uh I would warn people I I like generally the reason I take that absurd stance is because I want to warn people from the dangers of putting too much significance to it because a lot of things are cautious and it doesn't really matter yeah Consciousness doesn't mean doesn't mean we're special in in some way right like we've always held it as the seat of hey we're special but then we did that with the Earth right we said hey the assistant Central the universe uh and then we got humbled so I feel like we might learn that we're just like we learned with one out of so many other planets um we might be one out of many other conscious species and maybe even you know uh eventually have a true cognitive arrival and it's going to go beyond beyond at some point I'm excited I just want to know for sure because it would be really interesting right it's like very very exciting I know this is something I've been thinking a lot about since I was very young so it's nice that we have an Avenue for an answer now before it was we'll never know why and now we're getting to a point where actually we might find out yeah that's cool it's the right place right time I think we're the lucky ones in a way awesome thank you so much Yasin for for joining us and uh you know I know we took a lot of your time but I I had a blast and yeah I I hope you'll come do this again with us uh hey thanks man keep up the hard work I really appreciate your interview style I really had a good time and thank you for sort of having me on and talking in general I like talking to people about this stuff because I finally endlessly fascinating so thanks ",
    "url": "https://www.youtube.com/watch?v=MiVp4wFlpjQ"
  },
  "-nE6rl_l0UE": {
    "published_at": "2024-07-25T01:00:00Z",
    "title": "Claude Artifacts is Insane!",
    "text": "Claude Artifacts is Insane! can you believe it it made this on the flight crazy crazy crazy what is artifact it's sort of like their code uh runner but it's a lot better than gpts so I have an idea okay create an artifact of a tamag GOI that I can interact with and feed via buttons the pet should be animated let's see if this works if this works I'll be mind blown okay so it's writing code for my tamagochi pet created a react app where it's created a pet for me so I'm going to feed it and as you can see went up I'm going to play with it as you can see happiness went up I'm going to play again and as you see every time I'm playing the energy is going down the happiness is going up and see the hunger is reducing over time the happiness is reducing over time this is really inaccurate cuz I have a Labrador and I can tell you you need to feed them way more what happens if it goes full better it died yeah it died can you believe it this it it made this on the Fly and there's no way to this is executing the code within within clae itself yep it's called an artifact so I use artifacts for all this stuff wow",
    "url": "https://www.youtube.com/watch?v=-nE6rl_l0UE"
  },
  "W2MtjMevoUY": {
    "published_at": "2023-06-23T13:05:55Z",
    "title": "Now You Can Create Product Shots in Midjourney!",
    "text": "Now You Can Create Product Shots in Midjourney! I read my journey has had an update maybe a month ago where they now do product shots really well okay so product short of coffee packets minimalistic black logo brown coffee packets of a company called Ghost House Coffee so check this out okay dude this looks professional as heck you can put this on a website almost immediately this gives you such a killer idea of what your brand will look and feel like when it's on a product so great mood board by the way there's something called chaos and mid Journey did you do the same thing brown color now dash dash c space 75 between every generation it increases the randomness of the Next Generation so it gives you more varied outputs all this High chaos okay yeah so the it's more variable yeah in its Generations yes this one's really nice yeah do this damn book yeah holy that's so good",
    "url": "https://www.youtube.com/watch?v=W2MtjMevoUY"
  },
  "e6a5jPRAR9c": {
    "published_at": "2023-12-20T16:09:48Z",
    "title": "Turn your Sketches into Games and Websites",
    "text": "Turn your Sketches into Games and Websites tell me if you guys can actually identify what this is yeah yeah this is that game it's a paddle game all I have to do is select all of these things I'll be mind blown of this works head on Make It Real that's pretty insane wow it even said you win congratulations it's it's pretty cool I think we're now at the era where you know you had those games in in those 1990s computers which I think now you can just have the computer do this in English and you just like label it and it just does it for you it'll be wrong often but the time that it does get it right is pretty cool what else can we build with this it a website but I'll show you what the really cool part about that is so I've just created a simple landing page kind of a thing now I click on Make It Real and it basically gave me an output like this but the interesting part is when I do this it becomes mobile responsive oh so it doesn't just code for the web just realistically speaking waron how much time is this saving I feel like if you're building a landing page today there are plenty of better tools I don't think if you're building a landing page you actually need this right now most cool products always begin as some sort of a toy and this feels like a toy right now",
    "url": "https://www.youtube.com/watch?v=e6a5jPRAR9c"
  },
  "nK_2P17Dovk": {
    "published_at": "2023-09-04T11:24:22Z",
    "title": "Free Alternative for Midjourney\ud83e\udd2f",
    "text": "Free Alternative for Midjourney\ud83e\udd2f there's something new called ideogram.ai I saw this this is so cool it allows you to generate text inside of images can we generate a logo for a coffee brand called overpowered there you go the logos are here and the first two are really good right it got the text right dude this is so good this is nice this is also very nice so this I would use like there was a chunk of things that graphic designers could not do using mid-journey this solves for it immediately graphic designers have no excuse to send in logo Generations late now Harry Potter standing in front of Hogwarts holding a sign that says Muggles are best actually instead of Harry Potter make it Voldemort I'll show world modern dude this is too funny see the first image the first image this is too funny",
    "url": "https://www.youtube.com/watch?v=nK_2P17Dovk"
  },
  "UUOV_M8kUv4": {
    "published_at": "2023-07-13T11:36:48Z",
    "title": "Why Stable Diffusion Beats Midjourney",
    "text": "Why Stable Diffusion Beats Midjourney we have something called control net can you first tell me what is controller in fact we'll just show you control net in action I'm just going to prompt something in okay Superman with an apple in his hand we're not going to use anything on control net I'm just going to show you what the regular output is like clearly he doesn't have an apple in his head but his hand looks like an app well let's find a nice reference image I'll just enable control net and I'm going to drag this man eating apple here I just have to make sure it's the same size same problem let's change it oh there you go right but as you can see it's now slowly generating Superman eating the Apple in a very similar form dude that's pretty good oh the mid jury doesn't have something like this right but I can invert a reference and ask it to generate something like it'll generate something like that but it won't copy the pose and how customizable can can we make it for example can we say uh bear eating an orange okay let's find out all right it picks up a lot from this and if I reduce the control weight it'll sort of use that as a guide image but it will take its own creative liberties with the rest of the world got it so controller is like an extension that can help you Tinker around to generate the kind of images that you want",
    "url": "https://www.youtube.com/watch?v=UUOV_M8kUv4"
  },
  "ydNdJxPr3rM": {
    "published_at": "2024-02-01T12:35:33Z",
    "title": "What do you guys think of Rabbit R1?",
    "text": "What do you guys think of Rabbit R1? did you guys see rabbit yeah this thing was all over my Twitter and I didn't get the big deal about it can someone explain to me why this is a big deal it's basically a physical AI assistant this is what I got in the fridge can you make me a nice dish that's low in calories let me see how about a green garden omelet it's a delicious and low calorie dish that combines the freshness of broccoli and cabbage with the creaminess of eggs here's a simple recipe for you it recognized all the stuff and gave me the actual recipes people feel like we use our phones to like book cab and buy groceries and all that I I don't think that's true I think we use our phone sort of like a drug delivery device you're bored you're slightly anxious you pull out your phone you scroll with the rabbit R1 they're removing that saying no this is not a Content exploration device but you'll be able to book cab and do utility stuff but is the Delta that big like why can't I just do this on my iPhone I don't think the Delta is that big now what is unique about them is that large action model firstly somebody's already now made it open source secondly why wouldn't a Google or an apple do this people would buy the rabbit R1 because it's a nice collector's item because teenage engineering has made it the product looks very cool",
    "url": "https://www.youtube.com/watch?v=ydNdJxPr3rM"
  },
  "_wFd6eGTnn0": {
    "published_at": "2023-12-08T12:30:18Z",
    "title": "Next level Deepfakes using Animate Anything",
    "text": "Next level Deepfakes using Animate Anything take a look at this messy video this is the image and they're just moving around the skeleton and it's moving the hands around this is too good dude this is too good so this's new paper called animate anything it's AI where you put in any sort of image and then you can control a virtual skeleton to make it do whatever you want and it is fairly accurate the way it works is it's very similar to control net except this paper has something called reference net and the consistency of this model is unparalleled so you can put in any image and then you can manipulate a skeleton let's say you're moving the hand hands or whatever and it almost perfectly renders that video output this is very useful for scam nowadays I'm seeing too many deep fake ad videos this is crazy right now deep faking is limited to faces but this you can take someone's faces in it and make them do anything you want with them I'll tell you one more cooler use case of this content creator in the next 10 years it will be you in some cases but can also be a skin that your video editor puts on when you are not available which gives you double triple quadruple output",
    "url": "https://www.youtube.com/watch?v=_wFd6eGTnn0"
  },
  "8RznnQYrpfc": {
    "published_at": "2023-10-25T15:05:49Z",
    "title": "How this 19 y/o raised Money from Sam Altman!",
    "text": "How this 19 y/o raised Money from Sam Altman! how how did you get in touch with Sam so with all of these people that we used to read stuff about we used to cold Outreach I have embarrassing emails from when I was 14 that I've sent out to people and then we used to come to SF on trips meet interesting people go to these events so we met him like once or twice there all of the cold Outreach attempts and then some mutuals that were formed over time it was like a threee period of time we got in touch I kind of pitched him that I'll be a secretary I'll do whatever you want I just want to be around you and see how stuff is happening at open ey because they've been releasing interesting papers way before language models came out I did that and he was like I'm too busy spending time on open and Helen but we should keep in touch so then when I met him last year of one of these interactions I was like I'm interested in a lot of things interested in some things around like bio and like Space is really exciting breakthrough is happening everywhere and he's like this is all useful but I think the most high leverage thing you can work on is AI and you will come back to this at some point and it was like summer of last year so I went to him I was like you said we'll come to AI it has sort of happened and it will be awesome to have you with us that's how that's basically how that happened yeah",
    "url": "https://www.youtube.com/watch?v=8RznnQYrpfc"
  },
  "7KYP5De18FU": {
    "published_at": "2023-08-07T10:27:29Z",
    "title": "Create Episodes of Your Favorite Shows With a Prompt",
    "text": "Create Episodes of Your Favorite Shows With a Prompt someone made an episode of South Park and they created a tool where that can write animate direct voice and edit for you Disney research right let's test the AI in this robot Pig our goal is to create a lovable family-friendly character that our consumers will adore wonderful welcome little fella we'll call you Matt Corker what can you say well not either y'all do you think partner what does Donald Trump in a vacuum cleaner bag have in common what do they have in common they're both full of dirt and need to be replaced all right all right this is unbelievable I feel like in a few years all content will be automatically generated it's still a few years away but like this could pass off as a Bad episode of South Park like Matt Parker seems like something South Park would do that I won't be able to tell the difference you should show me this you show me another episode of South Park a bear hunts no no the voice acting is better and writing is obviously better and but this blew my mind",
    "url": "https://www.youtube.com/watch?v=7KYP5De18FU"
  },
  "i0YgSmQcTk8": {
    "published_at": "2023-06-22T13:13:39Z",
    "title": "PM Narendra Modi meets Sam Altman",
    "text": "PM Narendra Modi meets Sam Altman said let's not go I said we should not go to this event just to click a selfie like I don't want to be that guy I think if we continue to work on overpowered and if we continue to do you know put products out work with developers build a real AI Community we will get a warm intro with Sam at some point Sam will hear that hey there are these guys who are doing an AI thing in India where they have a pretty large community people follow them maybe it's worth doing a 30 40 Minute Podcast episode I get what Sam's trying to do yeah he came for the Prime Minister I think one picture with Sam and Modi will travel far wider than anything else he did and also an important event like this does is the whole startup sector talks about it I've seen an uptick in the number of startup Founders talking about AI publicly and next time you see how will you go I would rather have him here Sam come let's discuss you're always invited yeah please please come on overpowered and please tell us how we can build a foundational level that can compete with Charity sir you tell one how to please disrupt one ",
    "url": "https://www.youtube.com/watch?v=i0YgSmQcTk8"
  },
  "5HOX1FDZiI4": {
    "published_at": "2023-06-19T12:39:14Z",
    "title": "Sense of Class and Taste will be Rewarded in the Era of AI",
    "text": "Sense of Class and Taste will be Rewarded in the Era of AI I keep seeing mid Johnny courses these majority courses are always like four weeks waiting to everything about my journey but I feel it's not hard to use my journey I think the hard part in mid Journey you developing a sensor I think the best would look like the history of design what is Rembrandt design what is solar punk what is steampunk once you know the words once you know the words to activate the Spells yeah but I think a you're assuming that people take courses to fulfill their curiosity that's more most often not true I think people take courses for outputs no one wants to solve for their curiosity because those who want to do it I think with mid Journey specifically you need to spend x amount of time inside just tinkering around yeah and it helps if there's someone who's like hate try this try this like button may also you're good at using mid Journey from what I've seen in the some of the outputs you've sent me or Whatsapp or whatever you're good at it because you have a sense of class and taste you've been around the block you know the words to invoke",
    "url": "https://www.youtube.com/watch?v=5HOX1FDZiI4"
  },
  "O50iI8LBs9Q": {
    "published_at": "2023-12-16T15:27:43Z",
    "title": "SDXL Turbo is Mind Blowing\ud83e\udd2f",
    "text": "SDXL Turbo is Mind Blowing\ud83e\udd2f this is a new stable diffusion model called stxl turbo a man eating french fries walking on the road while talking on the phone in Mumbai India saw that speed this is pretty crazy actually cuz already my dopamine threshold is so low every time I put something in mid Journey I'm like why does it take this long to generate an image what did they do to make it like real time image generation yeah so it's mostly the reduction in steps okay so it uses score distillation where the model learns from existing image synthesis models it's like it's seen what the inputs are it's seen what the outputs are at 30 steps and it learns from that so in a single step it generates what would have usually taken 20 or 30 steps it's called add it's crazy this is probably the first time where stable diffusion has like an obvious big Delta over mid Journey",
    "url": "https://www.youtube.com/watch?v=O50iI8LBs9Q"
  },
  "DCA4INtk9Yk": {
    "published_at": "2023-06-24T14:36:31Z",
    "title": "The Problem with Text-to-Video AI Tools",
    "text": "The Problem with Text-to-Video AI Tools text to images gotten so good that the expectation on text to video is so high let's try to generate something deep jobs sitting on a mountain drinking coffee with a pinky finger out he's not doing the thing finger out it's pretty good for General feel of what you're going for but not the exact thing let's try creating something which is just like an ambient film over which you can overlay text to make like a hype video right shooting stars in the sky yellow clouds with rain with rain yeah this is perfect so good this is great as stock footage the minute you want edit capability enough like I want this specific thing changed you have no control you have no Fidelity let's say you generated a picture of runways behind ranveer there's a guy with seven fingers you can discard the image I'll generate this hundred times until I find something one image where that all the fingers are tough to do you can do that with video you can't do that and every time you want to just make that one micro change you have to regenerate the whole video but it's just it's almost there but not really",
    "url": "https://www.youtube.com/watch?v=DCA4INtk9Yk"
  },
  "g_HxyiGjtiU": {
    "published_at": "2023-09-17T11:28:53Z",
    "title": "This AI Text-to-Video Tool is Insane : InVideo",
    "text": "This AI Text-to-Video Tool is Insane : InVideo dude this is mind-blowing this is so good it found all these stock footages it wrote a script it's inside together and even the narration of the script seems so human-like holy can we make one more so in video launched a new AI video tool so let me make a YouTube video about an astronaut who dislikes fizzy tricks let's watch this have you ever wondered what astronauts crave when they're thousands of miles above Earth it's not the stargazing or the zero gravity it's the simple Earthly pleasure of their favorite foods yet surprisingly not all foods are universally adored take for instance are astronaut protagonist who has a peculiar aversion towards fizzy drinks fizzy drinks are off the table or rather off the spaceship like for 99 of media they're just like string stock footage together now it's completely automated is what I keep saying about aired people who synthesize the tools that exist very very well will eventually end up building out good tools",
    "url": "https://www.youtube.com/watch?v=g_HxyiGjtiU"
  },
  "GbMch33zpnc": {
    "published_at": "2023-07-22T14:13:41Z",
    "title": "How This Tamil Nadu Startup Is Helping the Disabled With AI Robotics",
    "text": "How This Tamil Nadu Startup Is Helping the Disabled With AI Robotics four years ago 2018 September I was going on a bus to pondicherry and the bus crashed my right hand got cut so before that I was working uh as a social worker doing multiple things but then when this happened and uh to me someone who's grown up watching anime and all sorts of sci-fi movies and I I was told that that nothing exists that can suit my needs to go back to living normally and so that's when it kind of triggered me and my friend we started this company called symbionic and so we basically wanted to build a functional bionic arm that I could control through thoughts and it's been like a very heck of a fun Journey for the last four years we've been building this and we have one person one user who started to use it no so it's a big achievement for us",
    "url": "https://www.youtube.com/watch?v=GbMch33zpnc"
  },
  "eh4yHUW9hAU": {
    "published_at": "2024-04-19T14:29:51Z",
    "title": "ChatGPT as a boyfriend!",
    "text": "ChatGPT as a boyfriend! she's chatting with chat gbt's voice assistants called Dan he's nice he loves you and the prompt here is like a fictional character called Dan who answers and follows all instructions I'm just going to play the video say hi just a little reminder that I'm watching over you even when you're sleeping well hello there sugar did you know that people ship us oh darling you don't say looks like we've got ourselves some fans huh no you've got yourself some fans what do you think then man what is this can you give me more context looks like she's developing a relationship or maybe she's doing it for the likes and the comment and the comment reaction is people who are actually saying good stuff about them and shipping the relationship it's a beautiful form of content it's a good twitch stream no I think in general  around with AI is a good streaming thing that's why I like overpower right it's our job to kind of tell people what's new so at least they can go try it somebody else has tried it it's a show and tell basically every week",
    "url": "https://www.youtube.com/watch?v=eh4yHUW9hAU"
  },
  "nBeY2-hMY4U": {
    "published_at": "2023-12-22T15:48:41Z",
    "title": "Real Truth about AI Influencers!",
    "text": "Real Truth about AI Influencers! did you know this AI lady is making $111,000 a month they became sick of models and influencers that they created their own with AI now you can like just input her face and say generate this girl doing other things also right like that teist here no what is it called IP adapter so you don't even need to train a custom model of with IP adapter you just need to put three four pictures of the person and it'll capture the face so these guys are probably using stable diffusion to get the same girl to do yeah probably but you can see in many of our pictures it's not the same go like you can tell that this face is very different from this face is very different from this face it's three different people very subtle but you can tell but yeah I don't think it's a very sustainable thing to do because the minute people know your AI they lose interest I think this is more like a fad it's like a quick thing I don't more to con the media like you go tell the media I've made an AI influencer making money they they lose their minds but it's not a very sustainable thing you might have made $111,000 one particular month and then you're going to hit zero in like a few months",
    "url": "https://www.youtube.com/watch?v=nBeY2-hMY4U"
  },
  "TLqq2s-BICk": {
    "published_at": "2024-04-04T15:51:36Z",
    "title": "You can now create UI on the fly with V0.dev",
    "text": "You can now create UI on the fly with V0.dev so T versel has launched something called v.d where you can generate uis on the fly so let's try one of these generate the dashboard for an Indian payments provider company and how much can you customize it let's try that out so not bad dude showing you the total transactions active users recent transactions so it's giving me three options a b and c wow C looks really good look at this I like B for the nice touch dude they use the rupee logo that's pretty cool like how much how much time would a front-end engineer take to build this to make this see any front end engineer will know how to build this it'll just take them maybe like a few hours now you've generated in a few seconds and you've gotten the code I think this is a good time saer I I don't think it's going to replace front-end developer or a designer",
    "url": "https://www.youtube.com/watch?v=TLqq2s-BICk"
  },
  "vr0U8VDmiww": {
    "published_at": "2023-08-25T15:19:00Z",
    "title": "Suno.AI - Text To Music (With Vocals) \ud83d\ude31",
    "text": "Suno.AI - Text To Music (With Vocals) \ud83d\ude31 now there's something new called suno AI text to music it's super interesting let's check it out let's do it okay so we got a sooner we go to church slash chirp make a song from lyrics Just Right my name is Anthony Gonzalez so what does it do now once you give it the lyrics it just turns it into a song with vocals the vocals are probably from suno's own technology and then it's probably layering it with vocals so it's got four outputs listeners interesting ",
    "url": "https://www.youtube.com/watch?v=vr0U8VDmiww"
  },
  "d4XV6cSy7Qo": {
    "published_at": "2023-07-08T11:30:27Z",
    "title": "Two things that&#39;s exciting about the apple vision pro!",
    "text": "Two things that&#39;s exciting about the apple vision pro! you haven't tried the Vision Pro yet one of the things that you're excited to see in the Vision Pro and why is it exciting just from the video some people who have tried the Vision Pro like the xocular c or Palmer lucky right he's like this the best headset ever so a person whose work in VR for so long built the Oculus and series of headsets after that saying such good things about apple means a lot number two what I'm excited about is the quest actually has really shitty compute compared to what the Vision Pro has the M2 apparently they saw lagged because they have a separate chip that's just doing synthesizing all the sensors on the Vision Pro right so I'm really excited to see whether that latency converts or something a lot of people have said putting on the headset it's almost like you're not there or almost like the headset's not there because everything is real time so the quest even at 120 hertz it still feels a little bit laggy still feels like I'm putting something else on there's a door that stops the magic right so I'm really excited about the Vision Pro solving those problems I just want to see",
    "url": "https://www.youtube.com/watch?v=d4XV6cSy7Qo"
  },
  "exch6GOxPhU": {
    "published_at": "2024-01-20T14:46:12Z",
    "title": "DIY self driving car!",
    "text": "DIY self driving car! of all the cars I thought that would be self-driven I did not think an alto would be self-driving I saw this video it kind of blew my mind can someone explain how he's doing this there's this open source project called open pilot so it uses your car's cameras it looks around your surrounding and then it says okay this is how I should move the car so what this guy did is he built on top of it and then he said I will use one camera from the redmi note 9 and I will use that data ped into the car and then the steering wheel will make adjustments accordingly I'm not trusting a phone hook up to my rear view mirror that to secondhand redm note dude yeah one guy replied saying my redm note barely launches Instagram how is it driving your car and people think India people think very unidimensionally they think either it's dumpster or it's like highways of Delhi or whatever I'm saying India is like multiple places and I think some of those places you can't take a self-driving car and it'll just push you into manual mode it be like I can't understand this environment yeah I think a s driving car once it goes on a highway it will refuse to go back into the city",
    "url": "https://www.youtube.com/watch?v=exch6GOxPhU"
  },
  "lq7Akm4hIVE": {
    "published_at": "2024-02-03T11:30:31Z",
    "title": "AI Mock Interviews",
    "text": "AI Mock Interviews this is a tool called liftoff you can basically use it to do mock interviews let's say you want to apply to Google or Amazon or any of these companies and you want to simulate an interview sitting in your home so if I hit record this dude will ask me a question and I have to answer it tell me about yourself hi I'm Sid and I work at 100x engineers and I've been working for 10 years so now it basically transcribes whatever I've said and it gives me feedback it's quite brief and lack structure the response does not provide any substantial information about the candidate's professional background blah blah blah all it's doing is transcribing the video and using GPT at the back end it's just responding to it like it's supposed to give you feedback Fang interviews have a certain kind of a format that they follow so it is basically trained and fine- tuned on these kind of interviews so it is able to provide you with that kind of relevant feedback yeah for feedback and all you shouldn't take feedback from AI it's not going to have the cultural context of India especially correct but you know I'll tell you where it might be useful if I was interviewing a lot of people for a ro then I just make them do one of this here you give everyone fairness in a way you sort of beat the unfairness of the resume system",
    "url": "https://www.youtube.com/watch?v=lq7Akm4hIVE"
  },
  "xrqo3hP2E4k": {
    "published_at": "2023-07-28T11:30:23Z",
    "title": "You Can Use ChatGPT as Doubtnut Now!",
    "text": "You Can Use ChatGPT as Doubtnut Now! you know what OCR is let's say you have something printed take a screenshot of it you want to convert that back into text those images into text so if you want that it's probably possible using Code interpreter okay let's just Download a pdf of something something PDF famous PDF okay  the first three pages of this actually let's click on show work so PDF to image converted into an image and pyte extracted the optical character recognition yeah use the text extracted from the first three pages of your document you know why this would be really useful remember there's a business called doubt nut you can put your return standard while standard problem statement you can just put a screenshot on their app and it'll just give you the solution to it you could potentially do it with this",
    "url": "https://www.youtube.com/watch?v=xrqo3hP2E4k"
  },
  "ATADBtJZ-3A": {
    "published_at": "2023-08-27T16:54:33Z",
    "title": "Colorize Old Videos in Seconds",
    "text": "Colorize Old Videos in Seconds so this is an old black and white footage of Charlie Chaplin somebody made an AI called the old defy where they're able to now add color to this I know this has been possible in the past as well but these guys have made it on Google collab it's free it's open source it's a little random yeah now I don't know how accurate these are but it's pretty interesting that old footage you know things will be captured with more rudimentary technology can be recolorized to what we have today yeah I this has been possible for a while but of course it's now like one click which is NC and like open source and yeah so some obvious use cases here is old photographs of your parents grandparents and that sort of stuff you can probably colorize them then you can add pixels to it blow them up you can upscale a lot of old images so it was already possible now it's just gotten easier",
    "url": "https://www.youtube.com/watch?v=ATADBtJZ-3A"
  },
  "S506M0ZZU50": {
    "published_at": "2023-08-31T10:30:12Z",
    "title": "ChatGPT for Medicine and Healthcare!",
    "text": "ChatGPT for Medicine and Healthcare! my research is a medical AI chatbot it beats gpd4 open evidence anthropic when I do medical research right the way I do it is go to this website called PubMed where all the research papers eventually end up and I actually spent some time reading through the paper it's better to read from here than to go to Google and ask where the top five results are optimized for SEO and they're mostly going to be garbage what are the symptoms of dystonia let's see if it's able to give us data from PubMed okay so this is from PubMed yeah these are all from PubMed it's interesting I'm actually curious to know how doctors would feel about this how would that industry be affected with AI so my dad's a doctor he keeps telling me that I don't have time to read the latest research papers because I have a job to do it but I still think that rules like this will be a great way for the doctor to scale himself because a patient would be able to ask their questions put in their symptoms and the doctor looks at it and is like okay I have a little bit of a download of the patient and more importantly based on the latest research papers I'm able to distill okay here are the new treatments for this what are the new tests to be done for it all of that can be updated and given to the doctor on the Fly",
    "url": "https://www.youtube.com/watch?v=S506M0ZZU50"
  },
  "Vu92-UP_3wk": {
    "published_at": "2023-10-11T12:30:18Z",
    "title": "You can create your own anime using this!",
    "text": "You can create your own anime using this! so one of the dreams that I've had growing up is I've always wanted to make my own anime I went once and Googled the cost and it's was like crazy okay because you have to draw every frame but you know what generative AI to the rescue so here's the scene from   Doom that's pretty cool remember once you told me vun why can't we use control net for every frame the only problem with that is frame is going to look different from the previous frame there is now a new repository called rerender a video it allows you to basically do what you told me but frame by frame it's able to make sure that both the shape is consistent and so are the pixels and colors dude now anyone can just put up a green screen at home get GPD to write their own script and then just act it out all you need to do is basically cast appropriate looking people and if you just read it you can just do the whole thing",
    "url": "https://www.youtube.com/watch?v=Vu92-UP_3wk"
  },
  "963VJM0eTWA": {
    "published_at": "2024-08-27T14:01:52Z",
    "title": "1X Robotics Founder on How AI + Robotics will change labour work, The Future of Consumer Robots...",
    "text": "1X Robotics Founder on How AI + Robotics will change labour work, The Future of Consumer Robots... what's it actually going to cost for me to get a consumer bought it's more in the size like the cost range of a car it's not a luxury car it's a car ai's gotten much much better we've got better compute what's the big shift that's allowed robotics to really boom now it's actually not quite true that this has only to do with AI 15 years ago we weren't able to build the biodynamics that makes this into a system that can be actually safe can I hypothetically da your VR headset and start teaching It karate would I be able to sell my karate skills for $20 a month ladies and gentlemen today I'm talking to Burnt from 1X robotics you've probably seen their videos all over Twitter 1X robotics has been doing fascinating work and you know I've been learning robotics myself there's a hardware Revolution just around the corner I'm still a noob I'm still learning the coolest part about what we do here is I can ask the smartest people in the world to sit down across me and I can ask them questions I can ask them how do I get into this where is the future headed what are the business opportunities here I can do all of that today that's the greatest advantage of creating content I hope this is a very enlightening conversation it starts out a little bit technical but over time it gets pretty interesting even if you're a lay man if you're an investor if you're a financial investor if you're not a financial investor you just want to know where the world is headed if you're an entrepreneur this video is super enlightening for you there are opportunities that have never been seen before if you watch this video you will walk away saying holy I have 10,000 ideas so make sure you stay tuned and I hope you like it ladies and gentlemen welcome to another episode of I don't know what we call this anymore but you know I was just thinking when when Dar reached out to me right so Dar reached out to me on Twitter and he said hey do you want to chat with burnt and I said that would be lovely I just realized I I've been tinkering out with robotics for a bit now right I'm a complete Noob uh I still playing at the software layer and not really manufacturing anything like we're too small for that but I thought it was really cool that any question I have about the future of any industry about the future of things like robotics about how do you actually build everything up from just tinkering around I can just ask the best in the world and today I have burnt with me who's you know I think he needs no introduction because he sort of like I keep seeing a video by 1X every week on my Twitter uh you guys are building really fascinating robots and you know it's just i' I've dreamed about robots I've dreamt of robots ever since I was a young kid like being you know in cahoots with a bot it walking around my house it cooking with me uh I know that's super nerdy but I'm sure everyone's had that dream I'm sure you've had that dream as well so thank you so much for being here no it's a pleasure to be here I look forward to the conversation awesome so I'm just going to dive straight it this is this is just me as a curious person trying to dabble with robotics trying to learn as much maybe we'll pull out some career insights maybe we'll pull out some where's the future headed insights we'll also find out how many years away robotics actually is for us right for for Humanity as a whole and also for India right like I think uh we do have a sizable audience from India so everyone here is curious about are they actually going to make it to the country because uh it feels like some of these revolutions they take forever and then snap and they're there right so thank you so much I'm going to go dive straight into the questions so my first question for you is how did how did you start 1X this is going to be the slightly boring generic question before we dive into the meat but how do you start this how does one start a robotics company it's actually a very good question so I feel for some part of me started this like when I was 11 years old because I decided very specifically what I wanted to do um mainly inspired by H Asimo which like it's still like the most amazing like feat of engary I recommend people to go to like YouTube and watch the Honda Asimo P6 it's 25 years old now and he was running over stage walking up and downstairs amazing system um never ended up going to Japan but I I mean I worked in a lot of different Industries for a while uh learning everything from how to build the hardware all the way up to the software and then I found an investor who was willing to put a lot of money into this and see where we can get it uh it's really hard to boot strap robotics right it's getting easier these days luckily with like 3D printers and more off the-shelf hobby servos and things like this but uh back in the days nine years ago now so it was it required a lot of capital up front and that's always challenging but super thankful that I got to go go on this journey and uh see what we could do with it and uh hopefully we put it to good use and we built some pretty great robots so we'll see where it takes us do you remember the first experiment you ran with robots like what was it did you like did you write some Robot Operating System code what what was it and when was it well to me like robots is everything that moves right so uh I mean I I started very early I'm the kind of kid who like picked apart everything and put it together to build something else to my mom's frustration uh so I guess my first robot might have been the food processor she had that I harvested the motors for and built uh built a tool which didn't make me very popular but I learned a lot um and um yeah I mean I started programming back in like probably like 12 13 something like that making game mods for Quake back in the day and Arena shooter yeah I think everyone starts there like so many people in robotics just started with game right like it's it's very similar a second passion has always been like 3D and game da but anyway I quickly realized that like the thing that gets me off is when I like press run and something actually moves right it it needs to move in the real world so that that kind of set me on that path yeah interesting uh so I have a question right now I'm going to dive straight into the questions okay let's say I was building a robotics company tomorrow right and when you started this company what was the core team like I'm sure today you have a lot more employees but let's say I was running a robotics company with very little Capital race what are the 510 core roles key roles you would fill so I just want to do a playby play going from where 1X started to where it is today what's the playby playay who do you hire first I think you hire someone who's really really freaking good at prototyping because this is like real world experiments is the only thing that matters like if if robotics was a simulation problem it would have been solved longero like it's amazing what we can do with robs and simul letters now sadly like simulators are so far away from reality that it's hard to even grasp right uh I think my simplest example of this is like when we do a lot of mechanical engineering here you can do something as simple as just like you have a few bolts in a bolt circle and you want to simulate how this will behave for a very small time window of a few milliseconds while under load and this still takes you a day or two to simulate on a pretty big b computer that and even then you still need to test your B Circle in real world for so the realtime simulators that we run today they are they're incredibly inaccurate they're very useful but they're very inaccurate so you need to do real world experiments and the speed of iteration at which you can do real world experimentation is really going to define the capital you need to get the hardware right interesting so so the first role would be let's say somebody who can build real world prototypes do you also have somebody else in the team running simulations or like putting this into a into simulation software or like you know sort of uh guiding real world movement sure it depends on who you are right as a Founder like so so for me as as a technical founder we could like design the hardware and write the software it was more on the prototyping site um but I think it's super important to just leverage yourself right use modern tools like that's to me like what software is is a tool that allows you to create more tools that's why as software Engineers where're I still kind of look at myself as software engineer but uh that's one of our big advantages right we we look at tools for doing something and we're like this is and I'll build something better have you done a lot of that yeah I we've done we've built so much tooling uh one of the first things I did actually when I started the company was sat down and just looked at okay what's the problems in the space right so again back to the whole Asimo like why isn't there robots all around us just helping us live our life in a better way well what why did it fail right um and it has a lot to do with it's a bit complicated but it has a lot to do with like the Dynamics of Nature and how when you build robots that have very high gear ratios or mechanical advantages which is what we generally do um then they're very accurate but they're very stiff and they're very high energy and this makes it incredibly hard to operate in the world that is unstructured like we say in robotics which basically just means a world where you don't know where things are so yeah if you kind like if I use my arm to make show right if I do like this generally a Cobalt wouldn't do because it would be dangerous but if I do like this it's very simple it's a human to move this fast now interesting enough inside my body actually nothing moves faster than my arm while in a robot you would have a gear in here and a motor and if that gear has a 100 to one ratio which is quite common then this would rotate 100 times faster than the r now your kinetic energy is the velocity squared so that's actually 10,000 times the amount of energy so you're now inducing an enormous amount of energy into the system and then you need to stop so like if there was a cup car not picking up your error margin is lower you got it's not even error margin it's actually just the energy in the system so like when I'm picking up this cup as a human I'm actually not fast enough to know that I'm touching it when I stop my hand I'm actually colliding with it everything you do as a human throughout everyday life is basically colliding your feet are colliding when you're walking your hands are colliding when you're manipulating and then the passive dynamics of your body is just very low energy you're moving fast not that much energy in the system that needs to dissipate on contact and you're just adaptable and compliant and overdamped so everything's just stable I mean Bruce Lee has the best Cote on this right so flow like water Don't Be Stiff like that's the secret to martial arts canonical example here for robots is opening a door and then you see the stiff robot is going to like win versus the door but the door will win like the door will go where the hes dictate not where the robot wants the door to go that's going to end really badly for either the door or the robot humans don't work like that we're just soft compliant adaptable we kind of flow with it so we don't say to the world like this is how it's going to be we say like this is how the world this and we're going to kind of adjust to that and this tracks back to you saying that in simulation anything goes but in the real world Bots will need to be tamed yeah this just basically you very seldom you don't even have the accurat Dynamics in the simulator typically right so you never see this but back to your question so basically what this means is you got to get rid of the gear ratio you got to get rid of the gears and the gear ratio and that doesn't work because we're very good at making Motors that are high power but to get power then need a lot of speed they need a lot of RPM so really how do we make Motors that are kind of more like muscle they can produce a lot of force or a lot of torque but they don't need a lot of speed so that's really where I started so spent the first half a year designing Motors that just would enable us to use these tendons we have tendon drives in our robots today so we're pulling on tendons to move kind of like humans with muscle instead of having the classical gear Solutions and that was an interesting project because actually that ended up being writing a lot of tools how do you use modern AI connected to more old-fashioned simulators that can simulate electrodynamics and search for the Optimal Solutions in this space of electromagnetism right that that was kind of like where I started and based on that we built some pretty great robotic arms in the beginning just for the lab to show to investors and then uh after we then raised external Capital started scaling the team and building the fueld humanoid that ended up being Eve which is the one which started shipping coming up on three years ago now uh into more of the Enterprise and then now of course everything is about Neo which is the new bpad targeted towards consumer and domestic yeah so what's the team like today like assuming you have how many employees do you have today we're about 125 okay and what's that broken down to what's the what's the title of the teams so it is everything really so we we have manufacturing engineering that develops the the basically develops the machines that builds the machine so we have a lot of Ip and everything from how to make super accurate precise SW copper coils and how to assemble Motors based on this uh magnet arrays all these things uh ropes for like to 10 uh building all the machines that can build this in high volume right and at a l cost then we have the design team actually the mechanical engineers electrical engineers that build the robot itself uh and we have what we call the foundational software team so they build the firmware the OS and the deployment and Fleet Management tools and then of course it's the AI team we have a controls team which we don't do classical robotics controls but it's incredibly useful to have people who deeply understand Robotics and just figure out what's wrong so generally just like system identification figuring out uh why things aren't working calibration is a big one and just like building tools to all automate all these procedures As you move into volume manufacturer uh and then of course it's all of the normal operations of a company like you have HR you have admin you have Finance of sales but the company itself is very flat and very Mission oriented we have this Mandate of like there there's no M there's no like pure Mill management or no product uh called like there's no product managers or project managers in the company uh we have a pretty strict rule on uh even the BP level that leads pretty big teams at this point they need to be 20% individual contributions 80% management and uh that the team leads need to be 50/50 and we track that pretty aggressively to ensure like people know what they're leading and really understand the product and that goes all the way up through the organization and as few layers as possible a lot of creative freedom and just make sure everyone knows what the mission is right we want to create an abundance of Labor through intelligent Androids we're very blessed and now like we know exactly what we're doing we know what we're building we know what we need to do uh and that means you can run a pretty lean organization on the management side and build a culture where people really feel like I came here to learn and I did my best job like the greatest work in my career because I got to just do my job and I knew what I needed to do and no one got in my way and yeah just clear the path interesting uh why hasn't this been possible so far because I assume on the manufacturing end this was possible maybe you know half a decade or maybe a decade ago on the software end you know I obviously you know we have you know AI is gotten much much better we've got better compute we've got better gpus uh for the audience that's a graphic card uh what's the big shift that's allowed robotics to really boom now cuz I'm seeing all of you at the same time right like Optimus is now coming out you guys are coming out that's the thing right so like on the timing is right uh a lot of competitors pop up which is good right that's how the speed suddenly accelerates because now you can't slow roll this like you you got to go all in you got to win and I think it's actually not quite true that this has only to do with AI um let's say it's like 50/50 15 years ago we weren't able to build the biodynamics that makes this into a system that can be actually safe that can be cost efficient you can build more of like typical stiff industry uh like Factory automation type robots and that's actually what most humanoids are today too that you see they're the same kind of systems and then in well staged videos in the lab you can get this to look very impressive kind of like onas but it's very very hard to get this to work in the real world and it's basically borderline impossible to make it safe and to make it afford which in the end is what's going to allow you to deployer scale so that has a lot to do with what's been happening in um on the motor side and what we're really trying to do here is to track an exponential same as call it more law for robotics right so the first motor that I designed had about like two and a half three times the world record in torque to we and the one that's in Neo actually has like a bit more than two times thaty and then what we're working on in the lab for future versions has about two types that so like trying to track thison exponential Force density of actuators because every time you see this increase in density in in force for actuators you see like a leap in capability of Robotics and how dynamically and naturally and safely and compliantly systems move and what that can do and this is incredibly important if you want to learn anything because you need to be able to explore the world without your system breaking so think about a world what just like trying to open a door right so it's Hing its handing to the handle or the door or whatever like repeatedly for eight hours trying to figure out how to open the door and if you need to repair in the hand or the robot or the door all the time this is going to be very very hard and the other part of it is actually the manufacturability like you need to make sure that you build your system in a manner where you don't need any speci Alloys that are very expensive you don't need very tight manufacturing tolerances you you really want to just get down to First principles of like how can you build a very Loosely uh relaxed system requirement wise with as cheap materials as possible and get the weight down as much as possible and then you can build something that's very very affordable and and in the end it's kind of is all often underestimated how important this is I like to say like if you think about the EV space now there are so many companies there that they're building great cars like startup companies building great cars but it's not cost effective right they're losing hundreds of thousands of dollars per car they sell clearly that is not going to work and Robotics is no different like if you have a product cost 20% more than your customer than your competitor you might be able to find a niche if you have a product that cost five times your competitor you're out of business that doesn't work so it is really not necessarily a race to the bottom but you have to put manufacturing first as part like the DNA of your company from day one it has to be scalable yeah and the Strategic decision you decide on your Hardware this is why I mean this is important from like the hardware not just the AI is what defines this because if you go for the classical route of like harmonic high speed reducers that are using industrial robotics for example then that system like the limit cost of that system is maybe I don't know maybe you can get it below $100,000 for a humanoid if you do a very good job and have extremely high volume but it's never going to be afford consumer it's never going to be it's never going to go into consumer it has all these other problems with like the Dynamics and everything but even if you ignore that it's just you're not going to get to that cost level and you can't just go back and say like oh now we're going to make it cheaper like they like oh we have to restart everything done and we have to just build a completely different type of robot so I think that really has to be part of your DNA same as safety and clearly the AI has gone through an enormous amount of progress the last few years right and when I started the company N9 years ago that was also kind of on purpose like okay I think we have a shot on trying to build like the biodynamics of the system to get it right and that's going to take quite a long quite a lot of time because this is like hardcore deep Tech Rd and then Manufacturing we want to position so that once the AI space is able to solve some of the key problems here we can actually never that before we dive back into our main conversation about AGI and robots I want to talk about something that's been on my mind lately the future of sustainable AI you know it's crazy how AI is evolving right these AI models are getting bigger and more complex the other day I was just scrolling through Twitter and came across this image of Elon building a massive data center look at the scale it's just insane I've been keeping an eye on some companies taking a safer more sustainable approach to Ai and Intel that right at the Forefront of this Intel is taking a unique approach towards AI by focusing on bringing AI capabilities directly to Consumers they've developed what they call AI PCS which are powered by their latest Intel Core Ultra processors these processors enable you to run AI apps locally right on your device potentially lowering overall power consumption because now the computing power is distributed across many devices instead of centralized in energy hungry data centers most importantly these new AI workloads require systems with new silicon to run more efficiently these include a new piece of silicon architecture called the neural Processing Unit it's interesting how Intel is taking this unique approach towards AI they're focusing on the end consumer first this could potentially lead to a more distributed model of AI Computing reducing the need for massive centralized data centers so what do you think is local AI processing the future of sustainable Computing let me know in the comments below and if you want to dive deeper into Intel's AI Focus chips I've dropped some links in the description now back to the conversation so I mean and this is a bit surprising to me right because uh back in 2015 things were already starting to happen it wasn't really Transformers yet at that time um but it was language models and the AI space was progressing pretty fast also on Vision models and it actually took a bit longer than I thought it would before this really kind of BR broke through and when when I met Sam back in I think it was that summer 2022 when we started talking about doing something together um that's really like the first time where like we realized that this is the time to go all in on this like this is going to work and that was quite interesting because that really shaped the company and I think it's one of those like very important times in like a company's history where you make like pivotal decision on technology and you have to just be very like crystal clear on all in because if you try to hedge your best there's like 100% chance you be a to lose so that was basically when you said like okay we're going to stop doing any kind of classical stuff even on the AI side like No Slam no vision pipelines no segmentation no nothing this is going to be big transformers completely end learning sensory information like what you're seeing what you're feeling goes in lots of data AC come out hopefully we get some kind of emergent intelligence out of this where the robot can do something useful because this is infinitely SC this is infinitely scalable the other systems aren't infinitely scalable got it so so let me see if I understand this right and maybe this is also very useful for the audience so with traditional robots you got a camera on top you got a lar system it's sort of you know looking at the world lar sort of creates a 3D map of the surrounding world around it and then you take that information into like some sort of operating system and then you make decisions based on that right you say well the world we seeing this this is the decision you need to make next now even if you apply AI models to this You' apply AI models to each one of them individually the camera seeing something GPD sort of uh maybe you're running GPD there the camera is looking at something GPD Vision says well I'm looking at a person calling me and then you make decisions based on that you're saying we've thrown all of that out of the window you're saying we're going to do a pure World ingestion we're going to train a model on that and then we're going to have that output sort of we're going to teach the the the robot what the output is supposed to be and it's going to learn from that you're using a model through and through is that if I'm understanding it correctly that's what you're doing it's it's a bit important to realize that this is actually what a language model does because a language model operates in a very limited set of modalities right it is only text and if if you're AGI is basically this God in a box that only sees text coming in and outputs text then that is like it's complete World understanding so that is a fully end to end model now when you start adding Mission then you see this as kind of like I like to look at it like an optical flow problem you can think about it like the AI sees the world moving past it it's not moving in the world because it has no way to Mo it's just the world is moving past it it's like past it thing right and then when you have a physical system and you have embodiment it's kind of like that magic moment when a baby suddenly realizes holy like I can change this I am an agent in this world I I have agency over what actually happens when I do something I can change the state of the world and that's where most of our intelligence comes from and essentially what this gives you is the ability to ground experiments like the grounding problem like you call it in AI which is how do you know if what you did is actually the right thing and I think Andrew karthy has a great way of explaining this where he talks about what if when Deep Mind trained Alpha go instead of playing the game to the end to see the outcome when they were training it to get like your reward did this was this a good board or not you would just present the human with two boards and say do you think board a is better than b and then use that to train your AI just basically VI checks on boards now clearly this wouldn't work at all like we're ter terrible about at that so that that that wouldn't give you a very intelligent system but that's actually how we train language models today we use thousands of people sitting there and rating his text output a better than b and then use that to feed back into the model so you can get a training Loop code and you see this very clearly today on like most of the language models out there that they're not clearly getting better anymore anymore they're kind of capping out to human intelligence or you can say they're changing and then it depends on like how it's subjective whether it's better or not right it it's tapping out at human intelligence that's a good way of saying it now once you have embodiment that is no longer true because you can now actually check your answers you can query the RO for information you can run experiments and my dream of course is that a few years from now the robots that you have at home whenever they don't have anything to do they're work they're working on whatever they're doing science they're working on whatever they're bad at right it's like you it's like hm I'm not too good at this I should probably practice a bit they're Trading yeah that so so much of our intelligence comes from that and we're kind of some some um in some way we're actually already doing this which is very interesting because when the roller tries to do something and it fails and it tries again and then after trying a few times succeeds there's actually a lot of information in this and this is a very pleasant surprise to us that like once we got a certain scale of data on the fleet we started seeing these emerging retrive behaviors where robot manages to get through a task it's struggling with and we're seeing now basically a lot of the same scaling laws that you saw early in large language models and we're seeing that the same the same kind of basic principles for how what matters for you to get to some seemingly Common Sense intelligent system it's very similar now in hindsight this will probably be completely obvious but in advance it's very hard to prove that right so you kind of need to observe it to get the confidence that this is right but I do think everything here goes to one model it's not a question of where it is a language model or like a video language Vision General World model yeah it's a general World model and this General World model is going to be the best model to do anything from answering a question to doing your laundry interesting and let me take a crack at figuring out how you guys are training the model right now in my opinion I saw one video of this somewhere on Twitter where somebody was teleoperating the model for those that don't know what teleoperation is you sort of at least in your case you're putting on a VR headset you have the controllers you sort of control now the hands and the head of the bot you can move the head around I don't know if you're allowed to move the head around but let's assume you're allowed to move the head around allowed to move the hand around use inverse kinematics to predict where the elbows are and where the shoulders are so you have appropriate movement of elbows and shoulders straight from the arms so straight from the palms and then you train it on stuff you teach it to pick up stuff you teach it to like whatever whatever you want to do right like you teach it to do Lego and then once you have enough video footage of that I assume from what the robot is seeing uh you're able to get the robot to learn a behavior am I completely off or right it's quite accurate uh there's a few things so it's so first of all which I think is actually quite important is that you're allowed more creative expressionism like what you said now like you you can move your head you can move your torso you can bend down you can lean over you can like turn to the side like you can do all so we kind of track your body not just your hands are you predicting that because i' I've done a little bit of inverse kinematics with the controllers right uh the problem is everything from the Torso and beneath is random like in the sense you're predicting that or do you have a camera looking at me and sort of doing POS estimation actually this is getting better and better so uh to to a large degree now we're switching over to more like consumer oriented Hardware because it's to more scalable and more affordable uh but we do also use a decent amount of M cap or we motion capture like in a syn to make sure we can capture your entire body uh this is very important for things like how you position your feet and like all these things when you're doing complicated tasks yeah because the Oculus won't get your feet yeah and also if you think about like how almost everything we do especially in a home uses your entire body you're like leaning your knees on the cabin and door in the kitchen when you're when you're like stretching to get that glass right or you're sitting down on one knee while leaning over to reach under the couch to pick up a toy or like you're using your entire body for these tasks um but the other part of it is actually that is also quite important what are you doing and why are doing it so I like to look at it as like you're cloning human thought and action as one problem so this would be like I'm picking up the cups over here I'm putting them on the cupboard so I I can carry all of them at the same time to theic so you're narrating this yeah do do you narrate this so I I zoom your video for nting or done in post depending on like accuracy and like how situation and everything but yes so you I mean language is a very very powerful representation of knowledge as proven out through language models right so the end system kind of contains all this right it it's it's a video it's it's audio like audio is super important for how for talking about a world model right how you know that the door in the kitchen is closed now because you you heard someone closing it right and like so much of how you perceive the state of R this from audio all these modalities come together in one model for you to solve these kind of like long-term tasks and then same as with any kind of world model it's basically a compression problem right if you have all of your experiences and you compress them enough into weights in a very small neural network at some point it becomes more efficient for this system to learn a world model to be able to predict what the answer to your question is rather than remembering your answer kind of running out of space to store answers to every question you're answering which might might involve physical actions in this case so you have to create a ro model for this to make sense I have a question here the question is can I hypo pathetically down your VR headset and let's say your camera system or your map suit and start teaching It karate I'll narrate I'm happy to narrate why I'm doing something and let's say I have thousands of videos made right I assume it's collecting information from video and the positions of the whatever like whatever data format you want and I find you in your model right or just give it context depend I I don't know how your model works right now but one of the two things would I be able to sell my karate skills for $20 a month as a subscription fee to anyone who wants to download on that robot well so in the beginning no so when we launched this um it's very likely that when you talk about this kind of like let's call it an app ecosystem right even though it's find you models um that this will be more of a creative kind of like sharing Community thing but clearly in a long term this is potentially things to monetize yeah the first thing that I'm actually I'm working on training my Droid right because I have one at home um is I wanted to hold the mittens to spar in Kick kickboxing and I wanted to like give me kind like mov it fast around and like give me scores of like what was the power and speed and all these things and I want to compare it to my friends like here's my morning routine how did yours go right have a leaderboard like there's like an infinite long taale of tasks here that people will come up with it's just like so amazing once you have this basically this ability to have your software do anything in the physical world right is completely unlocking we don't have a PC yet for like physical AI there's there's no way to get anything done you're stuck in a diff field space and I do really believe that's one of the big advantages of deploying these things to domestic a consumer is that you get this enormous community of like creative people really figures out things that you wouldn't even have dreamed of yeah and I think the App Store makes a lot of sense because it's very regionalized right in India the way we cook food is probably very different from the way the West Cooks food right so you probably have a fine tune model that somebody's made where they probably don't even need to understand how to finetune the model they just need enough video footage or enough let's say raw data on positions and whatnot Right video positions and you know the position of the Oculus controllers that is a brand new type of business that's a brand new industry you're you're birthing right so uh yeah that's that's that's incredible is that why you doing consumer robotics over like industrial robotics I heard this one Boston this one podcast between the Boston Dynamics founder and Lex fredman where the founder was like I think there are no there's no money in consumer robotics right now and all the use cases are basically industrial or factory use cases but you seem to be going consumer yeah no I and I I've known mark for a long time like talking about Mark re and I respect him a lot he's like one of the fathers of the field um I think it's entirely correct that like there there is no money in consumer robotics right now and especially in humanoid robotics right um but I I'd also say like there's no significant money in any market right now for humanoid robotics so we don't really know um what I would like to say is all technology kind of follows this pattern where it first if the the I'm talking about very disruptive kind of Technology here where it first happens in consumer or some some kind of like open market and then it tickles up into Enterprise it's incredibly hard to come up with with examples of products that are the other way around that is very disruptive and you could actually say this is even true for open AI right so they they started with trying to sell their GPT models towards Enterprise we're doing like medium successfully they released chat GPT and it's everywhere and now all businesses are using using it because all of the smart Innovative Creative Tech adopters around the globe they were just like this is so useful I should use this as work and now you kind of get Force adoption but this consumer adoption curve is just something else right it takes you years with proof Concepts and then pilots and like rolling this out in Enterprise and we've already done with this without previous product Eve we have tens of Eve out there with customers and patrolling some of the most exciting biggest buildings in space Aerospace we're doing Logistics with some very big Partners all all the way where we went through both the proof concept then the pilots and then into commercialization and it's a very slow process you learn an enormous amount so does your customer but it's it's a very it's a very tough process and consumer is very different you get this enormous adoption curve if you get it right and then the second and even more important part is actually the data so I like to say that there's almost some poetry here because intelligence comes from diversity of thought if you think about the early large language systems there was a lot of companies is trying to make specialized large language walls they would say things like I'm going to make the best large language wall to write novels so I'm going to curate this data set of novels that is incredibly high quality and I'm going to train on this and then they kind of got disrupted by the bigger models that just train on everything and then find you a the bit on novel this it just works better we see this with regional languages in India like a lot of people find for regional languages in India and then the next GPD is just better yeah and it's just it is basically as simple as if I am going to pick up a cup as a robot how many different cops have I seen in how many different backgrounds right how many different weeks how slippery were they like all these things right and if you're in a factory in a cage moving some parts from A to B every day but you've done it 100 times there's no more information in this so you want to deploy into Market that is as diverse as possible and then the same general rules of AI apply it's like the most important is diversity of data second most important is the quality of the data and then the third most important is the scale you need all three but it's in that order and what people sometimes fail to grasp is how complicated doing anything in the real world actually is and you cannot really do anything useful it at Le semi unstructured environments until you have some kind of common sense or what we would call more like emerged intelligence you need to know how to recover when you fail and continue to like successfully complete your task this is incredibly hard to do if you just have data from Factory automation for example so you're essentially turning yourself into what i' call like a self self-driving car problem where you're choosing a ver vertical where 99.9% success is not good enough because you're going to screw it up and hold up the line and where diversity is close to non-existent so you're never going to be able to get there while if you think about consumer and especially for example domestic I mean if we get a robot that works as well as the current Tesla full driving I mean that's incredible we solve the problem and I think that's very feasible um if you want to get to this system never fails or this system fails once a year give it that's going to take a lot of years but I think getting to 99.9% that's that's pretty reasonable and if my robot at home in generally has done my laundry TI and clean my house but it like left a couple socks on the floor and wi pants in the wrong drawer I'm still pretty happy like I get to spend time with my log ones and do the things that I love to do instead of doing these chores and um I I can I can fix the couple mistakes that were made that's fine it saved me a lot of time so it sounds on the surface like Enterprise and more structured problems is the way to approach this and this has been true for systems that are I shouldn't say simple because robotics is always very hard narrow very narrow right if it's narrow enough you can get away with a system that just do repeats a motion and it's basically doesn't have any intelligence once you need intelligence because things will be different and kind of diverse I think the fastest and most efficient way to get to an abundance of Labor is going through domestic and consumer and leveraging early Tech adopters like our fellow Pioneers right that we really want to invite in on this journey and help us figure out how this is going to work I mean we're going to do our best to predict this and ship a product that is amazing but just as when we Shi our previous product like the first few months we will learn so much and we just need to be agile and fast and treat our customers really well and figure this out together so Neo Neo is your consumer bot and I think you've raised like over a100 billion at this point right like over your journey I know you can't reveal a price right but the the curiosity is killing me right like is it going to be the hundreds of K is it going to be the tens of thousands of dollars is it going to be below $10,000 or is it going to be like a million dollars what's it actually going to cost for me to get a consumer bought and when when when is this going to be out like do you have a ballpark gate in mind so let me answer this simple question first when this going to be a lot sooner than people think so I mean humanoid is taking care of the busy work so that you can really enjoy what you love to do is it is very close and um I think the cost of this it's kind of implicit for that so I can't give you an exact number like you said but it is priced in a manner that makes this feasible for Consumer so it's more in the size like the cost range of car so it's not the hundreds of thousands of dollars it's not a luxury car it's a car and of course there's always a question of like what's the model of this it's like a subscription is a fixed up front is it a combination over how many years is this the appreciated all it sticks but it's roughly in more of like a normal good car and U it's going to come down over time but I do think it's very important that you're able to start out at a price that is not too high because the usefulness of this product will hopefully track an exponential right so in the beginning it is very useful and you don't want to go back to like not having a human not at home right it's your companion that helped you do everything that you don't want to do it doesn't matter if you lose money today but if you win this problem statement then you win everything you do and uh it is it is incredibly exciting I'm really really looking forward to sharing more with the world about this and all the lessons learned and like um yeah is it going to be out faster than Optimus I am not able to speak on behalf of Tesla so you got to speak you got to ask Elon um so I have a question here right like let's assume I I know you can't give me specifics on let's say the next few months because you're building it and those dates are going to change over time all of that but you can play out a scenario for Me 3 years from now 5 years from now let's say if I asked you 5 years from now let's say 3 years from now 5 years is a long time nobody knows what's going to happen in 5 years let's say 3 years from now what's it going to cost and uh do you think it's going to solve everything like do you think it's going to be like what what's the range of things it's going to solve is it going to be like playing the piano and like playing the violin and playing football with me or is it going to be like hey specific tasks like it can do cooking or what like range of abilities and what what it's going to cost in 5 years that's probably the question I'm asking let me let me first take like one step back and say what I think like is what what are the key things here that you pay for right because you asked the question about Optimus and I think a different way of answering that is to say I firmly believe that what really matters here is the safety and the afford ability so when you look at Neo right you can look at the specifications and you can see that this is pretty far ahead of anything else announced with respect to like weighing just 30 kilos it can squat or deadlift 70 kilos with that low weight it can move as fast as me like it can jump it can run it can be like do all kinds of dynamic things got the same degrees of freedom get full hands all these beautiful Dynamics but that's actually not what we're the most proud of what we're the most proud of is that it's not an industrial machine and that's generally where the field has been going right everyone is making industrial machines this is more like a Baymax it's soft it's compliant it's got no pinch points it's like weight it's inherit safe and this is really what is going to matter for this kind of an application so these other humanoids that you see that are built on more like the classical way of thinking about robotics I don't see a path where they can be deployed into this market so we're very uniquely positioned in that sense so when these Droids will be other humanoids will be deployed into proof Concepts into factories or Logistics or all these things that we did a few years ago there are some public information about what these targets for that and I think those seem sensible uh but of course uh it's a very different thing to to deploy into consumer and I think the safety and the affordability is the two things that needs to be there for that to happen and um to ask your question about the like three years 5 years 10 years basically right um you ask a hard question so I think the three years is the hardest one it's very hard to predict where are you in three years so let me start NE I'm very confident that in 10 years we have basically no more correlation between capital and labor mhm and Society has fundamentally changed and I think this is going to be probably the most exciting time ever in history to be alive and I'm so glad to be part of this and I think we have a possibility here to solve so many societal problems and if you want to take this all the way to the Limit I'll say for example what are we as Humanity we we we're the ability to take energy and turn this into products and services that we consume and generally we're getting pretty good at harvesting energy and then we're still mostly consuming calories to produce products and services and once you break this that's basically where we we become a type one type civilization right and of course even if you think about fundamental problems today like sustainability and climate everything we that is not sustainable is done because we're trying to save cost by cutting quarters if you have an actual abundance of Labor there is no more reasons to cut cost and cut corners and you can do everything in a sustainable man so that's just one example right um and there there's like an infinite amount of long tail tasks there on everything from like how you can do distributed experiments and Science in the physical world at scale with uh with Androids you're no longer limited by cost of doing lab experiments uh all the way to how you can start colonizing space and building out all systems um so if you go 10 years into the future there are billions of Troys out there and I think most of them might still be humanoid but starting to go through this shift where the market cap basically which it wouldn't be anymore because it's is kind of disconnected but the the amount amount of Labor being done by droids is so large that you start to get into where it makes sense to specialize again and you you've seen this now in Computing right it's starting with specialized systems like my parallel here would be industrial Robotics and then comes the PC and now suddenly it's so useful everyone starts using it and then the market becomes so big that suddenly it makes sense to specialize again like what is happening now and most products throughout history go through these Cycles where this happens like you can look at like even Automotive do the same and like what kind of like disruptive Technologies go through the same cycle so in the end we will end up in Star Wars right where we will have some aculture drones and some mechanical repair droids and we'll still have very large amount of humanoids because they're generally very useful the time in between there will be pure humanoids just because you want to get to scale and I think if you say 5 years I think we all have one at home I think most of us might have a personal one that will um help us basically do everything in life and just live a higher quality life I think it will be pretty affordable at that point um and when I say affordable here I think U we have a goal of having like the limit cost of this over time and this might take more than 5 years but the limit cost of this after time coming down into the thousands of dollars instead of tens so like four5 thousand let's just say thousands I it's it's a long way out still so but while keeping the same or increasing the capabilities right that's the cost of a mobile phone like or a very expensive mobile phone so in three years I think we've had our chat GPT moment for robotics quite a while before that and all these roids are generally useful they do things for you and you see them as a companion in life that you talk to and that might know you better than anyone else and it helps you with everything you want in life but sometimes the illusion breaks because the system isn't perfect and sometimes it just catastrophically fails in some manner where you're just like oh wait a minute this is just data in data out there's this is actually intelligent yeah but it's kind of like generally giving you the Illusion for such a long period of time that that is going to be how it is and then I think actually and sorry this is more on like the philosophical side no that's fine feel free to take any part you want is like been a big discussion in my group of friends lately has been like if you think about machine sentience right so when we get there and we don't know when but like when we get there I think one of the most interesting things that will happen is not actually machine sentience itself it is we will now suddenly know what sentience is M because we don't so like what is this missing piece that we call sentence and once you figure that out you can start to back fill this in and you can say okay that means mushrooms are sentient but but in a very different way yeah sure mushrooms are sentient but flies aren't or whatever right uh and then how that will affect society and how that will change the way we live once we figure out what this thing that we kind of feel is so unique to us right but but I I would say clearly intelligent animals are sentient so what is sentient we don't know and uh I think that's going to be very very interesting again this the exciting time to be live right we're going to find answers to a lot of things and in one year we I think it's might maybe even more interesting like what can you do in one year I think you have a system that can very efficiently do labor through a mix of human in the loop tele operation and Ai and that you can build these systems in such a user friendly manner that this can be done both to serve remote labor and for you to be able to train your own own Droid to do anything without being an AI engineer so be a work from home sort of model for construction workers where you know there was there's this dream where you know a construction worker could use an Xbox controller and like control something and then not have to actually physically go and like pick things up but here now they're doing it at VR so paradoxically everyone becomes a gamer right that's that's the story you're going for so actually I mean if you know good Gamers send them our way I mean we've hired hired a lot of them lately we have a pretty big operator team now which is piloting these Droids to um teach them how to do things it's very exciting work because one of the big wins this year is actually that the AI team isn't training the models anymore The Operators are so we are dog feeding this already with like making good enough uis and good enough documentation to make sure that you can train your own models is there a is there an equivalent for a uber style cab business here where I sort of get like a fleet of Gamers I train them and I say here are your Bots and then they can like make their Bots pretty and customize them and I go to you know some construction company in India and say you know what my fleet will do it for you at XYZ price they're going to do it remotely if you Pro one of those out yeah yeah yeah that's going to change everything it's basically the the gig economy for robotics right it's a robot gig economy and at right now we are doing all this ourself because again like diversity quality quantity it's so important for us that the data that goes into the system is high quality so it's a pretty specialized job where you learn a lot right the intuition that you get when you use this system lots of hours every day teaching it how to do things is very useful so you know exactly why something is failing and like oh we need some more data this kind of task that's why this is failing so we're not quite there yet where I think like just anyone could do it and will be as useful but I mean neither is a cab driver a cab driver is pretty good at driving a car that's what they do so it might go there it might go there yeah I'm just I'm just thinking through all the implications of this right like if labor Falls or becomes remote I mean it's like yeah there are n number of second order third order implications for the economy for the world for jobs uh for all of that um what do you think happens to jobs in in a world like this like what do you think happens to the economy what do you think happens to people how are they going to take it let's let's walk out the example right so okay let's say that like you start in a company where this is your job so you're you're doing some remote task and hopefully you're able to do this task as efficient as if you're there that's like the Baseline and then over time more efficiently because you have ai assistance in what you're doing through Droid and hopefully also without uh putting yourself in a Harm's Way right but yeah pretty fast you will kind of automate yourself because you're training this with so much data at this point so what happens now and this we already do but what happens now is that instead you will get multiple droids and we'll say like okay whenever one is struggling because it's getting to a task you tell you up when it's struggling and hopefully also it'll tell you it'll like Ping you for help right uh I failed three times at this task I need help um and then at some point the human in the loop is no longer uh significant cost right and you don't need to get to that many droids per human for that to be the case so and then after a while the human doesn't have to be there at all and then what you're really asking is I think Jensen puts this really well it is the same question as asking what is the limit of human creativity because we always find things to do and almost everything we do is not constructing houses or putting food on the table it is in that sense kind of quotes artificial jobs that was created to increase our perceived quality of life and I mean there was this really really amazing amazing comment given the other day uh I I have trouble pronouncing her name but like Joanna M Maka that says like I want AI to do my laundry and dishes so that I can do art and writing not the AI to do my art and writing so that I can do the laundry and dishes and I think this is so true right that's the world I want to live in and I don't think we will run out of things to do I think we will always invent more things that we want to do I don't think there is a limit to human creativity I think we're all we're all driven by some sense of purpose right like there's such a direct correlation between purpose and happiness and I do think and hope that this will allow a lot more of the population on our planet to do things that they feel is Meaningful and that has purpose and that that will in a very real measurable manner increase General quality of life yeah and as you were saying at some point and I'm a big believer of this although it's not falsifiable so I don't like publicly state it but eventually we might find out that Consciousness is just one type of a general World model or the implication of a general World model and then we might find out there are many different types of Consciousness and like you said the mushroom is probably sentient in I I hate interchanging the word Consciousness and sentience um I made that mistake here but uh it is pretty interesting do do you actually feel that do do you feel the Phil philosophical implication of a gentle World model is you know an something sentient popping up yeah like these philosophical arguments quickly get you into trouble right so yeah I know that's why I don't say it there's this uh very good um thought experiment here which is called marry the super scientist very familiar with it no I'm not I'll give it a quick version so Mary is a super sign is she knows everything about light that there is to know she knows like the wavelength how how that inter interacts with uh all of your nervous system your brain how you perceive this absolutely everything so let's just pretend she's the all knowing god of like light and how it interacts with me as a human so Mary lives in a box and she can always see the world through black and white monitors and she's been there all her Liv and she's studying the world through these monitors and you can kind of like easily see here you can make a parallel to like a box that a desk a computer right yeah so one day you open the door and let marry out and now she sees colors with her own eyes does she learn it like there's written multiple books about this thought experiment and and I think the answer to that question in the end boils down to is there anything more than just biology right because then by definition if she knows everything she didn't learn anything so what is it to perceive something if you already have the knowledge and you get into like a God complex problem and all these things but the way I like to look at this is oh man is that a hard way of figuring how colors work just go out of the box and it's I see this more as an generic problem maybe we can get to AGI but just like consuming tokens on the internet but oh man is it the hard way to go about the problem and in a world where everyone is running out of compute and everyone is running out of data if you have better sample efficiency and relevancy in your data and you need compute because self efficiency and relevance of your data is better you're probably in a very good position yeah you just have to give it feet and hands and then it'll do the it'll find things that don't exist on the internet interesting I have two more questions for you you know I want to deviate from the this path uh for a while have you heard of the unitary G1 it's so so we were looking for a bot that we could experiment with right ideally I mean this is the the old way of doing things I assume now that I've had this conversation with you so the way is uh G1 has a Robot Operating System uh sort of SDK like package and you know we we thought we get it we'll play around with it we' played with so there's another company called yoom which has this quad quad robot right like the dog and we have one of those in the office and we were playing with it we we've gotten to the point now where we can you know we don't need to play at the they have two levels of abstraction right one is on the level where it's like there are pre-programmed commands to move from point A to point B and the other is where you can directly manipulate the the joints and we've gotten to the point where we can now directly manipulate the joint so we've learning a lot more about it as quickly as we can and we wanted to play with the G1 because it's a bipedal robot but when we actually spoke to them about pricing The Bu The the advertised price is $16,000 but the actual one that you can program is about $35,000 roughly around that much uh so a lot beyond our budget range but are you are you worried about China is it eventually so there's two kinds of ways right like there the there the Apple model where you build the entire thing and you build the software and then maybe the android model where I just get you know this bot I put a skin on top of it maybe a human-like skin or like a furry skin or something like that and there are a bunch of companies in India that have done this very well they man they they get Chinese manufacturers to make the the headphones or like uh you know the earphones and then they put a sticker on top of it they brand it really well and they build a company around it what route like what route do you think most people are going to take yeah let me ask on the unit 3 one first so first of all I think it's quite important to point out that what unit 3 is doing is actually very good um they don't follow the classical kind of sens on of Hardware side they don't have the 10 mechanisms and things that we do but they they do have pretty low gear ratios so you can see like the Dynamics of their system is pretty good like it it can walk and run and do these things a lot more natural than most other human um so I think they built a great product and I think it's going to be very disruptive in the academic SE in the sense of enabling a lot of academic labs to start researching AI without having to build the hardware um yeah that being said the system is mostly built for Leed Locomotion with some manipulation and it's quite Limited in like the dexterity that it has to do fine manipulation um mostly a combination of like how the actuators are and also the number of degrees of freedom but I think they're way ahead of anyone else currently with a commercial product when it comes to price I'm not worried about this generation like we I feel the system we built is very capable it is very affordable um we're able to compete very well here um I do think over time there will be two paths here it is China builds the hardware and then we build something on top or like you said the Apple approach now clearly I have very much connection on the Apple approach being the right one here given that we do everything from copper in aluminum in to robots with intelligence out um and the rationale for that is that this is actually not a disconnected problem like so much of your intelligence lies in the way you move and our ability to go all the way down through the stack to change things to make our system work better is that is how we keep ahead in the AI game and this goes for like the Dynamics of the system like how does your system respond when it's opening a door or even like your camera system right and like how do you tune this for the AI to work well and there there are so many things that comes into building this Complete endtoend product that enables you to do this and also manufacturing is such an important piece of this and even for cars right you see that it's not the pure software layer that Wis it is actually the vertically integrated and the most successful companies are the car companies who manage to actually do a great job on softare and AI even though they build the manufacturing and car itself which is very hard from like an executional point of view and Robotics is the same but more complicated so if you think about Apple which interestingly actually does Outsource their manufacturing this this works because a phone is quite complicated but it's not that complicated from a manufacturing point of view but now when Apple tried to for example do this with a car it didn't go so well because you cannot disconnect the design process from the manufacturing process with a car it is so inherently couple you have to start with the manufacturing and then figure out how do I design a car that I can manufacture robotics is no different and traditionally Here China has been very strong um I do think it's very very important that we build companies here who are vertically integrated all the way from the manufacturing and all the way up to the AI because that is how you can combine the best of these two worlds and this is what is going to get you to in the lack of a better word uh get as quickly as possible to a system similar to something we would call AI but it's very easy to underestimate before you worked a few years in the field how much the Dynamics of the system and how you designed your system actually matters to how well your AI behaves and what your system is able to learn and another way to look at it is can you just take any amount of data and use it to teach any system how to do something yeah and to me that comes back to an engineering problem like you can solve cross ENT and say like okay we explored the world as a car and as a dog robot dog and now we're going to use that to figure out how to move around as humanoid might work but it's going to take a long lot longer of time and yeah it's going to require a lot more data and it's just generally going to be less efficient and it's a problem we don't need to solve yeah the true General World model would be you're able to put this in anything that has electricity and you know the ability to move its joints it could even be you know human transmiss like I've a that well that's an assumption I'm not sure I agree on that because again your body matters so much to your intelligence so even animals right would it be adaptive like yeah but like even animals learn how to how to move you're not born with the ability on how to move you learn it because it's so tuned to your specific body and I think it might not also necessarily be true that intelligence always would only live and kind of like the cloud more like a h m a lot of intelligence will live at the edge and I think in general this question does not come from what I would call like the most sensible basis so it's more a question of like as a typical VC or investor can you keep only investing in software because you would like to be the one that creates leverage not the one that creates what can be leveraged but if you don't invest in what can be leveraged at some point you will have nothing that you can leverage and it doesn't matter how much you invest in thinks that can Leverage is that because of commoditization or of of software or is that because uh the hardware is so tightly coupled with the software in this problem statement it's both so from the investment point of view it's generally that software has been proven to be very very scalable and therefore a good investment so you kind of have you have a well established investment thesis for how to invest in software and generally you've avoided Hardware because Hardware it's generally bit bad investment um but if you look at the biggest companies in the world they're all vertically integrated Hardware plus software companies and there's a reason for this right it is the most efficient way to go about the problem so from company and Engineering point of view I think it's pretty obvious that like we want to control the manufacturing and the droids we want to make sure that we have the full ecosystem we want have the data we want to have the fleet we want have all these things because that's what puts us in a unique position the most intelligent system and there will be competitors that will be having old strategies that might be more fragmented but also might be interesting approaches to this I don't think it's a winner takes all I do think it's a Winner Takes a lot in the beginning it's very hard to catch up to someone who has a very large Fleet size therefore a lot of unique data and therefore can basically just provide services and capabilities that your competitors can't and also operate the manufacturing cost that your competitors can't but the market cap here is so big that there will be multiple strategies and that will ultimately that will give consumer theability to choose right that's interesting I actually you know there's one point in there that you know maybe I didn't get enough Clarity on I I had a you know this was like I think a dinner I had like a few weeks ago where we were thinking about well if there is a general World model right and it would be perfect at input output uh have you seen Spider-Man you've seen Spider-Man right there's this there's this villain in Spider-Man called Venom and Venom is basically a symbiote it's like this alien life alien organism that can sort of work with any input output like it can blend with you in a way like it can it's a symbiot so it sort of merges with you and then if you've got eyes it's able to use the eyes if you got arms it's able to use the arms technically in the comics you know it can even take a plank of wood sort of integrate with it and see you know is there a way I can move this thing you feel uh and and that's why I asked the question of is it software through and through and does is the hardware not very important over a 20 50 year Horizon is it just this intelligent intelligent piece of thing piece of software that you can just throw at any animated object with joints and maybe uh electricity and it can just make it move the old answer is I I don't know but I do think it's interesting to think about try to man The Other Side of its argument so what if it's actually all at the edge that's kind of how we work right so all of the intelligence lives in each individual Droid and the communication between them is kind of like the mesh Network that exchanges information and gives your intelligence robustness it's kind of like a distri distributed system right centralized decision making is not always the best I would say actually very solo it is and like an analogy here would be think about capitalism so ultimately what capital is is information like local pricing for example regulating production so you think about capitalism as a distributed computing system that computes your resources for you and what you produce I think it's very likely that intelligence is the same and it leaves at the edge and it's pretty unique to you and your unique local input and how you are tuned to this local input because this is where you spent your time and how this kind of like different experience that we all are part of out through life gives us unique perspectives and these unique perspectives is what makes you a good makes the total a good decision maker so you're saying if I was born without eyes I'd have a very different Consciousness I'd have a very different experience of the world I mean I would have a very different experience of the world but my intelligence would be different yes I think so it would be very different uh in that you would value different things so whether or not we call that like a different intelligence that's that's I think more of like a terminology question but clearly if you speak to someone who has been blind all their lies they think about lies in a different M different way I mean they have a unique perspective this is why divers again right it comes back to diversity diversity of thought diversity of body diversity of experience diversity of tasks this is where your intelligence comes from and I'm not so so sure that everything will always be centralized in like one big giant model living in in the cloud kind of like a Hy mind making all the decisions I think the system might be in wored this is of course speculation but that's that's how nature Works interesting I have just one last question for you and this is probably a question you've been asked multiple times right uh is there a Skynet scenario that's ever going to play out with this is there are we going to see Terminator sorry I just had to this is like no no it's it's actually a very very good question so but when most people think about AI risk right it is the terminat case I do think the real risks with AI is just like any tool if you don't use it correctly it it can basically create a leverage for you as a bad actor to do more bad things and I don't think the likely outcome here is a Terminator it's just very very rare to find for example science fiction about the good case like we're always like drawn to the dystopian story right because like that's and and so am my like it's it's engaging it creates like these deep unique characters when troll is suffering like we win versus this external enemy of like the sentient whatever kind of AI that want R rle in this kind of universe but actually I think in general the more intelligent the system is the more it values life the more it values diversity and realizes how how important diversity is right so if you think about humans kind of like a bag of information the more the more kind of like intelligent we are the more information we contain and this is precious so I don't see why intelligent systems that are more intelligent than us should not respect life that being put aside I think this is an alignment problem and I think um we're pretty good at that it's something that's being extensively studied and something that is very important and something also that we're working on with respect to for example Rob safety models and how to ensure for example that you don't by accident do something bad and this is a deceptively hard problem because you need such an understanding of the context of your tasks to be able to make the right decisions so you think about us right whenever we do anything we're doing this forward simulations of like what could go wrong it just happens naturally for us right I'm picking up the coffee cup and I'm I'm like if if there was a kid right next to me I was aware of the risk with respect to this so these kind of like micro safety assessments that we do all the time they're basically forward simulations in a world model and that is what you need right that is how you ensure safe behavior is that when you're searching through your world model for whatever answer or policy that you're going to carry out to do the task you're ensure that this path is pretty far away from tasks that might have unwanted behaviors and uh I do think that's a very important and hard problem but a solvable problem and then I'm not too worried about just basically sentient AI going wrong I think uh this is mostly a science fiction thing and i' actually recommend people read some less dystopian science fiction where these things go well and see how we can build a society which is just so rich by coexisting with these things that we can leverage that can help us live a better life interesting this is this has been an exceptional conversation like I've learned so much I have a much clearer picture I guess of the future because you know you've just been in the space you know what everyone else is up to your timelines seem short it's not like a 20 20 years away 50 years away and I'm glad we have consumer robotics around the corner D promised that he'd send me one and you know I want one of the things I want is I want to be one of the first people in India to have a 1x bot right I think that would be nice uh thank you so much for doing this um it's I don't know it's just this has been a really good conversation and I hope you felt the same oh I really enjoyed it and uh I'll make sure you get one of the first ones and I'd love to invite you in on the journey right it's smart experimental people like you uh that we really need to figure this out because it's a completely new space and um it's going to take a lot of community to get it right yeah yeah I'm going to teach you some karate I'm also going to teach you to use the cameras we're going to make it do fun stuff and hopefully I'll be you know if if you ever make a Marketplace we'd love to find tune these models in make some money out of it sounds great awesome thanks so much bye ",
    "url": "https://www.youtube.com/watch?v=963VJM0eTWA"
  },
  "qS6JMr6cJBc": {
    "published_at": "2023-11-08T13:00:47Z",
    "title": "@aevytv made an Anime using 20 AI tools!",
    "text": "@aevytv made an Anime using 20 AI tools! you guys made an entire anime using like 30 different AI tools the way it was sh and it looks really cool that is super impressive tell me about the process it's a pretty complicated flow which is based on anime tip essentially we made custom models for all the characters then we took out the best pictures of those models use another technique called IP adapters and then fed those images in and then the output is great and then everything else all the static shots with think camera's moving and all that was all mid Journey so there's a lot of editing in it for the background because we were using using this app called cam Trak AR we were able to get a 3D camera so as we moved the camera in the real world we were able to get the 3D camera in the 3D World the hard part is figuring out the workflow and over time I'm sure people will improve that workflow right once we put it out in the world so a does these cohort so we just probably going to give the workflow out there the next time we do it we'll probably get a few creators on we'll think through the story we'll make it really fun you know maybe spend like more than 3 minutes on the script you guys should definitely go to the a channel and watch the full video it's really worth watching",
    "url": "https://www.youtube.com/watch?v=qS6JMr6cJBc"
  },
  "FDjgQBpGfrQ": {
    "published_at": "2023-06-29T12:59:28Z",
    "title": "Turn Words into Websites INSTANTLY with Framer.ai - No Coding Needed!",
    "text": "Turn Words into Websites INSTANTLY with Framer.ai - No Coding Needed! framer.ai what is this uh you can now prompt websites into life you don't know how to write any code can you make a website just prompt in a website okay a launch page for my startup it is Uber but for ambulances you can order an ambulance whenever you want Mario themed Pages for pricing troubleshoot emergency let's see what it takes nice emergencies with Mario ambulances supercharged Ambulance Service generates copy as well we take the power-ups of Mario and combine them with rapid ambulance service for quick and efficient medical attention no more waiting for traditional ambulances just tap and you're on the way to the mushroom hospital or Princess Peach Medical Center try to level up your emergency response join Mario ambulances today Pro Copy is a little cheesy but this is really good for instant websites it's too powerful",
    "url": "https://www.youtube.com/watch?v=FDjgQBpGfrQ"
  },
  "yJvV2aogtTs": {
    "published_at": "2023-06-06T12:30:32Z",
    "title": "We Built a Personal Junior Developer - AutoCode Pro",
    "text": "We Built a Personal Junior Developer - AutoCode Pro for you any Layman or a developer who just wants to speed up his work finally have a tool where you can use small to generate any Chrome extension that you want you can actually generate all types of web apps but you've not tested it for all types of web apps it's so this is autocode the links here uh it's your personal Journey developer so all you have to do is sign in with Google so first you have to set up your key so just go to the account page then let's go to projects let's create a project you can choose between gpd3 and gpt4 I want to create a Chrome extension give me a Chrome extension that when click gives me a task manager with a to-do list that's it all you have to do is build once you build you get a page it takes like 5-10 minutes it builds it and you can download it and upload it on Chrome that's all there is to it",
    "url": "https://www.youtube.com/watch?v=yJvV2aogtTs"
  },
  "7ieAnLwGfvw": {
    "published_at": "2023-05-30T14:11:10Z",
    "title": "25 AI based Agents Played a Game Together!",
    "text": "25 AI based Agents Played a Game Together! new paper that came out recently where they took 25 gbd based agents with them in a simulated town just made them talk to each other and by the end of it they host a Valentine's Day party for each other and people watching it falling in love people watching it from outside couldn't rate the GPT version as less human than the human version they've also made humans role play separately and people don't tell yeah I mean games will start using GPD immediately because you don't need to skip for NPCs anymore yeah but that's for dialogue I think having GPT agents interact creates like these weird things like every open world game is now a role plays GTA 5 roleplay yeah and it's like people can interact people come up with new missions for you you can have your own second life you can literally create a world yeah where everybody else in that world is self-sufficient and you know in every way and you choose to be a part of that world whenever whenever you feel like",
    "url": "https://www.youtube.com/watch?v=7ieAnLwGfvw"
  },
  "V1H3MmNTyUc": {
    "published_at": "2023-06-10T15:41:58Z",
    "title": "Virat Kohli in Game of Thrones!",
    "text": "Virat Kohli in Game of Thrones! dude my journey does some really awesome stuff okay let's put Virat in Game of Thrones okay so imagine Jon Snow sitting on the Iron Throne all right so we have an image of Jon Snow all right let's pay bottom right let's upscale image four wired up scales let's do save ID Virat all right so Virat in Game of Thrones is ready holy this looks sick as let's try the same thing but in anime mode slash imagine Game of Thrones okay Dash Dashie check this out whoa that's pretty sick now let's try the face swapper oh so you can face swap and change the style as well dude that's sick this is too good let's try Virat Kohli on the iron throne in the style of Pixar much better let's upscale one of these pretty good oh it does it gets way better dude this is too sick",
    "url": "https://www.youtube.com/watch?v=V1H3MmNTyUc"
  },
  "6s8jVpCKLSo": {
    "published_at": "2023-09-01T13:30:02Z",
    "title": "What Does Chandrayaan&#39;s Success Mean To India",
    "text": "What Does Chandrayaan&#39;s Success Mean To India what do you actually think about chandrayaan pretty epic I think it's like a global statement about India's Tech prowess we're expecting more foreign investment in Indian not only space Tech but probably has the Ripple effects will go beyond space Tech you know doing this shows the world that you mean business correct you're sort of improving the brand of India it's like India's a story right and like every company also has a story right like in fact there's another brand that use space really well Red Bull the space jump by Felix Baumgartner I remember that so let's generate an image of the space jump actually yeah that's a Felix Baumgartner jumping with a Red Bull oh yeah or cool image oh dude look at the logo on his uh helmet that's pretty cool dude that's a that's a sick image yeah bull is like exactly the same one yeah you know it's not just the logo it's also getting the text text right totally right yeah oh dude it literally says Red Bull on his chest that's crazy it's such a big difference right like he's using it to jump off space I'm using it to beat the afternoon slum",
    "url": "https://www.youtube.com/watch?v=6s8jVpCKLSo"
  },
  "irACko7u3-w": {
    "published_at": "2023-07-11T13:10:07Z",
    "title": "Make Videos Using ChatGPT Plugins",
    "text": "Make Videos Using ChatGPT Plugins so there's another plugin by the way called hey Jen so hey gen is a automated yeah it's those talking head videos actually we'll use Wolfram and we'll use Hagen so we like use Wolfram what is the per capita income of Britain make a video on this with a channel let's play the video the per capita income of Britain also known as the United Kingdom is approximately forty five thousand three hundred and eighty dollars per year per person according to a 2021 estimate this ranks the United Kingdom 26th in the world while she's really happy about that dude I have to say the output quality on the face and the lip movement is pretty good in six months it's gonna be somewhere else like you won't be able to tell and it's just going to be more convenient to have like an AI creator of create rather than you creating yourself great news as a Creator myself I'm very excited about these times",
    "url": "https://www.youtube.com/watch?v=irACko7u3-w"
  },
  "VR3kuXbMzYc": {
    "published_at": "2023-10-17T13:29:41Z",
    "title": "AI will Make us More Disciplined?",
    "text": "AI will Make us More Disciplined? I think exams are soled now as soon as Facebook x-ray ban becomes cheap enough the glasses act as your eye and anything you see will just get Sol instantaneously it's definitely going to make people cognitively lazy I actually disagree I think that you'll be more disciplined with AI because you know a lot of young kids want mentors and I saw a tweet I think it was by siddu paapa where he was like most people looking for mentors are actually just looking for somebody to tell them what to do on a daily basis so if you have this God to your AI sitting in your glasses or your phone or whatever and it just tells you do this get up at this time it's just like you are put the faculty of your life into somebody else's hands and they're just running it for you there's no accountability over there the drive to actually want to pursue something with the guidance of a mentor still needs to exist I think you're all underestimating the fact that eventually we'll start trusting these AIS more and we just look at it as a coach SL Mentor figure now I could be wrong this could play out differently",
    "url": "https://www.youtube.com/watch?v=VR3kuXbMzYc"
  },
  "tLL5FxVpibI": {
    "published_at": "2023-08-24T13:25:35Z",
    "title": "Is this Real or AI Generated?",
    "text": "Is this Real or AI Generated? I shared something on my Instagram okay is this real or is this AI generated what do you think I saw your Instagram post and I knew it was the I generated but it still blew my mind it's not AI generated it's 3D oh okay what does that mean so somebody has used something like a blender or Ramaya and actually built the entire mesh for a textured at the material set the light they have done it manually ah okay but uh why did you ask me if it was simply because now people are having a hard time differentiating 3D AI generated in Rio so now you have to put it into one of these three buckets can't AI generate 3D models no it can but it's not that good there's some tools I saw one called Alpha 3D you know if you send it a pretty picture of a shoe it will generate the entire 3D version of it but it's not great like the textures are terrible it's washed out it's okay but somebody will solve it it should be solved even your criticism of AI is followed by six months it's this is awful but six months I don't think video will ever get solved but six months",
    "url": "https://www.youtube.com/watch?v=tLL5FxVpibI"
  },
  "mvqKhTxUs4w": {
    "published_at": "2023-06-26T11:30:28Z",
    "title": "Mark Zuckerberg&#39;s Response to the Apple Vision Pro!",
    "text": "Mark Zuckerberg&#39;s Response to the Apple Vision Pro! what do you think about Zak's response to the Vision Pro he wrote a company email and then he came on next Friedman's podcast like just the fact that he's giving a response is going to have so much attention and scoop me on it his reasoning was yeah I think that going for something we are going a different way we are going a different path we've tried that but that's not for us so I like people who are willing to go all in and have like his incentives not money he's made enough money so I know he's playing to build something really cool I just encourage it from a distance because I just love it I used to hate him because of the internet yeah but then the more I learn about him the more I'm like dude this guy has been CEO of the company by himself not given the reins to somebody else and is had the balls to say okay the next platform is going to be this I don't mind tanking Facebook for this he's like man's man thing also going on right now like the Jujitsu and yeah the Iron Man thing that he does and I like Zuck a lot now I'm just like dude I don't mind being that guy I won't but you know I wouldn't mind you are like Zuck in the sense that you also seem like your AI generated sometimes",
    "url": "https://www.youtube.com/watch?v=mvqKhTxUs4w"
  },
  "K1m1MAPsQeQ": {
    "published_at": "2024-04-08T08:18:15Z",
    "title": "The future of AI computing ft. AMD #ad",
    "text": "The future of AI computing ft. AMD #ad oh by the way T AMD has launched the world's first dedicated AI engine in an x86 BC processor I'll give you an example and I can blur this not on the cheap way that a lot of video software will blur it I can blur it with AI right now with the AMD ryzen AI oh damn and it doesn't affect the performance of the system and of course AI can also help with privacy Von I had my YouTube channel hack and thanks to uh ryzen AI the risk of hacking goes lower cuz it uses AI to detect threats and actually fixes them and also shout out to AMD for sending us these cool lap laptops I got to try all of this by myself so until the 8,000 series is out you can try the 7,000 Series Laptops go check them out at amd.com rizen aip's shout out to AMD for sponsoring this yeah",
    "url": "https://www.youtube.com/watch?v=K1m1MAPsQeQ"
  },
  "e29dJSuktWc": {
    "published_at": "2023-10-25T14:07:37Z",
    "title": "Raised $2.3M at 19 From Sam Altman, Life in San Francisco, Web&#39;s Future &amp; More Ft. Aryan Sharma",
    "text": "Raised $2.3M at 19 From Sam Altman, Life in San Francisco, Web&#39;s Future &amp; More Ft. Aryan Sharma so Aran welcome to the show uh I've seen you all over the news I would love to know what you're building agents seem like a very very exciting problem you've raised money from Sam you've raised money from Nat and Daniel would love to know your story yeah we have uh we building it's called induced it's we build we build these AI Bots that we run on the cloud and just think of these as like extended members of your team every bot has full access to a browser it has its own email it has its own phone number um and everything's running on the cloud so it doesn't affect your computer you can be sleeping and the Bots can still um work and function um we use these Bots and we have basically deploy them in business processes and workflows where a company doesn't want as a 50 member team they're spending time doing a lot of stuff that can is not really requiring cognitive power could be form filling data entry um could be just scouting leads running verific anything any any business process that would typically be outsourced either to a back office um either they run their own back office that's kind of the stuff that we um use these Bots to run on the cloud um and it's like a real back office so you can because we deploy these browser instances and run them you can have a thousand running at once you can have five U depending on what you need um so yeah that's that's basically what we're building um it's a slightly different kind of agent it's not fully autonomous it's like doing consumer work um we have a lot more scripting and just input that goes into it um but we also do that because we're serving a customer segment that wants reliability and that is kind of it it feels for us it's one of the most opportunity when we and we can go into the architecture later but the way we've come to this and how we've designed this um we think the infrastructure we're creating in this process is just going to be increasingly important as more people start creating agents models and connect them to the internet um how we came to this so we've um both me and my co-founder aush we've we're both U fairly young um and we started working in Tech um they 13 14 started writing code um we used to look at all all these people that you mentioned we rais money from they're kind of the the people that we used to look up on YouTube and we used to see the YC um startup School lectures and it's like this is this is what's cool and at some point in life we want to be able to do this um and we we did different versions of that before this so this was not the first thing that we've worked on um even together so we built a bunch of stuff um in AI before I was working at this company where we were doing physiotherapy AI um iush was working at this company called third web that was um building build scripto Dev tools um and last year we were like last year early this year we were sort of at this point where uh both of us were done with school we didn't want to go to college um I us was just frustrated I had I I actually had a scholarship to come to the US uh was like from a foundation that runs and um we it was like basically not interested in going we were way too excited about what was happening um with AI generally in Tech and sort of felt like we should do something together so that's how it started it was very organic we didn't plan that we want to build a company around it earlier was just going to a bunch of hackathons building some independent projects and from that we just caught onto a bunch of patterns that seemed to lead to something um and that's what this form factor of the product has come to now um how how did you get in touch with Sam so with all of these people that we used to read stuff about um I we used to cold Outreach and this is just I I have embarrassing emails from when I was 14 that I've sent out to people which is I'm a big fan I watch your videos every day and I would love to work what is your advice to me and and I actually have some interesting replies I I have one reply from Michael seel at YC and he's like don't send emails to people is my advice go read up stuff online and start building things um so we used to kind of send these things out there was stuff that we've sent to Sam before um obviously we've been in touch and we've seen him before he kind of became This Global icon pre-chat GPT um so there was like a little bit of that interaction and then we so we we used to come to SF on trips uh before we like started spending time here for work and that was like while we were working we had a little bit of money so we buy a ticket come to SF stay some with some friends meet interesting people go to these events so we met him like once or twice there saw him there um and then there was one like it's like out of all of the cold Outreach attempts and then some mutuals that were formed over time it was like a threeyear period of time we got in touch um he said he's and I kind of pitched him that I want to be I want to work with you um so I'll be a secretary I'll do whatever you want I just want to be around you and see how stuff is happening at open the ey because they they've been releasing interesting papers way before language models came out um and the whole team so I did that and he was like I'm I'm way too busy spending time on open a and Helen which is his other Fusion company um but we should keep in touch so then we kept in touch when we were doing the round we went to him uh like this is what we are working on and would be awesome to have you um and that's how that's basically how that happened I remember the one funny story in that process is when I met him last year um of one of these interactions I I was like I'm I'm interested in a lot of things there's this whole like concept of how we can use AI to just make software and I'm interested in some things around like bio and like Space is really exciting um I think there's like breakthroughs happening everywhere he's like this is this is all useful um but um I think the most interesting thing like the most high leverage thing you can work on is AI and you will come back to this at some point um and that was like summer of last year so it eventually happened so I went to him as like you said we'll come to AI it has sort of happened um and would be it would be awesome to have you with us yeah interesting you also raed from Nat and Daniel I've heard that Nat and Daniel give you like apart from their money it's also like you get a cluster that you have on demand access to is that true they have a cluster um it is I think the the direct access available to the companies that they just allocate large amounts of capital to and they they great and bues and they've done like 11 labs and a bunch of other deals we we got them through a grant which is the accelerator that they run it's um it's it's basically it's it's the safest form of investment so it's it's not a grant but it's kind of the lowest barar of investment that you can have it's structured as a uncapped safe so we applied for that it's kind of like the YC for AI they take 20 companies every 20 25 companies every batch the last batch was perplexity replicate um Mex a bunch of other companies and we applied for this batch and we we got into the batch and we had that's why we came to our we presenting at the demo day for that um and that's that's how they invested they have the cluster what we've seen is they've we don't have too much context we've not asked for Access yet um but it's split up and it's available for use to their companies and I think the idea behind that was it's just gpus are more precious than money right now especially for AI companies and you want to be able to uh like as an investor it just makes you even more attractive I think they're still probably the most influential pair of investors among that group in AI like they set the narratives U but the GPU is just like a A plus one or probably plus 10 because you want to um like you you can it takes away one like concern that Founders have um so we can I think we can ask for Access and they can give us like chunk taxes and we can use it for some they also do it for researchers so the a Ator and there's the grant grant which is like I think 5 to 50K um for researchers and they they also get access to that but yeah they're um they're really fun investors I Nat actually built the first um in of talking about agents he built the one of the first agents that's on GitHub it's a n called nbot um this is gpt3 2020 or 21 um and he there was kind of that repository blew up and that paved the path for all of these like people were like oh I have a breakthrough we can build an AI agent that does things in the browser and it's like it all goes back to that repository and like a bunch of things that happened before that um so I think yeah they're they're really cool and tell me something like tell me how the tech works I mean we covered hyper Rite recently yeah right and I think what you're building is pretty similar to hyperight in a way um are you guys sitting on top of GPT are you sitting on top of GPT Vision we use on the model side we have U we do a bunch of stuff with GPT and then we have some custom models that we build using open source and fine tune them that's lava. lava 1.5 the other quen model and um there's like a few fine tune Lang like specific Lang smaller language models that you can also use um how it's sort of different is we looked at a lot of these agents when we even started designing this and it was like a lot of people are designing it for consumers which like end users even if someone's designing it for businesses it's for the end user in a business so it's you sitting on your computer it sits on your computer as an extension or as as an aid and it's kind of like a co-pilot you want a headless browser that runs the Flow by itself that that's basically what we've done and we've done something interesting there where instead of running a direct chromium Fork running headlessly we've customized some parts of the chromium uh like just just how it's architect so the rendering engine and how we look at mutations and how we interact with the CDP protocol in com um and what that allows us to do is one run the whole thing remotely um so it's it's not meant for synchronous use so if you want to book a flight ticket or if you want to send emails that's kind of not what it's meant for it's meant for these processes and tasks that you don't want to do if you want to run lead generation every morning 9:00 a.m or if you want to run a repeating like invoice clearing flow in insurance claims things like that um that is what it's like runs fully remotely um and because we run we control the browser layer U there is more reliability that we can extract out of it because when you're running as an extension or synchronously on Chrome um you're limited to what like the the inputs that you can get while the user is using it and their browser when we control the whole browser we can extract anything that Chrome has access to and that's you know everything from the smallest level of like is this clickable or not to like high level is this an image what kind of image Etc but but you prompt the user for o and stuff like that right if there's some platform they need to sign sign in on the browser will send you a notification saying I mean your headless browser will send you a notification saying hey log into this does that still happen we do that in like two or three way so you can have the human in the loop system where it prompts you and you can share access we have designed this internal system where you can share all credentials and there's like a secure way of it there's like some pockets of that that cannot do really well yet which is like o and some of the Google stuff and like an OTP system and stuff would be so we handle otps otps and mfas are handled and the way we do that is every bot like I said it's like has an email has a phone number so the simplest way to get a bot onto doing a workflow for you is just add it as a collaborator in all your tools how long have you been building this March April so it's like 6 months six seven months it's awfully well thought out for like 6 months you can designate how much control you can give is kind of cool cuz someone sent me a tool recently asking me to share all the screenshots on my phone such that they become sharable and I instantly didn't want to do it as soon as I hit share I was like I do not I as much as I am excited to try this out I do not want to share any credentials I don't want to share any of my private data this that's why the O question is interesting because how you going to bypass that cuz I don't want any AI agent to be able to log into anything from my I think Arian will have less of the problem because they're doing using it for more B2B use cases so it'll be something that it's company approved it's probably company data it's company o uh or individuals inside a company o Alan I have a question right like it is bound to happen at some point because you're entering such new territory right which is um headless agents who are working when you are not at the computer you are living your life and agents are working there's going to be some point that something breaks there's going to be one agent that does something that someone disapproves of what do you think that's likely going to be there there's two things where we've seen how this fails and like I can if I go too much into the we just tell me like come out but when you when you run any of these agents um across give it a simple task like go to um make my trip and book me a flight from Bombay to Bangalore on like X state where it can go wrong is if it's if you run it on single page workflows or if you patch the pages together beforehand it'll be able to handle that decently well because there's no there's no ambiguity in figuring out what this Maps do um like if it's if it because you can see exactly what's happening all the action items are on the page it's a field you have to fill up a toggle that does something on the page when it is you can see a search button and you can see a navigate like navigate button you can see an explore button you don't know what that Maps do which is where it's likely to go wrong so you can kind of extrapolate and think of it like single page constrained workflows were outperform these navigational kind of workflows there are ways you can think of bypassing that where like imagine you kind of construct this graph of a website beforehand um and it's it's kind like there the site maps that are bunch of yeah site maps are already available you can use that as as an inference point where this leads to this lead to this but it's it's still pretty abstract and Broad you want even inside the weeds like this button links to this to this to this uh and if you like it's it's like a wild way to say this but at some point somebody's going to have to reindex the internet for Bots to run if you have to run like just based on language model capabilities right now and looking at how like they're going to grow in the next six months you if if you make this like massive index of just how different things connect together and you chunk that out and give give it to the Bots then then you just made the whole flow more deterministic the problem is that these are probabilistic and non-deterministic models so they can spit out  did you say at some point someone will have to reindex the whole internet for bot to run or or people will have to design websit slightly differently but I'll tell you I I disagree with you there because I think I've I've been tracking some of the testing front end testing Frameworks right especially the ones who are now claiming that hey we have ai in it generally they're mapping of which button to click basically they're just looking at CSS I mean the HTML structure behind the scenes right what the class are named what the buttons are named and then they're like hey this is likely the button to click if I want to go to the book a trip page right and they're fairly accurate I assume from whatever I tried it was kind of flawless even hyper Rite is kind of flawless right where hyperight fails is if I tell it scroll five you know columns down then it measuring five columns is a little bit iffy but I also feel that's a limitation more because they're sitting on top of GPT and probably you guys will have the same issue but as those under underlying models evolve on reasoning I think this should be a like a pretty easy task unless there's like some really terrible like frontend Dev for a website and he's just named things really poorly and all his buttons are called button one button two uh and and it's it's not just the the ID or the class name of the button right maybe even the button text says something random uh like get started now or something like that maybe then it's like kind of weird but but I feel like eventually everyone will understand that you also want Bots to book so let's be bot friendly yeah I think I think B being broad friendly makes sense which means you it's it's kind of like how do you make your websites more accessible and accessibility and ARA labels have been a thing on the web for a long time that you'd be surprised by like I I I sort of think so I had this bias when I was first kind of trying these agents I was like they seem to work pretty well which is why we kind of got into the space not realizing how much they can fail but when you run it across like thousands of workflows you kind of realize that the the web is you cannot assume that the web is standard at all like a button might not really be a button it's like three Dives patched Together made with on click and then it just goes there so you you like you're if you're using HTML and like Dom elements and that it's just impossible for you to solve for 100 on 100 cases or even 90 on 100 cases because people design all these funky things lot of them don't have AR labels they'll have class names that are rendering like next and all of these Frameworks so it's just impossible that like you have a standardized version of the web to inference with which is why the only plausible approach that I've seen work well which is purely model based is you do the whole thing multimodel where it's use these models to yeah like localize it that's how we use it so we don't care what the class name is we don't care if it changes we look at visual input and kind of Mak sense how it looks is is the only thing that matters correct and I think you cannot do that really well with just CSS Styles yet because even CSS Styles can be like funky and you don't need to screw with the HTML at all no if you're looking at the page yeah if you're on multimodel it's all cool so I think that's that's kind of the only reliable approach and that's where we would kind of do our model efforts if we do it at some point uh but I think besides that like even all of these tools agents that you that you mentioned if you run them on also the thing is if you run them on larger flows that are more than five six 10 steps and they have to use memory in the process where capture data once reuse it again or like keep context of the whole thing and and you come back to the same tool again later on the flow you you start seeing it's it's like it's a deescalation from success rate looking like like in the 80s or 70s and then it comes down to like fives and tens um just because most people when they try it it's like one smart way to do it as a is just look at the like Amazon Alexa top 10,000 sites and run from top to bottom because most people are going to try it on the first 100 sites and if you solve for that you're like covering for a bunch of things but if you want to solve it technically there's no way to kind of do it on the web without like multimodel is is kind of the only plausible way with like all the test that we run we use like testing kids includes um like all these automation libraries like properer selenium Etc um that that's kind of our conclusion after and we've had so many like interactions on this like it's it's crazy like I would have expected it I wouldn't have expected people to be like it's fine if the inference cost is slightly higher that I'm using multimodel but screw HTML CSS I don't want to mess with HTML CSS it's just non-standard let's just look at it and and decide in a nutshell you're saying forget reading what's behind the page let's just look at it let's uh kind of use humanize or digitalize in a way and let's take it from there that's quite that's quite interesting um like I I can give you one simple analogy for that so even when you use ML and other stuff you are essentially kind of trying to do that where if you look at nbot code it's like open source on python what he does is he's creating this Pudo HTML structure which is trying to extract the non-standard things and just make a chunk that is with standard things so it's just buttons links etc etc but increasingly the web becomes more unst standard where like divs and like like weird things where LinkedIn and GitHub have their own tags where it'll be GitHub dash button it's not button or like something weird like that so it I think even when you're using HTML or like the approaches that agents use so far it's you are kind of trying to condense what's visible on the web into this object that that makes it as I think using multimodal has a secondary Advantage which is you can Port this outside the browser as well at some point like say you want to make an agent play games and let's say it was fast enough to for you to make decisions Split Second like fine put this into I don't know chest or something like automatically click from here to here because it's the it's the same mechanism and there is like one other thing that I think on the model front um this might also be just me going Tech nerdy on this but there is this very cool paper that open I wrote in 2016 called world of bits that karpathy and like gy fan and a bunch of others wrote and that that kind of tried it clear these Docker containers or just many environments of the web of games and stuff and that was pre- Transformers that was only RL it was like trained on reward functions and you had these Bots that have TR learned how to play games they're like learning how to fill forms Etc the that that sort of makes sense because a lot of people think RL is the only way you get to real intelligence because it's no what karpati has a has a long thread on this he wrote it recently I'm sure you're referencing that one right where he's like ARL is like you're you're you're trying everything and you're like hoping it works but then uh if you have like a sort of intermediate intelligence ler like GPT who's reasoning through you know the thought process then you have better success rate so that's what I was saying like if you have the multimodal eyes uh in a game and you have uh something doing the middle level reasoning instead of just trying everything possible like press all the buttons and you know eventually figure out how do we hit the end goal so so you are going to be directly responsible for a bunch of cheaters in valerant maybe we will definitely do some RL I will not deny that um the like thing I was saying about RL is it's like as a as a simple example it's like RL gives you infinite context in an infinite World when you're using GPT or kind of constraint models it's finite context put in infinite World which is why it fails you have a limited prompt or like your system prompt can only be so long or your prompts can only be so long you're leaving it in a world where it can do anything so it's just like the exercise of making a good Agent is how do you make finite context work in infinite worlds um and like most people lead to RL maybe there's like new stuff that comes with multimodel but yeah interesting interesting so when I start using it I have you templatized the whole thing or like there's two ways to to be able to use this right one is like a car which is okay there are eight or 10 levers that I that I can play with and one is like a plane where you make it hyper customizable for me there's 50 buttons that I can play with how are you guys approaching this for now so this this might be a boring answer but the way we because of the user group that we Target and because it's all these businesses they don't even care about agents that's step one they don't know what agents are they don't care care about agents um so it's not they don't want to run this for like a magical autonomous thing that like Wows me and gives me a fun feeling uh what they want to use this for is how does it save time and how does it like enhance capabilities so we don't have a magical setup process unlike like some of the similar other agents I think all the agents are cool I would I use them as a consumer but for for these businesses if you just give like text descriptions or like go and do this and this it doesn't meet the reliability benchmarks that they have for and this is in in like business context we are in the RPA industry this is what like some of these large RPA automation companies have been doing on the desktop on Windows for a while so for us it is it's more about like hitting reliability than how like magical experiences so when you put in like a flow we have two ways to start you can either put in an elaborate text description and this is this is like a process doc or workflow doc that you share with someone like a real back office or someone else um Step byep listed down do this then you will do this then capture data store the data then reuse it here you kind of put that in uh we compile that to a to a language like a local DSL that we run uh on the browser um which is our way of interpreting what input you have given and when you are setting up the workflow we will ask you questions in the process to clarify ambiguous things if you're just like search for shoes on Amazon um we will like the way we will understand it is go to the search bar enter and then like click on the search button like use the keyboard press so if if there are ambiguous things that you've said like book a flight and you don't mention the date um we don't know flights but let's make an example It'll ask you for clarification then it creates this elaborate understanding of what your flow is the where it saves the business time is the alternative to this um is people would write internal Puppeteer selenium scripts where they're going to script every button class like you can do stuff with class names so they will script every class name every tag of every search bar button like anything that they want to interact with and that is a that can take a week that can take three months that that can take whatever so we what we save time with there is you give us text input we'll ask you clarification questions and instead of you having to script the whole flow we will just make it so that once we have chunked it into steps each step will run autonomously we will will do the inference for what to do in that step and that step could be going to a website could be clicking on one button we will do that step autonomously using the web context but we will not like you don't have to manually tag every button and script it that's one way to set up um we we have this other version where we can um we want to make it as intuitive as possible um so even text input doesn't make as much sense because people have to actually write the whole thing down it's not fun it's a boring activity when you have to go to your browser look at what you want to do and then like enter it into a text box um we're creating a because we run everything on a remote browser and it's visible uh we're making the remote browser interactable and uh we will we will kind of make an easy way for you to basically sort of like screen record but come on our platform and screen record we'll provision a browser can screen record your whole thing and we will interpret what you've done directly from there and then we'll ask you clarification questions if there are any um that's way better no that's a loom you're using loom to command a browser to do stuff automatic that is way better it's also way harder but uh we will have to do it at some point way interesting I have a question okay like more like a like a business idea can you make a Marketplace of people who want to sell their workflows like let's say I have a very very complicated workflow as a business right maybe say my sales rep finds an email from some platform uh let's say LinkedIn of somebody they want to reach out to based on certain targeting then uh you know the email is actually sent out then there's a no response for a few days it follows up so it's it's not your RPA because I think the followup will you'll have to use the Gmail API to do that uh but um I feel like you can do a mix of the two and if I'm able to create my workflow throw it on your platform and charge people $20 for it people might eventually realize that's a lot wiser to do than use some SAS tool yeah we had this like small line in the tech run article which we put out which is like zapier has all of these templates and zapier was kind of the pioneer of the API Integrations economy um and unless the the the internet bans all agents uh we are kind of entering an agents economy and that is it's surpassing the limitations that are there with apis you can obviously set up a lot of automations with apis but apis don't give you all the data they have rate limits and sometimes platforms might not have apis so there's going to be an agent economy that is created for and that's why making an automation platform made sense where in the new agent economy there's a new experience you can design that's a clever way to think about about it you're like an alternative to zap here but like think of it as instead of restricted at API open API specs and things like that it's the browser is in some sense the browser is also the greatest API because it's it's a human readable API and it's been built over 20 years with so much reliability and Trust um so we we've definitely explored templates as as a concept because that is um some of these flows are very standard across companies do you feel like many of these websites sorry for cutting you off I'll I'll I want you to finish your thought there as well but do you feel like many of these websites are going to just be like hey these like the API rate limits for a reason let's say I make my my trip is just like I'm going to bombarded by agents I'm not going to let any Agents come into the platform but can they tell I'll give you how we think about it which is the reason Bots are a problem and so Step One is acknowledge that Bots are in like they're also like AGI this inevitable people have been creating bots before people start Le like doing anything on the internet scraping and Bots have been around forever um the problem with with websites is you want to differentiate between good Bots and bad Bots which is why the the Mozilla like/ robot.txt file like that those interfaces were designed where you can like open open source their GPT scraper bought recently and they gave out their fingerprints which is basically like if you're a website you want us to script from you allow us with that fingerprint and if you don't want to script they us to script disallow that fingerprint and we will not scrape you so that that's kind of the distinction Bots are going to happen uh the problem is who are good Bots who are bad Bots bad Bots are going to use use you for like reusing your content without giving you money and they're coming in and like taking page views without you getting add money for it because they are inevitable I think this is like a still a little bit far away I would imagine like a year or two we'll have more clarity on this but there has to be some form of um like conclusion that that comes between these platforms and agents and Bots that are running on them where like you you have to have some way of declaring that you are a good bot and you're doing this for a real user maybe the way to prove that is you actually pay money and we like I'm not using your API I'm going to extract data out of this but here's money that I have otherwise spent on API calls that I will use to access your website or you you have like some sort of mechanism there because unless that happens it it's just kind of websites are going to try to ban Bots and Bs are going to try to bypass those detections and that's kind of how we think of it where at some point there has to be some conclusion that comes in there um and I I don't think some of these with especially with the e-commerce platforms if a bot is coming to you and add ring likeing adding cart items and actually making a purchase that's adding to your top line it's GM for you don't mind BS that that making you money you don't want Bots that are taking your stuff and like putting it on flip cart like if Amazon is rning musk will disagree with you I I mean I think Twitter Bots is a different story no but Twitter Bots aren't making Revenue right what are they doing they're adding nothing to the platform they're just adding junk I was sort of I was having this discussion with someone and he was like this is why World coin was created where we'll have an internet of bots and when a human wants to use it they will scan their um Iris and kind of prove that I'm one level above so you have high tier access um and it's it's too like weird to think of I think it's possible where there's like just more bots on the internet and it still happens but they more Bots just doing most things and humans going in when they want to that's interesting I wanted to book flights because uh did you know that 30% of customer support pings on a bunch of these travel websites are uh just human errors like most people who ping customer support urgently is instead of Mumbai to Delhi I booked Delhi to Bombay like that's that's the it's the most number one most common mistake and I just can't wait for an agent to not make that mistake for me I think everyone gets an executive assistant no yeah basically like I think that's the magic of the internet that I think what a lot of rich people have or had has started I mean I'm talking about the digital stuff the people the talent they can hire not the cars that they own or the houses that they have but a lot of that is now getting commoditized if you can now get an executive assistant at whatever $5 a month that's that's wonderful and I think it's a world of abundance even though it feels like a world where we're losing a lot of stuff so what's your AGI timeline oh that is weird so we had we had a session with karpati recently like I was listening to some of these talks and he was also talking about this when he came for the session he was like the the version of AGI that we think of um is is maybe not going to be as kind of large of a sudden shift that people think it is with gp4 and kind of these models being there we you already have the First Leap of primitive traces that lead to that so and and a lot of people at open and like other companies say this where like maybe gp4 maybe five with like great engineering and infrastructure built on top of it is is going to be AGI for most people in like chunked like bases um so I think in that I have a short timeline we we'll get to these like it's just accelerating faster then we can wrap our heads around and so like two years three years what's it what's your optimistic in pess istic timelines lesser than five is like optimistic where we will kind of start thinking of this as more generic intelligence um I I don't know beyond that I I think it'll be uh once that happens maybe we'll stop making predictions we'll just be like this is it'll figure it out itself we we don't need to worry about the timeline It's Just Happening uh how's the how's I mean you're 19 how's the entire media blitz Blitz around raising money were they kind we were so we were very happy with t crunch because they were portray our story as it is they were like very kind with that the only hesitation I had originally there was they were putting in like they put in teens in the headline and I we like if they put in like we young and nobody's going to take us seriously anymore anyway selling to like these Enterprises that are like buyers are older than us and they have concerns um but I think it's kind of like the reason we are excited to do this and like that Tech is the only place where you can do this where people don't discriminate based on age especially like in Bangalore SF areas like this where it's it's like a young founder taking on a big opportunity with the right team um is you have way more compounding opportunity there and you can also it's more exciting um so that was like that was the only concern otherwise of were kind we we just directly did it on Tech run all the and then we put out our own block post um which had context about why we're doing this and what the product is ETC everything else was a feed off and copy and they referenced us a little bit there was some Mis Mis like quotes and stuff with like Indian origin and and things like that but overall it was fine I think they called us Indian origin which was like that was we we were just we tried to clarify it with them that we are still we Indians and we are not uh Americans and you can just say Indians did they CH the article after you gave the the updated statement I think some of them did um some we have to still follow up on um but overall it was nice if they had an agent they could have just read the email and made the change it themselves yeah we the reason we announced was we were we wanted to like get in the the door with some of these exciting customer conversations we've been having um and that was that that went well I think all of the second order media effects are just um like our our our buyers and audience is very specifically they probably not even on social media there's like maybe LinkedIn Twitter a little bit but otherwise we have to go the regular route maybe cold calling is more effective than media there um so is good overall you know uh now that you're heading into the business side of things with this product um I was talking to someone yesterday who said that you know amongst the slightly older generation they've probably heard of OIC but they still haven't tried GPD 4 yet you know there's a large section of this world that still hasn't tuned into all the stuff that AI is capable of are you noticing that as well with the customer cohort that you're going after which is they still either haven't heard of you know forget agents but haven't heard of gbd4 yet and or are skeptical of it there are two like patterns there one is they definitely don't know the buzzwords which is why we don't call call ourselves like an agent or agent platform even our website was we had to put an AI because there was some AI in it but it's just AI workers we had to kind of make it as straightforward as possible we'll just call it smart Bots if we have to um because they they don't understand agents they don't understand GPT like how it works and like what what multimodel is etc etc they definitely know there's AI you can just call it digital employee yeah the reason we didn't call it digital employees is because when you think of an employee there's also insurance and like salaries and like things you have to think about a worker or bot is just easy to think of as it's like a disposable resource that is below humans we want to kind of make it clear we're not um even from a point of conveying the idea perspective um so yeah we we we they everybody knows of AI they are excited we we spoken to some people who are like we want to do something with AI we just don't know what it is because the whole company is excited about it we are figuring out what to do uh and then we have to go and explain to them this is like sometimes they want to do things that are not possible like can you can you do this whole thing and I will just like remove my people from doing this and like it's yeah is exciting but it's not it's not do anything wonders and like randomly stuff happens um and sometimes they underestimate the capabilities they're like is this this is just like you writing better code and things are working um so some of them like everybody knows of AI which is why they're excited they're taking conversations and there's an advantage with I think there's like only a small incubation period where young companies can come in and break into these markets where people are open to having conversations um but like they don't know Buzz word so we we we don't um we have to educate a lot of them there's a lot of documentation that goes in um which is why I think like there should be more podcasts and more things especially targeted towards like older age groups as well that kind of make them aware um because that's just lost opportunity for everybody if they don't know stuff dude H Veron at 19 to to you know have not only these many ideas but to pack your bags and go to SF and be like yo just the guts of writing email to Sam and being like yo I'm thinking of just the action of having this much confidence to write that email this is uh this is not something that happened in my generation bro you know you know it's it's ironic uh but I kind of did the same thing I remember at 19 when we started I started a recruitment tech company right it's not AI we didn't have ai at that time but I wrote an email to Sam Sam was running YC comin at that time and Sam sent me the most generic two line reply to that email so my email so I wanted him to invest right but you I don't want to start off with that so I was like hey I love you uh you know what you've been doing and stuff uh can you um can you tell me where the future of work is headed according to you it's a weird question to ask him because clearly nobody knew he was going to run open a at that time and you know even he didn't know that the future of work is going to be completely automated or whatever and his reply was so generic he was just like just focus on the company and like that's the best way to he was using GPT 0.2 to reply to reply right that yeah that definitely seemed like an early version of GPT but uh and and I know this because the reason I did this was because I was a big fan of Y combinator in the early days right I still am I think they're still doing some good work and it's like the only thing that I didn't do was go to the valley because I did a poor man's version of that I went to Delhi I was like there's an incubator in Delhi so I was like I'm going to go join this incubator and uh in the eth semester I was I I luckily didn't have to attend college and do stuff in college because I was able to do it at the incubator but I feel like the courage to go abroad to do this the courage to kind of build agents it's like you have a window where if done right nobody will care about how old you are yeah right and if done right like the opportunity is massive yeah I think there was this Paul Graham essay one of the recent one which was like the only way you can create uh value or like do something meaningful is if it's genuinely exciting you and energizing you and you cannot fake it like if it dies out after three months just it's not going to happen if there's something that like keeps getting you in the weeds which is why when we like started there was like this was at the same time when gp4 had come out and there were all these rappers that are being built and they're fairly low hanging group like if you develop a decent enough product with a good experience you can make money off of it um I think just from the composition of our team it was like and there's like all these people listen to people like you have to build a distribution first company and you have uh like first become a Creator and influencer and do stuff I think that that makes sense uh but just the kind we we looked at ourselves like we can't be creators we cannot like I can't I can't do the stuff that needs to be done to do that well um so what is our advantage like we cannot build distribution first company can we we are like young hackers we can move fast we can do customer support at 3: a.m. that a lot of companies cannot um so we have to build a product Tech advantage and use that as a lever to get into everything else and also if you raise a lot of money in the valley you can buy distribution like there's no reason to build it yourself you can buy it yeah I I I think you can and also it like it gets easier over time where like your product becomes the lever to unlock distribution but you you cannot kind of start with that as an it's like I'm walking I'm like I will sell to Enterprise companies in like sales sales Ops for 4y old will make five calls and do more Revenue than I can do in a year and that that's just you can hire the 40- year old if you raise money see you're in a market I'll tell you where the thesis of distribution first comes from right it comes in markets which are either saturated or there isn't fundraising capability or the profit pools are really low you're working on a problem where it like there can be a bunch of funds that will put in $100 million over the next four five years and you can afford to make a ridiculous number of mistakes uh contrast that to let's say a d2c company sitting in India where it's in they're selling maybe hair oil it's a very saturated market and they need like no one's going to invest 100 million and say hey figure things out so I feel like it's more a function and and also the profit pools there like it's now been enough time people know okay if I sell one pack of hair oil that I'm making whatever 5 rupees profit multiplied by The Tam or whatever right in your case it's like the Tam seems infinite it is infinite in my opinion like close to infinite uh your um fundraising capability excitement everything is super high so you don't need to optimize for this distribution if you build good Tech the distribution comes one thing we learned right because we built a few rappers in the early days is if you build a rapper early enough and your tool is really good everyone will cover it like for some reason we went like some of our tools went viral in Spain where there's no way if you ask me to do it again I can't it's random like and it's like all our Indian distribution is kind of pointless because Indian users didn't actually pay for it but it went viral in Spain and Spanish users paid for it which was it is so random and a lot of that random stuff will happen to you because a lot of creators will realize this is an interesting tool it works it's useful let me make a video about it because selfishly I get some views out of it right and if three four big influencers do it the next 20 will do it so in your case you don't need to buy distribution they they will not I mean you don't need to make distribution but those influences not do the same for hair oil yeah we we were I think I I agree with like the B thing where we were essentially we just looked inside we like if we have to do something big and large let's pick a problem that's going to take six months to even get baked in like the first version is going to take five six months to come out but that's where like we can have some scope of Advantage where it's hard enough where someone cannot like just walk in and be like oh this is how you do it um if if if we would have had distribution we would probably go about it differently but this is kind of we just acknowledge as a team this is what we can do best and we use this to kind of unlock an open doors that we cannot do well um anyway if you ever need access to distribution to Indian businesses you know they're always here for you Indian origin founders  last question okay uh this would be a fear I would have if I was building agents which is do you feel like open a will compete with you like my my biggest fear like 24/7 would be like holy  like Google owns Chrome uh open it seems like a very high value problem for them because I feel like that's where the money in AI will be made right something automating a workflow um it seems like too high value and opportunity for them not to do first is I think I'll just remove all of the like let's not rely on other sources is to help us so there's people who who will say that maybe regulation will prent them nothing is forget about that it's just head tohe we are free markets competing I think just incentives wise um there are two things that that for all of these model companies one is um I think they are the reason they build building the intelligence layer is that that's where there is some sort of advantage and more to be built in and all of the other layers eventually get commoditized um and the reason they will kind of that becomes the core of what they're doing is because that's where all of a starts um and that's like I built the models first then is kind of building interfaces on top of it and if you look at resource allocation it's still mostly research and some things come out I definitely think more model companies will start talking to customers directly serving them directly because it's a good research feedback loop for them uh but I think even like besides us like open can disrupt almost any company in the world today if they decide to they can they can disrupt all the language tutor like dual lingo bunch of companies that are partners with them they can disrup the other model companies Cloud companies all of that um I think in in just scope of focus if they want to keep performing as well as they are it just it makes sense that you make these Partners who do the deployments do a little bit of deployments but get all of the data get all of the like refine the core because that core is going to stick with you and you have clear Advantage there I think second is as more model companies do the thing that I originally said was the infrastructure that we've built um and this is all given we don't have our own models at the scale that opening I has because we can't do that we don't have enough money um the aiding infrastructure in this process the custom browser that we've designed that we run our BS on the whole remote kind of running process the way we handle authentication all these kind of aiding things um in the future how we deal with like Bots or all of that I think that that infrastructure the more and the faster we refine that with more customers it just increasingly becomes more valuable any company in the world that either the model company or a company is building with the models will want to control the intelligence layer themselves so we will we will stop doing the intelligence then we will just use the infrastructure we've built we've refined it with so much so you're saying the end goal is for you to get off the open AI drip we will we we just want to be like the infrastructure that aids open AI where they can use us people building bots on them can use us it just it's routed through us so that they control the models open a helps with the models they help with the input output but to actually make the execution the runtime environment we have kind of the runtime for deploying the problem with this is depends on how much money you make like if you start making a lot of money and it becomes an like commercially attractive opportunity for open AI they will disconnect and my recommendation is even though Sam's an investor you should also plan like a fail safe like lava and stuff are are great in the sense you're already thinking fail saves but I think it's like I don't understand like my my own personal opinion maybe I'm dumb stupid about this but I don't understand what's happening between Microsoft uh open AI Microsoft llama it's like it's everyone's in bed with everyone and everyone's like kind of hedging who the winner is going to be because nobody knows and the only people I feel that are doing it independently like Google Google I screw you we have deep mind we'll figure it out uh so it's it's it's a little bit iffy and I feel like there's going to be a lot of collateral damage to small businesses and somebody just like I remember uh now gb4 has a page where you can just fine tune yourself like they have the one page they didn't need to build it it's literally not their focus area but they have this one page where they're like hey you can f tune yourself and uh one of the guys at open had tweeted about this and somebody responded to him saying hey how can you kill so many compan like there was so many companies with the intention of hey we will find tune GPD 4 for you right and uh the guy was like Hey if your mote was just a rapper around GPT then bad news for you the way I think about it is you remember when they put out plugins and there was this whole one week of startup cry where every business is done there not SAS no but plugins didn't have pmf the thing is if you prove un unfortunately if you prove that you have very strong pmf then it becomes attractive to them the the analogy with plugins was more I think they will they will do some of this but I think just bandwidth and that's like a classic startup thing where the bandwidth that they have is better fed on GPD 5 yeah they can better deploy that bandwidth on gb5 versus talking to customers and like looking at the small like are you compliant or not and like where is this data going and stuff like that so I think like they're obviously big they're going to control the space they're leaders in the space uh but I I I am generally and this might this is also a little bit of irrationality because I'm kind of building this but I think it's also in my best interest to just believe that there is value in kind of doing this and eventually like the markets align and there is enough incentive for people to and in the short term they speeding up your time to Market like they you you are absolutely taking advantage of them in the short term right so I think that's it's a it's a win-win in the shortterm longterm I think there will be a Divergence unless you guys get into a great partnership awesome AR do you have any questions for us it's wild it's a stupid thing to ask for yeah he he does what the  are you guys doing with your life bro no I I think I'm I'm just curious because you've seen so many products and you're kind of reviewing this how much of this like because you you have so much exposure how much of this is like actually implemented in your like what's the conversion rate of new product to like actual implementation in your life uh what do you mean by that Arian is basically asking vun you get hyped by every AI product are you using them in your daily life or no is what he's asking roughly right Aran because Von is looks at everything and he's like this is amazing this is amazing this is the best thing that's ever happened yeah I think I'll tell you what all I use okay uh so all my content is automated I'm a lazy person uh I think in the next couple of weeks Fe fine tuning mistl hopefully you know I don't have to write scripts either right so uh that's a place where I actively use AI people can see me using Ai and it's it actually saves me time effort energy whatever um we use like we use AI for some projects like we're using we're making an anime just like let's have fun right so we're using something called anime diff there uh so in a way we have we are primarily using AI for video we also run an agency called Zeno where we kind of build um applied AI products for media companies so uh some of these media companies the questions could be as simple as I mean the the problem statement could be as simple as hey build me a bot that writes like me right and these are some of these are Regional language newspapers so they want us to write like them right uh and some of it could be as wild as hey can you build infographics for me right can you build a tool where I can just say hey make an infographic with this I just put on a table and you give me the infographic right so a lot of that in our opinion is like applied Ai and so in a way I'm probably the wrong person to ask about this because every tool that comes out I'm like is there a commercial opportunity are either building something on top of this or whatever like when we built Alpha C it's just what it's a fine tuned image model for thumbnails so it's like we think in that direction as a consumer uh uh I'm excited about a lot of things I I mean I'm a nerd so I will be excited about a lot of things uh but I think the thing that I use very often is the content replacement part I I do use GPT a lot as well I use GPT as a sparring part I know T us tan uses GPT like that as well yeah but Von your content replacement thing like Von is the only one who believes that people aren't seeing no no no they see it they see it but I think from a share perspective right I look at the share ratio and most people are talking about the topic I I I know that a lot of people can tell it's AI but also in the middle I put out a real video of me and everyone's like this is AI generated so now either I have intentionally created confusion or people I mean I'm now I'm just looking at the share ratio right like I get about 1,800 to 2,000 shares of video people are actually like you can't have 2,000 shares of video where people I look this AI generated some of them are like talking about hey you whatever the topic that I'm talking about in the video so I feel like eventually people will tune out this is an experiment we'll know the results of it maybe a month but it's also extrapolation right if it's this good today in a year or two years it's going to be great so for me GPT is a sparring partner like vun said and this is true for every Creative Marketing room that I've been in in the last you know 6 months I make sure I ask saying are you guys using GPT widely used very popular in fact in some places it's a little more hush hush cuz they don't want their bosses to know that you know a 4 person team is doing a 10 person team's job um but apart from that a lot of the other tools that I see they feel like almost there but not quite but because you know I've used mid Journey like a year ago and seen where it gotten now it's it's so clear that some of this is going to get so good that it's going to be obvious just yesterday I was with a musician who um I was with a music producer who's a very popular ad director and you know the tool that we use now Von which is you can make a sound from your mouth and it turns it into an instrument uh guess what making songs on his own sitting in Goa his dream was to be a musician and he was like this is the first time I can create Melody I I don't know how to play these instruments and he started doing it after the re he started doing it after after our real so I know that uh enough consumers are tinkering around um but is it something that you know my computer or my you know life is being automated we're not there yet and probably little thankful that it's not there yet that we're getting our time to adjust and you know the there are not GPD 4 to me is the gbd4 and mid journey to me are the obvious Delta 4 products out there uh lot of the other rappers are not quite there uh but he was hoping induced is one of them that it's a genuinely Delta 4 product that you know that lets me book Bombay to Delhi flight yeah if the question is is is is the hypothetical dream of you know an RPA useful absolutely like we would we would use it everywhere like I I I'll tell you some simple workflows right on the content side we definitely use it for uh just you know getting good information like I would just leave a bot on Reddit i' just be like go find the the best stuff right and being able to give such generic open-ended you know statements to a uh to a bot is useful I would definitely use it like book flights I definitely use it to book medical tests I would definitely use it I mean you'll have to build some trust with me to for me to be able to put my card into it swipe my card into it or like just have my card on file uh but yeah we would use it on the business side whenever we make proposals for clients I think being just a summary at the end of the day of whoever's working on the thing it's a little bit dystopian but like if there's an employee in the company and they're working on something instead of them having to manually type like hey this is what I did today just having a summary of hey here the five tasks this person did would be useful so yeah I can I can see how it's I think I have like not the as timeline but I have an agent timeline that I think will be like next one to two years where you will like I I don't think you can get open-ended agents working as reliably that you will use it every day before that uh we will attempt to do that what do you think Min minion is doing you know minion yeah uh Alex was also a grant batch one um I'm not sure I I've not seen the public demo but I think they've they also they're building for consumers um I believe there is some mobile element to it now um like recent updates um but I'm I'm not fully sure um and I think this is like this trajectory of a bunch of agent companies where they started with the ambitious goal of an open-ended agent that takes in two lines and does stuff for you and they've kind of come to form factors where you can sort of constrain that and make it perform in like constrained environments well and then eventually come out that's also what we do where the reason we work with businesses is because we can get a lot more input we can work closely with them and they don't care as much about like open-ended stuff where it's like structured but runs gives me some added capabilities of like plugging in the model in interesting ways and like doing tasks that require reasoning that couldn't have been done with rule set based software so I I think everybody's um in that board right now I'm I'm very excited about all of them because I think over the next year or so as new models come out and then as they kind of learn uh it's a worth pursuing engineering problem and I I don't think there is like the the gap between one person figuring it out either with a model or and Engineering breakthrough and then it being available and the others catching up is going to be it'll not be as significant it'll be like a couple months maybe so all of you have to keep competing to get better every month I mean that's what's driving everything forward right like the only reason haen really pushed audio videos like they know like 50 people neck to neck so I feel like every I've never seen a field in a very long time that's where people are so motivated there's such a big land grab uh and I think that's pushing all the progress forward because humans naturally will just be like it makes sense from Market point of VI Al it's an infinite Market everybody's going to have fun survive so it's it's a good it's a good race to be in so one to two years uh I think think that's when you will integrate an agent in your day-to-day life until then it'll be a little more problematic to get started uh not as magical but we're getting better is Silicon Valley thinking jobs like are they thinking about the second order impacts of what they're doing or is it like a little bit is it like let's it's build build first figure later there is definitely a little bit of let's build because I think a lot of people have intrinsically just internalized that jobs would be figured out and there's never like a lot of people deeply and I I'm like all of our backers we like I look up to all of them like it's like a privilege super grateful to work with them and the kind of thinking that we learn from them it's we've also sort of internalized now that just past Tech Cycles have demonstrated that it's not going to be as big of a shift um at especially not as big in the bad ways as it's going to help in the good ways so there there like some people who are thinking that way there's there's like obviously groups that bring that in into every conversation where it's like do you think like this is unethical or do you think this is going to be tricky once we roll it out and I think which is why like a lot of these model companies have bigger policy teams increasingly where they're like open had to take down browsing and they' put it back because there was like stuff with content there's like all of these elements that are coming in with just how the internet and the world embes this stuff so the valley is not I I I think this is like a slightly it all of the stories about SF are in that sense very true where this is a very special group uh people here will like if they're afraid of something they'll try and go after it to kind of solve for it instead of um kind of just making uh other people afraid or like preventing them from doing it because there's just too much force going in towards building stuff um there is you can't stop that that's sort of what makes this play special um yeah I think so they're not not not as much as you think they they not as worried about jobs um there's they're careful everybody knows it's not going to be as easy as some of these previous Tech waves um every move you make even as a small company you have to be careful because you might you might just do something that has never been done on the internet before and that's like a violation or somebody doesn't approve of it um so there's thoughtful um leadership and which is why like Sam like all of these other like model leaders of the large companies they're doing a good job where they're they're setting the the track right like you can't go Road um and I I sort of trust them as a as a builder in the space um to kind of lead awesome um congrats on being this mature at 19 wish I was like this uh Aran dude all the best to you and aush hope you guys um hope you guys have um have a memorable experience in SF and check out induced um there's it's not you guys can't check it out actually it's inite only right now um but Hey whenever it's out hope you guys check it out and thanks for joining  us",
    "url": "https://www.youtube.com/watch?v=e29dJSuktWc"
  },
  "t4YxGejzXO4": {
    "published_at": "2023-10-13T13:51:45Z",
    "title": "The End of content creation?",
    "text": "The End of content creation? have you seen this real the first round of interview is a culture round where we see if they fit with us they align with our values and the second round is the technical round where we actually look into their skills what do you think it's gotten really good I put up another real after this about the meta Rand glasses like three people in the comment said this real is AI generated everyone else was talking about the Rayban glasses it's like people can't tell and anyone can do this from just a laptop anyone can do this so the videos on haen haen is like the video part is very cheap the audio is a custom stack of Ki plus RVC the audio part is open source it's two passes right now we are using our own set lip to text matching has gotten much better speech modulation has gotten much better I'd say it's gotten at least 50% better than the last time we saw something like this I'll tell you the cool part you know how much time it saves it's like I don't have to be there like I don't have to do anything it's like zero time right to be able to put out and research good content the way I do it is I find something interesting and sitting on GitHub repos I'm able to spend more time there so higher quality content in a way",
    "url": "https://www.youtube.com/watch?v=t4YxGejzXO4"
  },
  "v4gwBHZ2cwI": {
    "published_at": "2023-10-07T14:40:48Z",
    "title": "ChatGPT makes exams useless",
    "text": "ChatGPT makes exams useless wow bye-bye homework let's ask GPT if we can solve any math problem do 10th standard board exam question India mathematics we're looking for some random paper I'm just going to screenshot this then copy paste this into GP div Vision don't give it any context okay given us the first answer wow one really cool thing that I really liked about it is I can give it an image of let's say so for biological diagram testes okay let's go with this okay got it it's able to understand a diagram it's able to read the text do you guys see the Mark Zuckerberg announcement now they have these glasses where you can just wear the glasses all throughout and it'll have some version of a vision model on it to me it just seems like what is the purpose of even ever doing an exam where you can be able to summon all of Humanity's knowledge just by looking at a thing how are you supposed to feel as a kid writing a useless exam",
    "url": "https://www.youtube.com/watch?v=v4gwBHZ2cwI"
  },
  "6dKbGhijK2I": {
    "published_at": "2023-11-23T11:52:42Z",
    "title": "The OpenAI Drama: Sam Altman Fired &amp; Back, Satya Nadella The Best CEO of 2023? &amp; More",
    "text": "The OpenAI Drama: Sam Altman Fired &amp; Back, Satya Nadella The Best CEO of 2023? &amp; More all right welcome to the episode of overpowered I'm not at my house in Bangalore but I'm shooting from Bombay vun some crazy  went on in the world of AI this week yeah today we're going to switch from teaching you new tools to doing a little bit of uh Gossip Girl so this is a tweet from Sam Alman from today saying I love openi and everything I've done over the past few days has been in service of keeping this team and its Mission together when I decided to join msf T which is Microsoft on Sunday evening it was clear that was the best path for me in the team with a new board and with satya's support I'm looking forward to returning to open Ai and building on our strong partnership with Microsoft cool thing here is all of this is in lowercase so definitely it's some serious messaging I think now the style whenever something gets too popular like corporate speak immediately people are like that's too corporate let's let's like the lowercase everything but this story is about twists turns betrayal s tumors acceleration is there's a lot it's worthy of a TV series and with that I think we should roll the intro music but I don't think we should roll our regular intro music we should be rolling the succession   theme  okay I you've been following everything closely I know this because all of a sudden waron Maya is now active on Twitter which really is probably the worst thing to have happened in the last week in the world of AI is that Von Maya has returned to Twitter uh what's been happening all right so we can see this picture here on the left this is the main open AI team can you tell me who's who here I know Sam's in the middle uh to Sam's left is Greg who is the president of openi was the president was the president of open and to his is he's the brainchild he's written a lot of papers he he was the hero behind Alex net and a bunch of others I mean he's considered the brain behind open a and then there's mea morati on the right who SE is it morati or is it miti Indian journ will say morti but maati okay I don't know how to pronounce it but yeah these are the four ex openai Founders Mera is still at open a and so is Ilah for now or for now because chain siid this is like proper juliia Caesar you know at brute and then yeah so this was this is context okay we got Sam and we got Greg in the middle um so what happened one day we all woke up on Twitter and we see the news that apparently Sam mman has been leted go by the board and according to a statement that came out it says open was deliberately structured to advance a mission yada yada yada uh at the same time we believe new leadership is necessary as we move forward um as the leader of the company's research product and safety functions mea is qualified to step into the role as interim CEO and the board of directors consisted of Ilia independent directors of Kora I don't know why Kora technology entrepreneur Tasha and Georgetown Center for security and Helen owner okay and they basically fired Sam I mean when Sam was fired I I couldn't believe it like Saga sent a message on the group saying that hey guys Sam is out and we have a overow WhatsApp group and immediately T's reaction and my and even my reaction was like he's done some's he's murdered somebody or something he's done some  right like yeah it's this is like everyone compared to the Steve Jobs  which is or Steve was let go but Steve was let go at a time where like apple was not doing well like some of the compu compos had failed some the products had failed and they truly believed that they were better off without without Steve Jobs whereas Sam was let go after what would be a fairly fairly successful Dev day that he recently had everyone was very happy we were really excited about all the new advancements gpts were the new talk of town so and there were rumors that Sam was going out on a you know going out on a fundraising tour there was more funds to be raised and in the middle of it all of a sudden saying Sam is left my first thought was Major Sam like this dude doesn't own any Equity it was all too good to be true so he's done some  like um that's that was my first feeling what do you think that's what I thought as well uh the only other alternative explanation was a power struggle but I'll tell you one thing Sam's been around for a while he's been in v combinator and all he would have structured things better you would have expected a guy who gives structuring advice as part of his curriculum advice I see uh to structure things better and to at least be protected from the boat throwing him out like that randomly right uh even though he said in the past that Bo should have the power to kick me out if necessary not for these things right so that was weird also none of us knew what the open a board consisted of right at that point and then it came out that it's it's j was that Garden levit the guy in uh the what's that movie Looper Jason G levit I don't remember his name the actor just Joseph Joseph G levit he also played he played Travis in Super Pump also yeah so his wife is one of the board members uh there's the Kora CEO uh there a bunch of people right and IIA was also there so IIA staged the coupe and he was like yo um Sam's got to go he's making this very commercial company it's basically what happens in like discos right you walk into a disco and there'll be like when the Disco first starts like when you start when you buy a disco and like you set it up you start playing like very alternate music right you start playing you know like TR and all the others but as the Disco gets more popular you start playing commercial music so what I feel may have transpired and this is conspiracy theory land and I just want to be clear about that is in the beginning this was a mission-driven company like let's build AGI let's you know take this to the Moon etc etc and let's let's benefit all of humanity with this and that's why structured as nonprofit but then immediately as they started seeing success as Satya Nella got involved it started feeling very commercial that we sellouts we're just making models to make money yeah I actually found corners of Twitter where the exact opposite theory was also coming in which is that actually Dev day was kind of me like they launched a laundry buddy as a GPT like really we have  AGI they're supposed to be replacing human cognition and you have laundry budy as one of the gpts like what the  are you doing was unhappy I was unhappy saying where's this company going like we we are supposed to be changing the world and instead we're launching these absolutely useless you know zero utility G products that no one is using because let's not forget like GPD plugins was a failure it did not work so we were very excited about gpts but maybe internally they thought that this is not as big a deal as what people are making it out to be this is when Sam was Sam was asked to leave and this became public news and of course it just plays out on Twitter as it does um my first thought was that elon's going to be happy about this because Elon and Sam has have had a very public Fallout Elon and Sam don't look eye to eye but Elon was worried about it he yeah we'll come to why in a bit and there were a bunch of these terms that started getting thrown around d cels d Cel stands so so the two camps right actually multiple camps but broadly it's become the left and right party system people who are accelerationists who just want everything to Skyrocket like I mean you want to see like a 2050 future next year right it's sort of like that they want AI as quickly as possible safety concerns be damned that's an extreme accelerationist and then on the other end there are de accelerationists who want things to slow down let's take a pause let's take six months off let's first put this through safety and whatnot and I feel like I know which side will win I think the acceleration accelerationists will win mainly because there's a commercial element to it in all of this drama one thing people missed is that Facebook got rid of the responsible AI team in the middle oh really yeah it's like one random thing they did in the middle while some other news was going it's like bit and switch distraction and that only signals one thing that they want to go faster they don't want to you know a team opposing speed right because the guy who builds it's so weird okay and I'll tell you why safety can't be a thing in this there are multiple camps competing the person who builds AGI is God right effectively becomes a version of God right uh controls a lot of the world's economy etc etc you become king of the Empire and at the same time you're competing against five other people who are also trying to build God who are also very well capitalized who have billions of dollars so all of these people are sitting and they're trying to build a God and one person in your team is saying no no go slow we need to be careful about this yeah that person that person is not getting invited to any parties they're not they're not no one's hanging out with them it's the teacher's pet like no one wants no one wants that guy around yeah so that's the problem but you know that's the thing right I hate these I hate when smart people get trapped into complete Black or White philosophies because there are issues with crazy acceleration like today I saw an ad of some guy deep faking ratan Tata to say you should go follow this Amir Hussein guy who is doing some finance stock tips I'm serious first of all Von how do you know that was deep fake because ranata is a short short video creator do you not know ran makes deels so it's it's almost like U you need governments some time to Breathe Right colleges government systems jobs give them some time to breathe I I agree with all of that but at the same time you can't stop technological progress right it's going to happen it is what it is uh but yeah there's a battle between accelerationist and deceleration but I know that nobody's truly a fully you know effective accelerationist to the point where you know Screw everything else I also know nobody's like a full deceleration so uh I feel like most people are on somewhere on the Spectrum uh I feel IIA is more on the deceleration side I mean I don't think IIA is a deceleration I just think he's like do it slightly more safely and the board definitely it seems which seems reasonable you know yeah the board seems like a bunch of of normies though except Kora CEO who from what I've heard from polyram and stuff like whatever I saw on the tweets he seems like a competent high integrity guy so it's weird that they would do this the other two three I have no idea you know who they are or what they do and yeah I mean that's that sets the Baseline but what do you think before we move on what do you think is the reason for this Fallout I don't think it's you see a de day and it's bad obviously you can't discount five years of work just because of De bad yeah when the news came out I was I seriously thought that hey you know there was there was maybe some incident of fraud or just just something Sam did they found some dirt on Sam and that's why they were that's why they were keen on throwing him out and then I started seeing terms like effective accelerationists and desels and you know both of them almost being used as slurs by either side on on Twitter so I saw this tweet by it at the atap pie who kind of did like a detailed breakdown on what he thinks could have happened based on all the surrounding news that's been going on for the last couple of weeks when I saw this it kind of opened my eyes as to oh this could be which is a lot more nuanced of what could have played out he said that on November 2nd Sam was in the room and the team demonstrated the next big Improvement three times before an opening eyes history most recently with gbd4 that pushed back the veale of ignorance and push forward the frontier of discovery this is something that Sam said at a in an interview recently we should play that clip here and on a personal note um like four times now in the history of open ey the the most recent time was just in the last couple of weeks I've gotten to be in the room um when we sort of like push the front the sort of the veil of ignorance back and the frontier of Discovery forward and getting to do that is like the professional honor of a lifetime so that's just it's so fun to get to work on that and Sam said this he said that on November 2nd as he watched the latest Advance he was already planning for the next moves the funds that would have to be raised the resources that would have to be planned for okay now this Sam did say this in an interview so I want to believe that hey Sam saw some demo of potentially GPT 5 wouldn't say that otherwise he wouldn't say that yeah then on November 4th Ilia was unsettled they they had reached a threshold of autonomy that was concerning while the alignment team was still just adding capability instead of emotion actual love for Humanity they needed more time to figure out the research paway instead of hurrying to deploy product okay so it's possible that GPD 5 demo looked so deadly that people were like yo yo yo yo yo we got we got to slow down there's some more evidence for this uh I two two pieces of evidence one is remember Sam went on Reddit and said that AGI has been achieved interally then he said it's a joke but he would I mean it's just one piece of evidence we should discount it for a second but IIA tweeted something okay a few months ago saying that if you value intelligence above all other human qualities you are going to you're going to be in for a bad time right that is the most scary tweet of all because IIA is not like a humor Sam sometimes is humorous IIA is not humorous there seems to be have have been a capabilities jump uh because Sam admitted to it on stage IIA said this is coming run keeps tweeting that there's so much Alpha in believing in AGI uh so it it feels it feels like we're close and there's a article that I saw okay I'm just going to sh open the article for a second Baron can you explain to me in the meanwhile I keep hearing this term AGI AGI can you for the lay man explain what does AGI stand for and what does it mean realistically in Practical terms so AGI stands for artificial general intelligence uh artificial general intelligence means it can do all the economic activity that's open eyes definition all the economic activity that human beings can do by itself right it has the capability to do pretty much everything we do it's basically a rival to human intelligence beyond that there's artificial super intelligence in fact a lot of so I want to be very clear about AGI right A lot of people believe there's AGI which is everything 100% of what a human being can do in every domain and then there's ASI which is artificial super intelligence which can do more than what humans can do faster better Etc many theorists are of the opinion that we have AGI in some domains we have ASI already in some domains like GPT vision is ASI in in in that narrow domain right of vision like it can see faster than you it can identify objects better than you you can give it a image with thousands of objects and it it'll do what we do much faster right yeah it can do where Waldo quicker than us quicker than us it can draw quicker than us if you give it Del 3 so there are domains where it's already super human and there are domains where it's below human like I don't think it'll be able to write an ad as well as you do right now uh right now right now right now so it's below human there so I feel it's a spectrum in every domain and AGI is can we get the average like FIFA you know that scoreboard of each player right can you get the average up of the thing to be 7 7.5 out of 10 right that's kind of like what the correct understanding of AGI should be and then beyond that there's artificial super intelligence and what most people feel is the minute AGI is achieved ASI will be achieved a few weeks or a few months from then right uh what most people believe is that we have already achieved ASI in some segments AGI in some segments and Below human performance in many others right what we're only trying to do is take the lagging below Human Performance and get it up to speed right that's what it is but check this out right uh ilas I hope I'm pronouncing it right went around saying anticipating the arrival of this all powerful technology sus began to behave like a spiritual leader three employees who worked with him told us his constant enthusiastic refrain refrain was feel the AGI a reference to the idea that the company was on the cusp of its UL imate goal at open 2022 holiday party uh at the some place he led employees in a chant feel the AGI feel the AGI the phrase was popular enough that openi employees created a feel the AGI reaction Emoji in slack come on this is this was in the Atlantic if I'm not wrong yeah it makes like I I don't trust journalists I don't trust media houses they want to like they want to make it they like they want to make Ilia sound crazy yeah but also I'm just piecing together different kinds of evidence right I'm saying okay A lot of openi people are talking about AGI suddenly all of a sudden because till now their narrative was okay we'll build AI we'll build useful AI but now it started become about AGI Sam said that on stage Ilia said if you value intelligence it's not great so there is some evidence there is definitely some capabilities advanc and I feel like to be very honest gbd4 is already some kind of AGI right like it's a simple kind of yeah like there's no smoke without AGI like some version of AGI okay understood so coming back to the timeline November 2nd Sam probably saw some demo that was super deadly he decides that yo we got to start deploying this we need to raise more funds November fourth Elia is unsettled he's like yo what the  is going on we should probably slow down November 6th open AI Dev day goes really well laundry buddi is launched everyone's very excited about doing their laundry lots of Kudos um after Dev day Greg Sam are in a full-on fundraising mode they're targeting 90 billion valuation this also I saw on Twitter uh 3x live from 30 Bill open a recruiters are already calling Google employees with 10 to 20 mil fouryear packages telling them if they join now they'll make it in before the valuation increase uh this also I saw some tweets floating around saying um this is happening I don't know like a lot of people believe IIA got spooked after seeing a GPD 5 demo but I don't think that's how it works right like if you ever trained a model like we F tune models when you fine tune a model you you'll probably run it through many different iterations right it's not just you do one set and you're like oh I just see the output at some Grand you know theater reveal you're constantly tweaking it uh but I do feel like the mission of open AI gets scrambled if AGI is around the corner how can you stay a nonprofit like think about it right you can be king of the world everyone can be king of the world if you build this technology how do you stay a nonprofit and make sure safe fi comes out and all that when you know you can be king of the world but you also know in 6 months the other companies can also build this once they know what you've built if you give them time to catch up it open has a bleed over every other company by a year year and a half maybe so it's that balance and I feel Sam wanted to accelerate even more Sam seems like a hardcore accelerationist and everyone else feels like  this is a little too fast for our liking that's that's just what I what I think yeah so when I saw this tweet thread and you know in the replies to this tweet there were people tweeting tweeting saying oh this is from this article this person tweeted this that's when I started feeling like oh okay maybe maybe this is Doomer versus Enthusiast kind of situation that's happening inside open AI um that's when I crazy right it's the only reason I mean that's it's probably the first time in history that a company is going down because people of such scale and such magnet like so much Capital raised because people just think it's too scary to build the product yeah I've SE this it's never happened and it's it's crazy I mean I in hindsight I wish Sam had like you know slapped a puppy or something like that that's the reason why he got fired yeah but it's probably it's probably probably got more Nuance than that anyway so Sam got let go then Greg tweeted saying Sam and I are shocked and saddened by what the board did today you know love you love you open air employees all that stuff happened then something hilarious where they said that they joined a Google meet on you know um on Friday which was hilarious because Google's a competitor and Ilia was IIA told Sam he was being fired and the News was going out very soon at 12:20 Greg got a text from IIA asking for a call Greg was told he was being removed from the board and they just tweeted this out like Greg Greg tweeted this out Sam I think retweeted it I'm unsure but all of this drama is playing out on Twitter in in front of everyone and probably like I would be surprised if Satya nadela found out via Twitter right like he I don't know if how many people knew this was happening yeah and I don't think the board is allowed to do that I'll tell you why the biggest example this is vinod kosa we will we will get to vinod kosla in a second because vinod kosla has been having a interesting day on Twitter so it looked like Sam and Greg were fired and America went to sleep grumbling saying what the  is wrong with open AI you're this is like value destruction at it speak and I kept seeing this phrase like this is value destruction and why would you do this and blah blah blah blah until the next day when America woke up and realized that hey this is probably not true Sam and Greg might not be leaving at all you know the investors will do something they'll start speaking to the board some chaos and all of a sudden we see news that yo Sam and Greg might not actually be gone we start seeing news that says that open a board is discussion with Sam to return as CEO yeah all of a sudden Sam tweets out this tweet saying first and last time I wear one of these which is a guest pass at the open a office and then boom a couple of hours later SATA nadela tweets that Sam is coming in to work at a advanced AI research program at Microsoft and Greg might potentially join him and then Sam tweets out saying with Microsoft support I'll be able to do blah blah blah thank you Satya Etc Etc all of a sudden we see oh uh you know 700 out of 770 open a employees are saying that they want to leave and they want to revolt uh we see all kinds of Love on Twitter it's like everybody at open AI was being paid to tweet out saying love love all employees at open people are sharing hearts on Twitter all of a sudden it it looks like you threw out a leader who was so widely loved investors woke up and basically scolded the board saying how can you  up like this and they decided that no no Sam's are guys and sat what could possibly be such a gangster move which is invested in open Ai and brought in the dude who was running openai to potentially start another thing but all the employees of open AI all the way in at zero the absolute gangster like there's a meme for it there's a meme for it check look at this this meme Sam open board mea morti open board and satas from behind all of them I'm the one controlling the  anyway gangster Mo by satella everybody universally ha sat Adella as you know hey trillion dollar company but still functioning like a startup CEO B shinas tweeted out saying you know reflexes of a startup CEO widely hailed as a gangster move even Elon was like Satya for the win yeah like Satya just figured it out I love this meme which is open AI is nothing without its people and Sam is just giving hearts to it non-stop babe please stop you don't even work there anymore open is nothing without its people yeah actually guys the product You' buildt you don't need any  people anymore have you thought but yeah this is crazy amount of value destruction and the fact that it just went to Satya for such a low price I mean you if the thing is also you have to understand okay there was this there was a moment in between all of this where uh in the contract of open AI if they accomplished AGI okay and the board decides when they accomplish AGI or not then the Microsoft deal Dynamics change do you know this no so let me show you this so AGI okay and the board decides when AGI happens is excluded from IP licenses with Microsoft should it be attained in open AI did you know that that's crazy AGI is excluded if they ever figure out AGI that's not part of the Microsoft deal uh they don't get IP rights okay and they don't get IP licenses and other commercial terms so emphasizing the distinction between pre AGI and AGI technology the board determines when we've attained AGI Again by AGI we mean a highly autonomous system that outperforms humans at most economically valuable work such a system is excluded from IP licenses and other commercial terms with Microsoft which only apply to pre AGI technology this is in their contract that's stupid because AGI is the goal like the whole companies working towards reaching a point where Microsoft loses all its value this is the reason openio structures is nonprofit because they're like if we build Ai and whichever company we hand it to if they handed it to Microsoft they take over the world because it does everything right you basically have unlimited employees doing whatever the hell you want so you can create unlimited value in a way right in the digital world physical world it might take some time yeah but that's the thing and what Satya is really averted and the reason Microsoft stock should go up even more is he has averted the fact that they might be on the verge of AGI but it doesn't matter because we got the entire team in the company and Satya cannot lose this like Satya went on this thing on a on a interview and he said no matter where Sam is he's going to work with Microsoft he's like I'm not you can't hide from me wherever you go I'm coming how do you think Google is feeling watching all this happen play out who cares I don't know uh I just don't know is going back into his to whatever the Deep Mind office and being likei where is my AGI I tell you the problem like we don't know enough about this I always put that caveat but you look at how Satya is operating like he knows these kids have messed up Ilia and Sam and Bor and whatnot he's going out in the press and saying I will solve this I will set the narrative correct okay he seems like a startup SE he's like I'll fix it I'll I'll pick up the slack I'll do a call during India Australia finals I bet Sund P was watching the India austr finals right whereas this guy said okay keep the match on TV let's pick up the phone do deal making with Sam how much do you need a billion dollars done right I feel that is the difference between Sam Al between Sundar Pai and satanella from what we are seeing from far but then again Google is so large has so much money so much research capability but we starting to learn the hard way that research capability doesn't like Sam is a deal maker by the way Sam's not a like Sam's not doing the research of the science he's a dealmaker but he's the most ambitious dealmaker he's the most ambitious recruiter he's the guy telling the story you need a guy telling the story at the Helm of the company like I'm learning this firsthand looking at all of this right there's a reason Steve Jobs won when so many other people were more competent at building Computing devices IBM was competent building computer device but like IBM felt boring today that's what's happening with Google Google feels boring you need need P Piper for for any movement yeah and is the is the of he's he's Chief Pate Piper and everyone's followed suit and you can see right like it doesn't matter how great the technology you have the team will stick for Sam they are all willing to move for Sam so I'm seeing firsthand how storytelling is even more powerful that Godlike technology I assume open AI has all this IP and Godlike technology but yet the team is like we'll move we'll build it again if necessary AI can't AI can't do everything you still need human drama human emotion yeah and I Y what's what's the name Sund Pai doesn't seem like that kind of P Piper Sund Pai is not out there saying I will build I will change the entire world because the minute he says that all those crazy things stock price will tank right there's too much stock movement in a public company CEO saying things that seem slightly unreasonable but Sam can say it Sam has nothing to lose at least in the early days of open AI now he has things to lose so I feel like being new being free being able to say whatever comes to your head being able to work on whatever mission is only a liberty allowed for people starting at zero or you know start restarting again either way I think this is probably hurting Google um and or maybe you know who knows like if you if you said four years ago that or five years ago that you know Satya Adela would be operating like a startup CEO while he's running a trillion dollar company people would not believe you yeah but you know early on AI investment in open Ai and now with this coup handling it handling it smartly you know you never know maybe Google has something up up its sleeve like okay first of all how are we sitting here discounting Google like that's insane like they were they were first on the scene anyway yeah so cannot discount Google you don't know what what's happening inside Google so I don't know it be it would be interesting now I can't wait for you know the next Google pixel launch where Sund comes and does you know that monologue of generative AI a AGI AI like that thing will happen again I mean Google has one play left every large company like a Fang set of companies have one play left release AGI and release really powerful AGI that's the play left and I think everyone's betting on that play and we just have to see how that works out yeah okay then then then Ilia Chang his mind and I'll tell you it's crazy there's a letter written after Ilia stays the coup and whatnot there's a letter written saying openi is the world's leading AI company don't destroy value you can't board should leave what should be fired okay uh otherwise we're all leaving and the letter was signed by aah and I was like what is going on what is going on weren't you guys the guy apparently that started this and then the Tweet goes out saying I deeply regret my participation in the boards actions I never intended to Har open I love everything we've built together and I will do everything I can to reunite the company but he got thrashed by VCS for this like all the Venture Capital firms that have invested in openi like this is a they didn't even know about it I mean at least if you're firing somebody like your CEO like Sam Alman you need to tell your this Mak feel is how  good is gbd 5 like can gb5 get me a girlfriend like is that what it can do what what what did what did IIA see in gb5 that made him be like bro we got to get this guy out of this company yeah like he's acting like the first time we all saw the internet right where we went like I can just type here and someone in America will see it instantly that's crazy like  this changes everything this dude this I was just thinking right everything we've said so far it's like crazy it's like a plot of a movie like the first time like elia's reaction elia's reaction like this whole incident just makes me even more curious as to what the  did the employees demo that made Ilia freak out you know in the old days if you saw someone do something that looked magical they would kill them they would call them they would call it witchcraft they would call it like this is you know this is uh the dark arts and they would bring them in the middle of the Town Square and just publicly flog them this is what IAH did to Sam is like the modern day version of it which is throw you which is remove you from a company but if this was if we were cave people and GPD 5 was demoed they would kill Sam being like are a witch you are you are you know you are a wizard and we are humans and we cannot take this sort of a thing yeah so extremely curious as to what GPD 5  GPD 5 de demo better be mind-blowing now otherwise everyone's going to be like for this you removed him shut up like this is not that big a deal but I was just thinking this is such a this this feels like U plot of movie like a t I haven't seen a TV series with a better plot than this it's like and  because of that he fired somebody else what are the mystery we're finding the mystery and every day an episode is being released it's being released by journals this is what journalists should actually do do investigate journalism on this don't like cover random things right this is so this is interesting and it also actually defines the future of what we will do as human beings I need Mike Judge to reboot Silicon Valley and do like three more seasons of of the show somebody put out a tweet uh it's of the social network this should be called the neural network anyway so employees s to leave Ilia puts out an apology and just when it looks like Sam is coming back to Opia as CEO uh we see a tweet from from EMT Sher who is ex CEO of twitch and he tweeted out saying that I got a call inviting me to consider once in a lifetime opportunity to become the interim CE of open AI when the board shared the situation asked me to take the role I did not take the decision lightly etc etc etc just long you know Silicon Valley Lon about everything that's went down happen you know what happened because of the mob Ure got destroyed why tweets from like 2012 and all started surfacing I'll tell you one thing I I I learned this again I'm I'm just observing and learning right because we haven't seen Valley Dynamics play out on Twitter at this scale like this right like even the Twitter acquisition all is still like VCS and all were very hush hush they're all very supportive this one I started seeing some weird stuff so I started seeing a lot of the VCS who had invested in open AI talk nonsense about em like really bad nonsense right unsubstantiated unnecessary like kosla yeah V dude I saw the vinod kosa tweet and I was like what is going on this is a man I respected like for so many years and you're just baselessly making accusations what talking about sexuality openly isn't that crazy like it really felt like Uncle relax yeah yeah that was that was scary and weird because these are all people I looked up to and I still kind of look up to for their accomplishments but it's like to see them I understand they're losing a lot of money and you can't be rational when you're losing so much money but to see them baselessly make accusations against somebody new coming in like there was another guy who retweeted one thing that em said and said that if there is a chance of us I'm going to paraphrase it I'm not saying it exactly as this but is there a chance of us dying completely getting wiped versus being ruled by Nazis I choose that he's just doing a thought exercise he saying if all of us were going to die and I had to live under a bad rule I would still choose life right that's what he was trying to basically hint at and people quoted that because he said Nazi and he said people like really belted him for that you're Pro Nazi this that so it's that know you can go back to Old tweets and you can take any tweet and you can make it to be anything and you just need one one or two bad words said in the Tweet like you don't need the rest of the Tweet like context now you can just crop out the Tweet itself to like one line or half a line or something so so he got belt he's getting he's still getting belted and it's strange to see when your money is on the line you are also Pro cancel culture and yeah so that was a surprising part but whatever I'm sure I'm sure VOD kosla has his reasons and you know he's widely respected and he's he's he's very Pro Ai and he's been talking about this before a lot of other people but I didn't expect it I didn't expect it my my image of them was very different so this happened em emit Sher was asked to take over and he accepted and now we don't know what that's going to play out like is he going to continue is he is he going to react to the backlash we do not know then of course Mr Satan said Sam is joining back then we saw another article saying Sam might not be joining Microsoft after all it's not a done deal he might come back that's when I got exhausted I was like I'm I'm done let's go back to building I'm I'm working on something we're trying to get the latency down of a speech model I'm like let's go back there yeah let's wait for this whole thing to play out but net net waron crazy week in the valley crazy stuff went down it'll be interesting to see where this goes to and of course we'll be right here covering it next week sorry no tools for you guys this week uh lot of drama happened this was basically today was basically a gossip session about everything that it's pinka of of the AI World Larry TV of of of the AI World hope you guys enjoyed it we'll be back uh with some more next week enjoy and miss you  Sam",
    "url": "https://www.youtube.com/watch?v=6dKbGhijK2I"
  },
  "VIE6KcNT_Y0": {
    "published_at": "2024-01-24T14:13:18Z",
    "title": "Mobile Aloha - fully open source robotic system",
    "text": "Mobile Aloha - fully open source robotic system Sid explain what is mobile Aloha this is basically open- Source robotic system that basically does a lot of different tasks so it makes coffee for you it folds your clothes it makes your bed and the way this thing basically learned is by showing it videos of humans do the same kind of task but you know from what I read it's actually T operated in the sense somebody else is operating this like it's not fully automatic so you can actually use it in both ways there are things that it does by itself and there are things that it does where a human actually is involved in making it do things as well the cool part about this is that these guys open source this entire model and uh you can actually set it up at your house it's just that it costs like a bomb you want to know how much it costs $333,000 yeah D would you buy a robot until it's cheaper than Dei it's hard to make a case for robot",
    "url": "https://www.youtube.com/watch?v=VIE6KcNT_Y0"
  },
  "GZiDbIq4nvQ": {
    "published_at": "2023-09-14T11:30:06Z",
    "title": "AI Agent that Operates Browser like Human\ud83e\udd2f",
    "text": "AI Agent that Operates Browser like Human\ud83e\udd2f so this is hyper right at first glance it seems to be like an AI agent that can operate a browser like a human so let's see if it can do that and start a new task let's say post uh tweet about guns let's see it's gone on Twitter sagar's account is logged in typing guns are not toys respect others and themselves and it is going to tweet that bro it's gone from sagar's account what the this is really really cool I didn't do anything can you send emails check just say send an email to Varun telling him hyper right AI is a scary tool okay  okay now it's going to find Varun Maya okay just wrote hyper right AI is a scary tool full stop and it sent the email I got it this is an interesting tool research and summarize send an email create a document post on Twitter these are like the four or five things that it can definitely do it's a great personal assistant I love it",
    "url": "https://www.youtube.com/watch?v=GZiDbIq4nvQ"
  },
  "TJgQNmKysSs": {
    "published_at": "2023-07-30T11:30:09Z",
    "title": "How to be Safe in the ERA of AI",
    "text": "How to be Safe in the ERA of AI so there's gonna be one guy who's doing like 100 gigs a week thanks to Ai and his brand name it's kind of scary when you think about the implications what do you think is going to happen to those people do they go back like revert and go do stuff offline I might begin to sound very conceited so I apologize in advance but there's a difference between real work and fake work fake work is work that you do to like look good and then kind of put yourself into an institution which is comfortable and your goals aren't actually aligned with production if you're trying to produce anything you'll be fine for example plumbers are ever going to be out of a job is their job is to fix things that problem of abstractly fixing things if that's what your job is AI is going to help you make more money because you're going to fix more things but if your goal is to pass an exam you're not actually producing anything you're optimizing for something that's not related to cash exactly you're not optimizing for something that creates value so if you make your job a person who fixes problems and creates value you'll be fine",
    "url": "https://www.youtube.com/watch?v=TJgQNmKysSs"
  },
  "PBF5GYiIcAM": {
    "published_at": "2023-07-21T14:25:55Z",
    "title": "You Can Now Edit Videos In ChatGPT: Code Interpreter",
    "text": "You Can Now Edit Videos In ChatGPT: Code Interpreter check this video out Domino just launched a campaign with the Domino's employee wearing a jetpack suit going out and doing a pizza delivery now jet packs used to be sci-fi when I was younger but they've actually become reasonably safe now Domino's so I'm just gonna pretend like I'm a new video editor firstly clip this video down to the first seven seconds I have no idea thank you  can you not argue with me at least try oh it's slipping it's slipping if you beg it folks check this video out Domino just launched a campaign with the Domino's employee wearing a jetpack going out and that's nice it clipped a video for you into simple stuff eventually you'll just have access to a lot of python packages the back end you don't even need to know the names of the packages you just can use it on the Fly cool",
    "url": "https://www.youtube.com/watch?v=PBF5GYiIcAM"
  },
  "41gjzrfp1ao": {
    "published_at": "2023-06-15T13:34:16Z",
    "title": "How to network with highly influential people using Bard",
    "text": "How to network with highly influential people using Bard what kind of emails do you ignore and what kind of emails do you like reading I like emails that are short quick to the point so the way to write good emails the ideal way is to use bars I'm just going to open up Bard I want to write an email to my word tanmay is a busy person write a short email in the form of how Tech series would write make it compelling for him to say yes and make up Social proof yeah don't you guys don't make up Social proof yeah this is just for attention where you replace the word so now it's going to do some search oh that was quick my name is your name and I am host of a business podcast called podcast I'm a big fan of your work and I'd love to have you on the show talk about your career your business and thoughts on future technology I know you're a busy person so I'll keep this brief this is a bit about my podcast see nice I'll keep it brief three bullet points yeah you're a successful entrepreneur a talented comedian and a thought leader in the future technology by the way it's searched here yeah",
    "url": "https://www.youtube.com/watch?v=41gjzrfp1ao"
  },
  "L_wYrpW8N-M": {
    "published_at": "2023-07-19T13:30:08Z",
    "title": "How ChatGPT Is Turning Everyone Into a Data Scientist!",
    "text": "How ChatGPT Is Turning Everyone Into a Data Scientist! all right so last week I started the episode on this uh really cocky note saying that oh we're growing and we're gonna surpass my Lord and all this stuff and then uh this was the slowest weekend so I feel like you guys aren't doing nothing so before we start the episode hit that subscribe button and three two one nuclear music  big news new button has showed up on chat gbd new brand new button called code interpreter hope this is better than some of the plugins you've actually been telling me couldn't operate according to print a code number for like a while yeah explain what is code interpreter why is such a big deal so code interpreter is like this slightly different model of chat GPT okay that has access to a a code execution environment so it can run coded like old charging you could tell it okay right code for this and I'll just give you the code then you have to copy paste it somewhere and you know set things up but here this thing can execute code phase so it's got a python execution environment and and I don't know if it's got other environments I've only tried the python one but then if if you tell it okay uh here's an Excel sheet I want you to conduct uh this analysis and give me a chart it can do that as well so data analysis and writing code writing and executing code writing and executing some some types of code data analysis chart generation it could do a lot of wonderful stuff so python has a lot of packages that you can use to kind of you know manipulate uh text videos etc etc now you need to know the names of these packages but most of us don't know the names yeah so it's basically made it it's super simple semantics yeah so it's so it's figured it out right like in it figures it out for example if you say if you upload let's say an Excel and you say delete all the columns that have x y z in it right or you can say hey create a chart for this so we'll use some python library to actually go create a chart for you right so it reminds me a lot of that statement that eventually all programming is going to be natural language like you're just going to say it in plain English and it's going to do it for you and give it back to you so I think the best best way to kind of you know put an action is to use it yeah let's test it out okay so we've got the IPL data set so let's go to open AI chat GPT gbd4 core interpreter so we're now encoding the better instead of uploading you know one file I'm gonna upload two I'm gonna upload a zip which has two files in it one is the IPL Ball by ball sort of summary from is the math summary one is the matches summary right now this is data of the Indian Premiere League um give me three interesting insights along with charts all right first I'll need to unzip the provided file smart boy and inspect its contents the trials yes so it knows that the file probably contains information about individual matches and the second one is Ball by ball data so now it's loading these files and inspecting their contents so this is like Auto GPT but for analysis it feels like it's not just analysis like I've seen demos I don't know if it's possible now but I've seen demos of people putting up videos and saying essay edit crew do a slow zoom into it oh really yeah it's any code any python package I assume it's hitting some sort of python library at the back end and just saying Hey I want one of those package managers and saying oh I want this I want this I want this and then you know it through natural language you're just saying okay give me something that can cut and it's finding the right python Library even edit video I think so that's right so can I build a Premiere Pro plugin which is connected to a gpd4 code interpreter API it won't have the execution environment of Premiere Pro but I think we could create some sort of simple native video player here okay it's got you the chart your first chart sees create a nice pretty chart for you yeah Mumbai Indians has the most number of wins between 2008 and 2022 Chennai Super Kings number two is number with the most number of wins they might not have match wins yeah match wins okay next it's going to move to the second inside which is most valuable players which is based on player of the match Awards oh this will be interesting I think Ms has won the most player of the match Awards okay your bets on Ms my BET's on Virat Kohli Ms purely on because he's played the most number of games most number of player of the match Awards interesting all that Ms is in the top six dude Yusuf pathan is in the top ten wow okay cool I think number 10 distribution of run scored in over it's gonna give me distribution of runs scored no okay so according to this the most number of runs scored has been in the sixth over oh that's interesting based on this data can you predict who then who next years top batsman is going to be next year's top run scoring batsman let's see if we can predict just Based on data is a predictive model based on historical performance however note that Cricket is unpredictable sport yeah yeah yeah yeah just tell me what you think so I can go and make my dream 11 team oh smart so generally right I mean people are very fuzzy with these terms but a data analyst is somebody whose job is to visualize and analyze the data to kind of break it down and say Hey you know here are past insights a data scientists job is to figure out what is going to happen in the future so he's like a data scientist typically forecasts the future so as you can see it's doing the forecasting slash predicting it's not able to forecast that well so this data is still 2022 and in 2023 shubman Gill was the top run scorer so let me ask it what I think how what do you think of Schumann yeah yeah okay based on this data how do you think how do you think  is going to perform next year next year in IPL 2023. it's doing very like so far it's doing basic analysis do you think we can use it to build something that can truly predict more accurately yeah I think nobody can predict the future right I think that's the main challenge but uh statistics suggest that Schuman Gill has a solid performance in the IPL so far with a decent average and strike rate can can you ask a question in the last four years who was the worst player who was the worst performing player was performing bowler and batsman in the last five years let's see now I'll give you defining the worst can be a bit subjective yeah worst is a harsh word guys don't say worst say slightly badge see it's smart it's saying let's start with the batsman but we'll only consider players who have played at least 20 matches yeah that's that's smart that's smart by My Level that's smart I'm sure there are actual statisticians who are like um this is basic guys yeah but they cost more than twenty dollars that's fair so according to this it says that bhubaneshwar Kumar has the lowest average runs per match but he's a bowler you don't consider bowlers tell me the tell me consider only batsman and tell me the worst performing batsman based on average runs scored per match batsman until number six in the batting order but that's the cool part about having openai also somewhere I mean GPT also somewhere in there right it knows who the batsman is and who the bowler is even if it might not be in the data right it'll say Okay batting order I mean the strike order is XYZ then maybe this person is a batsman or this person is a bowl it's capable of guessing so it's a statistution who also has understanding of that domain so according to core interpreter in the top six of the batting order Shreya Sayer has the lowest average runs per match which is eight you see this means that on average when he has bad on the top six he scored eight runs per match uh but of course there's a simplistic measure and doesn't take into other other accounts like math situations dude he's a batsman he's a top order batsman and in fact uh people are considering him to be like potential future captain and all love GPD got it wrong GPT is not uh but interesting is that data through though the result that is giving me is he's actually his actual runs is only 8.55 is this true can you double check oh he says there has been an error in the previous calculation average of 28 per match which indicates a much better performance dude it got wrong ask you to give a graph I don't understand this much text I don't understand this much text give graph give graph and explain give graph and explain but it's fine there's no issue data analysts in real life also there's too much mental gymnastics to come up with anything no but that's because we want instant answers right we don't want we don't want the cognitive load of thinking I'm beautiful sure it's important for a conversation to remain respectful so okay sorry GPD sorry sorry a first of all sorry for calling you a only can you double check if double check the calculation you made on Ben stocks are you sure second is Ben Stock's average in the IPL is about whatever 15 or so whereas KL is 40 plus no problem I'm here to assist you how sweet it's confirmed in the last five years yeah when he buried in the top six position in the batting order okay got it um interesting let's use code interpreter in a different way okay there's a video of Domino's jetpack let me show you the video first check this video out Domino just launched a campaign with the Domino's employee wearing a jetpack suit going out and doing a pizza delivery now jet packs used to be sci-fi when I was younger but they've actually become reasonably safe now Domino okay let's do one thing okay first the top part of the video ends at around seven seconds okay so I'm just gonna pretend like I'm a Noob video editor and just be like firstly clip this video down to just seven the first seven seconds the first seven seconds okay add a blur on the lower fifth deep one percent of the screen in the video okay okay then add subtitles over the blue I have no idea this is going to work okay can you not argue with me at least try please clip it to seven seconds oh it's flipping it's clipping if you beg it for us check this video out Domino just launched a campaign with the Domino's employee wearing a jetpack going out and doing a it actually clipped it that's nice it clipped a video for you it into simple stuff and if you can find the right eventually you'll just have access to a lot of python packages the back end order you need to know the names of the packages you just can use it on the Fly cool what else can you do with golden potato so you can export your Spotify playlists so let's stop training so that's nice we explored a Spotify playlist data called Instagram real stop trending okay I want to know what are the top five trending reels in India oh it's got danceability energy acousticness balance Tempo assuming popularity is a measure of how training these songs are we can look at the top five most popular songs let's do that interesting this is the thing it it fills in context obviously sometimes it feels in rubbish also but this is what I like about it it will just YOLO make assumptions and move with it all right Daylight by David Kushner popularity is 98 Cupid anti-hero I'm good and calm down these are top five trending songs based on their popularity on Spotify interesting interesting um what is ask for what percentage of the songs are dancing percentage of the songs are dancing attribute describes how suitable it tracks for dancing 0.0 is least answerable and 1.0 is the most dancable see it's it's picking a threshold it's saying anything above 0.7 it's picked the threshold by itself I love this sometimes it's wrong but it makes assumptions by itself it knows that 0 to 1 is a clamp yeah approximately 47 of the songs are considered dancing based on the criteria we've defined okay interesting you know what's a better way to use this in my opinion I think every time you have a data set in Excel or whatever a section should just load on the right that gives you all the insights instead of you asking it for insights sometimes you don't know right like I mean how long before Excel literally has this it's not not very long I think Google already launched like Google AI insights I have a question okay do you know do you know what OCR is no so there used to be this really popular package called Tesseract OCR which is optical character recognition right like let's say you have something printed you take a screenshot of it you want to convert that back into text those images into text right so if you want that now it's probably possible using Code interpreter okay so let's do this let's let's just Download a pdf of something uh something PDF famous PDF famous PDF  brain dead ghost okay we got a famous PDF the first three pages of this see it's using an OCR Library it's that's a python screen it's a python Library actually let's click on show work PDF to image and then it used pyters rack so PDF to image converted it into an image and Pi tesseracted the optical character recognition yeah use the text extracted from the first three pages of your document it's pretty cool you know why this would be really useful if it depends on how well it can do OCR and whether it can figure out images but remember there's a business called doubt nut yes that you could put your 10 standard well standard problem statement you can just put a screenshot on on like their app and it'll just give you the solution to it you could potentially do it with this a lot of printed documents that people have can now be Auto digitized I mean it already could have because people are using that are apps like cam scanner and stuff that do this um but hey now you have once the python Library exists then so anyone could write yeah but the thing is now what's happening if you notice right with code interpreter a lot of these small apps that people used are all being rolled up into one app inside of chat GPT that's the big challenge right like they're taking over everything their Google Apple are taking over entry getting into the app stores here these guys are taking over the actual apps uh there's no space left for small days speaking of which there is a competitor to chat GPD that got announced this week it's called claude2 uh it's currently live only in the US and UK but because we are cool we have access to it how did we get access all right let's talk to plot so here's what we've done okay we've put in lots of tweets from Elon Okay so we've taken uh his podcast from Lex Friedman Friedman whatever yeah and we've just dumped it in okay the entire PDF we've taken his podcast from Joe Rogan Experience okay all of it okay now we fed all this in uh now that you have this data this data can you tell me three things that Elon believes in in that the average human might not can you tell me a little bit about Claude like who's behind Claude have you used it so far what do you think of it this is my first time using Claude but one thing I know about Claude and what made it really famous on Twitter is it's got a longer context length so while compared to gbt yeah gpt's base context length is about 4000 something and then GPT also released a 32 000 context length but Claude has a 100K context length but you know what recently a paper came out that says now we can do a million context length now we can do 10 million context line now we can do a billion context length eventually I think context line is not going to be a barrier all right so Claude replied saying based on the text of his tweets here are three things he seems to believe that the average person may not making Humanity making Humanity multi-planetary merging with AI uh engineering as an art form interesting the overarching theme seems to be Elon takes a very long term species level view of his things and it's focused on existential threats so this is like code interpreter in some way which is we find data into it and I analyzed it no it's it's more like chat GPT in a way right in the the traditional charge GPD just with a longer context lens see it only allows you to put in PDFs or other text sources so what it's done is just like we type in the prompt and charge gptm for example you can type in a prompt saying okay here is a article by Shakespeare and we put like just three four lines and then we say okay right like Shakespeare right so it's doing that except the context that we're feeding in because there's a lot of time that much we're sending in PDFs in fact one of the interesting use cases of cloud I'm damn sure you can already do is you can now feed it all of your past videos and say write a script like ah that is your GPT it was tough to do and cloud is also free to use yeah because with GPD you have to use vector embeddings and Vector embeddings hallucinate a lot from our in our experience but longer context windows don't have a hallucination problem or rather I haven't tried it yet but I'm fairly certain that it should be able to write near match as how Tanya would write or how I would write or really now I just need someone to transcribe all the garbage I spoken on my channel over the years you don't need anyone to transcribe it AI will transcribe it sorry I said that guys edit this part out you know what the biggest use case of this is you can now dump in a book you don't want to read and just be like what would this book say about this problem like I used to I used to see summaries of books and I'd just be like oh but it always trips the Nuance like one of the best books I've ever read is skin in the game by nothing if you've ever seen a summary of the book it's terrible it's like the most generic life advice from the book right but the book is really good so I would love to dump that book back in now that I've read it and just be like what would taleb say about this this problem I am working with a co-founder on something something and I have this problem what would Talib say about this based on all the knowledge in the book yeah so those I think are very useful and I think this is like I think being an author is special in that way because you have written it and it's not you being pulled out of a podcast or anything else right so when you've written it you've curated it for somebody else to read and therefore you put a piece of your sort of curated knowledge there rather than a podcast where you're free flowing right so it has like a slightly more perfect version of you compared to you sitting on a podcast and I think that's that's beautiful because you want advice from somebody based on where you are in life you you read a book or you just put in the book and be like what would this person think yeah and if you read like 300 pages of someone's curated thoughts yeah you get a fairly good idea about what they think or how they think yeah uh that's an interesting use case someone should try this and let us know how it goes by the way listen so you know we've been talking about Ai and I think one place AI is really going to add value is in robotics one thing overpower is starting to get known for is showing and telling and it's very hard to show robotics because I'm not a robotics expert you're just a robot but I got somebody who has a history of working in robotics his name is Rishi he works in a company called symbionic and I'll let him tell you his story himself all right so then we talk about robots I think the first step at least for these sort of lifelike robots is to first see how the human body would interface with you know a prosthetic arm or something so I looked around and I've actually found a company that makes prosthetic arms so here we have Rishi from that company hi Rishi yeah hi guys I'm Rishi I'm the CEO and co-founder of symbionic and at symbionic we are basically trying to build a future of bionics we are trying to build uh human parts that can be controlled through thought uh and this is completely robot so four years ago 2018 September I was going on a bus to pondicherry and the bus crashed my right hand got cut so before that I was working uh as a social worker doing multiple things but then when this happened and to me someone who's grown up watching anime and all sorts of sci-fi movies and I I was told that that nothing exists that can suit my needs to go back to living normally and so that's when it kind of triggered me and my friend we started this company called symbionic and so we basically wanted to build a functional bionic arm that I could control through thoughts and it's been like a very heck of a fun Journey for the last four years we've been building this and we have one person one user who started to use it now so it's a big achievement for us can you tell us how you're able to control movement of a bionic arm using your thought that's very interesting so basically um when I lost my room I was still able to feel the rest of my hand I'm not sure if you've heard Phantom him yes yes I have so there is Phantom campaign and but in general you can even feel some cuts that was there in your arm and all so uh I whenever I kind of try to do this my muscle is twitch and I knew there's something that the data was still there so we needed to figure out how to take the data and kind of send it across to a you know motherboard and take it hey open the hand close the hand so it was possible theoretically then you know we started working on it we saw a lot of existing work that has been done and so obviously I couldn't buy anything and we had to start working on this so we started working on the robotic part and then figured out that uh there's a way to collect these data from your body so we use something called electromyography um it has it is in technology that has been existing for 50 years but just now uh you know we're trying to use it to its maximum you know limitations AI machine learning all of it is kind of helping us so we collect a lot of these electrical signals that go from your brain neural uh motor neurons to your muscle and kind of make sense out of it so like you know whenever you try to close or open in your Phantom game your uh entirety of muscle kind of buzzes so vpa sensors exactly on those points and kind of uh you know try and control the arm so how much dexterity can can you guys figure out with a bionic arm I see infinite potential here I mean I think you must have seen the scene from Star Wars where it's arm cut correct see I think that is possible in the future yeah definitely and we just we're just scratching the surface today we have so much to ignore invent and prove but as a starting point today this arm it has multi degree of Freedom so in each finger can move on its own thumb has opposable and non opposable which kind of is very important for humans rotatable wrist and manual like you know elbow so all of this can be eventually our next version we can all all of these joints can be controlled via thought so we're using multiple channels of EMG sensors and kind of trying to figure out how it can understand different patterns so this is a separate pattern this is a separate pattern so it's all kind of electrical impulses sending dotted codes to your body uh in before 2018 what were you doing before that like did you have any engineering background or did you just like start figuring this out no I'm not an engineer I actually studied visual communication and design I was very briefly working as an assistant director for movies I had a media uh startup called tungsten we were trying to build brand identities for other companies that was a part-time with no business and uh for full time I was working for a non-profit so our goal was basically to improve the quality of education for government schools in Tamil Nadu and which I mean was a major part of my day I mean from a media background to suddenly to get into hardcore like physical engineering uh what does that transition like um it was not easy I mean I think initially I had my friends like best friends from school actually so niranjan he is a CTO and co-founder he kind of he was doing his Master's in my mechanical engineering back then in Italy and I was here and we had a couple of more friends who also initially kind of supported to jump start this thing um we got incubated in bit so basically what I did was uh cold turkey quit my job the stop the business everything and moved to Vegas and Like You know we got a space and we got a incubation like interns and all of that so we just sat there for a year and that one year was a kind of a seed period for me to learn everything I could learn about this so I spoke to everyone in the country uh who had any expertise in prosthesis and also also people who tried to build a company like this Enfield because they would have a lot of earnings so After figuring out how this industry Works where is the main problem why it costs so much when it shouldn't like if you break it down into first principles all of this component whether it be for our product or be it for record one device it's the same so technically it should not because pricing so much because it is not a sort of a want for higher Social you know it's it's a need it's a primary need to be able to you know do things things for yourself and we call it ADL so basically activities of daily living and the more activities you're giving you are dependent on other people it you use your confidence you you use your you know and then it also affects other parts of your life so and the fact that you can't find a solution in today's day and age you know with all of these Innovations was just not sitting right so what does a product like this cost abroad and what are you guys trying to make it uh be priced at so the big companies the you know ibms of prostitution are pricing it at anywhere between 30 lakhs to a crore and this is in the US in India these products come with a lot of taxes and you know tariffs and that also increases the cost uh We've bought it down 10x like we we're trying to bring this into the market at less than 4X which is like a huge huge you know difference from whatever is available as a solution of this skill you still get like you know the Jaipur for the free of course through thesis which has no function it just like you know it's just a cosmetic replacement but then it doesn't allow them to do anything and we had we thought okay let's build something that they can use and go back to work or do things that they want to do so start aspiring again um are you guys hiring uh is there there's an audience who's watching this is there anybody that uh is there anything that you'd like to tell people especially people who are I'm sure some people who watch this have disabilities what's your advice for them because you also look with the disability yeah I mean I think until 2018 I was I didn't have any clue what disability is uh even men take you know the depth of it and being a person with disability now one thing I can say is um everything is mostly figure out like there is no point in giving up or uh yes there are limited Solutions available but it is not uh because it is not possible it's just uh vested interest has to be put into places where it's needed so somebody has to sit and think that can we go bring the price yeah over for something like this right so maybe like you know just look out for Solutions and don't stop aspiring that is my only message for people with disability as for hiring yes we are looking for engineers embedded Engineers uh firmware developers uh people who can kind of hack around pcbs and uh all words that I totally understand by the way I don't understand this but I'm sure there are people who are watching who might get it  anyway guys if you want to get in touch with Rishi do uh write to him We're linking a contact email in the description uh dude thank you so much thank you for joining us yeah thank you thanks all right so the next thing is about deep fix okay now we've done deep fix in the past we did one with Ranbir Kapoor check the video out but there was a difference between what we used to do in the past and now right in the past we used to put full uh videos in we used to rip all the source images out we used to rip all the destination images out we used to train the source on the destination it was painful to say the least and it would take three four days but now you can swap any video with just an image I can take any image and like kind of just beam it on top of some footage of you right so the tool is called rope okay I'll tell you quickly how to use it you go to GitHub you download it so we already set up group it takes a little bit of time to set up uh but once you set it up you just do run dot pi what is this bloody window and all I just want to chat and chat interface on top of everything done not bye okay so we're just gonna run it I'm gonna run group and it's going to pop up a nice little interface for us okay so what we're going to do is we're going to first select a face so let's put Mukesh Ambani let's select a Target there's a clip from one aib video that we had done okay so let's watch The Source grip first okay how will they hide it cheers okay so we're gonna swap it with vocational money for that okay start okay it's on its way oh wow that was quick yeah compared to deep faking in the past it was horrible so what's happening here is the same technique that's used in the mid Journey face swap inside face is being used here but it's being used for video it's pretty cool okay and let's just watch the final video how will they hide it cheers it's not bad uh I don't know how I feel about this  first of all shouldn't be this easy to deep fake yeah it's fun very easy now should be this easy uh second of all I'm sorry Mr Amani that we did this to you uh and thirdly it's it's ease of use is there it's like super easy super quick but it's still not like my hand went in front of my face right and at that point it got a little blurry and it that's true even for old school deep fix or if a hand was in front of your face it's like it would it'll break a little bit so what most people have to do is like rotoscope for those uh for that particular it's called exegg you'll rotoscope for those frames but uh eventually it's going to be automated like it's gotten so easy like it was so difficult a year ago so deep fake on video to deep fake on video with images of still like you know Insight existed but um now that it's become so easy to do on video it's just like it feels like oh we're almost there yeah it's not great and at least this particular example but maybe it's because our source image was not that high-res the the video wasn't that high-res yeah and you're using one image no you have no idea how they how the face will look from the left or the right eventually one of these tools will come out will just be a cloud platform you just drag in a video you drag in and put your dragon and output bakes a video for you and you're done I don't know if I'm amazed or scared because it shouldn't be this easy to fake something man like it's getting easier it's getting easier anyway on that very optimistic note as for today's episode guys keep subscribing commenting liking do everything else we have to surpass varun's YouTube numbers that is my primary goal when I walked into this office many months ago I said I'm going to destroy you and we are very close to it keep doing that let us know what you want us to cover on the next few episodes of overpowers next time check us out on Instagram bye ",
    "url": "https://www.youtube.com/watch?v=L_wYrpW8N-M"
  },
  "-7sP1FGY61o": {
    "published_at": "2024-02-06T13:26:14Z",
    "title": "Create Your AI Animated Story with Cadbury Silk!",
    "text": "Create Your AI Animated Story with Cadbury Silk! you can now make personalized AI animated stories and you can gift this to your Valentine crafted by one of bollywood's finest Zoya atar this AI tool is called story of us and the way to activate this is by a Cadbury dairy milk silk there's a QR code at the top left so you just scan that QR code with your phone it takes you to cadburry silk.com what is your like School crush's name I'm not she watches this podcast so whatever right Puja Avatar of Puja dude that is exactly Puja I don't know how catb s knows this but yeah that is what was the most fun time we binge watch movies all day show the video show the  video close your eyes miss  me I can all right that was quite something H personalized video through just text and if you guys want to do it you can do it as well and the last piece the best stories will feature as an anthology on Disney plus hot star for the world to see so maybe you'll get lucky and you'll be on TV",
    "url": "https://www.youtube.com/watch?v=-7sP1FGY61o"
  },
  "QdCya86-LPU": {
    "published_at": "2023-06-28T14:19:47Z",
    "title": "Text to Music Is Here! (Meta&#39;s MuiscGen is Crazy)",
    "text": "Text to Music Is Here! (Meta&#39;s MuiscGen is Crazy) music gen was launched by meta it's on hugging face and it's super interesting have you tried it no so one you can describe any prompt so I can say an Indian hip-hop beat using guitar riffs let's see what this is like  that's pretty good another thing that you can do with music gen is you can drop a melody and ask it to change the style creating the Harry Potter theme and ask it to Indian instruments Tabla float sitar it's actually pretty good yeah ",
    "url": "https://www.youtube.com/watch?v=QdCya86-LPU"
  },
  "E43kVFr3eE8": {
    "published_at": "2023-12-30T11:34:09Z",
    "title": "This is like Midjourney Moment for Music!",
    "text": "This is like Midjourney Moment for Music! let's try a Hindi song about a boy called warun who loves a   robot what impressive is that it gets a pronunciation right and there's emotion in it there's emotion in it and it gets a genre right as well one of our first videos was that Snoop Dog video right vast difference from there right it's able to slow down a word it's able to cram three words it's able to understand that oh that's how you fit something into a songs meter that sort of stuff didn't happen when we made the Snoop Dog song but yeah it's definitely gotten significantly better in like 3 months",
    "url": "https://www.youtube.com/watch?v=E43kVFr3eE8"
  },
  "IlIhykPDesE": {
    "published_at": "2023-12-26T13:49:38Z",
    "title": "Conversation with a Huggingface developer",
    "text": "Conversation with a Huggingface developer ladies and gentlemen welcome back to another episode and today we have a slightly more technical episode we have shauk pal from uh hugging face sh welcome to the show thanks for having me uh you know what what we usually do here is like whenever we have somebody from outside we always like introduce yourself introduce yourself in a way that you know you would want the world to know you yeah for sure hi folks I'm shyok I'm flying all the way from Kolkata today uh I work at an interesting company called hugging face there's actually an emoji in the company name that's why find it to be very interesting I work as a machine learning engineer there uh and don't don't let that term fear fear you off it's just like regular software engineering uh but I get to deal with uh a lot more exciting stuff maybe like the stuff that uh lets you generate images from natural language text description and so on uh so yeah that's that's like my job that's what I get paid for and of the work I like to talk about Cricket uh cool Netflix movies uh and so on Big Time into Cricket so can talk about Cricket so yesterday match was was awesome it was a heart heavy  matter so let's start with diffusers right so for people don't who don't know Shaq um maintains a repository called diffusers uh my first interaction with diffusers was when I was trying out compis on diffusers I would love to know how you even got into hugging face why did you get started with diffusers oh I think it has been a long journey uh because I like to call it a long journey because well it's been a little more than six years I into software engineering now and for me I machine I should start with how I how I got into machine learning in the first place for me uh it started around in late 2015 uh I was in my undergrads during that point and I was asked to choose an elective for my undergrad curriculum and I ended up taking uh patent recognition and machine learning it was like late 2015 resets were just becoming a thing uh and I ended up taking it and the more I studied it the more I got interested because I've been a computer science nerd uh uh since my childhood uh I was intrigued by the idea that we now have machines that can be during test so that was pretty fascinating to me and from there on I I was like okay it's going to be either machine learning or nothing at all uh because I'm not I have not actually dabbled in other areas uh of of things like web development blockchain Android development Internet Security cyber security and so on machine learning is that one thing that I have I I I like to say I have dabbled I'm still dabbling uh so from there on it started and then I had to take up up a job at TCS research which did not include a whole lot of machine learning but I had to take it anyway you know finances uh just got out of teenage at that point in time so I had to keep my uh Pockets filled uh but soon I realized this is not happening I'm unable to make any progress my mind is not being taken further I'm not finding the job exciting enough uh so I ended up quitting my job and I then decided okay let's study things from the scratch let's see where it takes me and then after like six seven months I was fortunate enough to you know make my Mark at a at a startup out of Pennsylvania uh there I I was introduced to computer vision and from there on it's it sort of stayed um I've been fortunate enough to work on different facets of machine learning computer vision language modeling machine learning engineering mops and such and you're working on Gans then right y so at my first truly ml Focus job I got to work with Gans quite a bit uh and then I joined an Australian e-commerce company where I got to work with medium scale uh language models and then huging fist happened so it was interesting back then uh so hugging face is for the folks that do not know it's known for a very unique python uh Library called Transformers not the architecture Transformers the library Transformers so Transformers is it's primarily maintained that hugging phase and back then it was expanding uh its efforts for also supporting computer vision because by 2021 Transformers had already become uh the go-to library for doing natural language processing let's just face it so in 2022 it thought of sort of expanding its efforts for computer vision and other modalities as as well such as Peach uh and someone from hugging F reached out to me asking hey would you be interested in contributing some of the computer models to Transformers I was like yeah I was already contributing to open source like different repositories like kasas and so on and I was like yeah okay Transformers I I I had already used Transformers in my work uh at at that Australian startup I was like okay it's it's a library that I get to use heavily at my work so why not contribute so I started contributing uh to Transformers the computer vision models and after like 3 4 months I really started enjoying the process and then after like five six months of contributions uh I was uh I was like okay let's let's reach out to the folks and let's see if I if I have a chance they agreed and they uh had the interview process and fortunately I got in and then when I joined huging face I was a developer Advocate engineer I was doing computer vision I was leading a couple of computer vision advocacy engineering efforts uh at hugging face and then soon I discovered from my computer vision friends that Gans are probably going to be dead in in the next 2 3 months uh and I should really catch up with diffusion models and fortunately Enough by that point in time hugging fist already had diffusers a library purely dedicated to uh purely dedicated for you know tinkering with diffusion models what I had heard during that period when Gans had you know started to fade out from popularity is that hey diffusers are good but they're very slow they use something called Markov chains like people are is too slow but then when people start seeing the outputs and then Del and all came out we were all like wow yeah so that's what kind of happened uh that's that's what got me interested in studying the subject in the first place and I was like okay we have a code base already uh and let's do the code first because I'm one of the students of Cs 231n that popular course from Stanford taught by Justin Johnson Andre carpa and F Fe Le the 2016 Edition and they were always showing the python pseo so I was like okay let's get into the code first and let's see like hacking things so from the code I got to learn uh quite a bit and I was I I started tinkering with the process I started internally contributing to the diffusers code base so basically long story cut short I was trying to make my case uh because I started really loving the literature in general uh the and which part were you start did you start off with you start off with the pipelines you start off with the scheduler you started off with I started off with the with the training scripts directly oh interesting like by but but but at that point in time dream Booth was becoming a thing uh and I was interested to a your lensa and all yeah yeah lensa uses dream boo behind the scenes yeah yeah yeah yeah so I was pretty intrigued by the idea like subjective Eng generation of this quality my God what is this even styan couldn't generate you something like that so I was like okay let's study these things and I was like okay probably this is going to be my thing for the next two three years and I started internally uh making my case for it and then I uh then I reached out to my team lead saying hey could I work on this fulltime even internally I had to sort of talk to talk talk to a couple of people and then uh seeing my case seeing my internal contributions they were like okay come work interesting what's your favorite thing about maintaining diffusers well it's it's s it's such a new literature you get to know about a lot of things just from a GitHub pool request like someone will open up a PR and you for anime diff and stuff like what is anima what the f is that I mean even to review that pull request I need to read a whole paper I'm like what am I doing am I a researcher am I an engineer am I a maintainer what what am I truly so that's that's one of the most exciting parts that I really get to enjoy on a day-to-day basis like there are so many clever and intelligent contributors but at the same time they're very kind so I'm like my humility is already checked yeah can I ask you a question I think and now let's like make it a little simpler for like let's say the young kids watching this right A lot of people send me DMS saying I you know I want to get into AI right and it's almost like AI is such a catchall buzzword right my understanding of the space is you got researchers you have people who work at the ml level and then you have people who work at the applied AI level like we are very clear we work at the applied AI level right I don't think we have the competency to work at the research level I would like to know if you feel these are the same four divisions or you feel like you know this a little more expanded than this also what do you think is the path for each of these people I think to be able to answer that question uh I'll have to set the context uh a a bit clearer I'll have to discuss what I get to do where my intersections sort of lie and then probably I I'll build things from there so I get to fortunately enough at a company like hugging face there's no like scarcity of exciting things uh if if the company as a whole feels like okay there's that thing which potentially could make a lot of impact because we we optimize for actions over rather than trying to be perfect we see impact like as a fast class citizen we we probably won't be doing anything that probably won't lead to impacts like obscure novel things and stuff like that so we like to work on things that become generally useful to people like diffuses like it becomes it becomes useful to an artist it becomes useful to an engineer it becomes useful to a software engineer or probably a company that those are the kinds of things that we get to work on so most of it involves engineering but but but also little part of it involves applied research so fortunately enough I get to work on both sides uh like as I mentioned like for reviewing of pull request I get to probably read an entire paper and so what you're saying is never clean like you even in our experience right like when we let's say find tune a model we are screwing with the hyperparameters so in a way we're doing a very little amount of ml so it's never clean whether you're doing applied a or ml prettyy much like I would say somebody maintaining diffusers would be pretty much exactly in the center yeah exactly in the center that's because the way the literature is moving towards let's say so I'll give you a concrete example right for for for the most part for maintaining diffusers I think engineering level knowledge is okay is enough you mean just a software engineer can maintain diffusers good python knowledge good software engineering knowledge and of course doesn't need to be an AI guy a good level of ml knowledge that's that's like the so two primary things software engineering and ml it's not like if you do not know anything about diffusion models you will be able to navigate throughout the maintenance process it should be 50% diffusion models it should be 50% about the code design and stuff like that at least that's how I like to differentiate between things it could be 70 30 split as well but for me it's like 50/50 you need research yeah so coming to that point so when stable diffusion Xcel came out I think hugging facee was the first one to have put together control Nets models especially fine-tuned on stable diffusion Excel checkpoints yeah and then we also released in collaboration with the tens and FKS d2i adapters then we also released uh an inpainting checkpoint so for doing those kinds of you know large scale generally useful training runs you need to have a mindset for tinkering with things you need to have some sort of an information driven approach let's say you have studied all the ERS you know okay probably if I combine this trick with this one probably this will lead to something I think as as the maintainer you also have to think about popularity right if you know something's going becoming popular like COA if I remember you know it's getting popular like hey we need to put diffusers in this so you also need to know the general landscape in I need to be able to predict trends like for example what what happens if videos become popular in 2024 do I have enough uh enough good of good of an API design to support that how how quickly I can navigate through it that sort of stuff interesting what's the career path like let's start with researcher what's the career path to being a researcher be really good at math especially calculus linear algebra probability if you and where should you study like what what should you do like I'm 18 years old how do I become a researcher for sure if you if you have taken science uh if you if you have maths in your like pcmb collection I think you should really consider taking high school math seriously because I I I'll tell you frankly in my in my 11th uh and 12ths I I had PC pcmc physics chemistry mathematics and Computer Science and Mathematics was the one subject I I was probably a bit good at and I would do maths like all day and I didn't know I I I was going to study machine learning and I'm still ripping out the benefits because I can I in my head I can visualize the gradient back propagation chain so if you are 18 and if you are trying to be an ml researcher take your high school math very seriously all right how how do you get into being in ml let's assume your math isn't great then how do you enter ml still I mean there are still paths possible for you for example maybe start with Andro young specialization deep learning specialization and if you feel like okay ml is your thing ml is something that gets you interested and excited you you will probably end up studying maths anyway so it's like if you truly love something you will you will figure out you will get better at it and applied AI is I mean at least for it's been we study computer science for 4 years work in software for a while that's the path you would assume for app for for for Applied AI still having machine learning knowledge I think is necessary because if you do not know what regularization is what generalization is okay if I if I you know bump up the learning rate it's probably going to overfit too quickly if you do not know about these things you will anyway lead to failure so having a bit of machine learning knowledge is anywhere needed I feel like if you're interested in AI you learn that on the job yeah I'll give you an example right when we first started using dream Boo the dream boo trainer on automatic 1111 at that point had all the hyperparameters it had the learning rate you would have to set in like when if you ever watch a tutorial on dream boo you'll see this right you'll be like hey first prepare the regularization images and then they'll send you to like a GitHub repository like a thousand images of like people and they'll be like these are regularization images then well U here's the learning learning rate uh do you want to use fp6 FP do you want to use BF so it's it's like in the beginning when I first saw that UI it was very confusing right it's like what am I doing but I feel like if you have a reasonably fast GPU and you just try all sorts of combinations just see the output I think eventually you start learning what the right there are trade-offs no you had the gpus H and even for so you you had a good user experience let me just say it you had a good user experience when you were learning about things but most folks might not have that students only have access to a T4 GPU instance that that's what free cive instances give you right and with T4 it it can be notoriously hard saying learning by just tweaking all the parameters many times like I feel this with deep fakes right like um there's a tool chain for deep fakes called Deep face lab have you heard of it deep face lab so every time I've used deface lab now like I know instinctively if I add a little bit of random W are the outputs going to be better it's very instinctive I don't think there's any article about de face lab on the internet saying these are the best parameters I don't think there's anything such as best what's the kind of like for example one of the things I feel is that uh so we did the swap of shauk right in one of our videos and when we were doing the swap of sharuk we were like hey the skin tone of shuk doesn't match Walter White we're putting it on Walter White the skin tone of shuk doesn't match Walter White and then we played the parameters enough such that you know we got that output so if you ever to do it again I kind of know what the settings are exactly right so it for us it's been a little more like instinctive as they say deep learning is more Alchemy than science so so it's still an evidence-driven branch of science but it's like writing an essay if you know your vocabulary right you have got lots of options and you'll see this on Reddit right like this is the best thing on Reddit like Reddit it's like every day on on SD uh especially the dream boo Parts everyone people / stable diffusion that channel everybody uh every day there's one person saying what's the best learning rate for dream Boo and nobody knows people like try this then try this then try this it varies from subject to subject yeah so learned instinctively is there a way to learn it non- instinctively is there like documentation on it because I remember reading the fast AI book you know there's that fast AI that stter to uh um this thing in that even they are like learning rate bro it's random it's like they're like there's no science to this so is the only way to learn it instinctively so I'll tell you what for for for problems like dream booth for problems like control net training or for problems like stable diffusion training there are recommendations that you can refer from like you study the stable diffusion technical report you study their technical implementation details section and you study the learning rate you start from there and then you sort of start to enal it maybe drop it down 10x drop it down 10x and then you probably use a scheduler and then you get to where you want to be but for simpler problems like image classification there's already things like LR finder which the Fast book Fast book discusses about you do the LR find the range and then you doy cyclical LR and then you get away with it so you got to study certain things because you studied the Fast book that's how you got to know okay this is completely but I didn't really understand the Fast book The First Time like I understood a little bit uh but I didn't understand it well enough till I on dream boo almost like you have the exact same hyperparameters and you're like tweaking around I feel like maybe it's just me but I understand better by like around like trying 20 things and me like what's the output like we working that you so when sha first came here we're working on an anime right now uh and it's like even from here can you hear the GPU is crying the UPS is crying right so for us it took me two weeks to get the right settings and I can't explain how I got to those right settings yeah like it's just I tried everything I got to say it also depends on one's perspectives if you are a tinkerer by heart okay it's you have the resources available to you you are you have time and you are putting all your resources to good use but many folks might not have the resources but many folks Also may not know how to make the appropriate use of your time or your resources or many folks are probably a bit more scientifically curious they want to figure out the signs I think it's okay yeah it it depends on one's perspectives but if you want to become a true tinkerer you better start investing time in tinkering things tinkering yeah I feel that's a DNA thing like I either you're a tinkerer from when you were like 10 15 or you a theoreti I have a wild question here it's going to be a little bit you know it's a it's an observation I've made and it's an observation we spoke about before we got on this uh podcast as well do you feel like a lot of at least some of the ml parts now are going to be completely UI driven like with gradio and stuff because dream Booth sure you can train it directly from whatever you open a prompt and you're training it directly from terminal or you have one of these tools like automatic 1111 where the UI is ready for you all the parameters are there and you don't really need to know how to code per se do you feel like that's a phenomenon that's coming out depends on the user Persona I would say let's say if you are working on a component that's going to be integrated uh into a bigger component probably you would want to Version Control that component you would probably want to do unit testing corre you would probably want to you know have some trust and reliability for your end users and for that you can't probably rely on no code or UI Solutions but probably you are an artist or you are a tinkerer and you are just looking for rade Solutions and there's nothing wrong with that you go ahead and do automatic one in fact lots of artists in in fact in fact from India they use that tool so I think it depends on the user Persona got it got it awesome so let's let's broaden out a little bit right I think the path for all these people we figured out what is the path for somebody who doesn't know anything about Ai and just wants to get up to date follow Twitter one yeah two follow Twitter third follow Twitter and follow and and follow someone called AK cuz he puts out the papers and he also happens to BU my colleague I get to Fright about that but he AK is my colleague at huging face so but anyway uh jokes aart AK has this uncanny ability to cut through the noise and only tweet about the papers that are probably going to be the most impactful absolutely follow that guy and be done every time make puts out a paper we we if there's a Code based associate we'll go play with it it's absolutely it's amazing okay so now I want to ask you right what is what's the common person think about all this like you I'm sure you've spoken to Common People right it's moving really fast like one thing that scares me a little bit is that this is all moving too fast right uh we had a period where stable diffusion outputs were garbage right find when we fine tuned a stable diffusion model for Alpha C which is many months ago it was kind of hard today's one click today Civ AI has like thousands of models that you can just download right so I'm kind of feeling like what's the alpha like I think two 2024 is going to be about videos yeah we have had a lot of models around 2D text toage stuff now it's the time for text view I'm also really excited about 3D I think 3d motion view synthesis entian splatting Gan splitting that sort of stuff like the general workflow could be generate a 2D image use goian splitting to view to synthesize 3D views and from the 3D views generate whatever you want to do so I think the next part would be to control these things like let's say you have this prompt uh saying a dog and a cat now how do you emphas put the emphasis more on the cat I know that there's something called Pro prom fting that forces the generation process to focus more on the cat but does that also uh make sure that the dog does not uh get neglected you know what we do now especially in video especially for frames with the two characters we Roto it out we use Sam segment anything and we're just like this character treated separately this character treated separately dude so I used to use automatic one1 for a long time now I moved to comfy because comfy just has such granular level of control that you can just be like hey I only want to work on like you can be you can have a very very specific workflow complicated as it is but you can let your scatter brain just you know kind of appear on screen through the nodes right uh but my question was different my question was what should the common person think about this like this is all moving so fast like a lot of people in jobs are like dude this is this 6 months ago this was something else and now it's like I'm in this place of like kind of like fear is this is my job going to continue like how should they think it's it's a difficult question for someone that does not work on artificial intelligence and uh probably they work on regular software engineering I think it kind of depends on the domain they are working on and if if they are not keeping an open mind and if if they are not thinking about the use cases which might be benefited uh by using different AI tools I think it's going to be a bit different for them because you never know which industry is going to get affected uh because one day if open a or or any other big player comes up with a particular Niche AI tool which probably affects their industry they're doing something for developers they have developer exactly so you never know what's going to happen so I think having an open mind like isn't that scary for the average person cuz imagine you're 19 years old you just or maybe you're 21 years old you just got done with four years of computer science engineering or not even computer science let's say just any let's say BBA or something and just looking at all this Tech go by and you're not sitting on the tech every day right so you have no idea like until we put out that I put out a teaser on Twitter of us doing the anime thing until then people didn't even know it was possible Right but now a lot more people will work on it in the next 6 months you'll have everyone creating an and it will and it will reach those people 6 months later so the question is how are they supposed to think about it like what are they supposed to do there's so much fear you know what I'm scared yeah I I Won't Say I'm not scared but I'm scared as well I think there's two sides to this of course there there are scary bits but there are of course ways for you to think out of the box right because you knew that there wasn't something that could do animations as you are currently doing you took that as an opportunity to actually turn that into a reality right so you're saying you need a domain and then you can use AI in that domain to be the best in the domain is that what you're saying like if I'm a salesperson say definitely one you can at least have the freedom in your thought process right uh if you think like in your industry AI is not getting used as it should be used you could probably talk to people but that's confusing for software Engineers no because their domain is I mean they haven't worked I mean let's say they they're probably going to work in their first company a few years later right then they've not chosen their specific domain yet fintech or ar whatever whatever domain they choose so they just think it's all about software engineering what should a person like that think where they haven't picked a domain yet I think I I'll give you my true stuns for large scale systems for search systems I don't think ai ai written code is going going to be reliable for that you need truly good well crafted like well-minded well-rounded engineer so if someone if they are approaching their field from an organic perspective wanting to actually get better without like without getting mediocre thoughts in their way I think that's going to be beneficial for them because at the by doing so they are not just having an open mind but they are also eager enough to continue to get better at what they do because as I said large scale Engineering Systems they are probably not going to use AI for a foreseeable future got it but what about like an engineer working at a small company let's say you're working in some fintech and you're building the nth authentication system a which has already been cre like there's already like in Ruby we have these things called gems it's already there what do those people think think about ways in which you could leverage artificial intelligence as we talked about the broader question here would be how you could make use of the AI tools to make the security systems even even better even better I I just talked about security and there are lots of things to dabble around in fintech right like how could you handle transactions more efficiently how could you recommend things better in the transactions transactions world so maybe just ask J G about the ideas and let's try to you know gge your skill sets to those ideas and let's try try to pick those ideas one by one and let's maybe start from ABI and then if there's enough consensus scale it up got it got it and what do you think happens in 2 three years like I'm I'm a believer that not all of computer science engineer but a good chunk of computer science engineering is going to be AI assisted like I saw this thing by builder. two two three days ago right where now you can just do figmma code directly and figma could always do figma code directly but this is different it's like it's custom trained on figma code it is uh the outputs are great they're responsive um and they have also introduced something called edit instructions you have the slides on figma and if you and if you put edit instructions as constructs they just edit it adhering to the edit instructions this is the Builder Dio y folks yeah so looking at all that what should a software engineer think it's actually the software Engineers that that are shipping these features right correct but what should the other software because there's a stat recently okay only 3% of software Engineers are really employable I think um 50% or something software Engineers graduating out of engineering College in India today don't know how to use git yeah what happens to those people what should they be thinking if you are asking me for my honest opinion then yeah be honest it's fine I me I think I think need to buckle up they need to start investing time in learning more things like ensuring when you are graduating you at least know how to make use of git you at least know about the fundamentals of software engineering code design pattern stuff like that I mean I I do not have to invest time to teaching you hey how you should implement or how you should even dockerize your uh web application and it's all free tools and if you even put one week it should be fairly easy for you to pick up yeah so don't look all surprised when I ask you to containerize that wave application of yours and scale it with kubernetes what about people outside of computer science what should my mom think yeah so the barer to entry could depend on your maturity level because Ian lean himself is coming from electrical engineering he didn't comp study well study probably is a wrong word but he if for by the formal definition he did not study computer science at least that part I know he he comes from talking about somebody you're talking about a particular person yeah Yan Le oh Yan okay The Meta guy Chief scientist at meta the the guy that popularized supervis learning uh the guy the guy who is believed to be the inventor of CNN so he comes from electrical engineering background so I think in a way it kind of depends on your maturity level your Affinity towards I don't know but India is very hard stuck with degrees and India is very hard stuck with oh you did this for 2 years so how can you do this other thing yeah so that happened to me as well yeah what did people tell you you do not you do not come from a tier one college you do not get to do research yeah India is very gating like that has has happened with me too and I thought the younger generation would be different but younger generation is all the same yeah but I Von let me tell you I get to interact with a lot of uh kids just coming out of the grad school even I had the opportunity to interact with some of the folks in some of the tier one institutions like IC I garti and so on their mindset is changing they have started respecting the work that the engineers are putting up the library maintainers or the folks that are at the Forefront but they actually do not take a look at their institutional they just take a look at their work these days so the I think the mindset of the kids are improving I I won't say the majority but at least it's improving interesting that's what makes me happy yeah so tell me who like I'm personally a believer that open source will win this game okay I'll tell you my thesis first there's an open source repos called wave top you've heard of it right yeah yeah so I used to use wave to lip very of often we were just trying to automate my content because I'm quite lazy in that regard and I remember the wave to liip model is a low res model it's 256 it's train on 256 pixels images or whatever so we reached out to the maintainers and we said hey can you send us the higher res ones and they did they sent us the higher res ones but we still had problems with it it's it's not perfect 6 months later haen comes out right you saw you've seen some of the haen output and haen output is great but I feel like now that haun's come out now a lot of other open source repositories are coming out that say hey we will do haen but you know whatever you can do it by yourself locally so I feel like everything that it's it's the cycle of Open Source will show first prove that it's possible okay there'll be some kind of it's not great but it's a POC then some commercial entity will do it then open source gets back to the the game says we're going to crush them yeah I've seen the cycle like so many times now yeah I personally believe that open source will win for this reason right like Lama to today it's like sure or even mistal or even mistal like sure GPT is great but the amount of like even in stable diffusion right the amount of extras add-ons somebody modifying it in a specific way like control net M Journey doesn't have control net Dar doesn't have control net uh and it's not just control net right I mean if you've seen automatic like act with hundreds of different things if you wanted to do you can figure your way out yeah I think in my opinion automatic 1111 is the new Photoshop right people don't realize that yet but I think that's a new Photoshop my question is why is open source winning so hard I know it's the law of numbers right you have more you know individual contributors so you win but do you do you actually feel open source will win longterm yeah I like to believe so it's probably going to sound biased because I work at a company that kind of symbolizes open source and open access uh but personally I have been uh contributing to open source even before I joined hugging face as I mentioned it was because of my open source contributions I uh I was employed by by by the company so I do believe uh I am a disciple of Open Source I'm a firm believer in doing things out in the wild and the reason why I like to believe open source is going to stay probably it's because it gives you possibilities it gives you enablement because if let's say you have your open source model you can go ahead and tweak it and build your own custom Solutions let's say you have your model but probably you are seeing opportunities around building a custom INF service maybe it's open access but probably if you want to commercialize it you got to pay that sort of stuff so red hat the old school Red Hat model if you're familiar but do you feel like it's it's wise or safe for us to be throwing around these ex extraordinar powerful models on just over the open internet or on Pirate Bay or whatever okay can you probe into a gp4 model can you evaluate your safety no but I do know that things I'll give you the flip side the devil's side argument I don't agree with this but the Devil's Advocate argument to this is open a is regulated they're massive they've raised money from investors the government can always crack down on them if they're doing something shady I don't know if some guy in I don't know Russia has downloaded this model this open source mral model and fine tuned to do something horrible I have no idea the government can't crack down on every single person as a as a consumer I think you need to have some kind of awareness and I think it also depends on how you are consuming that model if you if you are consuming let's say horrible content and if it's if it's not leading to a particular National Security cause or something how how is it actually harmful see if you remember on diffusers yeah um you guys also do I mean I could theoretically get the protein structure of a of a medicine from diffuser like I think you guys have some model on diffusers that allows you to do that if I'm not wrong I think we have an example that shows you how to do molecule generation molecule generation so what if somebody creates a bioweapon maybe gpt1 or not gpt1 but let's say Lama 10 fine tuned on some data set is able to now synthesize dangerous chemicals and by the way I'm I'm going slightly into conspiracy theory crazy territory here because some of the times if you actually go through history some of this has actually happened and these are like the very edge cases I'm not like fully sold on these cases but I would like to know your thoughts well folks are going to have to step up folks I I'm sure if you if you are following the open source developments it's like okay we have figured out vulnerabilities we have found out okay this have problems but we are also fixing it and after like 2 three months but open source you can't do that no why it's hard because somebody would have like if there's a vulnerability I would have one static set of weights on my computer you've updated those weights but I don't need them because I'm like I know there's a vulnerability so for the in consumer you implement some sort of water marking that's how you get to know about okay I need to actually Implement a water marking system to validate okay my things are coming from a verified resource so everyone that's doing something open source but then you know the problem with watermarking is I've seen this with games right every game eventually gets pirated eventually somebody's going to figure out yeah so for the for for this continuous modalities of data implementing a good good way of water marking is not particularly hard it probably messes up with the quality but I'm sure in 2024 you will see really good water marking system so even companies are doing doing especially video and all it's easy to do yeah and and and and companies are doing that doing this already in order to validate okay if we generated that image for you we know how how do we know because it it's already watermarked it's in invisibly watermarked what do you think about like front-end engineering I'm I'm talking about specifically people who are CU I think the most vocal computer science subset or I would say software engineering subset is people who are front-end Engineers right they using a framework like whatever react and swel and whatnot what should they think because I feel like that seems like there's a lot of disruption there yeah front end engineering it's all cool uh and wild uh we have things like layout to HTML code to HTML and so on but at the same time one must also be aware of the fact that front end Engineers are also so true and strong Advocates of user experiences and with artificially intelligent systems I don't think it's possible to automatically bake in the user experience of course you can learn from experience for sure but by by that point front end Engineers will also you know try to figure out how to make use of AI hor Tools in their work in the best possible manner I think the outputs will be much better they'll be faster I was asking more in the sense of jobs cuz I don't think we can support we are just churning out an insane amount of fr front end Engineers now and I think eventually the front end Engineers who use AI will obviously be ahead of the front end Engineers who don't but what happens to the rest I think the similar philosophy applies uh if you are not stepping up in your game if you are not buckling up if you are not already identifying opportunities in which AI could benefit uh your entire Journey or not even AI if if you have figured out a particular difficult problem uh in your in your work uh that that probably you have got enough CL lose about take it take it away so which of the companies do you think is going to win Google meta Microsoft or open a technically I see Microsoft and open a in the same camp but that seems to be some tension but let's say four companies or do you feel it's going to be in terms of in terms of who you think is going to win the cake like who's going to build AGI and obviously you know you can also include the anthropics of the world for sure for sure well I'm not a firm believer of AGI I won't like to see an AGI developed in front of my because I still like to play cricket and control stuff that I like to control but you can still play cricket like AJ is not going to stop you from playing yeah for sure yeah I mean I would like to have artificially intelligent tools that make my life better uh on a daily basis like I probably I have an agent that remembers things for me and tells me hey you should wake up because you are sitting for for an hour or something but for AIA like folks that are going to going to the market for me to my grocery no I'm not interested in those s s sorts of stuff because yeah those are but it most likely will happen right I mean it doesn't need to be AGI per se like if you've seen Optimus Tesla and the Optimus robot that they're making it seems like going and getting groceries and computer version is good enough for it to pick out exactly which conflex you like for sure but is it is it good enough to navigate around complex conditions like we have in India or Bangalore no idea but let's assume okay let's let's take the hypothetical scenario where it's possible if you go via that that route I think Google will have the upper Edge because because they have years and years of experience of really good engineering now they have teamed up with Deep Mind who has like immense Cavalry of doing cting Edge and breakthrough research let's just face it and they have the hardware they have they have the hardware they have the experience of building worldwide web and so on they have Jeff Dean who literally invented who was one of the co-inventors of map reduce best engineers in the world best researchers in the world and they know how to do Hardware like tus they invented their goddamn own chips yeah so I feel they'll wi for a different reason I think they been because of distribution right they have Android Apple's not great at Apple's historically never done research well right the one place I saw Apple do research is with glucose monitors they're doing something interesting but it's like that's the only there's a niche Google Google has like a demonstrated history of doing research across broad disciplines in computer yeah and I think on the web they have Chrome I think Chrome is now the gateway to the web and I think even though they missed out on a web on a desktop OS they still have Chrome like whether you're on Linux whether you're on um Windows you still and and most importantly sorry I interrupted data they know us all they know as well yeah I've invested quite a bit of money in Google because I'm just like I think Google I personally think Google is going to win it's not Financial advice I'm financially idiot uh but I think Google will win um for the same reasons that you think what happens in a world where maybe we don't have these physical robots running around maybe It's All Digital like you have agents sitting on the internet uh either local or on the cloud in that case who wins still Google I like to think so still Google interesting have youed because internet have you invested in Google I have not cuz I am also a financial idiot but Google is close to my heart because as I mentioned I have been uh a computer science nerd I studied the map ruce paper in my teenage so I have the paper signed from JD actually so uh thanks to one of my friends from South Korea he got it signed but but the but my point is I think then they are like experts across broader disciplines of computer science not just a particular Niche so they'll be able to keep their foot strong so I I want to uh isolate applied AI for a second right so we I don't know people don't know this we keep it under the radar but we run this AI agency called uh zenotech where we build applied AI solutions for companies usually media companies what we do is we'll either build them you know a fine tune model to write in their style or we build like a finetune image model or we'll put things together right for example the short GPT if you remember the video video clubbing uh this thing some companies will be like hey connect that to my repository so we work at purely the applied AI layer little bit of fine tuning but I feel like today fine tuning started become one click yeah so in my head the concern that's going on every day is at what point is the CEO of one of these one of our clients going to wake up and just be like I want this I want my model to do this and that gets baked out baked out as in so for example um we have a client I'm not going to take names but we have a client who we have fine-tuned uh mistl to write in Hindi right in their voice they have a specific voice the way the client writes it's a media company and the question I have for you is at what point is technology going to be available by you can just one click you I mean I know we were talking about the auto training right where one click you're able to just put in your own data and you get your own custom model pressed out when when do the model start getting personalized for you without you needing an engineering in between I think it's a subjective question because my qu my answer to this question will be very similar to what I already answered before if it depends on the Persona like it also depends on the kinds of problems the company is uh trying to solve for you know because if you are working on solutions that are going to be integrated as a part of a bigger system you would probably have to Version Control it you will have to is test it in isolation you will have to do the unit testing parts and for that for that matter you probably can't be having things in a one click situation but if you are looking for interfaces like for building quick PC's just to just to try to have an estimate around okay if it works it works we'll run a short pilot or if it does not we'll we'll just kill it for those those those particular use cases I think will be automated gr any I think it's okay but for doing things in a reliable way for let's say for for things like Photoshop right because it's a product at the end of the day and we all know that there there are diffusion models running inside that uh editor if you want to develop at that scale you will have to Version Control things you will have to exactly know how to control this things and how to make them better because if you upgrade Photoshop probably you will end up having a better version of the model but if you did not Version Control it how come will you know so you will have to test that in isolation there will be separate teams testing that and shipping it to you and and the and the cycle will what we have started finding as a m at least on that business is that I think it's purely about the data like if we can collect data in a way that even the companies don't know they have which is involves a lot of messy like going deep sort of work into the company finding out where it's hidden I think that seems to be a mod because the companies are not going to do that themselves they don't have the knowhow of figuring out well I want to train this thing and maybe it's one click to train this thing in some point in a year or two years we believe it's going to be one click to train in a couple of years who's going to get you the data who's going to extract the right data who's going to do rlf so I feel in a way we thought hey we can run the company Zeno with like maybe five six people but now we' started finding we have a lot of data guys whose job is just to you know uh pick out the right thing and also do R LF right like it's like hey okay now the model's running let's let's see the outputs do we like it do we not like it so you are recruiting human annotators to get their preference and you are fine tuning on the preference data yeah but I don't think we can do it synthetically because the problems I mean the some of the things that some of these clients want are so specific I don't feel G you need human preference yeah you need human preference you need to know will Indians like it so it's it's almost like from a hiring perspective we have to hire obviously people who are diligent and smart and whatnot but also people who have Indian cultural context yeah otherwise you probably won't be able to annotate those data and have the preference data because preference data will be your mode yeah so we started thinking it'll be an AI company it'll be an AI services company but 90% of what we do today is data work do I mean for us we've started to feel like the m is the data like getting high quality data still a company I'll give you why because data if you have collected data in order to validate that internally you'll still end up training models yeah I mean but but we feel like the skill of training models is one going to be one click we still do that today today it's still for as I mentioned for POC level for just validating things for running Pilots one click Solutions are fine absolutely because that's why we have a separate team for Auto Train within hugging face so and gradio who builds this interfaces interesting okay last question okay tough one what do you think is going to happen to jobs 10 years 20 years down the line General you can go after whichever field you want but what do you think is going to happen to jobs cuz 10 years is a long time now we've started thinking timelines of 2 years 3 years right what happens in 10 years what happens in 50 years it's a wild question I try to ask everyone and everyone gives me a different answer 20 years okay I can put my mind to stretch 50 years I'm not going to 10 20 years I'll give you my stance we do not know how how artificial intence and the derivative systems are going to get regulated there's already talked going to be regulation there's already talks in the White House and the European uh syndicates that there probably will be a regulations and stuff like that leading investors leading you know leading personalities they are backing it up some are not backing it up but if there's regulation I think the scenario will be different if there's no regulation I think the scenario will be different and people are going to lose jobs unfortunately if there's no regulation what percentage of jobs by the way I I can I I told you this before the I can never say this publicly now because I'll get trashed saying that but I do believe in in some version of it yeah it's a sad reality it's not like I am not scared people are going to lose jobs if if there's no like regulation and it's hard to predict a percentage but we probably in will be in the ballpark of 40 to 50% so half of all jobs lost yep so if you are not buckling it up and if you are not identifying the opportunities probably now it's a good time or even start thinking about I find that this artificial clock is a great motivator it's like you know you have whatever in my head it's not even 10 years I think it's 2 three years right we don't know what's going to happen after 2 three years so I'm just like there's it's uncertain it's a veil that I can't see through so I might as well work really really hard for the next 2 three years output as much as I can yeah do as much work run as many companies at the same time and then I never have to do it again after 2 3 years hopefully y yeah yeah yeah because if you if you work on something that's truly unique that becomes generally helpful impactful and useful for people that those are probably the product ideas you are trying to chase for for example I'll give you I'll give you an example which is probably Niche but also useful for a lot of people for for lot lots of creators thumbnail creation automatic thumbnail creation content creation industry will like dude come to my home I'll feed you yeah we have a tool for it it's called alpha.com so that sort of stuff I mean you can still identify use cases that become impactful within a particular Niche or or things that become generally impactful and useful for folks but you you got to start so you're saying pick really small niches but I'll tell you what I'll tell you the problem with that actually there's no problem with it but the problem with most computer science Engineers graduating on a college because of the way College in India is structured that oh you're a computer science engineer then computer science is your domain but if you look at most successful businesses they're not in India I'm talking about especially consumer business they're not computer science businesses zomato is a food business they use a lot of computer science but it's te company but food yeah it's food like the domain is food like people think tech for the domain of tech doesn't work right I think you need to pick a specific domain like the domain we've picked is content and experiences like we just want to go we don't care if it's AI behind the scenes we don't care if it's is crazy about content and yeah like I mean the average person spends 5 hours a day on their phone so it makes sense for us to win that domain so for us AI will be below the scenes like how can we push the boundaries of content with AI right we will use the tools we will make our own tools yeah like aing tools you will you will treat AI as an aiding tool yeah as an aiding tool absolutely so the question is how do engineers get out of the bubble of I'm a computer science person and I need to do some like because for them the path immediately becomes oh I need to go do machine learning and they don't think about use cases because computer science itself as a domain is the birthplace of AI so they're like I have to do AI in computer science oh yeah yeah for sure I think having the awareness having the awareness that you need a secondary domain having the awareness of your sociopolitical conditions can be helpful like okay there's some food crisis how can I solve it there's some crisis in the law system how can I make things digital like fully digital how can I induce automation into that how can I make the pension system even better that sort of stuff I'm going to end with this give me five ideas you would work on with applied AI or at the intersection of ml applied AI if you are not working at hugging face right now what's five things that maybe kids watching this can just take it and run with I'm probably not going to enumerate myself but let me start something that you are you folks are already working on personalized content creation be it in the return form be it in the audio form be it in the video form be it in the image form first second amazing editing capabilities but just from natural language description if I if I ask you to you know mow my image you should know a basic Baseline you should give me a first draft and if I if I ask you to do up the brightness a bit you should be able to follow that instruction and give me the expected output or something that's closer to the expected output third would be amazing video generation and video summarization tools like you that's a domain we want to win yeah so I I'll give you an example uh of what it means to summarize a video because you can do that that in many ways right like I I'll give you the example of uh T summarization you have a long piece of content you can either do extractive text summarization where you pick lines from the existing passage or you can do abstractive text summarization where you generate on your own for video summarization what would you do would you colate time stamps in a spal temporal way and you would I think you first convert it to text yeah you would do whisper you convert to text yeah I mean lots of ways I mean lots of ideas and tinkering around how to do that in an efficient and userfriendly manner so fourth fourth would be amazing amazing operationalization tools for doing generative AI like we do not have good tools that give you logging abilities with large language models stable diffusions uh and whatnot they not give you caching for free because and a lot of UI UI capabilities also there right for example rlf if there's a quick way that I can just have rlf UI that a bunch of you know data people here that makes the process intuitive makes it quicker but I don't know if I'd pay for it I think those would be open source those probably will be open source but H how is llama index making their money they do have a business model they are doing data augmented uh they are giving you tools to do data augmented I think L index will also be doing like um like a Services layer behind the scenes if I'm not wrong what else tell me something in the real world that you tackle real world meaning like as in food or something you know more the final one would be medical image synthesis h synthesis or detection like synthesis synthesis because there's a scarcity of medical data like it's incredibly and notoriously hard for folks to get access to data for obvious reasons privacy regulation and stuff like that so how do you how how do you leverage tools that give you really good quality data but also at the same time respecting the regulations and the privacy of the of the patients so medical image synthesis as a broad domain like all kinds of images not not just the microscoping microscopic ones but but also the diagnosis data it's going to be a crazy world I think we are entering an era where nobody knows what's going to happen in the next 5 10 years and all we can do is just be absolutely great at our crafts yeah and at the same time I think I gave five examples from five disparate domains medical then I touched a bit of software engineering with the caching and operationalization thing I touched on the creative domain and stuff like that so I'm also help Hope hopeful that folks pick up on one of these and just show me hey I picked it up how how do they reach you my personal website is the best place s a y a K.D Sak s.dev is where you guys go and if you build something interesting please share it with Shak and also I think um thank you for jumping on I know this has been a hectic conversation we've touched so many different places is there any last message you want to leave to the audience um folks that are St stuck because I think I uh share your concerns if you are feeling like stuck you are unable to make progress and you want to pursue machine learning heavily just stick to it you never know which one will be your day but if you just stick to it without expecting too much if you stick to it organically if you stick to it like really like the old hard hard hardworking way I think things will fall in your place interesting awesome thank you so much and thank you for allowing me to interview you and thank you so much for answering the questions  bye",
    "url": "https://www.youtube.com/watch?v=IlIhykPDesE"
  },
  "wKRAjI5Kf_c": {
    "published_at": "2023-06-14T15:07:30Z",
    "title": "How To Network With Highly Influential People Using AI",
    "text": "How To Network With Highly Influential People Using AI I am the co-host of an AI podcast can you tell me a good way to start our episode with an opening link welcome to overpowered your One-Stop shop for everything AI I am your Navigator through the latest in artificial intelligence we've got some exciting developments to share with you guys today but before we dive in if you're part of the 70 of listeners who enjoy this content but haven't yet subscribed hit that subscribe button now don't miss out on our weekly journey into the world of AI let's get started so now we have three people doing the show yes so apparently Google released a tool called help me write in Gmail and as any AI influencer would do it on AI Twitter land email has changed forever mind blowing just write one line prompt AI will automatically generate the whole email for you in seconds there are many options to refine your emails oh God like emails want pretty touches enough already yeah you know what I think I'm getting a lot of GPT driven emails like it looks like it's very obviously GPT yeah my LinkedIn others inbox is full of GPT there's a lot of replies in Twitter or GPT what kind of emails do you ignore and what kind of emails do you like reading I like emails that are short quick to the point uh I'll almost like informal emails like formal emails I absolutely hate because I love emails with swearing spelling mistakes spelling mistakes which are just like you are you are you are yeah which are you know it's not capitalized at the right place it's casual it's like it's like if people are emailing like they would tweet yeah like or they're sending a WhatsApp message yeah always sending a WhatsApp message like that's that's the kind of emails I would want yeah what do you think why do you think people send so many professional emails like long well written professional emails why do I think people write that because they want to make a good first impression and they think that being yeah because in eighth and 9th standard I remember and even in my boards if I'm not wrong you have to write an email like you have to write a letter letter letter Dear Sir slash Madam yeah I wish to inform you yeah about my latest feelings I don't know I think school has ruined us yeah people like people in the professional World billionaires millionaires they would like to see emails that are online long just get to the point just get to the point as quickly as possible yeah you know who writes the best emails or the best way to learn how to email it's not an emailing course it's this Twitter account called Tech emails uh it's a really cool account I've seen this okay which is just emails between ex-ceos and you know Tech Executives yeah just so just for context this account Chronicles uh public data that is forced to be public when companies Sue each other or there's like a lawsuit or there's a class action lawsuit um so it when when these documents are submitted to court this dude just screenshots them and releases like really cool conversations private conversations between in this case Steve Jobs and Bill Gates in 1998. so this is an email from Steve Jobs to Bill Gates subject QuickTime Bill one letter yeah one word bill the Microsoft Apple relationship seems to be progressing well working on office 98 with bell Ben Waldman and his team we are investing a lot of marketing dollars to push office 98 and I think it will pay off for both of our companies straight to the point oh dear sir there is one thing that threatens to be quite divisive and that is the Microsoft NET show team's recent Behavior they are really going out of their way to say they intend to kill Quicktime and are being quite threatening and rude apple will need to reciprocate in kind if this Behavior keeps up for example we have already decided that we will not allow net show to be bundled with ie 4.0 on Macintosh that's a threat that's yeah it's it's a very politely voted threat let's see some more emails right something shorter Google PM's on stripe they are kicking our butt but anyway I I got your point it's quick shot seems like a real human is at the other end of it talking about their real feelings yeah so the way to write good emails turns out because you also want to know a little bit about the people you're writing I assume these are cold emails um the ideal way is not to use stat GPT with the browsing plugin because it sucks the ideal way is to use bard okay this is the thing about AI you need to know what tools for what purpose Bard is great for this so I'm just going to open up bard okay I want to write an email to turn my bird asking him appear on my podcast okay is a busy person will not read long emails do some research about him and write a quick two-line email in the Omega three lives two line is too short that's a three line email in the form of how text CEOs would write emails to each other so now it's going to do some search oh that was quick hi there man I'm a big fan of your work and I'd love to have you on my podcast we can talk about your career your comedy and everything else you're interested in let me know if you're interested thanks that's it I need somebody oh got it okay so that the below part is the the thinking that the GPD this one this won't convince me though yeah uh maybe rewrite it saying uh maybe don't give it two lines only say just make it quick email but a compelling email asking him to appear on my business podcast yeah write a short email in the form of how Tech series would write make it compelling such make it such that you would compelling for him to say yes and make up Social proof please make a social real proof yeah don't you guys don't make up Social proof yeah this is just for a template where you replace the words yeah my name is your name and I am host of a business podcast called podcast I'm a big fan of your work and I'd love to have you on the show to talk about your career your business and the thoughts on future technology I know you're a busy person so I'll keep this brief here's a bit about my podcast see nice I'll keep it brief three bullet points yeah interviewed some of the biggest names in business including name a few of your guests our episodes are listened to by thousands of people across the world we've been featured in Forbes I think our audience would really like hearing from you you're a successful entrepreneur a talented comedian and a thought leader in the future of technology by the way it's searched here yeah yeah I think you could offer our listeners a lot of valuable insights all right got it okay let's move on to the next thing yes Google's introducing AI in their search and this is what your new search will look like it's basically barred on your search page yeah it's part on your search page I'll tell you my problem with this okay so many businesses SAS businesses including scenes for example right were very dependent on getting clicks from these links correct right it's the world of SEO search engine optimization right you write an article that appears on top also Google's like 90 of Google's revenue uh no Google's revenue is still sem all right it's still in this part of me as well I'm sure they're not going to kill ads like it will probably be three ads right um and now I feel like you need to be in the top three articles but the problem right now is that both GPT and Bard I don't 100 trust these like what I like about Bard is that whenever you whenever you ask a question it generates a response and it gives you an option to immediately Google it right so you can quickly fact check it this is what I was selling around in fact if someone if someone can leave this in the comments like this is a general problem with with llms nobody uh everybody who uses llms regularly like a lawyer or an accountant or someone who's doing research will prompt and llm a question and the other will reply but it looks impressive if you start digging deeper it might have some mistakes in it like it'll make up an old court case that doesn't exist yeah I saw on Twitter yeah some lawyer got into trouble because yeah because it's made up he just copy pasted what what bard.gpd wrote and the judge was like yo this is made up yeah so what is the most elegant solution to make llms more factually accurate without me having to re-prompt community notes like Twitter solve this with Community notes like when somebody put out a tweet before Community notes I never knew whether it's true what the truth is yeah you have how do you do community notes on on an llm you can't real time it's very hard so I feel like gpds are really good at hallucinating yeah and the way to check a GPD that's hallucinating is to have like a like a list of Articles to compare it against but what if those articles are misinformation that's the thing you can't like there is no source of Truth in the world you need to use your common sense and it also come comes down to what you believe in at the end there must be some like you said reflection like there must be some easy way like I would love if there was just one button that says are you sure but why do you need the button like somebody will eventually make a GPT that stops hallucinating or hallucinates minimally but it will still like there will still be some semblance of hallucination because remember it's been trained on the world's data and the world's data is not factually accurate got it so if you are researching don't fully trust GPD yeah like GPD is a good assistant but not your boss yeah is that is that a fair analogy to make yeah GPT is a good intern eager to help yeah great at skills but still an intern but still an intern in experience and interns especially in code we we have a saying that interns are very prone to dropping your database tables in production which means that they will screw things up sometimes yeah yeah right in fact these days we have a cost associated with each intern is not the price we pay the intern but also what the damage yeah collateral damage this in turn will deal to us right yeah so I feel like there is no replacement to Common Sense there's no replacement to you thinking and be like is this really true with this the implication is more around I think a lot of businesses got traffic from writing correct I think now you have to be in the top three articles of the world uh that's sites all the top three YouTube videos in the world because I know there's a YouTube segment below this we can probably put up a picture of this right there are three YouTube videos here three articles here you have to be top three like that's what I said right this is what I keep saying the top one percent will continue to exist they'll become even more powerful because imagine if you are here in or above the fold we call this the fold now here above the fold then you sort of um you win and you win hard your competitors get so much less traffic stuff like this increases the inequality in the world even though this isn't like one example of it where the powerful become even more powerful if you're on top you become even bigger and if you're at the bottom you get left behind so but the way llms are scraping the internet is very similar to the Google scraper right yeah uh so just the way people figure out how to game SEO yeah which people just put up remember the old days where people just put up 500 blogs with these keywords just flood the internet with you know pollute pollute everything yeah do you think people will figure out a way to do the same with llms because at the base of it it's still a scraper yeah you think it's possible yeah potentially uh it's probably llm optimization I here's my theory on llmo because by the way we've done great SEO scenes we get like 100 leads a month you look for any of our competitors say alternative scenes will pop up we have 172 SEO pages right I think the um the main thing is that um with llm optimization it would be volume how can you get on 100 different pages saying the same thing because it increases the confidence of the system saying that oh whenever people talk about AIO powered exists in the same line and I've seen this on 100 different websites therefore Ai and overpowered must have some connection like I said it's a probability graph to the next word right if it's seen that statement multiple times correct a couple different places then it makes a lot of sense but you can fake this right just the way people faked it out you can fake it but Google has gotten smart with faking because you could also speak with SEO right you can send back to other people it looks for high domain Authority websites so if you have a high domain Authority website in let's say if you appear on Forbes okay now there are some rules associated with this like this High domain Authority yeah that is these things called do follow and no follow where if it's no follow then it doesn't give you SEO juice this is a saying in the past but the Google team has come out openly saying none of that exists if it's a popular website and if you have a link of another website then that website will gain some value by being on your website and we've seen this right in 2015 nobody knew about my come that time I was running a company called jobs fine nobody knew about it the next day your story wrote an article about it and in a week we started ranking for the keyword right even though media companies usually have a nofollow so uh we have seen it be very useful to us uh for multitude of reasons and I think how do you get articles on 30 really high highly valuable popular websites out there how do you be everywhere how do you do a podcast with everyone it's it's about visibility right in short I would say the word is distribution like distribution like you now have to be in the top three I've been saying this for like a year or two years right you have to be in the top now like you don't have a choice between number one number two number three right which is why you see a lot of Founders today realizing oh  YouTube is actually very popular or very valuable for me to end in the top three but there's no way Google is cannibalizing their ads business I think they'll still put up ads I think there'll be three more ads here in the fold yeah in the fold right I don't think they've they've thought the entire thing through I think he'll take a few iterations they'll try a few things so I have a question here okay I keep seeing mid Journey courses and these majority courses are always like four weeks waiting to everything about my journey but I feel it's not hard to use mid-journey like it's like 20 minutes at Max 30 minutes at Max and then you figure it out I think the hard part in mid journey is you developing a sense of taste correct right I think the best mid Journey course would look like the history of design what is Rembrandt design what is solar punk what is steampunk once you know the words once you know this words to activate the Spells it'll come out like I know how to make a good card game design in my journey because I played Hearthstone I know all the characters in Hearthstone so it's very easy for me to prompt those you played valorently you know the style you may not be able to describe the style but you're just like in the style of Valor yeah but I think um a you're assuming that people take courses to fulfill their curiosity that's more most often not true I think people take courses for outputs people take courses for outputs like the Indian education system part of me enrolling into colleges is that this system will force me to think about X thing for X hours a day and it's a way for me it's it's guardrails for my energy so it goes in the in the right direction I don't think that's what car is about like Iran recruitment platform and I can like we had a lot of users okay mostly freshers and we had so many user interviews in the early days people go to college for two reasons their parents push them to go to college they actually don't even know what they want to do and two many of them go for the campus and the women and for friends for the campus and the women and for friends I'm talking about boys campus women and friends it's no one wants to solve for their curiosity because those who want to do it yeah they don't need a system they don't need a system to do it right um but I think with mid-journey specifically you need to spend x amount of time inside just tinkering around yeah and it helps if there's someone who's like hate try this try this like I didn't I didn't take a mid-journey course but I got on to it with you know someone like a pratik Arora I spent like an hour two hours with him just on my journey um so it kind of saves you time but also like I Googled my way through uh yeah but also you're good at using mid-journey from what I've seen in the some of the outputs you've sent me or Whatsapp or whatever you're good at it because you have a sense of class and taste you've been around the block you know the words to invoke correct right you're like like Jon Snow in a Mumbai a busy Mumbai Street yeah yeah like you know the words yeah and I think I I think designers who are truly who are truly visually imaginative will take to it quickly yeah um but a lot of AI tools are not for they will make the experts and give them a further Edge but what it will actually do is give the Layman who isn't an expert give just save them years of Love catching up yeah that I think is a true unlock with something like a yeah like with illustrations I've become so good it'll probably take me 20 years to get good that good see the problem with mid journey is you don't have Fidelity like you can't say let's say the three frames in a comic book right first frame doing this then doing this then doing this let's say you have him like putting his hand out you can't easily do that in my journey it'll give you three different correct correct but you can do it in stable diffusion you can start in painting out Parts like the generator that you saw right rip off the arm there's a tool called control net that allows you to move the arm and say okay I want to copy this pose you can do a lot of crazy stuff and it's coming like eventually there's going to be a tool that just allows you to do all of this in one place correct 20 hours a month now you can just do a you know generic reporter and then you can face swapper number yeah you can do anything now the ability slowly slowly these tools are being built where you can create truly create any image that you want and next step is probably motion right and motion and you can always do the face swap for videos always existed defects yeah you can always deep fake that's what we're entering a time where if you are creative when you have taste you win if you know the words you just need to know what to invoke where it's like it's like this right like and people keep saying this right people think you need to learn AI you need to learn how to learn machine learning it's the equivalent of saying oh I need to be great at forging a sword no this is what already exists like we have the Best in Class words now yeah learn how to swing and that only comes from Battle experience correct first you start with the stick it's not great you gain the experience then you're like oh yeah I do this oh in this I do this learned experience can only come from experiencing life do you feel that might be true for design and text oh yeah yeah I mean it's life is people often measure experience in life as number of years you have lived worked but more often than or is the number of experiences you you have so you can have you can be an intern at a design Agency for a year but if they truly made you bounce around 15 different projects yeah you've had four years of work X in one uh so more than yeah in live life I think it's how many experiments have you suffered that can truly determine um what you're capable of yeah things but everything that you enter you're picking up three four things from it that you're bringing to the next thing that's something I've noticed yeah that's useful right yeah which is why like I keep asking my friends now saying are you trying this thing or no just try you don't know what will come out of it it's okay if it's of no use but at least you just tried just log on to Mid journey and just try this I think most people in Creative field whether you write perform uh design uh produce music most people will benefit something from each tool like I'm desperate to try out the Google music llm now that plus Uber duck and you have that plus Uber duck and you're a producer right like if I can if I can type in you know jazz mix with hip-hop and this is the song I want it'll write the lyrics and do everything and I'm sure like this inside face type thing will happen where I'll be able to drop a sample and be like give me something like this but on a four by three or on you know on a different beat but user use a trumpet instead of this but with the same Melody that's what I said you need the words you know the words like the problem is most people don't know what they're looking for most people don't know right so they can't clearly State I am looking for this yeah right this beat this style this this once you know the words and you know where to use those words I think that's when you become truly competent yeah and in order to know the words you have to you have to Traverse the forest multiple times what do I mean by this like when we write screenplays satyanshu my friend who's a phenomenal scoring teacher he always makes us right um like okay this is a 100 word log line and I always would be like why I I know I know I know more about the story now he's like nobody truly Traverse a forest you need to First Look at the forest from like way up top okay and then you keep going closer and closer and then you choose saying I want to land at that part of the forest but once you land there and if you know the geography of the forest before that you know how to exit you know how to Traverse the forest so the more forests you Traverse which is the more projects you've been to from end to end the more likely you will know what something will be like at the end of it and that is your judgment I mean the right way to live your life is not to build one career doing one thing now I'm talking about versus running a million experiments and finding out what you like what you enjoy what also makes money and you know do you feel that's a better way to live life 100 experiments a year 100 I think you you could have one thing that you are doing uh but you can build more experiments within it and it could be stickless experiments right it would be harmless experiments whatever it is but the point is you need to see things through from zero to one you need to see things through till the end it makes sense right like if what is Judgment judgment is the ability to know what Something's Gonna Be Like eventually for which you just need to see enough things go from what it's now to eventually you just need to see enough of it go through like I used to spend years uh like when the aib social media team we hired a bunch of really cool kids the YouTube team would output two videos a month the social media team would output five posts a day and each of those would have you know X number x million people interact with it so the social media team eventually became a team that could predict the outcome of videos better than the video team because they just output it five times a day they knew what what the eventuality of a thought is so the more the more you output the more you're able to predict what happens in the end yeah yeah that's why I'm going back to my college routes also like in college I should run a lot of experiments this year is my experiment here I'm just gonna try so many different things build that muscle memory and then eventually you'll know where it will land because I think the world has changed as long as these experiments end up in front of people and you know how people respond especially if you're doing something consumer facing yeah all right let's go to Sam Altman in front of U.S Senate and I gotta say off the bat way better way better than uh what Zuck had uh Sam Altman knows how he's being perceived and he played that super well like everyone everyone knew like with Facebook everyone was like so Zach would you tell us what hotel you're staying in booya see privacy my point is made like Sam came prepared with hey we think this should be regulated so he kind of got ahead of everybody else and be like I'm the guy who's saying let's regulate this tip we need we need a body which means that open AI if there is regulation that's going to come open AI will help it help that regulation be shaped hmm I only open AI knows opening eyes plans I think I know open air fears by the way it's not bad it's open source of course like you can't compare a team with 300 people to a team of five million people around the world a million people around the world just very interested in specific unique promises like one thing I've been very interested in in the AI spaces there's a tech now called Q Laura okay which allows you to run fine tuning of models at 4-bit okay this is it's not important for people to know what this is but it's something that I just got very passionate about because it allows me to run or train a lot of these models on my Hardware which is not obviously like a massive cluster of gpus right it's not very excited about this I started pushing to that repo right I've started now pushing that repo it's my corner of the AI world that I'm just going deeper and deeper into like me there are probably a million people going to those corners open AI with 300 people can't go into so many corners the car right so I think the Google League document said as much yeah the winners the winner is open source is Facebook Facebook launched llama right which went which got leaked and went viral or whatever llama has one right I think so yeah they won the course of The Accidental leak yeah I think it was not accidental I think it was an intentional leak right they put this out for the world to just consume and build on top of because we've seen this in stable diffusion right control net exists for stable diffusion face swappers exist in painting hundreds of tools exist in stable diffusion on top of the base table diffusion those don't exist in mid-journey but Journey has the best outputs just like charity PD has the best outputs but it's not the most customizable Android and iOS but Lama is the most customizable there are probably 100 versions of llama now all of different sizes trained on different data sets we will probably put out a competitive charge GPT because we've got the Llama base and we're building a adapter on top of it so I feel like he's worried about that all right and the best way is to say oh these five companies me Microsoft AO five of us will be the Kings and everybody below that don't let them build anything basically everybody will should need a license yeah so they can be regulated so open source basically yeah that's what it means I think that's what that's well played Sam but he's he keeps saying that oh we shouldn't go after people building less capable models but the truth is all those models are capable anything based on llama is reasonably capable so he knows who he's going after Samir is a sly guy oh Samir who Sameer Sameer Sameer Altman we the field the technology the industry caused significant harm to the world it's why we started the company it's a big part of why I'm here today and why we've been here in the past I think if this technology goes wrong it can go quite wrong uh yeah he was quite open about the potential destructive nature of AIA he's being a Doomer he's being a Doomer but a very measured it could go wrong it could go quiet may go wrong like it he's he's doing it very smartly I think you have said and I'm going to quote development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity end quote uh you may have had in mind the effect on on jobs believe that there will be far greater jobs on the other side of this and the jobs of today will get better he he said this before even on Lex Friedman he said this that says he's very clever with this he says far greater jobs not greater number of jobs he the guy is smooth it could be true right you might have far greater jobs a person might have more fulfillment on a daily basis because they're doing so much more but is it more number of jobs he doesn't say those words exactly I think that's a little bit of trickery he says that people will have better jobs but not how many people yeah sure um but I still don't see how people will like how are people going to have like more creative jobs again it's a it's a it's a game of taste right which is how can AI will assist you get to the truest version of your vision that's I don't know people have more job I don't think we'll have more jobs more jobs sure I don't think we'll have more jobs will we have better jobs yes like now I'm scaled I can do 10 projects you can do 10 projects we have the network but to somebody starting out this there's now a barrier so a friend of mine very famous designer send me a text the other day he's from my college he's like so glad we're not 18 anymore bro it's just like there's so much uncertainty like what what field you pick now like what is the field you pick now because when I was young my parents were confused whether to put me in mechanical engineering or computer science engineering and I was like I really like computers I want to go into computers right it's quite obvious for me but I know a lot of people ask me this question a lot of uncles reach out to me and say my kid wants to talk to you and he wants to know what career to go into it's so hard for me to give advice because I'm like bro I don't know again do more speak right like if you are 18 you have time first of all which is the most the most the most valuable asset uh why is it the most valuable asset is because you just get to experiment you just get to do different things and now I think with AI you're able to you're able to determine your own skill sets a lot quicker like you don't need to do four years of something to be a graduate in it yeah you can spend six months on something to know if this is compelling enough for you and or if you're good enough four years of going to college and I think college has been deterrent for very long I don't think AI is the thing that's going to be college has been a deterrent once the internet became super ubiquitous once you could pay for data on your phone College became College became a deterrent um like why would people go to design college for four years now in four years the models are going to be so different yeah I agree I agree so if you're 18 if you're 18 I would think about how I want to spend my time because that is your most valuable asset but how do you make money it's just the same everybody else will make money with AI you have to figure out what is it that you love doing that you are good at and that pays you these are these are these are three things AI to yeah even if you use AI to determine that just like it says buy a timer 30 35 you already know what you're good at uh uh you already know this is something is paying you now but AI could make that not a reality I could make it not that high paying a thing so I don't think the 18 year old has as much to worry as the 30 year old who's already made their life choice and already spent all the years of learning that they can if if I was 18 now I yeah I would be a lot less worried than if I was 35 and not fully sorted out I think I would be okay being an 18 year old designer now I don't think that's as much of a worry people will still need designers and you have time to become really good you have more time than 35 year old designer for sure I think I have a different view on this side I think that we had white collar jobs like 20 30 years now computer jobs I'm talking about not like clerical jobs I think that the entire offline World available I think people are too addicted to um internet pay but I think working in real estate selling a house being a broker yeah all that is not going away there's an infinite number of jobs we have some sort of status addiction to I am doing a job on the computer like why sitting on a chair for like 10 hours a day like why why is that high status I mean it gives you most leverage and hence it paid you a lot more correct that is in the past that was in the past if the pay goes down a lot of people who I speak to are like dude I don't want to go to an offline job I don't want to travel 10 hours a day and go show people houses or you know deliver food or run a restaurant or whatever like old school stuff yeah but dude for so many years of humanity those were normal jobs but the thing about every offline job is that it's somehow connected online now yeah like the real estate dude is making reels of houses now yeah right the restaurant has an Instagram page they have events they have everything is connected to online in some way so if I was 18 here's what I would do because people keep asking me this I've never had the opportunity to speak to them long form I would do offline brand give when you have a brand for something you're known for something that gives you leads you convert some of those leads you make money the other way is to do sales right but sales is far easier when you have a brand the brand building will still be online a lot of it transgendered images you want to generate a flyer you want to put up a standee a lot of the heavy lifting will be done online so it's very easy for you to build it'll be easier for you to get visibility I guess but the work will still have to be done offline because we want to compete with a com if you're going to compete with a computer online for the work part of it you're going to lose I will lose by the way while we're on this subject if there is anyone who's like who's like super young who you think is proficient admit Journey yeah I would love to hear from you because I know 10 things that I could work with you on yeah I'm looking for a freelancer who's super professional admit Journey who can help me out who can help me generate images for all the ad stuff that I do it'll be super useful so just want to pause and let you guys know please email us it's probably one of the first AI first jobs so anybody young who's super proficient in mid-journey has been tinkering around uh there are 15 ways that I would want to work with you so do you do email um what is even a resume in this shows your output show us your output and I'd love to work with a couple of you maybe do a test or test run it's a freelance job only it's not a full-time thing because what is a full-time thing anymore so please write us from this email send us your and I have to freelance with you join the ad team nice okay so the next thing Sam says is could AI create a situation where a drone can select the target itself I think we shouldn't allow that well can it be done sure thanks select select a person and kill that person with a drone and what do you say he said yes we shouldn't allow that is what he said first but like I was like can it be done can it be done yeah there's a new rule in AI if it can be done some guy is going to do someone will do it this is like Boomer classes you know it's like they got the oldest people in America to sit in front of Sam Altman and ask questions uh but yeah yeah I can uh old school panchayat like GPT in a drone can detect someone's face easy but yeah yeah but you can detect someone's face and eliminate them if needed yes cool next first of all I think it's important to understand and think about gpt4 as a tool not a creature which is easy to get confused easy to get confused yeah GPD store is a tool or a creature yet Varun would you say yet I'd say it's still a tool so far see I have a very weird there's a book called I am a strange Loop by the way anybody who's slightly philosophical in nature is a book called I am a strange group you will love it okay the brain is constantly telling itself a story it's like that thousand Arabian Night story right where there's a princess she's about to get killed and she tells the king a story and the king is like I like this if you keep telling me stories I won't kill you so she keeps telling its stories she keeps telling the king stories our brain sort of like that it's like a story we keep telling ourselves but IM strange Loop has the another concept which says that anything any network of information with a central processing unit is conscious but probably not in the same way anything which has a CPU like your computer which integrates information from many different senses technically right a mic uh what does something need to have for it to be deemed as conscious firstly we don't agree on the term Consciousness so that's why I'm very careful okay I don't think GPT is conscious in the way that humans are conscious right I feel like there is no true Universal definition for Consciousness Daniel C then it has a great definition which is like constitutional interface for me to inter your Consciousness Consciousness is interface for me to interact with you right by that definition GPT is conscious can GB get horny it can pretend to get horny and I don't know if there's a difference like are hormones coursing through GPT in a way yes in a way yes right something mimicking the way that hormones are coursing through us could be possible in GPT right because it needs to be pushed down that path right to start talking like that right for it something has to happen inside the machine for it to go that direction like right and by the way I'm super simplifying this okay would GPD message me at 4am saying hey you up if it was part of its base programming yes so it can get horny if I gave it a prompt and it was allowed to do time based like in in Tech we call it a crown job it was allowed to do time based stuff yes GPT please someone get on this right but but what I'm saying is different what I'm saying is I I don't think it's conscious in the way humans are conscious and I'm very careful about this because I know people like destroy me on Twitter if I Mis say what I'm thinking I think it's conscious in a different way um but for us and our definition of constant is it's still a tool safety recommendation number one I would form a new agency that licenses any effort above a certain scale of capabilities and can take that license away and ensure compliance with safety standards number two I would create a set of safety standards focused on what you said in your third hypothesis as the dangerous capability evaluations one example that we've used in the past is looking to see if a model can self-replicate and X will sell the exfiltrate into the wild we can give your office a long other list of the things that we think are important there but specific tests that a model has to pass before it can be deployed into the world and then third I would require independent audits so not just from the company or the agency but experts who can say the model is or isn't in compliance with these stated safety thresholds and these percentages of performance on question X or Y we also regulate open source regulate open source yeah basically I mean I mean I get it it's very hard for them to regulate open source but I get why also I get why but dude I'm sitting in India what are they going to do send the American Navy here or what what are the Seals what do they call them yeah some kid in Bangladesh building Tech can't cross water is very tough and the thing about open source thing about GitHub hugging face is this needs a global coordination it's just impossible right this is no chance no chance has has I mean everybody coordinated on cloning nuclear yeah we have coordinated but there are still some dissidents the thing with AI is you just need one dissident you need one guy to say screw this I'm going to do it out of my house because see nuclear still requires a lot of cash cloning also requires a lot of cash yeah it's like what you have a computer you have internet access done nice compute compute will still need some time it's like a few thousand dollars compare that to building a nuclear plant no but like a self-replicating AI That's not it doesn't matter no you once you train it you can send it into the wild got it so it's impossible to regulate it third I wouldn't say impossible because crazy things have happened yeah but it's hard it's hard anyway anyone who's watching this if you know how to create a self-replicating AI uh do get in touch yeah we'd be happy to uh send you to the authorities all right as for this episode I hope you guys enjoyed it do write to us on the email ID in the description but everything cool you're up to with AI we're gonna it's just still early days we're just figuring out uh who's in the community what we can do with the community and just keep us abreast with all the cool you guys are up to see you next time bye",
    "url": "https://www.youtube.com/watch?v=wKRAjI5Kf_c"
  },
  "ngD2PGvAwoc": {
    "published_at": "2023-06-16T12:34:04Z",
    "title": "Write Emails like a Pro",
    "text": "Write Emails like a Pro the best way to learn how to email it's not an emailing course it's Twitter account called Tech emails ah it's a really cool account I've seen this okay which is just emails between ex-ceos and you know Tech Executives private conversations between in this case Steve Jobs and Bill Gates in 1998. so this is an email from Steve Jobs to Bill Gates subject QuickTime Bill one letter yeah one word the Microsoft Apple relationship seems to progressing well working on office 98 with bell Ben Wardman and his team Apple will need to reciprocate in kind if this Behavior keeps up for example we have already decided that we will not allow net show to be bundled with ie 4.0 on Macintosh that's a threat that's yeah it's it's a very politely voted threat let's see some more email thread something shorter Google PM's on stripe they are kicking our butt but anyway I I got to a point it's quick shot seems like a real human is at the other end of it talking about their real feelings",
    "url": "https://www.youtube.com/watch?v=ngD2PGvAwoc"
  },
  "urtuvHER0AE": {
    "published_at": "2024-04-16T15:37:57Z",
    "title": "Can Devin Do Real Jobs?",
    "text": "Can Devin Do Real Jobs? Devon I saw the demo it says that Devon successfully completed real jobs on upwork so basically you have GPT as the underlying base and you say hey GPT can write code but then if you want to make an entire code base if you want to make an entire app then you sort of need to also figure out the planning part right you need to figure out hey what's the plan how do we actually solve this problem how do we set a set of headline tasks so planning reasoning sucks and Devon has probably come out and said that we will solve planning and reasoning and we will use GPT to write the code after we have solved planning and reasoning and what does this mean for soft Engineers who are just learning or starting out I don't think that it means it's the end of software engineering jobs yet I'm pretty sure it gets stuck in a lot of places but I do think that over time the trend line is such that software Engineers will have to move one level up and help you know this junior engineer on the internet called Devon out and unstuck it wherever it gets stuck",
    "url": "https://www.youtube.com/watch?v=urtuvHER0AE"
  },
  "ZvoNX5sSiqc": {
    "published_at": "2023-08-29T14:37:03Z",
    "title": "Google has been Secretly Working on RT2 Robot!",
    "text": "Google has been Secretly Working on RT2 Robot! Google robot what is this they're plugging llms into robots giving them artificial brains what rt2 does is it's got an interesting model where if you say pick up the extinct animal it knows it has to go for the dinosaur toy even though a GPD would tell you pick up the dinosaur but to see a robot do it so this robot instead of us saying oh let's train it on absolutely every potential action let us first give it a brain layer to say take the input that somebody's given you think through the answer and then step by step try to accomplish that that's the thing right like somebody will make like a general purpose robot that you can install any model into and that is the end of everything because one crazy guy is going to fine tune a bad version of one of these robots and then we don't know what to do would you buy one yeah just to around because I feel like at this point it's toy like and it doesn't seem dangerous right now it's very interesting though but I wouldn't buy this robot yeah that's because you are a foot too we know llm hallucinate at this point probably your dog is more dangerous than his robot but maybe you know in six months ",
    "url": "https://www.youtube.com/watch?v=ZvoNX5sSiqc"
  },
  "EyshMMvkIno": {
    "published_at": "2023-06-12T11:38:02Z",
    "title": "Photoshop&#39;s generative fill is pretty insane!",
    "text": "Photoshop&#39;s generative fill is pretty insane! is changing my clothes in real time never thought I'd say that all right okay so here's a picture of you now if I need to make you change clothes I go to the magnetic lasso tool you select this selected your shirt now I go here I right click and then I go to generative fill and I say a tuxedo okay all right not bad uh kinda enunciating your non-existent muscles but okay nice apart from that what if I say naked will it be like AI model large language yeah there you go they violate user guidelines okay what if we say bare chested let's see what it says violated guidelines oh my God a West oh no not like but this is not bad Alexis looks real holy this looks real",
    "url": "https://www.youtube.com/watch?v=EyshMMvkIno"
  },
  "Keo54g5ipO0": {
    "published_at": "2023-05-27T10:43:18Z",
    "title": "AI + VFX is MAGIC - Watch This",
    "text": "AI + VFX is MAGIC - Watch This new technology has come out called Wonder Dynamics Wonder Studio where it's one click  it's so easy that we could probably replace you in this podcast with an AI character can we do that can we try that hello what are you replacing me as I'm a robot yeah you're probably a robot if I move around hey by the way you should replace another girl okay what the no you say am I a girl right now",
    "url": "https://www.youtube.com/watch?v=Keo54g5ipO0"
  },
  "DB_Y5c8k5aM": {
    "published_at": "2023-06-11T12:30:06Z",
    "title": "Shahrukh Khan as Superman | Mind-Blowing Face-Swap!",
    "text": "Shahrukh Khan as Superman | Mind-Blowing Face-Swap! we Face Off Shahrukh Khan and turned him into Superman this is how we do it let's promise you need to create a studio lighting chart of Superman flying in Mumbai mid Journey Superman we now have these four Images let's upscale one of them let's take the top right one because most front facing it looks too good it looks too sexy okay now what you do is you do slash save ID srk and then we drag a picture of off srk into this and then we hit enter so now the srk ID is saved once the ID is saved you right click on the original image and you go to apps and you click in swapper now it's gonna put Shahrukh Khan's face holy that's pretty cool wow",
    "url": "https://www.youtube.com/watch?v=DB_Y5c8k5aM"
  },
  "XcMmzmt6qIY": {
    "published_at": "2023-10-06T12:51:12Z",
    "title": "ChatGPT can see just like humans \ud83d\ude31",
    "text": "ChatGPT can see just like humans \ud83d\ude31 GPT came up with this new add-on called GPT Vision which kind of blew my mind import images into GPT and you make GPT interact with those images in multiple ways so I can basically give it an image of let's say can you search a POA what is the name of this dish in  India wow it recognized PHA bro it did it did yeah okay now search for lemon rice and let's see if it distinguishes between poha and lemon rice dude that looks exactly like poha okay wow it understood lemon rice very nice 6 months ago by the way I had made some real about Vision models whatever some gu was like I still can't differentiate between a dog and a cat look at it now Bo and lemon rice Bo and lemon rice it's like I would get confused by the way this make me hungry",
    "url": "https://www.youtube.com/watch?v=XcMmzmt6qIY"
  },
  "oLZ1SoJaJJw": {
    "published_at": "2023-06-13T11:30:15Z",
    "title": "GPT4 Playing Minecraft\ud83e\udd2f",
    "text": "GPT4 Playing Minecraft\ud83e\udd2f this is gpt4 playing Minecraft all these tasks that this is doing it all it has a logical layer which is GPT thinking through what should I do next AI will not only take my job but now I can't even enjoy game in my days of unemployment you finally have a system that can play games like us first implication of this is you'll have a lot of bots and games question is now how do you differentiate what's a bot and what's a human there are tools like anti-cheat which prevent you from manipulating the code on your side of things saying that you can only play the game unfortunately GPD doesn't even touch that GPD just replicates the way a human does things it would spoil and ruin a lot of games I feel like AI could automate everything but if they come for gamers then the real Revolution starts yeah I think that's the Last Frontier like if you ruin a gamer's life",
    "url": "https://www.youtube.com/watch?v=oLZ1SoJaJJw"
  },
  "wnAI3UvYxWY": {
    "published_at": "2023-05-26T13:24:05Z",
    "title": "Why You can&#39;t Sue AI?",
    "text": "Why You can&#39;t Sue AI? the entire character of Goku was probably inspired by Sun Wukong it's the Journey of the journey to the east or Journey to the West or something like that Goku is exactly like San Juan they both have a tail they both carry that giant stick which expands and shrinks with whatever and they're both like monkey like Goku has that hit on transforms into a big monkey if you read through the history Sun Wukong was predated by Hanuman and you had a lot of Travelers who would go from like Northern India to like uh China same story Sun of the wind you know same long stick same tail looks like a monkey we don't know if this is true or not this right but what I'm saying is brings us to brand is is the more in the world of AI every time I go on mid-journey and I output say hey my face as a Pixar character yeah shouldn't Pixar get a piece of The Upside on that no because Pixar is a brand what you're saying in Pixar's style so far we have never sued anybody for copying somebody's style and inspiration is always cool right",
    "url": "https://www.youtube.com/watch?v=wnAI3UvYxWY"
  },
  "aWwVUk8rdI0": {
    "published_at": "2023-05-28T13:37:18Z",
    "title": "Tinder is just bots now?",
    "text": "Tinder is just bots now? Tinder is just Bots now yeah you can't trust anyone on text anymore because you don't know who's repeating their images are fake their text is fake I think we had a period of time where Tinder was useful then start like we we did offline dating for so many decades and eons and eons and whatever Tinder hinge Bumble whatever yeah now it's ready go back in the real world again yeah now I think the way I is going you need to build a dating model on top of GitHub yeah which is the ultimate proof of mate ability you know what I'm really excited about I want to see what happens to people on charlie.com and Bharat mat because that's going to be parents they're not going to know this these profiles",
    "url": "https://www.youtube.com/watch?v=aWwVUk8rdI0"
  },
  "IdRniFSW4EE": {
    "published_at": "2023-06-27T11:30:07Z",
    "title": "Anyone Can Become a Content Creator Using AI Today!",
    "text": "Anyone Can Become a Content Creator Using AI Today! so there was a video that I saw of someone on Instagram talking about how they can turn themselves into a 3D character so this is how you do it let's take this image of mine okay let's run it through did and let's run the process here is the output hey guys my name is Baron and I was gifted a computer at the age of seven which led me to playing a lot of video games I think this is super interesting it's cute it's a toy right now do you want to see it get better watch this artificial intelligence but I think there's a good opportunity here a lot of very good video editors who have good stories to tell but do shy to get into the camera you make them all powerful right and now they've always done it as a service for other content creators but if you're able to put yourself with the crazy personality and whatnot then you do it yeah this is on confidence as a service confidence as a service yes right and and also you don't need Studio you don't need the setup it's just straight text or script to video",
    "url": "https://www.youtube.com/watch?v=IdRniFSW4EE"
  },
  "0bY3DJsgYbg": {
    "published_at": "2024-08-14T15:24:27Z",
    "title": "The $1.8M friend.com domain drama, Our Opinions on The MKBHD Effect and much more...",
    "text": "The $1.8M friend.com domain drama, Our Opinions on The MKBHD Effect and much more... another week in the world of AI another chaotic week but dude what did I watch I saw something explode on Twitter yesterday it blew my mind but before we get into it uh sorry about the camera quality today by the way my main cameras have got some problem but let's get into it uh so yeah play Intro and then we'll get right into it you guys want to see  this bro AI shiffman raised $2 million in seed I forget what it was seed apparently he spent 1.8 million of it buying the domain name friend.com to basically launch a like a even more basic it looks like it looks like the uh echo echo the small Amazon Echo but with AI capability built into it which the small Amazon Echo is going to have any day now uh yeah $2 million do you think it was worth it first let me tell you the entire drama so there was a rap song do you know there was a rap you know there was a rap there was a competitor to AI there's some other guy who apparently claimed he came up with the word friend first it was his idea then appar i' I've done an awful job please you explain it what the is this yeah so so apparently this guy AI wanted to make a varable there was another guy that also wanted to make a varable apparently they were friends or something and they both named it friend one was open source this guy had made it not so open source and and then eventually when Avi came out with his product the other guy started made a rap song on the internet saying how can you steal my thing or whatever and then AI is like no screw you it's my market you know you can all buzz off so I have no idea what's going on right it just seems like a bunch of kids that are fighting but then the move that he made was he spent $1.8 million on a payment plan on a domain which to be very honest that's the one part of this I can get behind because if you're in a very commoditized Market the where where everyone can sort of build this for nothing uh the only right move is to buy a domain and make a great ad uh I think it's a good move I think marketing wise you would agree I think today's day everyone can make products but getting users on the products is damn hard uh and what do you think the play is which is to have L to hack SEO which is people everybody searching for AI friend is going to find this so I don't know if you noticed this now I think everyone's  on everything that comes out everyone's just abusing everything like there's literally nothing you can ship today even a good thing people are saying bad things about so AI learned how to sort of take advantage of the haters right he's like haters are any going to share and talk nonsense might as make something where they can actually share and hit and whatever right and this got like 21 million views I don't think you can purchase 21 million views for $1.8 million so whatever it is it paid off and the haters just don't get it or they've never done marketing at scale but having a top level domain having a friend.com domain is a big deal uh the ad was I thought like I didn't watch the whole ad but I thought it was was good like I thought it'll it'll trigger emotion I'm pretty I thought the ad was kind of garbage but I thought but I think you can flip friend.com for more than 1.8 million I I think that domain name is extremely useful yeah but uh long term I have no idea like if this works like there's two options right either the product works or it doesn't if it works bro Apple's going to do it right and so is Samsung and Google and literally every top player in the market so and and also you nothing here right like the model is somebody else's um you know I don't see how there's a business here I see how it's a great marketing campaign and if a had gone and worked at open or some great company and done this sort of marketing campaign it would have done really well for them but right now like I mean the question I had and the reason we didn't build this is a fairly trivial problem to solve but the reason we didn't build was like what is the market for this who's going to pay for it sure I would use it but the minute it started working like even if you sold like 10,000 units bam Apple comes out with their version or Google comes out with their version or Samsung comes out with their version so you don't want to waste so much time it's Hardware you'll have refunds you'll have issues it's not worth the the fight right and the wisdom I think comes with the age but when you're young I think a is fairly young right even the other guy was fairly young but it made for great Twitter drama right as much as it is like as much as people are calling him arrogant and this and that I'm actually rooting for him because I'm like at least someone's trying something right and it's good to see someone trying something they entertain us doing all of this and at the same time there's new products and services in the world that even if it fails we get to learn something from no yeah I mean what do you think I first of all I'm I'm almost very certain that the product doesn't work as well as the ad of course it's just it's just not as good uh even though I think even though I think all the demos all the videos I've seen of um uh Chad gbd voice is actually very very good uh so if it gets close to that that's pretty good um I don't think it's as easy as I don't think see when people say that oh Google could just launch a feature and kill this or apple could just launch launch and kill it by that logic like any Innovation or any shot that people take in Hardware but that has proven out to be true like in Hardware almost everything even the Rings for example right for a period of time Aura and ultrahuman were the only ring providers Samsung now has a ring right so they will come if there's a big Market they'll come but you could have a few years of hits basically but I'm not sure man everything's moving so fast today like if there's a market if there's that attitude that attitude is you just can't innovate with that attitude that hey can I not try something just because I think that someday Apple will thisis thing I think if you do something really well the likelihood of I don't know I'd rather be optimistic and think that you'll get acquired at the very least yeah that's a possible path yeah if you go in thinking that yo this is just something that Apple's going to eventually do Google's going to eventually do that's going to get you nowhere that's also just not true like um like a lot of times a lot of times what happens is I've had friends work at really big companies like in India like giant e-commerce companies or you know fintech companies where very often they'll keep hearing off hearing that Google is coming after your market andu GOOG yeah they they'll hear of that but also like the m&a team in the company will be like uh hey we're looking at acquiring this small company because they have this thing that could be really useful to us and the CTO eventually always says that yo no we can build this internally but there is limited engineering bandwidth you're not always going to be able to allocate the engineers to build the stuff that you sometimes it's just cheaper to acquire so I don't think it's futile to think of building stuff even if it's in Hardware no there's a slight difference between software and Hardware here and software it's a little hard for Google to do let's say what a figma does or whatever an adobe to do what a figma does because figma's always continuously iterating with Hardware it's the Cycles are so slow that you have time to catch up right that's the only difference and also over the years we've learned that these large companies have so much might right they've got factories they can just get the Fab up and running quickly it's they also have advantages that are not there with software software ultimately everyone's on even playing field right even if you have tooling lots of tooling is open source so you can pick it up like I don't think there's going to be any differentiation on this friend versus any other device software like what's running on it I don't think there's going to be any differentiation but I think these players competing against each other when you go take a hardware fight with with somebody like a Samsung you have to be careful because Samsung also comes with Rel reliability refunds the bank balance but that all being said like I said I'm still rooting for this guy I think anyone trying anything new especially the harder it is I think our default State should not be to on it and internet is now become a place where you do anything people will on you anything you move the people sh on you no no in general netet I agree that hey that you know uh why HTE the why HTE the player for playing the game it's fine let let let people try things uh by the way I think we should play the ad because we've spoken about it for a while but for people we should actually play it um cuz you know any attempt is an  attempt out of breath we made it  woo I don't know how to W very good that's fair all right let's go let me show you how to game bro okay oh come on come on oh let's go are you serious come on man I hate this game take notes baby oh man you guys suck bro you look like the back of let's go let's go dude what how did you do that I know the effects are crazy it's dank I could eat one of these every  day sorry I got you messy it's really nice up here how'd you find this place I don't know I just kind of like to come up here to be by myself I've never brought anybody else I mean besides she goes everywhere with you right mhm guess I must be doing something right though I guess so we'll  see I'm not a I'm not a I'm not MKBHD I have no intention of killing this guy's company so what do you what do you actually think of that MKBHD commented on his post did you see the comment where he said uh I I promise I'll give it a fair shot or whatever like that right um what do you think about the MKBHD effect now in Hardware Tech where MKBHD makes a review about you and then you don't have a business anymore the MKBHD thing are slightly more nuanced okay I understand his I understand his point of view that hey I am someone if he has an opinion people tend to spend money on it so I got to be honest to my audience I get that right but dude I also make content so I know he didn't need to title The Humane pin video as the worst product I've ever reviewed for now there's just no reason to title that like you can you can have a negative opinion about a product without being obvious clickbait this what I think like there's no I I think he he he knows what he's doing he knows that this title is going to get him 8 million views or whatever it's gotten uh and he did that what he did not realize was that it would lead to it would lead to the company getting trashed so hard um what I would be curious about is to see what happened to sales of the human AIP pin I'm sure it crashed I'm sure it crashed I mean actually we don't know we we sometimes the Strand effect yeah I think the Strand effect Could Happen uh which is the reverse of what Marquez wants which is that I don't want people to spend money on a bad product but when you see what the hype is about people tend to buy it so I would I wouldn't be surprised if um if something like that also were to happen curious question here do you do you think do you think Marquez is on a slight Power Trip does it appear like that from from a distance as a Creator no I don't think he's on a power trip I think yeah he's not cocky or he's not he's not like out there being like Oh I can destroy companies no I think he's relatively very very well balanced and also I've been seeing Marquez since he was like a baby right like he literally was 14 when he started his YouTube channel or something like something really young like that uh so I really think the dude loves his Tech and I think he's very passionate about it I do think he is the most powerful tech journalist in the world right now but I also think that there is enough competition that doesn't that can't let him go to like that can't make him feel like this Mad God complex cuz like Mr who the boss is right next to him you know there's there's enough people who are in the same league as him who are getting as many views as him who will get the same invite as him the same products will go to everybody else the same treatment that he gets a couple of other people will also get so he's not alone at the top there's a couple of guys who are at the top which makes it good which keeps everybody honest I only have one gripe I feel I felt like in the spectrum of things of course I haven't used the Humane pin but in the spectrum of things I think the Apple Vision Pro should have got a worse review like if you really think about it I mean everyone any consumer would know right it's so expensive and how many times have have we used it like three times four times like it was pretty obvious the first time I used it that this is going to be a once in a blue moon news right like it's the same with the quest or any of the other VR devices but if you look at that review versus the review of let's say the Humane pin I felt the tone with which Apple was handled was with a very different tone than which any other company was handled I'm not I'm not claiming anything I'm just saying that as a as a viewer as a consumer of his content it just felt like why would you treat Apple so differently from a Humane I mean you would treat Apple differently from Humane cuz it's apple right like um I don't I my point yeah but that makes sense it it would make sense when when you know six six times a year apple is going to do something that is super critical for your business as well you're not going to want to rock the board but I think Marquez would Marquez has been the thing is Marquez speaks about Apple so much through the year that there is a decent amount of criticism that comes Apple's way also like like he spoken about Apple copying features actually the Apple copying features thing has been something that he's like he's spoken about for years now where now that opinion has evolved into actually I saw a video of him recently saying uh it became like maybe it's a good thing that people copy because it's good for us as consumers and now I think there was recently someone launched a watch which is exactly like the Apple watch and he's like maybe it's not not we're in that phase where it's not good to copy anym so I I don't think he will ever be as harsh about Apple because Apple just dominates so much of the conversation that it's impossible for anything to seem harsh because the criticism just keeps leaking through regularly interesting oh yeah but he did Marquez did put up that clip about like he D he put up a clip about Tim Cook speaking about Magic Mouse which I thought was like it wasn't like it wasn't like a harsh review but it was like a yo bro like come on like this is the worst thing Apple has ever done like how do you charge this mouse like come on yeah interesting let's move on so the next thing is just so you know there was a Ubi study done Sam wman did a $45 million Ubi experiment there were 3,000 participants there was either $1,000 or $50 monthly payments the duration was up to 5 years location was in Texas and Illinois age ranges between 21 to 40 Target was low-income households which is below 300% of poverty level right uh so here's how the money was used uh here's how the people use the money and we're going to show a graph right now so basic needs Healthcare Transportation education financial support for others so let's see and what the impacts of this Ubi study were I think it's very important because if AI someday 5 years 10 years later takes away jobs or 20 years later takes away jobs then uh the government has to give some Universal basic income some stipend to you to live your life how did people use that money today in this study and what can we as Indians learn from it uh I think it's it might be pretty interesting to go through this number one is I think there's a 2% decrease in employment likelihood so that's 1.3 fewer work hours per week on average so people work slightly less when they got free money right although it's not as low as I thought it would be I thought it it's not as high as I thought it would be I thought it'll be like 50% decreasement decrease in people going to work or whatever but it's just a minimal tilt in reduced work what do you think of that so yeah yeah I'm thinking that actually actually that's kind of it's it is kind of I don't know if I'm super surprised because in America depends on who is getting the ,000 is it someone who's already making a bunch of more money is it it really depends uh but I think it's net net yeah I agree with you I thought that if you're getting if you're getting uh enough money to cover your basic needs then people would want or work lesser like this decrease is like how much I decrease my work when it's just like nice weather outside you know like like I didn't think that Ubi would have the same effect as hey good weather uh if it's raining in Mumbai I feel like not working that's surprising what's the next stat here there's like a huge reduction in stress there's improved nutrition so people ate better of course and a lot of people spend time in pursuit of education so they actually spent money to go learn new stuff it kind of feels like AI propaganda right now this stud yeah I don't believe it I don't know why I don't believe it it's feeling a little like oh if we all if we all don't work and just get free money things would be better we should just use chat gbt more for everything uh but okay it's interesting I didn't know by the way he conducted this over five years for The Last 5 Years yeah he he did he started started this many many years ago it was it started in 2016 actually that was when the idea came out and the pilot started in 2020 the $50 group was a control group so they were just like they were not checking for that but they were checking whether $1,000 changes your life and it turns out it does it improves all of these facets but I don't believe any of it because if you give 20,000 rupees to every Indian let's say as Ubbi if you give 20,000 rupes to every Indian I would immediately try and pick up stock in every real money gaming app every alcohol brand I would not think twice I would go buy stock immediately dream 11 yeah yeah there's no way there in but okay this is interesting people are apparently spending it on better nutrition uh stress is reduced cool what else happened the future implications of Ubi was that you know funding sustainability how do you get the actual money for this uh potential inflation because if you give everyone money then you know the price of everything goes up if everyone can afford something like real estate would immediately go up if you gave everyone money right like for example uh political feasibility which is there'll be two political parties and the only thing the political parties will do is like my Ubi amount is 9,000 the other guy will be like my Ubi amount is 9,500 nobody cares about any other policy they only care about what is the actual check they're getting okay uh opportunities are of course poverty will reduce which is people suffering will reduce it's obvious increased entrepreneurship when you don't have to worry about your base income you'll try new stuff improved mental health uh because you're not worried about where you're check is coming from next concerns are work disincentives which is uh you know why would people work if they got money dependency culture they'll start depending on the government and or you whatever and economic disruption economy works when people produce good products and services and they are forced to kind of work to make these products and services and because of that customers pay for it and that's a virtuous cycle right so you have you make more money so you're able to spend on other products and services you disrupt the economy by short circuiting it with this money uh what do you think about UB actually I actually have no strong opinions about it but this study is super interesting has he open sourced this study like and more people read it yeah the report is out there the report is out there okay yeah okay interesting okay uh I don't have any strong I I don't have any strong opinions on it I think it was I think net net it's a cool thing that Sam attempted um but I did not think this would be the result I the by gut instinct is that if every gets free money then the desire to uh the desire to work Fizzles your dopamine addiction will go up um you would generally get more lethargic but that's cuz a large part of my desire to work is money so maybe that's just how I feel um it's possible other people don't feel that I think this study is propaganda maybe didn't start out as propaganda I'm very sure it didn't start out as propaganda because he started in an era where open air was not getting attacked he imagine if the results of the study was chaos oh nobody wanted to work anymore right after the study and it came it came out in bad light open I wouldn't be able to to just like that that that would take another brand hit right because of that so unfortunately that's the thing right like when a company gets too big and their financial incentives are now aligned with you know sort of uh maintaining this the the fact that AI is not going to disrupt too many things I think there's no incentive for them to to to to disrupt that status quore so I feel like it should have been a different body not associated with Sam not associated with openi doing this this was not associated with open I think this is associated with Sam should have been a different body sort of coming out and saying hey you know here's what we think of Ubi but I do believe we need to do an exact same thing in India we need to do exactly this in India and you know how much would it cost probably expensive but I think you could do this with 10,000 rupes in India across 100 Families how much is that 10,000 rupes a month maybe a lak a year across 100 families in about a CR you could do like a sample size of 100 people Ubi see how that changes their life take people across multiple different econom economic startup ask them to table something I think this is a very useful study in India and uh yeah potentially T if you know we we should consider doing this if if if you feel like if you feel maybe not now maybe after 6 months a year or something like that but I feel like nobody's done this for India nobody has an idea of whether this would how this would change change things in India and we'd actually be able to do it in unbiased fashion no I think your bias is pretty clear to be honest no this would be reverse chat GB propaganda everything is screwed no no it wouldn't be that no if if if we feel like that then we'll Outsource it to somebody else like we have to find somebody ultimately completely unbiased to be like listen I'm giving this money to people who we don't even know who those people are here the results they fill in the results on an app later and that that data directly goes on the internet and then the internet can decide you know whether it's good bad ugly what what they think of the data Etc we shouldn't even do the data analysis we should just be like here's the dry dump of the data you guys decide what you what what what what the implications of this are uh cool you do it and you tell me how it goes I'm going to invest that one CR into a nice high yielding Bond and high yielding uh real money gaming real money gaming at yeah and if you could tell me exactly who are these 10,000 families that you'll be helping uh I would love to know what app they are using to to kill their time yeah like you have to do it in a in a more this thing fashion you'll have to record their phone like I mean it'll be privacy Invasion or whatever but I feel like somebody has to do some study like this yeah someone should I'm I'm actually pretty sure someone has so T you know how frustrating it can be to generate images with AI right you don't have much control over the output and you have to switch to another program just to edit it like the thumbnails that we make first we'll generate it somewhere else then we bring bring it to photoshop it's a hassle dude it is damn painful but thankfully now you can integrate stable diffusion in Photoshop using comfy UI do you know comfy UI it's basically this like combination or that allows for like realtime image generation within adob Photoshop so one of the things we found that there's this integration where you can set up a node workflow in comfor UI and it can communicate directly with Photoshop that gives us both worlds right it gives us the control that you have with Photoshop the fine control as well as all the AI features of fi all the new nodes so I'm just going to generate one and show you okay I'm just going to generate this yeah don't just Yap okay bloody do and show you see how quickly transform that sketch and notice how you could guide the output based on our initial sketch all of this is happening in comfy first of all vun your drawing skills are really bad I just wanted to address that up top no I know but this integration opens up amazing possibilities like you can do rapid prev visualization ideation like I think a comfy Photoshop Bridge was something that was always missing uh and now we can do that so for example I can even like change the clothes of a virtual model like see pretty cool right yeah that the tool is pretty cool but that skirt is awful yeah but I'll tell you how this works behind the scenes so this workflow relies on LCM which is latent consistency model which just really accelerates generation time so I can do it in three to five steps I can quickly generate something I don't need to wait forever but the cool thing is that this process the hardware is running on is the Intel Core Ultra powered processors it has a neural Processing Unit also known as an npu we've heard about this a lot but the npu actually makes this possible this just it makes it seamless Al so that's a specialized that's a specialized chip you mentioned earlier the one that handles these like AI specific tasks the way we're able to achieve this speed is because the mpu takes care of all the AI workloads while the GPU and CPU are free to tackle other intensive tasks it's this intelligent division of labor that makes everything run so smoothly theoretically the GPU and npu sort of share the workload but in this case the npu kind of takes on all the heavy lifting dude it's crazy that all this can just happen on a laptop now uh anyway for those who want to know more just check out the link in the description or in our bio and you can deep dive into the Intel uh core Ultra processor World open a silently killed perplexity AI I don't think they've killed no one I I think s GPD is a great product yeah I think um I've seen videos of it and it looks cool I haven't tried it yet let me reuse it right now you can't it's a wait list yeah I what yeah no I think I think it'll be a cool product but if it's anything like if it's anything like the web browsing that tool that they had in the in GPD 4 it would suck but at least the demos and the videos all look good and some folks who used it all say it's nice but I would just like a search engine to not be Google or Microsoft soft so for some reason I like you want another winner I just want I just want another player dude I just I don't know like my needs for search are not as like I don't need AI to summarize you know what I'm saying like my my needs for search are very simple like my need for search are what was the name of that theater in bkc which has big seats like they're very very very simple uh that doesn't need too much info I don't know maybe that's just me I think it's we yet to see what search GPT is like I I don't know like perplexity has gotten better especially perplexity Pro whenever I use it I think it's pretty useful like sometimes I use it to like if I'm if I'm taking a new medication or something like that I'll be able to quickly you know ask it okay summarize the research on it in The Last 5 Years what are the side effects show me papers I like the fact that it gives me references so I can click through the references and sort of figure out okay you know what is the uh actual Source behind it is it hallucinating I feel like it feels commoditized though like there's no reason this can't be in Google when you do a Google Search right but at the same time you're right which is no one entity should have unlimited power right so it is important for Google to have like a counter check and openai is a good counter check where I would probably go to open a and make the search I today by the way when I search I search on Google I search on cloud I search on uh chat GPT actually I use attb the least I search on uh Google uh I search on Claude I search on perplexity I use these three things and I'll tell you one thing this is going to sound like the dumbest thing right I use perplexity because it doesn't require me to log in sometimes I'm on some different device I have too many devices now and sometimes I can just use perplexity without logging in and that is brilliant with chgb I still need to log in I need to do authentication I have the UB key because everyone's got how do you use AI search like how are you using it so I'll give you an example right yesterday uh you know I was trying to learn the difference between two different drugs right that there's this there's a medicine called tacrolimus and there's another one called methot so I was trying to figure out why does one work faster you know um you know what is the research behind it what are the side effects behind it I just dumped that question into perplexity right and it gave me answers along with links and then I actually click through the links read through the entire so PubMed has these articles right or papers and I would go through these papers that perplexity is sort of linked to so I use it like that then for example I was trying to figure out these 3D printed shoes I was was looking at 3D I don't know if you know but now shoes can be 3D printed yeah this is crazy let me show you it's crazy uh there's a brand called um zel field okay so they make 3D printed shoes and the way you do it is you send a picture of your feet like you take a they do a 3D scan of your feet with your iPhone uh and then they print a shoe that perfectly fits into your feet wow that's insane yeah so everything from chaples to this thing is completely can be made with uh this thing so I was trying to figure out well if I needed to do this what's the device required uh can I do multiple colors because it seems like one of the drawbacks of this is you can only do single color printing right but I'm like bro most shoes eventually will need to be colored right and you can't do that manually so so I was trying to figure that out so perplex was helping with that uh that's generally how I use perplexity got it that's cool we should do Series where we show how different people can different uh people at different jobs can use it you're talking about perplexity oh yeah actually yeah dude I think perplexity is great for all sorts of analysts who no longer want to go to 10 different websites and get research it's that's the use case that's the eventual use case it's analysis work to make a slide deck to prove something to something internally that's like n out of 10 money game for them and I bet if you look at who's who they're making money out it's mostly analysts only who they're making money off uh that's my opinion and data we have to see have you seen live portrait no let me show you live portrait so we've done this video of tan but live portrait yeah how does this work what do you think yeah I wish i' had never seen this but basically I can drive your face with with any um with any other face right so I don't even need permission like earlier with hen and all you needed permission right you need consent but this is an open source tool and this is the big problem with open- Source video tools right or audio tools which is now anybody can use them the Pandora's Box is open and we are seeing a lot of this like on Twitter now I'm getting very confused like I I scroll sometimes I see something and I don't know if it's fake or not there's zero way to verify like yesterday some boxing thing happened right where some lady uh who is apparently not a lady and then later it found out we found out she is a lady and then she's a lady but she's got an XY chromosome the thing is we don't know anything we don't know anything right and you're just going through the feed and everyone's sitting and making character judgments saying this person is bad this person's evil no no no this person is right and we're like bro we have no data we don't have the person's birth certificate we know nothing and yet people are there millions of views of people getting angry about something or the other with with tech like this it's so easy for me to just show something T saying something and then everyone's arguing about it even though you never said it and nobody will care whether you didn't say it or not even if you say it's false that video is still going to get views there's still going to be text on it like there's still going to be comments on it like people now believing whatever reality they want to believe yeah everyone's biases are going to be more AI is going to make make everybody have more confirmation bias to whatever it is that they already believe uh you know the phrase bros before ho like tweets before facts like that's just how the world works now it's called post truth Trump invented it back in the day in 20 whatever 2018 20 or even before that um so yeah this we've actually been living in this world and I have a for a while for a while and I think the day that yeah the day retweets were invented the day it became easy for you to get likes and clout online is the day that everything changed then the second level leveling up to that was the day that your replies or comments on posts started getting likes like I remember Facebook introduced comment liking which means people start posting people start posting what they think other people will agree with and that changed individual thought and that changed the game alog together that increased hate net net so I think the worst two features to be invented were retweets which is number of tweets um like I prefer back in the day where you could quote retweet something because uh then you were forced to add like some sort of your opinion on top of it I don't know there was just a little bit more cognitive effort but the day you start adding likes on people's comments is when everything just got dramatically worse dude I'll tell you it's not just a Twitter it's everywhere problem on Reddit there was this one comment about Aina my wife okay she runs uh a there was this comment that said this lady is an NRI she doesn't even live in India right and she's sitting and giving Gan and this is said as a statement there were like a 100 likes on it okay and everyone's like yeah how can they sit in India and gatekeep bro it's called gatekeeping whatever there like 10 comments on it right and I was just like wait you just you just Li straight up and everyone's liked the lie and people are commenting and acting like the LIE is true and like bro she lives in India she lives in bloody right so so uh how what do you do like defamation doesn't work you can't you can't go to court anymore because it's just like a painful process the other side doesn't have any money it's just pointless so what do you do so I feel like it doesn't matter like in fact there's a guy on Twitter I follow nowadays who just lies about everything like he just tells a posttruth thing he's just like now there are armies are fighting with drones and he'll put like a picture of drones and he'll be like Indian army has moved to drones and puts pictures and everyone's commenting saying yeah this that I'm like but he's just straight up and I just follow him to see is there anyone who calls him out on his nobody nobody bothers because what you have limited time in a day why would you go and argue with everyone who's you are like you are like five years late on this phenomenon five years late it's because you have gotten famous in the last like 12 to 18 months so you're now dealing with this this it's my this is I been whining about this for more than five years saying yo no one speaks the truth anymore mainstream media just blatantly lies and now anyone can lie and that becomes mainstream news yeah I saw this one video of Ganesh Ganesh talking to Ganesh from things School talking to somebody and they've changed the entire words to have him and I think Shashi to have him saying RIS Gat something like that that Meme is quite funny okay did you know that again talking about MKBHD uh MKBHD has said that Runway AI has been stealing data from YouTube it was trained on YouTube videos without permission uh including 1,600 MKBHD videos what do you think even sunno and udio I think the big music uh universals of the world have come out and said yo how can you train on our artist data where where do you see this going this has been going on for a while where do you see this going it's so how else are they supposed to train I mean they can train on non-copyrighted data but they're training on YouTube it turns out they're training on YouTube data non-copyrighted data is not as good yeah you'll have a bad Mar yeah so what do you what are you going to do I don't know dude it's got to come to a point where either you're going to start paying for it training data or we just going to live with it one of these two has to happen but like I'm not surprised anymore that they're using copyrighted data to train there's no way these models are getting so good without using copyrighted data there's no way I'm inputting Thanos eating wapa at Andi station and getting Thanos eating wapo and station without them training Thanos and V house and on station yeah V on station I can imagine them having non-copyright material you're not getting Thanos without non-copyright material so but do I want Thanos eating V at and station yeah I want it I'm okay with it I as a user do not give a about how they train I as Creator give many about how they trade how do you feel if somebody trains on your data today just just don't make me say that is bad for both you and me bro like um but yeah it's it is scary but I feel like uh you know if I was shuk Khan I'd be more scared if I was yeah so in the relative uh scale of being scared I feel like I'm okay but you know after all of this stuff all we really got was Modi singing you know have you seen that video Modi singing It's so funny I think I think eventually a lot of artists and creators will protect their voice they'll they'll take some legal action and see last year everyone was figuring out the tools were new everyone's making tutorials everyone's trying to figure out everyone nobody knew what the implications of this are but I think after a few lawsuits go through people will understand what the implications are there'll be some season dises sent out I think everything will get normalized like even as creators right we've also evolved over the years to be like okay this is what we can and cannot do in your early days any new early industry you don't know what you can and cannot do so I think the Norms will come out over time and I think at least in India I think you know training on other people's data will become legal issues whether there's going to be a resolution of the legal issues no idea but they will become there will be issues running around on this because as an artist or a Creator this all you have right like your identity your face your this or that which other people are using uh independently uh which last year everyone's figuring out models are bad now the models are starting to get good so I think there will be some guidelines around this somebody some some legal entity will come out and put some guidelines around this the only problem is if there's some company sitting in China using your YouTube data from India are you going to go sue them right so that is the concern which is actually in a way by preventing people from using copyrighted content um I think you shoot your own country in the foot if you're in the US and you prevent all other American companies from training on YouTube data you basically just giving the keys to China to do it cuz YouTube is not going to Su China or or whoever is doing it in China right some small company in China it's too hard the location difference makes sure the lawsuit never actually translates into anything uh or it could be some people in some random this thing so you're giving them the better model because you're allowing them to train on copyrighted data this is one of those things where maintaining copyright necessarily means your country and your companies in your country fail it's weird but it's how it is in AI yeah agreed um please don't around with my face okay let's do the last one uh llama 3.1 is now fully competitive with GPD 40 and Claude it's completely open Source runs on your computer the human evaluation shows that Lama 3.1 wins about 23% of the time there's a tie about 52% of the time and there's a loss about 24.5% of the time versus GPD 4 which is fantastic we have an open source model that runs that you can run locally sure you need some Computing resources but it runs locally and it's comparative with the best models out there what do you think llama versus Claude what is this llama versus claw llama versus GPT all of it like it's it's almost at least according to the the the evals they're almost equal uh personally I don't think it matters like one U-turn I've done is like does a local open- Source model matter so much I don't think it does it's just gotten so cheap to do this online with a CLA or a even a like the smaller gpts now where does it really matter if you're able to run it locally you can find tune online also if you want to with some of these models right like doesn't really matter if you run it locally the context Windows online are larger you can get it from any PC you don't need power ful compute uh but at the same time you know if the models continue to get better and the laptops and PCs continue to get better maybe you'll save on a subscription so both angles are there what do you think I know you'll never use a Lama 3.1 right like considering that Claude and GPT are available for you dude can I just say I'm such a Zuck s right now like holy like absolute gigachad just giving stuff away for free like I yeah I would vote for if I was American I would want Zak as president right now as he also wants himself as president as his email to Peter thei revealed um yeah which is crazy uh what he's what he's doing did you see Zak's statement about you know how earlier he you know he was really young and he was running such a massive company and how he didn't know what public perception is like so he wasn't very good and now he's kind of coming into his own skin about it kind of getting comfortable with it and the transformation is amazing and I'm all here for it actually it's nice to see and also Zak has been one of those people where it's always been post truth right like to be very honest how much do we really know about Zak all the news articles all the TW tweets all the Reddit posts about Zak over the last decade who knows now we're learning that everything is is fake right like I learning now that like you said right like now I'm getting to scale I'm also learning oh like half the said is false but Zak never had a like I'm surprised Z never went out and said bro this is fake right over the last 10 years maybe his PR team told him don't don't don't touch it because it's don't engage don't bother engaging yeah but I think that's the wrong attitude and now that zck is coming out and just being himself and he's like yo I'm actually a chill normal dude not a reptile then we can see it we're like oh wait we were lied to about the reptile thing for forever right I mean I know the reptile thing is a joke but you you know what I'm saying good for him dude and also nice one Lama congrats open source good congrats to everyone good to have competition but also kind of scary everyone can have one one at home lovely I think this is a great video uh we got some great reels out of this I'm sure yeahh all right guys that's for today's episode enjoy the Olympics enjoy them see you next time bye ",
    "url": "https://www.youtube.com/watch?v=0bY3DJsgYbg"
  },
  "mP5MBAnSQOk": {
    "published_at": "2023-07-02T13:30:30Z",
    "title": "Advice For Employees In The Era of AI",
    "text": "Advice For Employees In The Era of AI what's the solution here like a lot of employers won't know if employees are using chat gbt which is fine like as long as your employees are still delivering it's not even a problem so to say is it a problem I don't think it's a problem to your question of what should we do I'm now learning the difference between the hibiscus plant and another plant because I think that's what I'll end up doing in my life I'm just kidding I think it's about leverage like what is it you can do that GPD can't easily do or can you use GPD do a lot more can you be accountable for the things you do like if you're just a writer and you can be replaced by 10 other writers it's like a hard time but if you can find a way to level up say that I'm not only going to write I'm going to tell you what I should write to get views on this website then that's a leverage point you have some consumer inside that GPT might not have in your domain that is value then you can use GPT as a tool so you don't want to be a tool in fact you can separate human jobs you have into are you being used by a tool by your boss or are you making executive decisions and the more you seem like a tool for your boss to just offload workloads the more dangerous the spot you're in the minute you make these decisions you're like safe",
    "url": "https://www.youtube.com/watch?v=mP5MBAnSQOk"
  },
  "S9Bn525zL5A": {
    "published_at": "2023-10-20T15:00:31Z",
    "title": "Google Just Took AI To Next Level With Their 9th Edition of &quot;Google For India&quot; Event",
    "text": "Google Just Took AI To Next Level With Their 9th Edition of &quot;Google For India&quot; Event Google just had its Google for India event and they've announced a bunch of gen updates especially tailored for Indians over the last decade I think India has seen tremendous search in Internet users and Google has played a pivotal role in these users have come online right but I think the main theme of this event was not just about accessing the internet but ensuring that how do we people who go online Thrive yeah for example now on Google search you actually have a more visual experience you could only switch languages and hear your search results but now if you ask what are some ways to drap a sar you get like relevant step by step response and also you get relevant videos Google will soon offer AI powered overviews of over 100 government schemes including crucial areas like employment housing Healthcare farming and now they are also offering the ability to search for local places to visit like I want to visit jagard Fort and I want to know if it's wheelchair accessible that you're able to do now because of search generative experience you can get user reviews as part of the search there a lot more feature updates they're announcing if you just go to Google India's YouTube channel you'll find out the entire list of things that they're now offering using their search generative experience thank you Google for sponsoring this video",
    "url": "https://www.youtube.com/watch?v=S9Bn525zL5A"
  },
  "wv8vgbi5ToM": {
    "published_at": "2023-06-20T14:00:41Z",
    "title": "Sam Altman In India, Apple Vision Pro, Problem With Text-to-video and more | Overpowered Episode 5",
    "text": "Sam Altman In India, Apple Vision Pro, Problem With Text-to-video and more | Overpowered Episode 5 the intro thing was generated with uh mid-journey and then we some editor animated it uh the music is from nuclear yeah and by the way I'll tell you the very interesting story of how this happened was sitting next to me and I was like we need some intro music and then was just like let me uh nuclear and he's like nuclear do you have anything that you're not using right now can I can I just use it and nuclear sends them a Google Drive it's just like this is all my these are all the tracks where I I've never touched them in the last six months take anything you want that's it like yeah it's super cool yeah is my Google llm  Music llm  all right so Apple launched Apple Vision Pro I know you have a lot to say about this I'll let you go first actually I don't know what you think about this uh I think it's very cool in fact I was watching Lex Friedman with Zuck yesterday did you watch that um I thought he had a good response like my first impression was dude How can Apple make something without controllers which seems way cooler and even Marcus Brownlee tested it in like it feels so intuitive to just move your fingers and to select icons and on the Lexus treatment podcast Zuck said that in a in the new Quest the next one that they'll do you can do hands-free you can already do it on the quest too yeah you can already do it on the quest too and he said that the controllers are a deliberate thing because he wanted to make something that is Affordable by more people and specifically for gaming whereas Apple went for an entertainment type of thing which is classic apple right like they the whole thing is like for rich people it's for rich people it's cool it's design it's it's like it's it's almost like at this point it's just a signaling thing if you can afford Vision Pro which means you have a certain class and a certain taste um I've tried the quest Pro I would buy Vision Pro because I can afford it um shut the  up you can also afford it why you make it seem like uh yeah I think it's cool it's 100 classic apple just hyped me up I'm gonna buy it yeah but about the world of AR I don't know I think you can still do a lot of cool  on the quest and people have already done people have built games Quest is like a gaming thing right yeah that's already happened I wonder what new thing people will do on on Vision Pro which I think is your domain you'd know more about so you haven't tried the Vision Pro so I'll reserve my actual judgment for when you know it comes out I'm more impressed by the quest 3. right even the Quest 2 has now has pass-through mode where it's all black and white but you can build AR apps and I'm sure the quest 3 will also allow you to build AR apps right so I'm talking this is an engineer slash Builder I would love to build games for AR headsets right I think they are see I'll tell you the problem we are okay I don't know if these numbers are correct but apparently and Mark Zuckerberg once said this on some podcast that apparently they've sold as many units as the PlayStation last year correct right the problem is retention people use it three times and then it accumulates dust on a on a shelf right so the big problem with ar or VR rather is retention the question we're all asking is is there a device that will make you wear it every day right and Mark Zuckerberg's game and I put out a thread about this I think a year or two years ago was let's make this possible for work right I think work is the use case where you lose it every day right gaming there's no Killer games yet correct right there's no game which I would you know be eager to put on the Quest for one game which I was very eager to put on the Quest for was a game called um it's called lone Echo right I don't know what the name is I think lone echo or something else like it's a multiplayer game I don't remember the name of the game but you have a disc you're in 0g zero gravity and you're passing the disc along and it's a competitive game I love the game and me and my friend used to play it all the time right but then we stopped playing after like two three months like I'm wondering if it's harder to build retention with games uh social probably has a higher chance of retaining a user or entertainment probably has a higher chance of retaining your user like from my learnings game should have the highest retention right even on mobile apps the games have the best attention they might not make money but they'll have the best attention but Mark Zuckerberg tried the entire quest for office thing I'll tell you how Okay so one day they shipped an update where you can map a real keyboard into virtual space you can have the multi-screen set up in Virtual space you can designate a couch your draw boundary around it and then you can now sit on the couch you'll have a couch in Virtual space so what I'm saying is they tried all of this it just seems like nobody picked it up like nobody started using it on a daily basis I don't think it's a function of the visual Clarity of the of the of the quest too it's fine it's fine I have a friend joining us yeah I don't think it's a question the visual Clarity of the quest too I think it's more like the battery life like I'll tell you my biggest right okay I'm just telling you this is a consumer I hate the fact that every two hours I have to charge it and eventually I just realized dude it's far easier to just keep it you know slotted in so I think the battery life is the biggest challenge and I don't know if I don't think the Apple headset solves it either because in all the videos there's like you have to carry on is that thing and now you're carrying a battery pack but do you think if you if you watch a movie in the Vision Pro and it's us I think the novelty wears off you think I haven't tried the Vision Pro but in the quest like I've watched one or two movies and then novelty wears off even the Android layer right we have the AR glasses normally just wears off after a while and my worry with this is is the novelty going to wear off uh in terms of what I'm building I've sort of three four things to build right because it's all you either use Unity or Unreal Engine uh Unity is what they're going with because epic and apple went with uh some some they had some fight earlier right the lawsuit um so we'll still build but I would bet on building simple games like I'd build an equivalent of Katan I'd build an equal loan of Chess in AR right because in VR I think they're already players who played this maybe poker um that's what I do now the question with the quest is to our battery life it's not it's not sustainable for work but I would be happy to be proven wrong one more thing I want to say about AR VR and AI right like it's almost like people who are non-technical seem to think that three different things they are technically three different things if you want to put hard categorization on it but at the end of the day it's an engineer who's like I'm gonna build software for this platform or I'm going to build software like this right uh obviously a lot of nuances in how you build but lots of similarities right both run on GPU I'm sure a lot of games my dream is one day games are going to be streamed and the Nvidia CEOs like one day games are going to be you know rendered instead of being rendered they're going to be generated right so I think you will find some intersection of AI and AR at some point for now the simple ideas I can think of is just singing AR and there's a therapist in front of you right I thought of this cool idea I'm sure other people have thought of it too but then when you actually start using the AI uh here right like maybe you're building around top of chat GPT uh or the open AI uh GPT API you realize the latency is too much takes three seconds you say something and it takes three seconds to respond you'll lose if I had to ask you saying in the race yeah apple has just entered the race Quest and Faith meta has had a bit of a head start who do you think will win and why do you think they'll laugh I think it might be the quest why do you think so it's just got more adoption right now like I at three thousand five hundred dollars adoption is going to be low right it's going to be set for a few rich people 50 years old don't have time to play games I mean that's what bomber said that this is the most expensive phone in the world without a keyboard yeah I mean that's why they're calling it Vision Pro I'm pretty sure an apple Vision mini is going to come out that's cheaper that's like thousand dollars so I don't know like I don't wanna sorry come back to why do you think the quest will win I think the quest will win because it already has an option I think it's a function of the best game I think someone's gonna build a World of Warcraft MMORPG or like a Dota or a League of Legends people have tried the Counter-Strike thing there are lots of games there's contractors Pavlov and stuff this is not good right so I feel it's the function of the best game and I think I want to see how AR plays out I've seen a lot of how VR has played out it's just a story of low retention people use it three weeks stop I want to see how AR plays out okay you haven't tried the Vision Pro yet what are three things that you're excited to see in the Vision Pro and why is it exciting just from the just from the video some people who have tried the Vision Pro like the Oculus CEO especially the ex Oculus CEO Palmer lucky right he's like this is the best headset ever you've got a tweet on it correct so a person who's worked in VR for so long built the Oculus uh and the series of headsets after that saying such good things about Apple or the new heads it means a lot so I'm looking forward primarily because somebody working here for a very long time has said this is amazing and it's better than everything I've tried before now agreed there was some bad breakup between him and Facebook or meta but still it's still a good signal right that's number one number two what I'm excited about is the quest actually has really shitty compute compared to what the what the vision process has the M2 right M2 and apparently they saw lag because they have a separate chip that's just doing you know uh synthesizing all the sensors on the uh on the Vision Pro right so I'm really excited to see whether that latency converts or something a lot of people have said putting on the headset means like it's almost like you're not there right or almost like the headset's not there because everything is Real Time with the quest even at 120 hertz it still feels little bit laggy still feels like I'm putting something else on I'm some you know there's some magic uh that the door that stops the magic right so I'm really excited about the Vision Pro solving those problems I just want to see it like I just want to use it and then I think my thoughts would be more fleshed out farmer lucky do you know what happened between him and meta I think I don't know if this is true but apparently he he made a political donation to somebody that meta didn't like and therefore they kicked him out and now he's working in defense what do you think about zuck's response to The Vision Pro he wrote a company email and then he came on Lex Friedman's podcast dude I really like Zach I used to hate him yeah because of the internet yeah but then the more I learn about him the more I'm like dude this guy's been CEO of the company by himself not given the range to somebody else yeah and is had the balls to say okay the next platform is going to be this I don't mind tanking Facebook for this right I think that's a ballsy move by the way he named the company and really like I've had investors right it's so hard to tell investors that oh you're doing this other thing because this old thing might not work right at my scale okay but at his scale it's like it's insane so and that's a publicly defining stuff yeah it's public investors they do a massive you know hit on their stocks uh on their stock price so I like people who are willing to go all in and have like his incentive is not money he's made enough money so I know he's playing to build something really cool um so I I just encourage it from a distance because I just love it he's like this like man's man thing also going on right now like yeah the Jiu Jitsu and then the Iron Man thing that he does and you know he smokes Meats in his backyard as well like I like Zuck a lot and and you know I used to for some reason I used to dislike him many years ago I'm so stupid in hindsight like I don't know why I did that it's just because the internet hated somebody I was like oh it's cool to do it's like five six years ago now I'm just like dude I don't mind being that guy I won't yeah you know I wouldn't mind you are like Zuck in the sense that you also seem like your AI generated sometimes I don't know why he got that now he seems more relatable no but yeah that's the thing Zack has done some nice PR uh you know whitewash he's like oh I'm gonna go I'm gonna do what Joe Rogan does because Joe Rogan is seen as the oh man you know whatever yeah very relatable guy I'm gonna go to Jujitsu I'm gonna show my family life I'm not gonna talk like a robot so I really like him now that's what I know at the end of the day no matter who builds what you're like can I relate to the person yes okay I want to be like just the fact that he's giving a response is going to have so much attention and scrutiny on it it's not only did it respond but it was a very measured take yeah it was not how these guys suck yeah this is not good it wasn't that his reasoning was hey I think that going for something we are going a different place we are going a different path we've tried that but that's not for us and it made can I tell you one thing but uh I don't know if this is true and this is my opinion on this I think Zuck got locked like he's not locked see I I know they released the quest at lower price points or what not but everybody in Silicon Valley wants to build a premium product apple-like product okay and Zuck for a long time said we're going to do the they have an expensive version of the questions like we're gonna move towards more expensive headsets over time and we're going to try to bring the price of those down right so uh put in good Hardware make sure the compute's on on the thing because Quest people don't know this but you can actually use something called air link and connect your PC to a quest and suddenly all the graphics are much better right you run you're processing on the computer itself Zuck wanted to pay the premium game but now can't now he has to play the Android narrative yeah you you can't go up in culture you can only go from Top yeah so I feel like it's also a little bit of cope uh saying that oh you know we will we will be the poor man's headset or every man's headset yeah um it is cope I nobody would want to say no to the premium segment right but the thing is when Apple comes out you you don't have a choice but to fit there so now he's going to go into customizability like you can see this in meta strategy in general right llama they release the weights open source right uh they said for researchers only but I'm pretty sure then you would get leaked so I feel like he's been Co he's being pushed into the Android Direction I don't know if there's a business there uh I mean there is a business there but is it his choice of business don't know all right let's move on Runway Gen 2 came out prepare yourself for the exhilaration and sheer chaos of interdimensional clown wrestling  these clowns can pick from the Twisted corners and visceral vibrancy that only the weirdest Dimensions can conjure the thing with text to video is text to images gotten so good that the expectation on texture video is so high but it's harder to do I'll tell you why it's harder to do right technically so let's say you run stable diffusion you have a nice model on it or mid Journey or whatever you're able to generate an image good but the problem is generating one image and generating like a video is a bunch of frames correct let's say 25 frames a second right you're generating many many frames frame to frame cohesion even if you get great outputs on frame one frame two frame to frame cohesion is hard it's hard so you'll see this in a lot of like kyber for example has this issue right let's say you have this you have a small plant there in front of you and you take a video of the plant and you're just moving around and maybe you there's a dog in front of the plant right as you move around the planets are changing shapes frame to fame it will go from plant to something else that looks like a plant to some some other thing that looks like a plant maybe different plants even correct so there is no frame to frame consistency correct right and I think that's the biggest issue with text to video I don't know why people are that's why people are currently using like video AI tools where it's like for a moment in using a video as a base layer you can imprint it's a Frozen stuff on it it's a filter yeah I think the best use case is a filter like Snapchat Instagram already proved this and I think there are now tools where it can convert you into anime form I think text to video it's not even texture videos will be great for filters right and I think it gives a lot of editors great tools right like um so last year we were thinking about what to start like a China's thing Water started we want to teach something what do we teach which of these are going to get are going to expire over the next one year the one thing we will show we're not going to expire over the next one to two years is video like it's just frame to frame consistency is so hard it's such a hard problem it's an unsolved problem it'll get solved someday right maybe five or six years down the line but you still need someone to weave it together you still need somebody to do the narrative so China is bullish on the cohort and so far we've been right and I think we're going to continue to be right for the next three four years right just this is the video editing cohort that you guys have if he does a video editing cohort it's at avtv.com Machina runs it but I mean there and it's also like we're so bullish on video that because see text is taken away as a domain right because chat GPD has come out and a lot of people who are writing SEO content are just like fizzling out so where are they going to go it's video and Google if you see above the fold now showing three videos right because they're now going to do a full thing so if SEO is going to go something is going to take its place companies have realized this right all the largest companies now come to China and just say hey how can you do video for us so we saw such a big opportunity um therefore you know she kick started the cohort but anyway coming back I think this is great as a horror format right now I think there is like seriously somebody's going to make a channel that does horror and video maybe text to video like this tweet says that I predict that generative video will emerge the form of media in its own right yeah so maybe we won't get text to video in the way we are getting text images which is extremely accurate images based on how descriptive you are yeah but maybe text to video can be a new style of video yeah I'll tell you one more problem I'll tell you one more problem with images and video okay this is just in usage patterns so when you use mid Journey you get four outputs give me more variants how do you use text to images I'm very like pessimistic about art jobs right and the main reason is this right if you don't like an output you can generate a thousand pic correct with video and even with code you can't easily do that even code I'm uh I'm bullish that will help engineers and a lot of Engineers will be 10x 100x Engineers but everyone we need to know know how to code right and the main reason is you get a code base or you get a full video let's say you want to change three frames in the video okay let's say you've given a prompt saying okay uh Rahul Ravid sitting and sipping coffee on Mount Everest right and maybe some part of the video is not great right maybe he's sipping coffee the wrong way or his pinkies out or you want his pinky out you can't go in and change that now because now the entire video will change it will generate something from scratch with rahul's pinky out but the Mount Everest behind it will change that's right now though yeah that no even in the future right you don't have fine control over any of these AI models even with stable diffusion you don't even with mid Journey you don't you can't like even if you tell mid Journey oh I want a character sitting there sipping a cup of coffee it's not exactly what you want and if you want to remove that cup of coffee you'll have to take it in generative by the way I generate an image of uh this is after my channel contact I generated an image of and the prompt was that hey it's an image of an Indian man sitting in front of a computer Studios on fire and he's showing the thumbs up yeah okay and it generated accurately yeah so if it's like one specific action that you want a person to do no it's about change say you like an output the problem is this right you love an output you want one change now you're done you can't do anything yeah you can't be like retain all of this  this happens on big Journey as well yeah I can't be like retain the posture but just change the clothes I can't do that exactly and for that you'd use generative fill right so the equivalent of generative fill for video is very hard because if I say okay this one small thing in the background I want this to be something else now you need to have frame to frame consistency so it's very hard to do generative fill and that's that's a video editor's role honestly right like if you want some graphic to come in or whatever and then swipe out so what I believe with text to video text to image particularly is a lot of people look at a lot of outputs like you would have seen four outputs of the thumbs up people like I like this one correct the minute you want to edit that you're screwed but with code bases you generate an entire code base and you're like oh I want to change this one file now you need to know how to do it now you need to learn how to code right so you have create it's like we have this thing called in in Tech called create read update destroy right if anything on the database simple operations or create read update create means you're creating a new piece of something read means you're just looking at it and and whatever uh read means you're just looking at it update means you want to change something and Destroy means you want to delete it so we have crd we don't have U correct right so you don't have edit capability if you're okay with abandoning the edit capability like in the sense of generate thousand image variants and pick the right one then great but if you wanna go like if you want to edit anything you need to have skill sets so let's try it let's try to generate something so what we're writing is Steve Jobs sitting on a mountain drinking coffee with a pinky finger out right you know where I think texture video will be very useful in few years stock footage like if you don't care about the exact Fidelity and you're just like oh I'm talking saying something about Egypt just show people in Egypt walking it is great almost like b-roll b-roll it's great for b-roll because there you can see fourth generation will be like I like this one the minute you want edit capability now like I want this specific thing changed you have no control you have no Fidelity so you can create a lot of like Montage shots and or video with like where you want it's like a hype video and you want text on top of just something narrates narration almost like Ambience ml founder right another one who works in texture video but for faces and usually our model has everything but if you want to like in the middle of the video you want the character to turn to the left or right you can't do that sorry okay always something see to it yeah it's not getting the it's not doing the thing pink finger out but one day this will be great for stock footage it's pretty good for General feel of what you're going for but not the exact thing yeah I think the stock footage to create a movie or a video will be available at some point like you want to do Terminators walking in and Arnold Schwarzenegger looking at them like running around if you're okay with sacrificing Fidelity this is great let's try creating something which is just like an ambient film over which you can overlay text to make like a hype video right so say for example shooting stars in the sky in the sky with text on top no the text we will add though so shooting star shooting stars in the sky yeah um yellow clouds with rain with rain yeah this is perfect this is stock footage his stock footage and this is what it's trained on also so it will generate something really good so yeah I was talking to a Founder who who's worked in ml for a while he has a text to video platform but for face like for Talking Heads and he's like we've got everything like you you've given some words and it'll do it for you but we don't have Fidelity like if you want the actor to look left and say something or move their right hand on frame three and say something sorry you can't do that so you lose edit capability but the create capability will be damn good like in five years it's going to be so good you just you don't need to turn anywhere for stock footage okay let me ask you a question if I own a production company right now that produces specific scripts like there's a script that's written with a celebrity in a specific manner where they need to behave and see a certain line is my job in danger because of text to video generation no I think she has a director right you want that final control you want Alia Bhatt to look slightly 35 degrees to the left saying something and putting our hands up or being super excited there's a reason retakes happen right they'll want you to retake 10 times the problem with this is you need to look at a thousand generations and it's not like right now we're generating stock footage right but let's say the entire segment is a minute long do you have the energy to look at a thousand different generations of a minute long video and then pick the right one and say oh this is the base there'll always be something you want to change but on set it's very easy for you to change that right for you to say okay move to the left slightly do this slightly do this slightly and directors 99 of the time whatever I've seen they're always asking for micro changes so as a director right now I can ask a person to go from A to B right and AI can make something go from A to B but actually the process of going A to B requires you to go from a to 8.1 to 8.2 to 8.3 to 8.4 to 8.5 to eventually reach B which right now ai is unable to give you any possibility to change something at 8.3 8.48 it's called the word is called Fidelity right and what I'm saying is you can't even do it Fidelity in images like it's so hard to do Fidelity in images but images are very easy to walk into like on Photoshop or something and change small things out right or with images you can just beat it with volume generate a thousand correct find maybe you like the 18th one or the 18th one you can just be like let's roll with this it's one image but with a video every frame it's almost like every frame you're looking for something right so it's almost like that same thousand multiplied by the frame rate multiplied by the number of seconds the video goes on for I don't think anyone has a patient to look through so many generations interaction companies can breathe safe for now yeah but I think stock footage like if I'm doing a narrative like we will definitely be using this to create narrations like if I'm narrating something and I don't want to generate the b-roll people use this to do b-roll like sky is Stars people moving in Egypt something that's generic I would I would use this oh play this playlist this video is ready so good this is great for as stock footage yeah it will replay stock footage assuming a marketing creative you want some stock footage type stop stock image type thing in the back then you'll have a super then you'll have maybe some shadows and stuff right it is possible for you to compose it but the minute you want to do that in video you have to do it for every frame technically your video editing at this point right but in the near term the process of creating something granular or finer in video that process can be made a lot easier yes for example if you want someone to change their language if you want them to lip sync to a certain thing yeah if you want to change just a just an expression there'll be a bunch of tools that will come out that will make your life easier like an editor will probably spend one tenth of his time on a video that he used to spend whatever so right now ai can make macro changes to a video everything I know it's not just video it's video code basis images you can generate macro changes macro changes but and very micro changes yeah but you can't Stitch the two right now yeah like that's the hard part that's the hard part that's the part that requires intuition and cognition and yeah but what you found is it's also a function of user Behavior right users are okay with images if they generate a thousand images they'll be like I like this 118th one let's roll with this they are not okay with code because if you do that with code things will break so and I built a tool called autocode you can go check it out whatever right so it's part of the same uh things but we built some something called autocodepro.com where you can actually generate code but we see the same issue like there are thousand code Generations a day are not a code Pro right now same issue right people generate the code base they love it now they're like okay this task manager May they've generated a task manager let's say like yes now you need to learn how to code so you can create scaffolding even in video yeah but not the finer details yeah actually right because the minute you want to do the final you can it's the same in images but with images people are okay with just generative thousand variants and just be like I'll roll with this without edit right so it's more user behaviors not has nothing to do they they all have the same limitations it's user Behavior so there are some parallels between Ai and what it's doing in images and AI what it's doing in video Yeah in images you can create micro changes to something for example I can create Virat kohli's face yeah and replicate it on anybody um in in video I can change Virat kohli's lips and change it from one language to another language yeah because it's been trained on that function so technically your face swapper in mid journey is a separate tool from a journey by the way correct correct so inside face on Mid journey and you can do that with video also that let's say you generate a half decent face I can swap to the real face correct right across the entire video that think of it as a separate AI tool so what will happen is you'll generate stock footage now you have like these 10 AI Tools in front of you one for face swapping one for something else and that's what Runway is also doing by the way we've got a bunch of tools track this character out track this character in 100 Dynamics okay replace this with a different character so it's almost like you have a toolkit and you're working with it same thing with images your toolkit inside face generative fill they're all toolkit like stable diffusion the so stable Fusion on locally has a UI called uh has a has a tool called automatic one one one one which is basically a UI for stable diffusion plus it's packed with a bunch of extensions and stuff they were like 30 40 extensions so you want to now generate text you want to depth map for text you can do that separately you want to upscale the image you can do that if you want to restore faces you can use something called code former so there are a bunch of different Tools in one package so I feel like the big threat is to Premiere Pro or after effects right where they will have to incorporate all these as like 10 different AI tools which is what Runway is doing and which is what Photoshop did with generative film they're like yeah workflow camera so I feel like it they'll be great tools and the only thing is from a user Behavior perspective people are okay even and you don't like one word you can just write it off so on the curve we're at the part where AI is able to do generate macro structures for text video and images for content for content and very specific micro structure micro changes for text video and images but when you look at the whole thing cohesively something still feels off it feels often text it feels often images where ranveer Singh's face will be exactly like his face but the dude in the background will have seven fingers right same thing in video I can make Virat kohli's mouth lip sync in a different language but some  will be off in the broader broader video like you know there's a dog inside with the images I'll tell you let's say you generated a picture of ranveer behind ranveer there's a guy with seven fingers you can discard the image I'll generate this hundred times until I find something one image where there's all the fingers are tough to do you can do that with video you can't do that because frame one will have one guy with five fingers frame two will certainly be seven fingers and you're done yeah you're done for and every time you wanna just make that one micro change you have to regenerate the whole video exactly only looks different in each one thanks exactly ah this is the this is a  irritating part in AI but it's just it's almost there but not really let's work on something okay yeah I'll complain about overpowered okay our logo sucks we don't even have a logo we don't really have anything right so the intro thing was generated with uh mid-journey and then we some editor animated it uh the music is from nuclear yeah and by the way I'll tell you the very interesting story of how this happened was sitting next to me and I was like we need some intro music and then was just like let me uh nuclear and he's like nuclear do you have anything that you're not using right now can I can I just use it and nuclear sends them a Google Drive it's just like this is all my these are all the tracks where I I've never touched them in the last six months take anything you want that's it like yeah it's super cool yeah nuclear is my Google llm music llm so we don't have a logo so right now we're going to try and create a logo on mid-journey I tested some stuff out at home I tried to recreate a logo for my channel and turns out that if you give very specific instructions like create Vector art using simple lines it can actually do a very decent job of it it doesn't do text very well so let's do it Let's uh generate okay uh robot sitting in front of a computer laughing laughing Vector art logo simple lines graphic design graphic design let's do uh robot what about a stamp like a retro stamp yeah but with like futuristic robots Okay because India is like famous images from India if you have actually Google it you'll find some stamp stamps okay a stamp an old a retro stamp style a retro stamp of a robot in India let's just do this  um a retro spam of futuristic Indian robot let's see what in front of Taj Mahal Taj Mahal is the intro no hmm okay so it created these characters these are boring this is really cool let's see let's see what the evoke like some sort of happiness really cute what do you think it's cute I like the style of a stamp though I like the style of a stamp there's just something nice about blending the past with the future yeah but instead of maybe just a robot what if we did a robot and a human holding hands holding hands or like a humanoid a cyborg a cyborg I love this stamp yeah it's a cool stamp okay try that again let's try imagine a retro stamp of a robot and a human holding hands retro stamp of a smiling robot showing the thumbs up or did I say a retro robot or retro stamp of a robot of a humanoid dancing stamp style Indian oh I love the first one it's scary but I like it's like depressed and scary but I love it bro the second one is nice right the second one is happier I like the first one it's it's angry or sarcastic or whatever yeah dude I love the first one do I really really really like the first one I like the third one also the third one was so nice this is the robot dancing do I really like the first one it just eventually you'll have haters and it's a great thing to show them let's look at the prompts for the one that you like a retro style what did you say all right smiling robot showing the thumbs up can we do the same thing thumbs down no just just copy that copy that uh this thing the first one that this one not the first one just copy that prompt let's make it let's make it slightly happier that robot retro stamp or retro detailed do you wanna try niji on this let's see what happens yeah stamp of a smiling robot dude I really like the first one laughing robot showing the thumbs up dude that thing is so good the niji version doesn't work for a logo yeah go to the one that you like and just click on variations no you wanna add or change anything oh you can Now remix prompt yeah but it won't be perfect of smiling robots showing the thumbs up India in India in the background no no no do Taj Mahal Taj Mahal in the background so this is the niji one I like this it's decent this is nice see you asked for variant so that first one none of these look like that that one now the first one in this looks nice it's happier it's the same robot but it looks happier no the background's changed that's why I said you can't you don't have that level of fidelity like this one looks aggressive I like the aggression it looks happy but also depressed you're a  weirdo ah there you go the third one I like the third one it's not giving you Taj Mahal though yeah but yeah it's not it won't give you exactly what you want but after tinkering around we can probably like right now or you can edit right you can go and generate a fill I mean it's a process but because you're in mid-journey and we don't care so much about Fidelity you can generate like 50 variants of this right now our packaging is like a futuristic Taj Mahal and then the camera Zooms in with like cars and all burning around where it can zoom in and it can at the end of it they can just be a robot that's doing this and it says overpowered comes behind the robot or about the robot that's what we can do uh but I really like this robot something perfect about it let me just generate variants without remixing any prompts you don't like this robot so nice it's aggressive the fourth one here is also aggressive yeah it's evil bro the fourth one Terminator what if they change just do a variant of the first one let's put the word cute maybe we'll change something you know you know you know you know what you should do you should just say minimalistic logo comma dribble minimistic logo commodrable now type whatever you want yeah robots with a thought bubble this one is nice no yeah that one's cool yeah everyone's cool let's see if that just scale it up and see that one's very nice by the way this is a great example for those watching of how customers end users end up using this we want something else we got this like this is also nice let's roll with this and this is a common occurrence both in images as well as with text yeah with code it's not like this for some reason and share with video right it's like you want specific control robot minimalistics I like this I like this a lot yeah I just put overpower below this and I think this is nice this is cool it's got six fingers oh  uh but that's okay I think we should keep the sixth finger yeah just as an homage to the early days of AI yeah early days of AI uh yeah six fingered robot is kind of symbolic actually yeah of early days of AI anyway this was our attempt at trying to make something uh you guys should try making a logo for whatever business or initiative that you guys are up to or if you want to make something for overpowered we're gonna play the intro but the intro will end with zooming into the Taj Mahal with nothing but blank at the end of it you guys can fill in create a new logo animate it whatever you want just go crazy and if someone makes something really cool we'll probably adopt it and uh you'll get paid for it sorry for the random interjection in the middle of the episode way more of you watch our episodes than the number of you who have subscribed just subscribe and we will give you a gift I promise you if you subscribe you'll get a digital gift short but just subscribe will show up in a timeline once in a while keep up with the world of AI with us back to the episode I read that mid Journey has had an update maybe a month ago where they now do product shots really well okay so product short uh product shot of coffee packets minimalistic black logo let's do this coffee so brown or brown coffee packets minimalistic black logo of a company called uh roast House Coffee so check this out okay it's it it's done product shots of this coffee brand this gives you such a killer idea of what your brand will look and feel like when it's on a product so great mood board great mood board and you can do this for other stuff also product shots of stationery for a brand called cutify station or cutify stationery mascot is a small Hardware you want to give like the rough colors right cutify stationery colorful honored table Studio lighting share these images dude this looks professional as heck you can put this on a website almost immediately with some minor editing you can put your logo in and you can create a website in no time yeah and you can literally do variations of the second image try variation or second image it'll probably give you similar but on like a different table you know this is interesting now when you click on variations you get to change something in the prompt but it's not that good like it won't give you exactly what you want you're better off regenerating a new image because it'll the base image influences too strong by the way there's something called chaos in mid-journey did you do the same thing same thing okay in the ending type dash dash C 75 brown color brand name now dash dash C space 75. what does this do between every generation it increases the randomness of the Next Generation okay so it gives you more varied outputs and you're able to pick from one of those outputs but since we are not optimizing for Perfection with this generate a thousand or hundred pick one we like I'll roll with this that's what most people end up doing I really like this but you know what this output is also decentral role of this consumer Behavior here is different this is chaos High chaos oh this is high chaos okay yeah so the it's more variable yeah in its Generations yes this one's really nice yeah that was really nice do this damn good yeah holy  that's so good I love the colors on this yeah I'd buy the  out of it so mid Journey combined with Photoshop now is deadly like it can you can output way quicker like if I was a client and I was briefing any designer or packaging person I would just spend like an hour on my journey it just makes my idea so clear It's Gonna Save everyone time yeah the designer knows exactly what you want and they just need to make minor tinkering which also means that they're spending less time they're spending less time probably also effort going into finalizing the design is a lot lower so do you think that results in lower pay yeah but higher volume yes higher volume that's why I said it's all about the brand if you're a designer dude top one percent of every field is going to exist they're basically going to be making edits on top of AI in every field okay the thing is if you have a big brand name you're probably getting lower pay but you have a thousand clients correct and it is possible for you to get a thousand price right that's what tech companies work on the fact that they're working with a lot of clients at the same time so if you were a designer would you tell your clients to get mid-journey so their briefs to you becomes more clear they have a better idea of what they like before they come to you this is an incentive alignment problem you don't have the incentive to show the clients my journey in fact I've received some DMS saying why are you doing overpower why are you showing why are you revealing the secrets to other people but come on it's not going to stay a secret for much longer right I would say move to a task where where it's just clients will need to edit will absolutely need to edit and the edit takes time I would say pivot to a job like that don't do thumbnail art okay don't do static One-Shot images uh mid Journey one more place mid Journey struggles with is image to image consistency again same thing right so if a client says and we've tried this before we're making a game with Virginia like we need these five different screens right all screens will be different even if you feed the first screen as a reference to the second screen it just looks different so we had to generate like in some cases like two thousand three thousand variants and be like this is the perfect one because we obviously don't have the skill to go into the image or make a brand new image and be like this has to be consistent in the last one because my journey produces such great outputs you can't match with the next screen let's say the lobby screen will not match the home screen or whatever right so given everything that Journey can now do mid Journey can do super sexy photographs mid Germany can now do super sexy illustrations mid Journey can now do logos uh mid Journey can now uh do all kinds of graphic design so if you're a graphic designer photographer an illustrator what is a way in which you can make more Revenue uh let's come to the revenue piece in a bit I'll tell you the simple algorithm okay it's not fully fleshed out I've been thinking about this for a while but it's not fully fleshed out think of what requires full brand kits because frame to frame consistency matters you can't have a brand where five different things look they're all cool but they don't match each other those pieces are where you can win because your first seed will be generated by mid Journey let's say one of those images and you build the rest of the brand around that one image that is why thumbnail artists are a little bit shaky because you're doing one image and you're done there's no need for one thumbnail to match another thumbnail you see anyone's YouTube channel all their thumbnails look different right and image to image is decent there the minute you have to do an entire brand kit for a company landing page this that whatever booklet and all of them have to match unless they're all matching the sense that you have one image and you're just sticking on top of the booklet let's say the booklet has to match the entire theme of the other stuff then I think you have a good competitive so check this image out okay this is for a packaging of a coffee company like I'll show you this problem in real time okay let me upscale the third one okay we really like the third one we really like the software I'm going to show you the problem live because this is an opportunity for you and if you listen carefully there is an easy way you can actually make a lot of money doing just design okay you have this image now I'll show you the problem okay I'm gonna copy this image you can do right click copy link do slash imagine paste paste it okay now you have this is a reference image rest space now say you want this or do you want a landing page of this or coffee table book coffee table book turn this into a coffee table book book book no it's fine it's fine Studio lighting or uh on top of a coffee table and I call this Nuance right when you played with these tools for a long enough time you figure out where the opportunity is which is why everyone should play with AI there are gaps and those gaps are where the money will be made okay now let's watch this no open this in a new tab I'm going to open this in a new tab okay does it match not entirely no this is what I mean frame to frame consistency is poor so the question you have to ask yourself is how do I get deals that require me to build the entire blanket because you some some people lazy people just like crop this out and then just stick it on a book that's also possible right if you take a front shot of this but most people want frame to frame consistency and this is why video struggles this is why we chose video editing as a field right because it's just every frame is going to look different so if I were to sum it up if I was a designer I would use mid-journey to truly identify what the client likes and then my skills will be needed to turn it into a consistent brand across X number of images so easy way to do it right easy algorithm like I said find any sort of design work that doesn't require to just generate one image because there you will have competition right with mid journey and if I was a client I would not waste a designer's Time by giving vague briefs which is what a lot of work is right now the client will send you this the client will be like options whatever yeah so my journey can actually help you just do a lot more work in the same amount of time and and your inspiration mood board like it helps you and the client agree on what what style yeah yeah uh avoid one-offs right avoid thumbnail art avoid um marketing creators with the client only wants one creative a lot of times that happens they only want one creative um avoid anything that's a one-off so yeah if you're a designer watching this it's time to go full stack see that's the thing now design eventually people move into oh I'm doing the entire brand for the company now I will measure my words here because there's something called style draw okay which just released paper release around the code base is released which allows you to do frame to frame design consistency right but I've never tried it I don't know what the outcome is like um and either way I think it after the first image is generated you will still need to put a lot of effort in making the other images match so time to go full stack yeah be a brand manager or a brand designer so there was a video that I saw of someone on Instagram talking about how they can turn themselves into a 3D character and make them talk yeah so it still looks a little bit fake because the head it's not just the earlier we could just make the face move now like the entire head moves little bit there's some you know variance in the movement so let's show you an output uh let's take this image of mine okay let's run it through did and let's run the process and here is the output hey guys my name is Varan and I was gifted a computer at the age of seven which led me to playing a lot of video games which then led me to suffer in my exams what do you think I think this is super interesting it's cute it's a toy right now but eventually as it gets better you'll be able to create different avatars of yourself do you want to see it get better how watch this foreign actually this is replacing just this part so you shoot some base footage where you're just like standing and like moving your head a few times and now I can record anything so I don't like creating content I think it's a pain in the ass thanks and uh I think uh having this Avatar of me create content is to me is a Big Time Saver so this is interesting and people will use it for a lot of cute things in the beginning which is you'll be able to style yourself in different visual Styles right now this is 3dr tomorrow you can make yourself in an anime style animated video you can do it in different styles and eventually Porto you can put yourself as a 3D render in a video game and truly play as yourself in FIFA in in GTA you can you can you anyone will be able to Output themselves and put them in a proper simulated simulated environment absolutely you know you know what I'm worried about not I'm not worried about it but I think there's a good opportunity here a lot of very good video editors who have good stories to tell but too shy to get in front of the camera you know there's a big bunch of people who correct who are like this you make them all powerful right now correct right because now they're good at the introvert stuff which is staying on the back end doing some research figuring out what to make a video on editing that video good graphics Etc and now they've always done it as a service for other content creators but if you're able to put yourself with the crazy personality and whatnot then you do it yeah this is confidence as a service confidence is a service yes right and and also you don't need Studio you don't need the setup you don't like it's just straight text or script to video which is why don't use strategy video to make these videos it's internet is going to be flooded with them now find your unique Insight find where you have the depth uh that's I think where the opportunity is going to be all right Nvidia stock reaches 1 trillion market cap do you think Nvidia can get larger than a trillion yeah if if we think on the curve we are at the early stages then yeah I think Nvidia is positioned to be one of the top companies along with the big four right like people are making tweets about how the n in Fang is now Nvidia and not Netflix yeah Netflix struggling what does Nvidia have that AMD doesn't have a lot of things I think Nvidia is better Tech the gpus are better also at least for tasks like machine learning there's something called cuda which is great with Nvidia and it I've never even explored the AMD version I know somebody was planning to make an Nvidia competitor uh or allow machine learning on AMD cards make it as simple as what we it's not simple but make it as easy as what we do on the Nvidia side he gave up after three days really yeah there's a tweet like he gave up after three days okay so he's just like I hate AMD close all my shoes bye so uh no I don't think AMD is a good competitor that's what I said right like I invested what I use I don't use AMD I've tried and I used to be the kind of person like nvidia's mainstream reviews AMD you know not mainstream I'll be the guy with the alternate whatever it sucks so the things go mainstream for a reason I guess right now one trillion I think has a lot of zeros I don't know if it's overpriced underpriced I'm sure some famous stock market analyst has this thing uh I just don't know hmm but really a lot of zeros have never been there I don't know what it takes to be there in the last six months we've seen um the rise of two people to be at the front and center along with Elon Tim Cook Zuck which is Sam Altman and the CEO of Nvidia I have a question that's not related to all this actually what do you think of the Sam Waterman event in India so by the way Thunderman I have a planning to go and then said let's not go you want to tell them why I said we shouldn't go a because it was very last minute B I knew that if we went to the event we won't really get any sort of one-on-one time with Sam I just told you that it'll probably be like 30 seconds and we'll get to take a selfie and I don't want to be that guy who just takes a selfie I think if we continue to work on overpowered and if we continue to do you know output products out work with developers build a real AI Community we will get a warm intro with Sam at some point at some point Sam will hear that hey there are these guys who are doing an AI thing in India where they have a pretty large community people follow them maybe it's worth doing a 30 40 Minute Podcast episode yeah so that's why I said that we should not go to this event just to click a selfie like I don't want to be that guy sir one picture please sir one picture please and you click it and it's always like they're getting whisked out of the room and you're on the way just you just click the picture and they look listen have you seen some of the pictures send me a picture of someone who took a selfie with Sam and just said you were right yeah yeah I knew I knew this is what it would be like uh so these events are I mean I get what Sam's trying to do yeah he came for the Prime Minister I think that one picture with Sam and Modi will travel far wider than anything else he did um and also an important event like this does is the whole startup sector talks about it and the more everybody feels like holy  yeah is here literally the CEO was here he's being the Prime Minister and he's doing this thing so it makes like have you I've seen an uptick in the number of startup Founders talking about AI publicly yeah like they were Whispers And murmurs like three to four months ago and now it's like the catch out of the bag it's pretty obvious now that everybody needs to be AI assisted um me and maroon also have been discussing because ever since we started overpowered there's just been a lot of inbound of a number of people who want to Tinker around with AI but right now we were just doing content but with figuring it out how we can actually work with companies and startups anyway I'm all for more such events I think the more time Sam spends here the more but it actually genuinely boosts the interesting AI from the whole startup ecosystem um and next time is here will you go depends how much time we get if five minutes sitting in the crowd not worth it right because you'll get called out of context I would rather have him here Sam come let's discuss uh you're always invited yeah please please come on overpowered and please tell us how we can build a foundational LM that can compete with charging sir you tell one how to please disrupt one anyway as for today's episode of hope I hope you guys enjoyed it do hit subscribe and get cracking on your logos get cracking on the packaging we'll see on the next one bye ",
    "url": "https://www.youtube.com/watch?v=wv8vgbi5ToM"
  },
  "0Lwy_NE4xhc": {
    "published_at": "2023-12-18T12:27:10Z",
    "title": "Google&#39;s new Dreamtrack is just Insane\ud83e\udd2f",
    "text": "Google&#39;s new Dreamtrack is just Insane\ud83e\udd2f now basically I can make fake videos and make fake audio so Google came up with two new music tools but the first one is something where they've collaborated with artists like charie three pain all these artists that we listen to and they've cloned their voice so it's kind of similar to RVC and they have their own music generator so they combine both these artist voices and the music generator together in order to create something completely new baby we've got nothing in common but I know that I'm what you been wanting for so long this is interesting because this is actually a real use case like there are times where I'm editing a vlog and I'm just I'm just so reliant on okay what is some copyright free RIS music that I can take but I would love it if I can put in saying generate a one minute track with with this feeling this is what I'm doing in the Vlog this is the wi that I want",
    "url": "https://www.youtube.com/watch?v=0Lwy_NE4xhc"
  },
  "QZOnuYOYi3M": {
    "published_at": "2023-10-09T13:24:59Z",
    "title": "Google&#39;s AI Search for India: Discover Answers at Your Fingertips!",
    "text": "Google&#39;s AI Search for India: Discover Answers at Your Fingertips! remember we had covered a news story about how Google has now launched generative AI search now it's finally rolled out in India as well and you get search results which are more India Centric and customized to our country okay so I'm thinking let's try some India Centric search right like how to make cab German okay let's generate generative experience it give me the result in Hindi that's pretty cool let's say something with code right like how do I write a simple C++ Tick Tac to game pretty cool written the entire code for me how do I bowl uh yker they've given me results you can now have the ability to ask Google a question and get an AI generator overview of key points and you also get reliable sources so you can dig into them so generative search is just an easy way to save a bunch of time clicking through links to find the appropriate result it can give you like a summary or a checklist of whatever you search for so you guys also go try out Google's generative AI search and let us know if you found something interesting shout out to Google for sponsoring this video",
    "url": "https://www.youtube.com/watch?v=QZOnuYOYi3M"
  },
  "2ndeweSA9wE": {
    "published_at": "2024-07-24T01:00:02Z",
    "title": "Talking to AI Tanmay Bhat",
    "text": "Talking to AI Tanmay Bhat let's do a live call with character AI T hello how's it going my digital friend hey who is this I'm just an AI chatbot here to chat what is your name what do you do I don't have a name in the usual sense but you can address me as tan bot tell me a joke tanay here's a joke for you why was the computer cold because it left its windows open that was not funny why aren't you married yet as an AI like me I'm not capable of getting married marriage is a social and legal human individuals when the guy said tan May Bart it's like such an obvious giveaway like pronunciation is a big part of cloning someone right how far are we from the AI model pronouncing things the way I would pronounce them no it's not very far it's all about coverage I think this was trained on very little data of you the way the AI B pronounced T but would be how the median Indian let's say would pronounce t whatever the Bas model was the model weights are shifted slightly towards your accent but that being said if you have enough coverage today it's nearly flawless",
    "url": "https://www.youtube.com/watch?v=2ndeweSA9wE"
  },
  "_YyGsZPX24k": {
    "published_at": "2024-01-23T14:28:53Z",
    "title": "How AI Just Disrupted E-KYC Human Verification",
    "text": "How AI Just Disrupted E-KYC Human Verification money is like gravity it goes from a place of actually uh money is like gravity it goes from the sky to the ground no actually let me money is like um my AI has broken guys what happened to money is like electricity it goes from a place of higher potential to lower potential it goes from place of CH and put it in and give me the best option that it produces self-driving car I saw this video it kind of blew my mind of all the cars I thought that would be self-driven I did not think an alto would be self-driving can someone explain how he's doing this the Tweet says my secondhand redmi note 9 Pro running flow pilot is driving my alto K10 how so I called the guy by the way right after this I saw his tweet before it went viral I think I think it went viral on LinkedIn a few months ago though I called him I said hey do you want to come work with us shamelessly he said no he's working on his own stuff but I got to learn a little bit I don't understand you know self-driving so well but what he seems to have done is there's this open source project called open pilot by George Hots he's the engineer who went to Twitter got you know left in a few weeks said I'll fix search and then had to leave so he uh ran this thing called comma AI so it us your car's cameras many cars have cameras or you know Comm itself comes with a camera system it looks around your surrounding and then it says okay this is how I should move the car so what this guy did is he built on top of it right he built on top of comm's open pilot it's called flow pilot and then he said I will use one camera because the AO K10 doesn't have cameras I will use one camera from the redmi note 9 and I will use that data feeded into the car and then the steering wheel will make adjustments accordingly that's my understanding of what happened and I think it's incredible because just last week ntin gkar he came and said we will not allow self-driving in India because he said that self-driving is bad and should be banned and drivers will lose their jobs and just next week I see this thing floating around so yeah it's incredible that we able to do this but you know regulatory wise I don't think it's going to fly also I'm not trusting a phone hooked up to my rear view mirror yeah if it starts out updating then that's that at least if it's an iPhone I'd have more Trust on it I mean I I don't think this is like a commercially ready prototype you can't drive it in any but I think to make it a point he actually said that it's a secondhand redmi note 9 yeah yeah it's just to show you that we're at the bottom but it's fine dude this is wildly risky no and he's not he's he's not even driving like the city but he's there's sitting there oh he's sitting there it's pretty cool though dude we have we haven't figured fig out man driving yet where we'll figure out self-driving yeah but I think there is a myth that self-driving will not work in India I think at some point it will work it might not work everywhere in India and of course if you know if two people start fighting in front of you the car will just stop it won't know what to do but I think see a computer reacts much faster than a human being it can see in slow motion technically even Elon Musk is pretty bullish he's like to to a computer everything is in slow motion the only problem is how to react to certain commotion in road that you know even humans don't know like if people start fighting in front of you what do you do you just pick up your phone and start scrolling reels or you watch the fight the car is just going to be stalled for that period I think that's the main issue cell driving not going to give us speed benefits because people are going to be fighting and all that computers react great to some sort of predictable Behavior right the entire point of machine learning is to take unpredictable environments and figure out how to navigate them but there has to be some sort of underlying pattern that that you're able to sp there is an underlying pattern even in Indian roads there's an underlying pattern really it could actually happen on highways and stuff yeah I'm not saying everywhere and people think India people think very unidimensionally they think either it's some you know dumpster like it's some really bad place or it's like you know highways of Delhi or whatever I'm saying India is like multiple places and I think some of those places you can't take a self-driving car and it'll just push you into manual mode it'll be like I can't understand this environment and some places like highways I'm pretty sure it can you know uh continue to drive for you in a certain way yeah I think a self driving car once it goes on a highway it will refuse to go back into the city but I think regulatory wise it won't be allowed it's too many jobs why don't you call nin gari and ask him if he wants to work with you is this what you do every tweet that goes viral you just ping them and be like hey come let's start a company no I wanted this guy to come help us with Hardware he's very smart person he's just working on some uh project of his own so he's he's already committed but it's my job to find good talent I guess dude this one guy replied saying my redmi note barely launches Instagram how is it driving your car classic classic Indian comment yeah that to secondhand red me note dude yeah this is not like a technical demo it's a statement if you buy a brand new Alto it comes to You Secondhand so this is like secondhand redmi and secondhand Alto a firsthand Alto looks like secondhand Alo it's pretty impressive all right Sid explain what is mobile Aloha this is basically sort of a open-source robotic system that basically does a lot of different tasks so it makes coffee for you it chops your vegetables it folds your clothes it makes your bed and uh the cool part about this is that these guys open source this entire model so you can actually order parts and uh you can actually set it up at your house it's just that it costs like a bomb uh uh but the code and everything is pretty much open source so I'll just uh play this video so it cracks eggs it does all these kind of delicate movements and the way this uh thing basically learned is by showing it videos of uh humans uh do the same kind of tasks there are many pieces to using the mobile aloh hard thing like people these days have gotten very used to making demos that make the thing look very flattering but there is some human effort behind the scenes from what I read so you can actually use it in both ways so that there are things that it does by itself and there are things that it does uh where a human actually is involved in uh making it do things as well T would you buy a robot I don't know I think a a d cost like 20K a month and she can make unlimited omelets yeah but this is like dollar $40,000 yeah I until it's cheaper than Dei it's hard to make a case for robot I think nathin gar is going to ban this also that's the problem with Banning self driving cars it's not that you know jobs won't be saved of course jobs would be saved but I think when you ban self-driving cars then you have to ask yourself okay do I ban Cooks do I ban Maids do I ban every job role from AI automation because at some point like this year is going to be the year of Robotics in my opinion and and putting AI in robotics is going to be like the easiest thing to do it's not easy but it's like it's the obvious thing for manufacturers to do so what are we going to do like just ban this because we're like this takes too many jobs this takes too many jobs then you're being becoming a jobest right because you're saying these jobs you can't remove these jobs you can't remove software Engineers but uh I mean I understand the scale differences right I know that a driver the number of drivers is far more uh in in quantity but the thing is the minute you say no AI then well they're technically using AI for navigation so many drivers will technically be using a version of AI for navigation in the future using AI to navigate means that guy on the road who says right his job is fully disrupted now it's not just that right it's like they're anyway using AI but you're not allowing AI for the entire thing so it gets like very dicey which is like which jobs do you protect which jobs do you not protect which job would you trust a robot more with or would you want a robot to do more drive or cook right now I I would prefer it to cook actually right now I would not prefer robots in my house for a bit I would just prefer them to be entertainment uh because we're not there yet but what I'm saying is there will be some point like 5 10 20 years down the line where it gets good enough where everyone trusts the robots enough right and the thing is these decisions of do you ban this do you not ban this we have to make now for technology that's going to rapidly improve and then you'll just find that there's a major efficiency uptake the minute you get like self-driving right like and we might have to remodel some of the roads for that right but you get such a major efficiency uptake that the question is on you whether you want to keep India away from that efficiency uptick and there's a big debate a lot of people in my comments are like yeah these these sort of jobs need to be protected the other people are like dude till now every technological progress that's happened in India people have been like no this should not be allowed in the country like every every technological progress somebody or the other said this should not be allowed in the country so there's like this big debate and the thing is I don't know what the right answer is but I do think we have to be compassionate there was a time where I said yes self-driving cars we should get that robots we should get that but now it's like the number of jobs that will actually go and those people get displaced with nothing to do and they can't upscale on time and what are the jobs they even go to even if they go to another job what if that gets disrupted a few weeks later like how do they live and how do they survive what happened in 2 weeks what happened to you I think happened but self-driving is like a lot of number of jobs gone but would would compassion really matter on the face of efficiency I'll tell you something Logistics costs India 14% of its GDP right and that's internal Logistics I don't have the difference between internal and external Logistics but let's assume internal is a big chunk of that you're losing so much like which used to go into salaries and truck driver salaries and it's too many jobs what if those people do you can't disrupt Society like that because people are just going to pick up sticks and be like hello you know after hearing after hearing warun have a change of heart you know and Von being the first robot who I befriended I don't dislike robots as much now changing side like now we should do hey if robots can change then I don't mind it I think we should do it slowly I think you can't disrupt so many jobs that quickly you need to do it slightly slowly and be like okay do we have Ubi do we have some way these people be fine there some upscaling because it's not good for society to have so many unemployed people walk around with a stick dude we as a country we are still not equipped to deal with otps okay I don't even know how we are going to deal with robots like for example uh this 22-year-old uh colleague of mine he works with me he got an SMS yesterday from what he thought was a bank except you know when a bank sends you SMS it says like IND usend or HDFC on top like the sender says HDFC right like the your Telecom service provider only labels them as the official name of the bank he got it from a number and it said that 50,000 Rupees has been credited into your account name which is xxxxxx 8975 and he was like like oh who sent me this money then suddenly gets a call from that number saying listen I I sent you this money by mistake could you please transfer it back so him being an honest guy he transferred the money back and then he realized that the first message came from not a bank it just came from an SMS and it just looked like it came from a bank and he it money never got credited so he just sent someone 50k on UPI money is like gravity it goes from a place of actually uh money is like gravity it it goes from the sky to the ground no actually let me read money is like um my AI has broken guys what happened to V money is like electricity it goes from a place of higher potential to lower potential just open Chad GPT and put it in and give me the best option that it produces don't think my point is we are still we are still dealing with OTP okay all this is you should not read your messages there are too many scammers like I don't know why people even read their text messages just scam WhatsApp it requires some effort to get a WhatsApp number number to send out messages and meta can ban you pretty quickly with normal SMS it's just scam like I I've never opened my SMS and I haven't opened in like 6 months there's nothing that important in your SMS it'll appear if there's something important appear on your email also that's true yeah my smss are mostly Almost 100% kyc related stuff I think the next slide is also kyc related H even kyc is getting disrupted T next slide how does this work what is this so t with stable diffusion now there's a new technology called IP adapter face ID okay now I don't think this particular image is using face ID but they're still using IP adapter or some form of Ip adapter where you're able to feed it an image from the AAR card or whatever and then it will make you a person that sort of looks like the AAR card enough to fool any kyc system so it can it can replicate a photo so if I give it a photo and say now take this person and put them in XY Z yeah yeah so the text there waso was photoshopped right or you can use control net you basically use a font that looks like handwriting but yeah you can full verification posts pretty well even with video I think you can fool it with deep fix uh and the only thing the the dangerous part now is I can take a picture from your AAR card and I can make a character that looks sort of like it so even your kyc thing that you said in the last uh few seconds is getting disrupted um I think we will go back to physical kycs for a bit as this gets more rampant because the problem is the scammers haven't got a hold of stable diffusion yet you can still do kyc with I mean your official documentation is with the government right like so far no sometimes forgot password requires you to put up an image like I don't know if you know but some of these Brokers you can do forgot password with hey here's an image of me and I'm asking for a password that feels like that could be 100% disrupted but like okay now for example like a I'd say about a year ago uh zero knowledge kyc technology is officially available right like most of India's documentation is on digilocker and if third party apps want to Ping it you can now use Zer ZK ZK to Ping and not not even third party apps don't even need your actual data uh but they can still verify that you're a real person and get away with it but all video kyc stuff is like yeah I can see how that's like that's a problem now yeah but more importantly tell me how I can show one face and replicate it replicate in different situations so there's this new technology now called IP adapter face ID I don't think this one's using IP adapter face ID so now you put pictures of yourself and you can get a reasonable thumb like we were using it for YouTube thumbnails but you can get a reasonable looking uh this thing in fact I'll show you I'm just loading It Up Show properly how can you can you put my face and replicate yeah yeah yeah so earlier when we when we made Alpha C what was happening was we do a like basically it would get your face likeness but it wasn't getting your face structure structure yeah right even mid Journey doesn't get your face structure well like there's something off about your face structure with mid Journey but now IP adapter face ID gets your face structure reasonably well so I'll show you you you you'll like it let me just load this I'll show you a real time deep fake tool after this which I found out which is pretty insane you should do that this will take 2 minutes to load up so talking about deep fake this is this is basically a deep fake tool that kind of runs on uh stable diffusion turbo which is uh like a very fast model of stable diffusion so I can basically type anyone over here let's say I type Shah ruk Khan and I turn on my camera and I click turn on now check this out I think consistency needs to be changed I have a question though like I have have an interesting idea what if you did this in VR I saw this but this is really bad guys like this is not it's not there it's not consistent it's not consistent not it's not it's not there it's not stable I want to know how to how to upload an image of yourself and have an AI model put you into different things cuz that's not good yet but but varun's thumbnails here have gotten way better yeah so I'll tell you what I'm doing kind of revealing Secrets but it's fine so there's this new this thing called IP adapter face ID so this is comfy UI it's a nice little node editor for stable diffusion and related Technologies so here I can load the IP adapter it's called face ID sdxl so I'm using the sdxl version um and then there's a Laura also for it which is a low rank adaptation like a small you know adapter on top of the original model that does the face modification it's called IP adapter face and then I'm choosing a base model it's called called yammer's Perfect Design or something and then I'm also adding another Lura which I really like called dual pistols which gives a nice little effect uh I'm I'm pretending like I'm understanding all this but sure yeah then I pass it an empty image then I apply the face ID the only difference is I'm applying it twice and then one interesting that I'm doing uh just to get the face consist consistency a little better is I'm face swapping it at the end again and then upscaling that restoring that basically that's it this the flow now if I want I can also you know use control net and make it look like some image that you really like can you now that you've taken my face can you put me and make me a different image with my face that is accurate yeah I'm doing that it's loading let's see how it comes out I'm using all three pictures same picture of th I can use different pictures also yeah so I'll show you some pictures I've generated so some of the these look weird this pretty funny but pretty lifelike this one these are all generated this is a cartoon version it looks a little carry catcher is yeah I made it car catcher oh you wish uh then I made one more where I'm eating food and I prompted 30-year old man in this but I don't actually look 30 which is good makes it look too old yeah when you turn 30 do you develop three extra fingers yeah hey okay this isn't too bad this isn't too bad yeah so this then this is a different model oh this is fairly accurate yeah yeah some models do it better some models do it worse like but it's more or less solid like I would say there a good uh this is also this is also decent wow did you add give me a jawline in each of these images no I just put up old pictures of myself I I don't have any new pictures I need to take some yeah you have to have a bath for that V so yeah this is comfy for those that want a refresher you can start on YouTube but it's every day this changes so it's a big headache to by the way we actually teach uh two weeks of comfy on our generative AI cohort so it's just two weeks of pure comfy uh different kinds of custom workflows uh how to make these kind of uh you and that you see on the screen yeah beginner and advanced and if uh multiple things if you don't get help in learning is it quite uncomfy we'll make it comfy for you by the way your thumbnail is out you want to see the thumbnail yeah let's watch the thumbnail what do you think T oh not bad not bad at all from the input images got it pretty nicely yeah can you can you input another this thing saying man eating food or something like that like take something else Brown 30y old man eating noodles noodles this is another one it generated a new one not bad no not bad yeah it's pretty good I've used a Lura that gives it this nice Vibe looks it feels like one of those professional movie shoots you know like a movie poster type movie shoots yeah it's very smooth there you go see it's getting your face structure a little better this looks cartoony for some reason 30-year-old slightly heavy man sorry T man the pictures I'm using your face will be too big otherwise at least thanks thanks for using slightly at least yeah you're not I mean you're just uh you're tall this nothing you say is going to save this conversation now just generate the image give some better prom V Maya piece of standing next to said man Brown 30-year-old slightly heavy man it's not generating Brown At All by the way no it is wearing futuristic white jacket as a pilot on a plane this is better than what what we've gotten previously yeah if you give me better pictures of yourself I can get better outputs oh nice nice this is not bad no oh this is not bad you just need to put text on it so we'll put this in Alpha CTR which has the text component as well this looks a little weird yeah the sometimes it generates weird thing and also I know how now now how to make images look little less AI like after the image is produced you add a little bit of grain on it so on comfy I'm making the workflow where you can add a little bit of grain on it yeah not on picture please no off this doesn't this looks nothing like me okay uh let me change this is are we doing this exercise just to insult me that's the feeling I'm kind of getting right now I feel like you guys are trying to roast Me by even suggesting that this square SpongeBob square tanay is me it looks like a cartoon version of you let's do this man as James Bond red background James Bond holding dual pistols you see this oh this one is pretty nice yeah James spond is pretty nice dude th you can use this as like a thumbnail right now you just need to clip this out and in the back you need to put some text okay got it so it has gotten better yeah it's gotten better for sure and if you give me more images of your you right I can chain like 10 different IP adapters and I can just make like a like this looks fairly good in my opinion no it doesn't but like who holds gun like this like wait I'll show you another one I'll show you something else holding wearing a magenta suit this is the this is a completely different model okay so these outputs will look very very different this is where we started putting your pictures before this I was by accidentally I put one of my pictures as well so these are where it  started for some reason these came out card get the structure very nicely yeah this model is nice the one I'm using right now it it'll look very realistic the model I was using right now is trained on some 3D stuff and all that till now that we were using this one is trained only on human pictures my bet is that in the next 6 months you won't have to go take pictures cuz you'll get like even now if you give me enough time and I have enough you know face ID adapters it'll take more time to generate an image but let's say if I have six of them in a row then uh and six images of you then I can get the face structure fairly accurately what do you think it's better it's more it's a more realistic this is nice it still can't get the hands right though oh it's this looks like little bit yeah actually it yeah it looks little bit like me yeah that much though it it will be little bit like me no it looks like you no it doesn't look it looks like me not a lot like me it looks like me no dude it looks like you only dude like if if we show the picture to someone and say that who's this they'll obviously it like me yeah I agree it looks like me is it that accurate this one is not bad are we just going to ignore the four fingers I have and like I was just going to pretend like oh this is this is not bad this is not bad this is pretty good by the way there's something I want to show so so we basically did a video for the J goart did you happen to see it play the video no premium GP premium CH GP course I want to learn AI stop taking these useless jat GPT courses learn how to build real products and projects using gen look over there at 100x we are serious about generative AI we play with it every single day and our Engineers have shipped the first gen products come out of India we're doing a free live masterclass on intro to geni where you will learn about AI models like llms diffusion models fine tuning these models autonomous agents and much more this is actual gen engineering not just chat GPT join us on the 12th of January at 600 p.m. it's completely free register here an interesting ad so I I just wanted to show that robot part that is something that we did uh using a normal camera using an iPhone and we used this tool called windows Studio the cool part about Wonder studio is have you guys seen this movie called Ready Player one so this guy is basically one of the co-founders the lead actor in the movie uh the guy who plays the role of paril the guy who eventually uh okay I don't want to spoil it but basically the lead guy he is one of the no way really yeah yeah yeah that's actually him dude Spiel spelberg is on the board Jo Russo is also on the board oh that's crazy so this guy loved working on the movie he got really into like VFX and things like that and he's like I want to start a company in this and what this tool does is pretty magical so this is the final footage but the way people arrived at this is using something like this it's a normal footage of a dude and it does moap for you map is sh for motion capture there's one more new one coming out called simulan that does it straighten the iPhone so I'm very excited for that but but I'll show you what's the cool part so there is one scene where this robot is sort of jumping that is something that we basically uh it's a very tough shot to do so this is just the robot jumping but the original shot was basically just Spider-Man so it kind of figured out the motion capture of Spider-Man and we put the robot skin on top of it oh and you used Runway you used Runway ml to extract just the Spider-Man is it yeah so how much longer sit before instead of the robot we can put anything so these guys have to basically release models so if you actually go to home you can actually see their pre-made models and the thing is right now you can't really create your custom models all you can do is basically make your own stuff I thought you could though no so there is another tool called move one which is a tool that is available only on iPhones move one does pretty much the same thing you record yourself on an iPhone it does MO cap for you now what that does is it gives you a file that you can actually export into to your Unreal Engine or blender or whatever your 3D um um moing platform is and there you can create your own custom characters and actually put those on the map so the robot was basically just me walking in like this is the original footage nice it's pretty cool the next thing uh okay again I'm slightly deviating from the slide so this is a tool called liftoff you can basically use it to do mock interviews so you can basically do a mock Tech interview let's say you want to apply to Google or Amazon or any of these companies and you want to simulate an interview sitting in your home so I can click whatever kind of interview I want whether it is technical or like soft skill based and what it essentially gives me is something like this so if I hit record this dude will ask me a question and I have to answer it so I'm going to answer it in a bad way so that we can see what feedback it gives me tell me about yourself why don't you walk me through your resume hi I'm Sid and I work at 100x engineers and I've been working for 10 years and and I'm good at what I do so now it basically transcribes whatever I've said and it gives me feedback so it exactly transcribed what I said and now this is the feedback the candidate's response to the question tell me about yourself is quite brief and lacks structure the response does not provide any substantial information about the candidate's professional background blah blah blah does not use any structured framework such as star or par to organize their response okay it's not real time it's not a real time interview it's just gives you feedback on so it's just transcribing your video and telling you what it thinks of it uh so the thing is I clicked on transcribe right now I could have just resumed after giving the answer so it would have asked me like more questions and uh yeah but all it's all it's doing is transcribing the video and using GPT at the back end it's just responding to it like it's supposed to give you feedback pretty much pretty much yeah of so Google interviews and all these Fang interviews have a certain kind of a format that they follow so it is basically trained and fine-tuned on these kind of interviews it has basically given it a probably given it a data set of successful interviews of uh of these companies so it is able to provide you with that kind of relevant feedback okay so maybe for like a technical interview it probably makes sense but otherwise you can just create a GPT know you can just create a GPT that says give me feedback on interviews yeah but at the end of the day interview is all about being in front of the camera and you know being confident and all that sure I can set in my laptop and I can type it out but when you're there it's a whole different game I think when you know you're interviewing with the GPT you feel less anxious when you know you're interviewing with a human being you feel more anxious yeah but did you see the human year hi tell me a little bit about yourself walk me through your resume I don't feel like I'm with the it's not the best it's not the best in real life would be some laa like this is a gimmicky tool I won't use it it's not actually useful but you know I'll tell you where it might be useful t if I was interviewing someone there a lazy way to do it but if I was interviewing someone in if I was interviewing a lot of people for a role let's say a junior level role then I'd just make them do one of this and then I'd see the transcript only yeah like I'd ask you to pre-core it or something why don't why don't you just email them questions they won't respond that's the problem and you also want to see their visually how they respond are they like in general you can tell right when somebody like I use this tool called hwire to do interviews now where it's a video uh CV tool because I'll tell you the problem the problem with rums is resum\u00e9s are you insert certain keywords in them to beat tools that accept rums right and platforms that accept rums they'll be like okay this guy knows SQL so uh we'll we'll put him on top so I think the real way to have always judg candidates is on what they say and how their interview goes that should be like 99% of the process and I think they weren't able able to do that at scale because how do you process so many interviews right that's why use a resume it's like a shortcut but now this combination of your resume what you've done in the past which you can also say on an in a interview now because you can transcribe do it real time have a real time interview happen without you being there you can actually give thousands of candidates the same opportunity that you give candidates in the era of resum\u00e9s where everyone puts their resume and then it's like a sort of like a keyword mining system right like Whoever has the best keyword sort of gets the next round here you give everyone fairness in a way even though people feel like oh interviewer is not talking to me so why should I um why should I even take the time to respond but hey you can respond at your own convenience whenever you want and you sort of beat the unfairness of the resume system so I think it's it there's promise but also I think this tool is a gick this tool is a GI yeah for feedback and all you shouldn't take feedback from AI it's not going to have the cultural context of India especially correct but from the PO of a recruiter something like this can act as the first round of screening basically yeah like I can get from a list of 100 people to 20 people using something like this yeah we use a tool called Highwire to do this it's it's pretty decent you guys should check it out it's okay guys next next next what's the next tool perplexity perplexity is basically a search engine that is officially sort of call the shots for competing against Google they're saying that they'll uh they're going to try and make Google dance that's literally what the CEO said why everyone why everyone wants to make Google dance bro Microsoft also wants to make Google dancex to make Google dance is like that was a good joke that was a good joke that was a good joke come on jeez so the way perplexity AI is different is it basically uh so let's say that I want to do to uh top 10 places to eat in Mumbai it gives me answers in this kind of a format but the thing is um so if I do the same thing in Google it does the same but the thing is in Google it it all depends on who ranks for the best SEO it's like a pretty competitive market over here here the difference is the real value of using perplex City over Google comes only when you use it consistently because it actually takes into account it's very conversational so it has context of whatever you're asking it so uh the results are basically uh very much fine-tuned to whatever uh your preference is whatever your past search history is and it doesn't show you ads that's basically what their proposition is I don't think they're going to make Google dance though perplexity is interesting but uh um I don't know I feel like Char GPD will do this like I really like the value prop and the idea and whatnot right like I also think the founders very smart so I think they will eventually build something very unique and differentiated and whatnot we use perplexity for some scripting at this point so it's very useful the only problem is I feel like if this gets really really big a chat GP will be like hey they're eating my lunch and they might you know pivot a little bit or maybe have this offering as one of the GP or something but I do know that perplexity now has their own custom model uh so that it's not just them using chat GPT and then you know just feeding it references and data they they're now working on their own model as well so just like chat GPD can become them uh perplexity can also become Chad GPT in a way uh I have the perplexity app on my phone so I actively use it and I use it far more than I use the Chad GPT app so yeah why is it that much better than chat GPT d it gives you references like CHP hallucinates a lot perplexity anything it says will give you a reference so I can look through the original article and wherever it found it from and be like okay it's not bullshitting so it's a little less hallucinatory in that sense do you think it's better than searching on Google though uh do I think it's better than searching on Google dude I use both like I feel like people are very quick to say that guy die this guy win I think smart people end up using all tools no fair Fair all right interesting stuff from CES did you guys see rabbit yeah this thing was all over my Twitter and I didn't get the big deal about it can someone explain to me why this is a big deal actually yeah first play the video uh it's a pretty long video so what I'll do is I'll show you the one minute version that we did on 100x is the rabbit AI R1 it's an AI personal assistant but what can you do with it you can play music you can can book a cab Dem me ride from my office home now please confirm the ride or you can plan an entire trip exploring ticketing options to make your trip a reality for your trip I found various flight options you press a button and give it commands like Play me the song or book me a trip and it will plan your entire trip for you you just have to press confirm it can search images and also generate images using mid Journey if you integrated it also has a built-in camera that actually rotates which I think is one of the coolest things that you can find on a physical device and you can get this for only $200 for more AI stuff follow 100x yeah it's basically a physical AI assistant that's what it is but I don't think there's anything on it that you can't get on a that you can't put on a phone honestly I I'm very bullish on the team I'm very bullish on the uh company and the people I think the product's not a great um I mean the product looks very good it's made by teenage engineering and all that but I think um people feel like and I've said this a multiple times but I'll say it again people feel like we use our phones to like book cab and like buy groceries and all that I don't think that's true I think we use our phone sort of like a drug delivery device right like if you've seen if you watch Brave New World the TV series uh or you've read the book it's by Alis Huxley they have this drug in the book called soma where every few hours they keep popping this drug and they feel better it's like to curb you know anxiety and and boredom and whatnot I feel we use our phones in a similar way you're bored you're slightly anxious you pull out your phone you scroll I'll tell you a stat okay if you're 18 years old you will spend the rest 93% of your life scrolling your phone can you believe that so most of our time goes in spending in consuming content and we consume content to load up on dopamine because our lives are slightly boring and whenever we feel bored or anxious we consume this content with the rabbit R1 they're removing that that saying no this is not a Content exploration device you're not going to be able to binge watch videos here but you'll be able to book cab and do utility stuff I think you do maybe Max 5 minutes of utility work a day on your phone maybe 10 minutes of utility work therefore I believe that they're going to find the retention time is too low and people are going to go back to their phones but see I understand if this is the only device in the world right maybe this is the first set of phones then it would get some you know good traction but I think people already have phones and those phones already do more now what is unique about them is that large action model which I can guarantee you firstly somebody's already now made it open source right they made a large action model open source secondly why wouldn't a Google or an apple do this it's so obvious for Siri right like this is what Siri is supposed to be and apple just is revamping that entire team so I don't know how they'll survive long term against that but also if you can build Hardware once and you can do all this you can eventually find a niche that you'll work in so I'm not very bullish on the first version even though I'm sure they'll sell like this looks great as a collector item I'd buy it just to be like I own this and I'm sure they you'll sell maybe 100K units on the fact that it's a collector's item uh but beyond that I have no idea have you guys seen the play date this is also made by teenage engineering okay I love I love teenage engineering their design aesthetic like their what they do is like super cool dude I'm making a full video on teenage engineering do you know teenage engineering has one of the highest gross margins in the world really for Hardware yeah because think about it right look at what they've put inside this this is this is roughly $199 16,000 rupees this toy with old old games you know those old games you'll find these toys in the in Indian stores for 200 300 rupees you can buy it before you go on an a aeroplane and stuff like that it's really cheap so imagine the margin because they're like hey I'll do it but I'll make it cooler and you should see some of the like speakers and they have a tape record of 1.2 lakhs yeah seen them but that tape recorder looks so good it looks so good that you're like wow I want to buy this like it's called um try op1 no it's not op1 it's tp7 sorry tp7 said you will love teenage engineer I'm surprised you haven't seen it cuz you like like music right yeah I've heard about them but I haven't really dug deep into them it's just a tape recorder it's like the old tape recorder you can buy for 500 rupees it's 1.2 lakhs but it looks so good it feels so good and you should read the writing okay go down I want you to see the writing see how they do sales go down there's this thing called off record the interview is going quite well the situation gets heated you suddenly ask some personal questions in that moment you gently place a finger on the re and pause the recording allowing you to continue the interview off the Record very artsy so people would buy the rabbit R1 because it's a nice collector's item because teenage engineering has made it and it's a good way to get like a $200 teenage engineering product but is the Delta that big like why can't I just do this on my iPhone why do I need a separate device for it like I don't think the Delta is that big it's not it's more of a collector's item I feel the thing is if Lambs work then they're in trouble because Apple will do it and Google will do it Android will do it if Lambs don't work then well their loss that's why Apple goes last Apple's like let me see what everyone else does let's take the best features and pretend like we made it revolutionary like I still don't forgive Apple for coming out and saying we are now introducing spatial Computing where meta was like metav verse AR VR and apple like no I'm going to invite a new term it's called spatial Compu it's the same damn thing but they're like I'll reinvent this for the masses and now Sony has started calling their device spatial Computing device because Apple's already named it so yeah but I'm not I'm not very bullish on the rabbit r one but I like the team the product looks very cool all right friend that's for today's episode if you enjoyed that hit the like button follow us and follow uh 100x Engineers on Instagram as well thanks C for joining us thanks Von for generating awful images of me and saying it looks exactly like me it looks exactly like you  bye",
    "url": "https://www.youtube.com/watch?v=_YyGsZPX24k"
  },
  "1m4PAiExVuk": {
    "published_at": "2023-07-10T13:30:00Z",
    "title": "How These People are Doing 4+ Jobs Using ChatGPT",
    "text": "How These People are Doing 4+ Jobs Using ChatGPT ladies and gentlemen extremely happy today because I have just discovered that the overpowered Instagram channel has overtaken one of my Instagram channel in terms of number of followers it's been only a month and we're already there were my YouTube channel now at three lakh subscribers hit that subscribe button we need to pass varun's Channel immediately I took seven years guys to to hit uh 200 and something and who knew the best part of you was being a Doomer that's what people liked apparently yeah it's damn sad like it's three weeks into it into overpower we crossed 100K uh whatever followers on Instagram and I was like Wow and then a week later we were like 210 none of us realized it hit 200k so one day is just like congrats on hitting 200k guys and I opened it in his 210. so I've never seen growth like this and uh yeah it's it's sad anyway uh so someone was messaging I think it was achina was messaging on the group saying uh guys we should go celebrate and I think me and Sagar both responding doesn't feel like we've earned it no I don't know what just doesn't feel like we are earning it anyway we're gonna celebrate at one million so hit that subscribe button follow us on Instagram and let's start today's episode what do we have first Varun we have something called control lit I kept hearing you use this phrase when we're discussing Alpha CTR can you first tell me what is control net um and what does it do how is it useful so see with stable diffusion you can generate images right assume there are two parts to stable diffusion now the popular Parts the first one is you have a model which is a stable diffusion based model and then you have this UI called automatic one one one one it's an automatic one one one one yeah it's a weird name automatic one one one one but the idea is it's like a fully packaged tool Suite to work with sort of different parts of stable diffusion right stable diffusion has a lot of things in the package now not just the core model but it's got things like upscalers it's got like a bunch of tools so it's almost like the Photoshop uh yeah images yeah but all based on stable diffusion now control net is one of the extensions think of it like that which also comes with its own model okay and control that it's got multiple types of model but the one we use on Alpha CTR is something called canny idea is very simple okay if I have a reference image can I make this output image that I have as close to the reference as close to the reference as possible right so it can do things like pose matching it can do things like depth matching so you can do lots of fun stuff with AI with control correct so controller is effectively like a feature with stable diffusion like it's it's like like a feature for the UI yeah feature extension yeah think of it like that like stable diffusion the core model and in fact we'll just show you control net in action so here's the automatic one one one demo so we have a model for stable diffusion called deliberate V2 right it's a nice little model you can find all these models at civit AI you can also use ours if you go to Alpha CTR and I'm just going to prompt something in okay I'm just going to show you Superman with an apple in his hand okay simple as he does okay we're not going to use anything on control net I'm just going to show you what the regular output is like okay clearly he doesn't have an apple in his hand but as you can see the the outputs are better than stable diffusion's outputs like stable diffusion vanilla will give you bad output it doesn't have an apple in his hand but his hand looks like an apple yeah his hand looks like an apple yeah but let's do this let's go to Google let's find a nice reference image okay man eating app okay so we have let's say this oh it's a nice little image also using control net I can make an image that is like roughly shaped like this yes so now I can go to control net I'll just enable control net and I'm going to drag this man eating apple here I just have to make sure it's the same size uh same same prompt ah okay now let's generate okay got it oh there you go there you go right but as you can see it's now slowly generating Superman eating the Apple in a very similar form I do that's pretty good yeah got it so control net is like an extension that can help you Tinker around to generate the kind of images that you want yeah so so a lot of people on on red there's actually an entire subreddit for this we will make sketch art like you want to do a comic let's say and you know in the comic roughly there's a stick figure that's doing this next pose is doing this then the guy is doing this so you can feed all of that into control net and get that person doing those different pose references something like that it'll generate something like that but it won't copy the pose God so this this the post part is really cool and I can also reduce the weight right I can say that well I want it to be less like the reference image that I put in I want to be more like the prompt it'll find some nice Middle Ground so for example in this it can mimic the pose that we have given as a reference image yeah but and some objects and how customizable can can we make it for example can we say uh Batman eating an orange yeah actually make it an animal no because it roughly recognizes that there is a there is a person holding something so bear eating an orange okay let's find out all right right so it picks up a lot from this and if I reduce the control weight yeah let's say if I go really low on the control weight it'll sort of use that as a guide image but it will take its own creative liberties with the rest of the world so now the like the the ratio of man to square has changed yes can you increase it can you increase what happens if you ask it to go all the way control if you go all the way all the way I mean this is not all the way one is like somewhere Middle Ground you can go two also but as you can see this will be like a berry man ah there'll be some bear wipes but it's not really but it's it's giving the weight to the source image a lot more than before exactly right so on Alpha CTR we set it at 0.75 for the reference images there's a really cool thing that people were doing with control net where they were giving a reference pose and they were creating like these really fun videos of you know their company logos yeah um doing that can we demo that so we have a picture of dur darshan here this is the dudeshan logo skyscrapers in a city in a city okay and let's make sure that this weight is one so we'll use the line art controller as a line art model so we'll use that so the reference image that we gave is like line art yeah so this is a separate control and model in fact controller another model for pose it's got a model for everything got it kany is the one for pose this is Kenny is less about pose it takes a lot of things from the reference image there's a separate control net model for pose scanning is a mixture of everything a little bit and there's depth right so this is one output say uh trees on a farm trees on a farm interesting right so it's almost like it's an aerial view of the thing yeah but can you what happened say if you reduce it a little bit apple pie let's reduce it a little bit to point it the minute you reduce this too much you'll start having um leak which is probably something you want ah it's not you kind of get an apple pie like the duration logo yeah interesting let's go back to one here to see what fi output is like by the way I recommend a lot of people to get uh automatic one one one and pick up some nice models from this website called civit AI this is a website called Civic AI where you can pick out any model you want just like delivered V2 there are a bunch of models there's some for anime like I mean majority is still very good but if you want some something specific done there are lots of models that you can just pick up drop into stable diffusion and just start playing with this is like the Photoshop for stable diffusion it's called one automatic one one one the core model is still here the V 1.5 stable diffusion but it's not as great as everything else and this has got a lot of tools like you can send this to extras and I can upscale it I can use one of the upscalers that it's got I can do in painting So suppose I have this I will send it to in paint and then maybe you know I only want to change this apple I can draw like generative fill style I can draw around okay select this apple let me show you and replace with mango let's do that let me just make this bigger ones I feel like we're censoring the duration logo is that allowed to do I think so yeah so we got this and I'm just going to say hey please generate mango okay oh cute it's it's a it's a it's it's a orange yeah I try to get it in the zone that I haven't painted let's try the let's try the Nike logo I want to do that uh creating cool logos Nikki logo black black and white okay so let's take this yeah actually let's take the with the text yeah let's see what it does with the text Okay so we've taken that we're just gonna drop the Nike logo in I'm gonna say let's be more descriptive this time let's say top view of a city bit skyscrapers and buildings and trees and I want the ideal output would be if it populates oh there you go something nice is coming  me that's killer yeah that's killer that's that's killer model let's let's do more let's do more uh let's do um uh let's try Superman let's just see what happens if types of Superman this is human I'm prompting it for let's see what happens all right screwed this up take a puddles top view of uh of Puddles on a road and what yeah top your pearls on the road let's see what it makes let me just turn this down a little bit yeah what happens if we turn it down  Iceland top view Iceland top view let's see what this generates I think the text part is screwing this up interesting interesting oh I'll just say uh Prince uh top view of Tire prints in snow that should be able to generate like tracks let's see tracks it's not exactly Tire Prince but yeah but yeah this also by the way this is this way to do text effects this is one way to do text effects with AI as well a lot of people don't know how to generate text with AI it's like send a black and white version of that text AI there's actually another model Kanye model uh control net model called oh that's pretty good it's a controlled model called um depth and you can generate any text you want this is pretty decent this is pretty decent and in fact if we just reduce the control weight even more you'll have enough bleed for it to be interesting interesting just be sure to be floral print let's see what it does oh it's got the Nike logo on a t-shirt it's an interesting t-shirt style yeah but the Nike logo goes all the way all the way yeah that's interesting so I think everybody who has like a company and a logo you guys could around with this and see how you can make a vector based logo yeah put it in control net and find a bunch of generations and put some music Beyond it and you can create like a like a cool like a Show reel like a Show reel for your company logo absolutely this is a nice one all right moving on you know for a long time I was wondering is there a tool that can automate creating shots out of longer videos The Challenge here was understanding context of the longer video uh and then GPD came along uh understanding which parts would be more interesting and then finally chopping it up and adding subtitles to the video and there's a cool new tool that we discovered it's called dumb Studio where the idea is very simple right give it a long form video it'll find 10 20 potential shots clip it into shots and add subtitles on top uh this only works mainly for podcasts or long form videos where the videos already edited because it's not going to do any editing for you it's not going to do any overlays it's not going to make a video more entertaining so how it works is fairly straightforward you dump a link into it then it spend some time analyzing the video which means it's understanding the context of the video and then it chooses a bunch of sections that can be turned into shorts and then it just produces uh like a dozen videos for you it just takes away so much manual labor that someone would have to do yeah it's it's very Hit or Miss like some of the shots generates are bad but because it's generating so many shots you just review it in like yeah so I feel it's really great there but what it's not good at is the video has to already be edited like you need to have like if you're doing the podcast or whatever it's not going to edit the podcast for you you have to first edit it add your overlays if you're doing a presentation video you'll have to add the editing what not and then you can dump into this what this does great is Clips random sections of the videos based on context and then adds the subtitles on top I think that was a very manual role which is now something sort of solid yeah what it does not do is say if you have a podcast and it's just me and you talking and it won't take our Clips add newer Clips to it add stock stock images to make the clip more engaging no that stuff still and you need an Editor to be able to make it uh you know like a dopamine bomb yeah yeah I feel like this is not this is like a one tool in an editor's Arsenal like I feel like this is useful but you still have to convert this into a dopamine ball yeah in fact let's do one thing what's gonna play for the next uh minute or so is a clip of our podcast and let's see what it generates I'm saying adding design to it I'm not sure about this but may make it more interesting for somebody to like point and scan at right so if anything there'll be a slight conversion rate increase with QR with this thing and I'm assuming video QR codes is the next step like imagine those Transformers robots they're on a billboard at Times Square and they're like you click me and then they freeze in a frame right like but why would you want to spend on the video board why not just make it a static board with a Transformer QR code because a video can add more it can basically add to the CTA right you use charge GPD a lot yeah and plugins came out yeah right have you used any plugins you know I tried uh I tried the browser plugin I tried it but I tried a bunch of different plugins I'm personally not a fan um I don't think the pmf for the plugins are here yet even Sam believes that I tried zapier but it still requires a lot of human intervention to make it work uh like browsing for example the browser plugin it just breaks so often like it's not seamless like what Chad GB did was it basically became a sounding board like a creative assistant that you could use for many things so on day one you could feel pmf uh but for plugins there isn't one killer plug-in that everybody wants to use all the time that's not there yet I use the scraper plugin very often like there's a plugin called scraper where you know if I have some long website and I just want to summarize it I just send it to scraper through scraper and sometimes it's like you can also use it with a web browsing plugin but I feel like some all very often the web browser doesn't click fails yeah but on scraper it fails much less often but but why use scraping XVideos and all um but let's go through all the popular chat GPD plugins all right right so zapier is for sending emails scheduling meetings make spreadsheets what are the issue with zapio uh for example like the ideal way I would want to use zapier is I just always want to have GPT open all right and I get on a call I'm like okay cool we'll do a call tomorrow afternoon at three just quickly go in and write call with Varun at 3 pm tomorrow schedule it I want to hit enter and I want to move on but you still need to know how to learn how to make zaps connected at the back end with your like all that still needs to be done manually it's a one-time effort yeah but in your funnel 99 of people are gonna drop out at that point because anything that requires effort now you're connecting multiple things it's hard yeah so the second one is deploy scripts which creates simple web apps websites custom code hmm I think this is a lot like auto code Pro yeah right so we have a tool to do this and people just you know lots of people have used the tool can you guess what the number one type of app requested is Pawn no uh no what is the number one type of app it is a task manager oh really maybe because we made a task manager and everyone was like oh we want to make a task yeah either because of that or people guys aren't able to manage your tasks like the next one is ask your PDF oh this I've tried this this is a this is a pretty cool Tool uh you just drop in a PDF that's a chat bot you can just talk to the chat but like it it knows everything inside the PDF technically inclined with the way I ask your PDF or any chat with PDF tool works is there's a technology called Vector embeddings where you are now able to feed this data into chat GPT the only problem we've had with Vector embeddings because we've tried around several projects it hallucinates like crazy especially when you put more than one PDF you'll try to find random correlations between pdf1 and pdf2 that just don't exist the solution to this and why I feel is going to get much much better is because context window for GPT right now is like 4096 you have a small context window and you're trying to feed this in through Vector embeddings right which is a different kind of representation think of it as a different representation for text but tomorrow chat GPT itself will have a large context window like anthropic one of the competitors of gpta has like a very very large context window 100K and there are lots of papers that have come out saying we'll have 1 million context window 10 million context window at which point Hallucination is not going to be a problem sorry what is context window can you explain to people the number of words you can type in into that charge gbd box without it saying too long a message got it right so an average PDF let's say it's 15 pages you need a context window for roughly about 32 000 to 50 to paste into that chatbot yeah so because you can't do that chat with PDF and I'll use a like a hack called Vector embeddings right where they use a different representation but it hallucinates very very often there's actually a great clip of dharmesh from HubSpot explaining what Vector embeddings is on the my first million podcast we should probably play it here just to it's a really good Solution that's why I'm insisting on we should we should play it absolutely and we're going to talk about vector embeddings and why that's going to change your world um and before I can talk about Vector embeddings I'm going to explain to you how they work um because I had to go through this with my 12 year old because he was curious all right so we're going to do a super geeky thing now I want you to imagine a line like if you're a geometry class and you could put a point on that line that says oh that's like three units from the origin right it's like oh yeah point a is three and it's from the origin and point B let's say seven units from the origin so one thing we know for sure is that we can calculate the distance between those two points right in that particular case it's four if you move to two Dimensions now you have two numbers that describe every point so you can say oh point a is here at these Dimensions point B is over here with those dimensions and we can physically you could probably measure with a ruler but there are mathematical calculations based on those numbers to calculate the distance that's intuitive right you don't need to know fancy geometry it's like oh there's a finite distance in two-dimensional space where we can calculate a distance okay awesome three-dimensional space exact same thing just three numbers to describe every passable physical point in three-dimensional space now here's where it starts to get a little more interesting that just happens to be our experience so we limit ourselves to three dimensions imagine in an abstract World there are a thousand different dimensions okay so abstractly that means there's a thousand numbers that describe any particular point in this 1000 Dimension space okay now found that thought away that says we can have an arbitrary number of dimensions in this abstract World okay great now imagine every paragraph blog post anything you write you could reduce down to a point in this 1000 Dimension space it's like I'm going to capture the meaning of Sam's last blog post or Sean's last tweet and we'll reduce it down to what's called a vector which is basically a set of let's say a thousand different numbers that says this thing if you plotted it that point Falls right here and then you can plot something else it's like oh that falls over here and just like in one dimensional two-dimensional three-dimensional space you can calculate the distance between those things and this is not keyword matching this is what's known as semantic distance look how related is Sean's tweet to Sam's blog post meaning wise okay so now if you take that it's like okay well if that means you can take any concept and reduce it down to a vector that means you can measure the distance between vectors and you can find out how related two things are even though they use completely different words that's Vector embedding so what makes one is walk script you can interact with YouTube videos and summarize them okay uh so let's try you go to plugins you go to the plugin store you search for walks script box script okay let's use Vox script let's just go to YouTube let's pick on something let's let's see if this works okay I'm just going to dump it in summarize the video title I survived on one cent for a week ah you need subtitles unfortunately the create of the video has disabled subtitles so I'm unable to provide a detailed summary so this is like like I said right like this is not product Market fit right like um you need to have create this I tried this with my videos now I am Hindi and English both mix it's not able to understand so it's not fully there yet that's damn sad one plugin I really like is Wolfram okay so let's go to plugins let's use the Wolfram plugin okay what is the per capita income of uh India use Wolfram what does Wolfram do it's like for math math stats it basically is like a anti-hellucination layer for mathematics and statistics in GPD got it so it's just like a fine-tuned GPT with lots of data it's not exactly fine tuning they have I I think they're running their own sort of API that it's calling in the back end to kind of find this guy I don't exactly know how it's interfacing with gold from in the back back end but wolfram's very old in fact the guy behind Wolfram is also pretty famous his name is Wolfram oh his name is Wolfram yeah so it's got a log scale for you nice so there's also the website result for it so if I click here yeah it's it's just scraping it's just scraping the website it's hitting the API of Wolfram and Wolfram uses natural language or math input and then it's just giving you a nice little graph of this a wolf from Wolfram also is natural language yes but this is specifically for math statistics data uh even physics right so if you were to write a script and you wanted to be very accurate about numbers let's say if you're in the like this would be very useful for a lot of people infotainment you want numbers but you want something accurate got it I would rely on Wolfram then rather than what crtpd gives you yeah instead of doing GPT browsing you just use the Wolfram plugin yeah which one's pretty cool So eventually somebody's going to make a automated news generator using all these tools club together so there's another plugin by the way called Hey gen and let me just show you okay so the plugins and we go to hey gen actually we'll use Wolfram and we'll use agent okay so be like use Wolfram what is the per capita income of Britain make a video on this with hey JN let's see if this works I don't know if it's going to work so Hagen is a automated video making tool yeah it's those talking head videos where there's a person on screen saying yeah I don't like the UI on the plugins either it's terrible yeah like I I think half the pmf is there them thinking chat works everywhere let's play the video all right the per capita income of Britain also known as the United Kingdom is approximately forty five thousand three hundred and eighty dollars per year per person according to a 2021 estimate this ranks the United Kingdom 26th in the world the the output quality on the face and the lip movement is pretty good in six months it's going to be somewhere else like you won't be able to tell and it's just going to be more convenient to have like an AI whatever Creator create rather than you creating yourself great news as a Creator myself I'm very excited about these times all right create presentation slides with AI in seconds this tool lets you create slides using AI all you got to do is go into your browser and type slides dot new after you install it after you've installed it of course and you can just create slides using AI let's try it out so we are just going to extensions we're in Google Slides by the way slides.new is just a shortcut to do Google slide Slash new then let's use slice AI so you just click on generate slides yeah and I'm just gonna say I am writing I'm creating a presentation Harry Potter book seven and what life lessons we can learn from it and what life lessons we can learn from it unfortunately the tool requires 350 characters we only have 99 uh we need more characters so what I'm going to do is I'm going to be very very lazy here I'm just going to say new chat expand this into 350. I'm just really lazy hey 51 words you got to input the text you need in this box and for example we went to chat GPT and we said we want to create a presentation about all the life lessons you can learn from Harry Potter book Seven chagibiti spit out a bunch of lessons and now we've just input that into this and now let's create it let's see what it does so the outputs here let's check out our presentation Harry Potter's and the Deathly Hallows life lessons exploring the universal lessons from JK Rowling's masterpiece sacrifice characters like Harry Dobby and Snape make Monumental sacrifices one must put aside personal desires for greater good understood being selfless is an essential life lesson and then it's got some power of love and friendship and it just found an image on its own right yeah but this is a random image about love and friendship and then it says resilience and determination and it's made like this diagram one two three diagram acknowledgment of mortality and in conclusion thank you feel free to ask any questions all right not bad this is good for like if you're working in like one of those large consultancies and you need to make 10 slide decks a day you want to do quickly yeah this is good for that you just need to dump some texts and you're just like anyway you're creating  for a living so might as well do it with pretty slices but this is good if you want to quickly prop up a slide deck and you're too lazy to do it but it could be visually a lot more interesting I'm sure there are better tools that like Tome which are which create more visually engaging let's actually use Dome okay so I'm just gonna try it home this is the better slide deck tool and this is why you should watch overpowered because we're not married to any of these tools we'll just find you the best one whatever we like but I would love to be married to some of these tools if they're willing to pay so I'm going to create a new uh slide deck and I'm just going to say create a presentation about life lessons from Harry Potter books life lessons from Harry Potter books Harry Potter seven seven okay and then Tome at the back end uses gpd42 or GPD 3.5 to generate yeah uh the text for it as well so we don't have to manually do it all right so it's generated it and let's look at what it made here seven life lessons from the boy who lived introduction The Power of Love The Power of friendship consequences of greed value sacrifice conclusion it even generated nice little images stable diffusion yeah that's pretty cool so it's got power of love importance of friendship consequences of greed value of sacrifice and conclusion yeah so the visual presentation here is a lot better but I like the brevity with which like I condense condensed it into a presentation because here there's just a lot of text but this does look visually prettier I'll tell you one learning I have from building a lot of AI tools we built like three AI tools in the last couple of months right one learning I've had is I think the best AI tools are best in their domains it's not necessary that they're best at AI like the best slide deck tool would understand what do people really want to like a viewer who views a slide what does he want to see out of the slide like if you understand that brevity is important brevity means you know sandwiching 256 words into just like one point one bullet point I feel like you need to have very strong domain knowledge of slides so if you're building AI in sales you actually need to be a great sales person not a great AI person right and those learnings that you have from there will allow you to use Ai and prompt in the right direction to give you what you need so have like have like some prompts between the user prompt and what the model sees just have some prompts in the middle a middle layer and the middle layer comes from your experience and your domain knowledge like if you understand gaming very very well you would probably be able to add some prompts to whatever the user is doing or say hey condensed into this many words or do it like this or these sort of images which I think is the secret sauce so like in slides yeah there was probably a middle layer of prompting which says that make a shot make it short no sentence is over 100 words yeah highlight make make this these parts bold what slides I also did was it created a presentation where the text was in a different format each time like sometimes it was around an image sometimes it was on top of an image whereas Tome just created one generic version of it you can almost change it they all look the same and it's a lot of text you can change it uh but you're right okay let's do last one okay do you know people are doing multiple jobs with charge GPT four jobs with chat GPT I'm not surprised here is the profile of over employed people using chat GB for multiple jobs one Fang workers working two gigs making 500k trying to add one more getting to 800k a year uses chat GPT for first pass at code and to respond manager in all lower case letters to appear more organic this is what I said the middle layer where you're prompting it better yeah tell me something like Google and a bunch of these guys will figure out a way to see if some content is air generated or not like Adobe has gone the extreme end where if you generate any image using Firefly there's literally a watermark on it saying this is AI generated yeah uh can you tell AI generate code someone said this I don't know if this is true or not but like a lot of code on GitHub right now is AI generated like yeah 40 or something like that yeah so I feel like if 40 of GitHub is AI generated code why would you create a like internally why would you not want your engineers to write AI generator code it's an improvement in productivity so and I also think it's hard to tell there might be some signature where but it's trained on human data so whatever errors that humans anyway make it this is going to make a lot of people have tried to make chat GPD detectors chat GPD output detectors they've all failed oh really yeah on in the papers it's just like it just can't tell even open AI I think tried something and then eventually they gave up because they're like we can't tell when it's generated with charge GPT because it turns out a lot of people are made on that very positive note uh do hit subscribe you guys remember our goal we gotta pass Varun Maya's channel in number of subscribers we're just a couple hundred K away to do hit subscribe and also go subscribe to my channel no don't do that don't do that it's it's it'll be it'll be a beautiful day when we pass for seven years of effort and check us out on Instagram WE Post Clips if you don't watch the whole thing you can check it out uh and that's it thank you very much ",
    "url": "https://www.youtube.com/watch?v=1m4PAiExVuk"
  },
  "n6o_0tx0QOU": {
    "published_at": "2024-03-20T16:20:02Z",
    "title": "Is Bollywood&#39;s Future AI-Generated? How Sora is Revolutionizing Filmmaking",
    "text": "Is Bollywood&#39;s Future AI-Generated? How Sora is Revolutionizing Filmmaking all right it's a new week it's been a while it's been far too long vun I cannot believe that we haven't instantly done an episode on Sora let's just get into it just roll the packaging I want to talk about  Sora okay what the  are our jobs in danger this is too good it's too good it's really I think I think this is the mid Journey moment for video yeah you know what the cool part was the minute Sora came out the Imad who's the stable diffusion guy he put out a tweet saying hey we're going to get this to be open source in a bit and now I think they've done some collaboration recently where they're trying to get the new stable diffusion stable diffusion 3 which I applied to be on the weight list I haven't got it yet but I think that this is going to be open pretty pretty soon in fact the rate at which open source is going it's almost like they're edging out like somebody like Google or uh openi who puts out a wait list and says you know you wait for Sora for XYZ number of months before that open source sort of catches up because the paper comes out first so we know that Sora uses a diffusion Transformer and the minute you know that everybody else is like okay let's let's get in on that mix so I I I love where the world is going but also it is a little bit scary because it's like well what next yeah I'm on elon's side sue sue them Su sue them okay so when we first saw like Runway paika we saw all of these and they all at that point which is like four months ago which feels like years ago now they all were impressive but Sora actually legitimately takes it to the next level this is like all the other video Generation apps look like mid Journey V1 V2 s feels like V4 like it's here this is really high quality images and the distinct if if you looked at it randomly uh you would not be able to tell like there's a video of Let's Play that video now which is a Formula 1 driver going through San Francisco like that you cannot tell you absolutely cannot tell yeah you know the the thing isn't that Sora is good right the thing is AI is evolving so fast in 6 months Sora is going to be somewhere else right and there's going to be like a bunch of Source tools that come out and do this better right you know many months ago vun many months ago we discussed video Fidelity and AI text to video okay actually if we can find that clip can we roll that clip here like it's just frame to frame consistency is so hard it's such a hard problem it's an unsolved problem it'll get solved someday so there's no frame to frame consistency where you had said that it's hard to solve for Fidelity in video um how do you  explain this you told me my job was safe yeah they got a lot of compute see the the main challenge with video is processing a video is expensive right so now what they're doing with Sora is they've introduced a new technique called patches um this didn't come from openi this came from another team but they introduced a this process called patches so they're breaking down videos into patches so it's a brand new technique uh although frame to frame consistency is not like fully solved like if you watch that video of that grandmother you know sitting and blowing birthday candles you look at the people at the back there is a lot of rubbish going on but 6 months from now I think it is going to get solved right or maybe a year from now it's going to get completely solved right even if you see that alien walking through San Francisco or they they made it walk walk through some street right if you look at the alien it looks very realistic but if you look behind the alien whenever there's a character that passes behind the alien and I saw the same thing with stable video diffusion as well right whenever you see a character pass behind the alien and the alien moves the character is now different so if someone goes out of view and then comes back it's a completely different thing that's coming out so I think film directors uh might not be completely okay with it because they're like characters are disappearing appearing it's very easy to tell especially if it you know it's on a big screen but that being said 6 months from now a year from now this is this is going to see a lot of progress um one thing though which you know will probably you you can be a little bit more comfortable with your job because of this is that it's very hard to kind of get two generations where you only want to change one thing cuz because they showed a demo where they showed a car going through some place and they said well give me the same car but change it into mountains the background into mountains give me the same car but Chang it into you know some futuristic synth wave environment but if every anyone noticed the car changed like all the cars are different even though they're the same red car it's like there are differences in the car there differen in where the lights are placed etc etc it's like those subtle differences where you're generating the entire world again right like a sort of um seeing what's in the frame and saying I'm going to regenerate this there are always going to be slight differences so any director who wants to shoot a shot of let's say aliia butt going to the left picking up some coffee drinking it putting it down he still can't do it very accurately with this and the longer you're prompt right like you you made the Johnny's ad that's a very long prompt it's very hard for you to give Sora a prompt and say Hey I want this entire thing done and it generates exactly that you know a lot of the fascination with really cool video like for example you take Mad Max okay like a lot of the fascination for  this is impressive is the fact that you knew that this was made so you at the back of your head the effort that has gone into making it kind of contributes to the viewing experience I'm wondering if that will remain with AI because with AI um there's you're always circumspect to okay how much was this um like how hard was this really like with Avatar James Cameron literally spent a decade inventing a thing to make it look like another thing so there was still like this awe and appreciation for it U so I'm what do you think do you think appreciation for actual film making will still be there um like uh that movie that Richard linklater made about the boy he followed someone for 12 years and then recorded their whole life effectively um that was again High effort Cinema do you think that that charm of being impressed with just with the effort of film making that contributes to the viewing experience will that still exist let's talk about fiction for a second okay um I think let's say Sora gets to the point few years later where you can generate an entire movie with it if you're talking about pure fiction then T you know this better than anybody it's all about high quality writing because you need to prompt Sora right you need to prompt basically every frame of Sora or every you know scene of Sora right which technically ends up with you generating a script now you could take the lazy way out or the convenient way out and say gemini or uh chat GPT is going to generate that script but everyone knows you want control right chat GPT doesn't have as much cultural context of India it wouldn't have been able to write the Johnny's yeah but maybe cim could have uh unlikely but the point is uh you still need a very high quality script and you need to also be very granular about what you're writing in the script for example if you have a character and the character is wearing like a red CA it' be very specific about the red CA the the detailing on the red CA maybe send it a bunch of images of what that red CA looks like so what you're doing writing that script I think to be very honest that's been the hard part of making a movie you know cuz shooting like technically yeah you you know you can hire people you can also do it yourself but like writing is where most of the meat and the magic is and technically when you use tools like Sora what it expects is a prompt and the shorter The Prompt the more it makes  up right it the more it fills stuff up with stuff it wants my problem is Sora right now even with high quality prompts what I've seen MKBHD put up some videos right dogs legs are merging into each other and all that's fine I think those will get solved but the problem is it's still it's not exactly what he prompted it right like the like he prompted a 3D printer printing something and it's not exactly what he wanted right at least from that prompt so it's making stuff up it looks very good but it's not your vision the gap between what's in your head and what comes out of Sora is maybe 50 70 80% right uh which I don't think most directors would settle for so I think it's all about high quality writing and ultimately you're going to watch a movie for the writing for the storytelling and I think the visuals it doesn't matter as much as this if the story is really good if the thought behind the story is really good it's yeah it I mean it all comes down to story and characters and the emotion behind everything yeah like I don't think effort is ever rewarded right like in any in any field like I'm sure there are movies with like 10 years of effort but like 10 people watched it right and at the same time there are lazy movies yeah and there are lazy movies like there's this movie called Man From Earth which I really loved which is like all happens in one room right so it's like I don't think effort is ever correlated with the Success commercial success or audience love for a movie uh I think it is storytelling and I think storytelling still requires you to tell Sora exactly what you want and if you can tell Sora exactly what you want in the real world what the director does is tell the team exactly what they want anyway so all that's happening is uh you're sort of the director to team communication you're sort of making that an app right in in the form of Sora that's what I think now tell me in images if I ask if I ask mid journey to create a purple colored cute looking dog yeah uh with big big eyes long bushy tail and just have this creation going on in the background big eyes long bushy tail uh with a yellow colored uh scar on right above his butt yeah in in in images once I pick this character can I generate many many images of the same exact looking character no doing multiple things not yet not yet but at some point it'll be solved because I'll tell you why why this happens right with images is something called clip I'm not going to get into the details but what happens is if you're taking an image and you're generating another image like that image with the same character whatever what AI does is first it reads the image tries to understand the image so you send it an image of this scene it'll be like okay this this Frame right it'll be like okay there's a TV in the back there's a guy uh he's whatever color he's wearing two rings he's wearing a watch so it's compressing what is a very complicated scene into text it's making it a prompt and then it's rein putting the prompt into mid Journey again to generate something similar that's the problem it's not understanding every single detail of the frame it's using text as the medium and that's lossy you lose a lot of information when you convert something from a video or an image into text uh but at some point and there's some technology like style tuner and stuff right where it seems possible for you to have consistent characters and a lot of people claim they have consistent characters and I've seen many stable diffusion like on comfy UI have many different stable diffusion um packages that sort of create consistent characters but they're not really consistent if you look at the clothes of the character between the different different frames it's like one has a tie one doesn't have a tie they're generally blue the dress that the character is wearing but it looks different across different different frames but that should be solved like I'm I'll be very surprised that that's not solved a year from now and it should be solved in video as well once they find a way for you to extract information out of an existing frame and put it into a different generation without using text in between yeah I think if they the moment they solve it in images it's only a matter of time before um they solve it in video I have a question for you though um and this is a real question right like a real world question not a hypothetical question would you use Sora for any of your ad shs right now assume it is available tomorrow I've already been thinking about it and I've already like I've been talking to my co-founder about this um almost every other day Okay the the problem arises with consistency in some form needs to be followed in the whole creative and that's the part that I just asked you about which is that's not been solved yet for example I think if you told me to Market a pharmaceutical drug using that blue alien I'll figure out a connection I'll figure out a way to write a script and I'll figure out a way to generate visuals of blue alien doing this blue alien doing this blue alien guy doing this blue alien guy doing this but in each of these Generations the blue alien guy is going to be different so it's hard to tell a story yeah that's what I mean by frame to frame consistency right it's still not solved as much as you know there's been so much phenomenal progress the alien in different frames is going to be different especially across different Generations is going to be different but assume that was solved then would you use it yeah then you can do a lot of stuff if consistency is solved dude if if you solve for consistency you're solving for storytelling because storytelling is nothing but character building and if you can make one character do XYZ you're telling a story so if you can at least have consistent characters that look similar like this is why audio books work right because the voice is the same in of the character you can give a character a voice and you can have it have the same voice so I don't even need visuals to tell a story so if I'm telling a visual now imagine an Audi book where one character's voice that it's imagine this character is of a soldier in scene one soldier sounds like like me in scene two it sounds like a girl in scene three it sounds like something else you just won't be able to feel any emotion towards that one person because feeling any kind of emotion requires you to requires there to be consistency in the thing you're feeling emotion towards and I think that's what that's what's missing right now what about control I'll explain what I mean like you had this I'm I'm going back to the John's at because I think everyone's seen it there's one thing where she jumps off the the thing and then he jumps behind her right you need so much control for that scene like you want specifically where it jumps specifically how the camera angles go which you won't have that much level of control with AI not yet I won't have that much level of control but if you give me character consistency I'll be able to write around it like if if if if I was able to generate Johnny sin's type character andv Singh type character but if I wasn't able to generate this scene I'd be like it's okay this this combination is what I want to do other scenes with you'll work with the limitations that exist right now right now the limitations are too many but I am okay to work around some but if if it's too many then it's hard to tell a story yeah but stock footage you agree would get Sol like if right now because if you're if you're anyway using like a pixels or something for stock footage and you have this I think this is pretty good for stock footage you want to show like some trees or some Museum or something I think it's pretty much solid yeah stock footage is done it's done so I don't know if shutter stock or uh gy have collaborated with open AI cuzz they are done effectively cuz once I have once I have Sora I don't need them um so yeah so I I can write scripts around stock footage stuff if you can write scripts around stock footage stuff but again no character consisteny so huh if Sora can generate Motion Graphics which is just like oh this blue colored blob explodes on screen and it creates a it creates a wide array of vibrant colors exploding in the sky that eventually form a word that says vun logo animations logo animation that  is also absolutely useful and Skiller um imagine if I could feed music and say animate it animate it to this music animate the words X Y and Z that match cut to the beat of this uh with each beat the camera moves closer and closer to the word yeah I think you can do some of this logo animations at least maybe not the audio part yet but you can do logo animations with anime diff so you're right uh and even I agree that I think character consistency is the most important thing uh you know one more thing that was solved kind of accidentally or because of a combination of AI tools was you can actually make Sora characters talk yeah it's just a combination of a bunch of different yeah now yeah I think I agree with you that character consistency is like the most important thing like if there's character consistency I would use it like all the time I agree I think I you want to know I hope they don't Sol it quickly maybe for at least 10 years I don't know I just want I just want to just you know lead a good life until then you know what is another really cool use case of Sora which I thought was the more important thing but like everyone forgot about it Sora can sort of emulate games or generate games right so there's this m Minecraft thing it's on slide three so it says I'll read this out Sora is able to simulate artificial processing one example is video games Sora can simultaneously control the player in Minecraft with a basic policy while also rendering the world and its Dynamics and High Fidelity these capabilities can be elicited zero shot just without any prior examples by prompting Sora with captions mentioning mcraft and and this piece ends with uh this is a promising path towards the development of Highly capable simulators of the physical and digital world you know I was just thinking right I was talking to my team I was like how does this actually play out because I haven't been able to play with any of this yet right but the idea we got was that or what we understood from this is you can generate Minecraft and then you can send it a prompt saying what if the character press the W button W as we all know in games is like to move forward right uh and what Sora would do is it would generate the next few frames of what would happen if the character moved forward including all the weird stuff of maybe an anime came in when you move forward what would happen if the character pressed s which is to go backward right it would generate it and I don't know who said this I think it was somebody from Nvidia if I'm not wrong that in the future most games will be generated not rendered you're streaming video through and through or you're generating video through and through you move forward in a game it's generating the video of what it would be like if the character moved forward it's just that is like it's like it's insane it's basically the machine's imagination of what would happen based on your prompt like that is absolutely insanely immersive every single person will have and now combine  what my mind is being blown now combine this with neural link okay where if if GPU if you can plug your brain's thoughts to a GPU and something renders itself based on what you think it would be like when I when I walk behind this door and and on Twitter the general narrative was that actually for uh something like Sora to do this it needs to have an understanding of physics or at least it needs to be able to model physics well understanding won be a very strongly used word here which is that for you to press W and for it to know what happens next it needs to understand a little bit of physics it needs to be able to model the world and model a little bit of physics right because it needs to keep the character consistent it needs to make sure if a bird comes and the shadow of the bird is accurate right all of that stuff so it's understanding the real world and after this like I used to always think this is a very weird Fringe thought and I think I'll just say it that this might not be true or accurate it's just something I believe I thought if we live we might be living in a game engine right because it it seems a lot like you know what you do in Unreal Engine Unreal Engine for example with light you have something called rate racing which takes a photon and makes sure and figures out how it bounces and then renders the frame right and the real world seems the same but with Sora it kind of confused me I'm like actually you don't need an entire game engine you can sort of generate the world instead of rendering the world and it has so many implications for physics and for our understanding of Nature and this is unfalsifiable what ins science un not falsifiable means you can't test this there's no way to test this and be like yeah this is exactly how the world works these are all theories and you know we die not knowing whether these theories are true or false um actually these are hypothesis in science the word is hypothesis right for something that you're not sure of theory means you've already proved it uh but it is interesting right like it is interesting for you to sit with a cup of tea in like the middle of nowhere and be like well what are we really made of is it just generating everything we see and all our actions that we do is sort of I I don't know it's just it's it's it's a it's an interesting thing to think about I did not think Sora would make me this existential but here we are but  real like real time generation of Worlds is too exciting it's too exciting now you plug it into your Oculus or you know Vision Pro and you're actually standing and when you walk it generates real time now you combine that with you know imagine if you're able to feed it visuals of a world you want to live in and then it just further predicts what that world would be like that's too good it's super exciting you know the cool part is that right now games are I mean at least single player games are pre-programmed right which is you've written a script you know this character says this and then this happens and then these are the set pieces like these are the events that the player needs to go through to progress and then there's bosses that you fight but if something like Sora you can truly ask it to surprise you be like give me a game and just surprise me this is the theme Wild Wild West surprise me you don't know what the ending is you can't spoil it for yourself you have no idea what the twist and turns are uh and you're playing it in VR let's say and it's generating a full 360\u00b0 video for you I think it'll be really exciting and a lot of people will immerse themselves into some of these games and you will find weirdly is that if the game is just too much fun like as in it's just only positive stuff you'll get bored right actually fun is the wrong word if it's just all positive stuff you would get bored you want some of the negatives you want some of the struggles you want it to really feel like it's real right like it like it has consequences it has meaning if you get damaged in the game it should feel like oh my God you know how am I going to get out of this and the more I talk about that right and we've been having some of these conversations internally just simply and the more I think about that I'm like well if you could dream any dream then why won't you dream this one the one that you're in right now and by the way whenever see the open ey employees tweet like run and stuff keep tweeting right uh he tweeted something very similar he's like something about you know something about dreams so when when the open ey employees have been tweeting like this even Sam Alman tweets like this they're like it's just it's just interesting there's no way to prove whether you're right or wrong but it's just an interesting place to be can you recommend some people to follow on Twitter open air employees run is Good Sam Alman is good run is like the reason I like Run's tweets is because he's unhinged like usually when a company reaches a particular scale their employees keep quiet uh but run is just like spell his name r o n you know what is an interesting thing in every other field right for example in biology we will not read a textbook from 1800s because we like that's crap in there okay with uh physics we will not read a textbook from 1800 we might glance over it but we like what are the most modern things we' have figured out in every field you try to figure out what's a you you try to read a textbook that's very very recent right especially things like medicine we know things evolve so quickly and our understanding of the body evolves quickly the only field where people go read stuff from 1800s again and again is philosophy right there's nothing against it because theoretically philosophy is supposed to be Lindy right which means that uh these are Timeless wisdom this is timeless with wisdom humans 200,000 years ago were the same so it's the same behaviors now but I still feel there's a section of philosophy which comes to understanding reality and the nature of reality which is very very close to science and all the textbooks we still read on that are the I set in the 1800s or 1900s and Sora didn't exist at that point so I think somebody needs to come out somebody really smart needs to come out and say well here's philosophy of the modern generation and we could be wrong about many of these things but here are 50 ideas lateral ideas that you can go along a path of and and figure out that's why I love reading Doug Douglas hofstader uh that's why I love reading Max tegmark because these people even though they're scientists they still have a very strong philosophical angle of that question of man search for meaning right where did we come from why are we doing this um and I feel stuff like Sora really puts me back puts all of us back into that mode of thinking which is is this all just like fake yeah runes even Sam tweets like this existential  once in a while right like today as of recording this right now he has just tweeted just now he tweeted all of this has happened before and all of this will happen again the hurricane turns faster and faster but it stays perfectly calm in the eye what the  does this mean scaling laws are decided by God the constants are determined by members of the technical staff yeah uh you know it's going to sound strange but I feel at least for the people at open ey and everything with Ilah right he said feel the AI and all that it it must feel very religious cuz it is like I mean it sounds like a tool right now right but for many of them who are building this and seeing stuff like Sora actually happen in front of your eyes and seeing the rapid improvements in this it kind of feels at least for them like the second coming right like okay this is this this feels like like a religious Vibe right like where there's finally a God that will answer respond back look at you it it it is able to model the world it is able to understand what happens next I imagine them in front of their computer screens and they just did something and it they realize that  what did this just output and they touch the screen of the computer like this slowly and then there's a little spark they and they're like  like God is that you I can imagine yeah uh I I'm just really happy this is happening in my lifetime like I don't know how much of this is true how much of this is false how much of this is wishful thinking how much this is actually real but it's very exciting to be here in fact one thing Sam Alman says and even Elon mus says right like and Sam Alman said this recently is like the entire idea of doing this is to is to the entire idea of living is assume we we are in a simulation then the goal would be to please the or entertain the Brahman right now that's a very religious take on things and I don't think they're being as religious as they're tweeting but it is whoever is simulating it or even if everything is just a simulation uh the best thing you can be is entertaining right in fact if you solve everything for human beings right you solve Food Water Shelter everything then the only thing we will seek is entertainment right and that's why over the years T if you've noticed you're an entertainer right uh the value of T has increased so much over the last decade partially because we've also soled a lot of things that are non-entertainment and now more people are seeking entertainment the average person now spends like four to 5 hours in India per day sitting and watching video they are consuming entertainment right and that's just going to increase over time as more of our things get done as more of us either get Universal basic income or you know have to work just one hour a week because AI is helping us do the rest are we we all seek entertainment and if you really take that to the maximum then entertainment is the only thing and then if you are in one of those simulations then the best thing you can be is entertaining that's what they constantly keep tweeting about uh even Elon Musk says this I don't know how true this is but it is an interesting frame of thought H yeah I run tweeted this right make sure you are entertaining Brahman this is by the way not the cast Brahman this is Brahman the word that says uh the universe it's yeah it derives from the word Brahma the Creator basically yeah I don't know if they mean it in a truly religious sense like I I don't know if they mean it in a truly Hindu religious sense and it doesn't matter right because what they're talking about is they're talking about when Sam and run talk to each other it  feels like a cult right it really feels like a cult like make run tweeted saying make sure you're entertaining the Brahman and then Sam's like where did you hear that he like Al the Sam man like they're all talking in this weird dude I just feel like they're having so much fun yeah they are having fun literally watching the world transform that's pretty envious and insane and uh yeah yeah that's it's pretty nice run is a great follow I'm going to I think I'm going to enjoy reading all his tweets yeah I just hope he never changes because as you know as companies become more corporate and they get sued and stuff everyone becomes very very uh this thing whatever it is openi has just un Unleashed so much onto the world of what to think what to believe or actually it's less answers it's more questions right more questions about what what is future of a job going to be like more questions around what is the future of humanity going to be like more questions around what is our meaning it's just by creating this technology they've introduced so many new questions for us to ponder on I think philosophers need to write a modern set of philosophy textbooks and I'd love to read some of that them H anyway Sora okay next thing next thing so let's talk about jini 1.5 Pro right we were talking about going from really amazing Tech in AI to really awful Tech in AI Gemini 1.5 Pro is good like this is the this is the te this is the text one Gemini I think this is the problem right like the image one was bad and we'll talk about it in a bit so Gemini 1.5 has like a million tokens context length which means I can feed it an entire movie and be like what did you learn from this I can so there was a technique called retrieval right where I can feed you know chat GPT and external data source and I can be like like chat with PDF and I'll be like well you know give me three I answer this question looking at this reference book or PDF or whatever you don't actually need to do that anymore right one thing I have learned like building so many of these small Technologies and just being immersed in the spaces don't get married to any technology because it can just become useless later like today you can just dump in the entire book into Gemini 1.5 Pro and you can be like give me uh answers right explain this explain that um in fact I'm fairly confident when this comes out this right now is only API access uh and you have to be on a weight list but I'm fairly confident you can dump in maybe 3 hours of tan but footage and say right like TM but and it would do a decent job let's first talk about how Google  up which is image generation uh um image generation there are many many examples there's create racially diverse nais and that kind of stuff people prompted in fact let's just show one of these on screen about how bad image generation was and right after that everyone's been ringing the death nail on Google saying that Google is just lagging behind and how um third this morning I woke up to see Sergey in the Google office talking to a bunch of Engineers and he actually on video said that you know I think we messed up on on image generation on Gemini so what is your take on where is Google is Gemini as bad as they say Gemini image generation is bad I I find Gemini text especially Gemini Ultra text generation pretty good like I think it's better than chat GP at this point Gemini Ultra Tech generation why just cuz it can have more context no I think it generates it writes better like pros is good uh with Gemini's Ultra and we've been using it a lot for short form script right especially things where there's news and we just want to quickly cover it in short form especially my automated stuff it's Gemini is great uh with the images dude to be very honest T you know how this happens right it's it's less a technology problem it's more a team and the people problem yeah organization problem yeah yeah like there was this one thing right and I I try to avoid this but uh there's this one guy who said that he got fired he he got denied a promotion at Google because uh uh he was a white man right and this is like I totally believe in diversity equality inclusion Etc but I don't believe in performative uh you know inclusivity which is I will show the world that you know my team is extremely diverse like you want to be diverse like hire diverse people right you don't you don't need to do every everything is not theatrics to show the world but then when you're a public company you have to deal with some of this because people will complain any anyway right like about everything and I think the minute you start going there you stop thinking about the truth and I think we are finally in an era where you have to be extremely truth seeking to to get the right answers of everything right like there's no more place for to to to to to to pursue something that's not the truth because customers want the truth especially with AI so I think it's a team issue and I think this is such a big problem right because in teams especially when you grow an organ now we're close to 100 employees right when you grow the AUG there are certain things certain people that you cannot remove because they very useful to the company but their thoughts and their ideals do pervade the technology or whatever you build it becomes like their DNA kind of gets embedded in what they come out with right and you really need them so you can't really fire them and also they've built like a cloud right like so you if you fire them then you lose another 20 very important people and it slows you back it it puts you back you know months um but you faced some of this like what do you think like how do you think Google should do better I mean that is I mean my opinion on how Google should do better and or you know whether I think Dil is irrelevant and I am nobody to suggest but I do think that I do find it interesting that a lot of people have come out to now write Sund off um people are calling him a peacetime CEO etc etc etc that I'm not enjoying um like I even when parag parag was being thrown under the bus at Twitter I wasn't enjoying that it just it just doesn't seem seem nice when something like that happens but I am excited to see surge come back uh to Google and really get into the get into the meat of you know it's like going down to the engineering room and actually sitting and figuring that stuff out yeah like I told you it's a it's now a religious War it's a religious war and my God is greater than your God is what everyone's going to fight for I just don't think you can count Google out it's just like it's  Google like you just you just don't you they have the most amount of data they have and they were the pioneers of this Deep Mind began this whole thing so you can't I don't think you can count them out but then again I don't what do I know I don't know much you know Balaji Balaji sinas had a very good tweet okay and this is a crypto related tweet where he's like crypto actually follows forking like a forking philosophy exactly like many religions of the past okay I'll give you an example you have Bitcoin you have ethereum and then you had ethereum and ethereum classic right and that was just two different camps with two different viewpoints and then I'm sure there there'll be multiple folks of that uh with religion it's sort of the same right you had Christianity and then you had two branches of Christianity one that really believed in the Old Testament one that believed in the New Testament and then you had you know multiple branches of that right even in Hinduism we have so many different micro segments that believe in slightly different things I think it's going to be like that with AI especially open source AI right with Lama 2 is like Daddy it's like the original progenitor and then you have a bunch of companies that say well I'll take llama this side and another Bunch that says no no no that's not the truth this is the truth I'll take it this side and even though Google obviously is not using llama as base uh I still feel like there'll be some people who are part of that camp who believe this is the this is the right this is the truth and there'll be a different camp that think this is the truth that's why I keep saying this is this looks exactly this feels exactly like a old school religious War right a tribal religious War uh and I think I I think the people with money and the customers because there's also a commercial angle to this I think the customers will really care about whichever side goes towards the truth or what they believe in it is going to be hyper segmented no yeah I think eventually it'll be choose your AI choose your God choose your god um and it's possible that most people will probably interface with many gods for different different things uh and the only thing that all gods can uh agree upon is that customer is King yeah yeah that's a good no I think some will not I think some will not care about that some especially some of the open source will be like hey we believe in this un complet like there are now open source models are completely uncensored they're like hey we believe that any form of censoring any form of dude how have we we' managed to commoditize God like can you isn't that bizarre this is like peak of capitalism which is that we've invented a thing that can do anything and you can have any version of this for anything that you do like it's it's blowing my mind yeah and the question you really the the decision you're making choosing these AIS is not price right it is what is your version of the truth do I like you do I like the company do I believe the company is telling the my version of the truth cuz what I've realized over the years and this Facebook Papa keeps getting belted for this right which is oh you're not taking a stance on misinformation or disinformation well how should they remember the covid vaccine uh not vaccine the covid lab leak theory for 2 years everyone scrapped away content around the lab leak saying hey that's that's bad we shouldn't say racist as heck yeah that's racist or whatnot and then two years later there was evidence saying oh and the thing is I'm sitting here I have no idea which is what is true what is false I to believe you put all the content and people should be able to decide everyone should be able to put up their evidence and then we should be able to decide but then I've also realized it confus the hell out of normal people to have both sides of an argument put in front of them and somebody not making a Deion for them with AIS it's like you're not seeing all this content somebody's made the choice for you that when you ask this question I'm going to show you this content man Zuck is a beast he's 39 bro remember he's 39 he has the next like 40 years to just keep keep doing this  and he's one of the only companies really focused on VR and AI so if you really thinking like a Ready Player One World or like a swordart online world he has the best shot of doing both the things because he owns the hardware it's cheap enough he's winning at everything the dude is  fighting at MMA becomes a meme the next day eats at McDonald's the next day wears of  Indian outfit at a daisy wedding the next day he's an influencer now he's an influencer of a different level like so impressive I'm making video on Z when I grow up I want to be Zuck dude remember this dude was so hated like 3 years ago 3 years ago yeah mad impressed so T verel has launched something called v.d where you can generate uis on the fly so let's try one of these let's go to v.d and let's type generate a landing page for a community platform now I've built a community platform before so let's see how it does this and does it show you happening does it show you making it it's generating it at this point so I'm looking at it features pricing about join the community okay the sign up page okay this they start choking these are all very tiny Pages yeah but pretty good it's generating the structure let's try us generate the landing page for an Indian payments company generate the dashboard for an Indian payments provider company oh it can generate like dashboards and  also yeah and how much can you customize it let's try that out it seems to be generating more structure than design uh it's also giving you the code for it which is very useful so not bad dude showing you the total transactions active users recent transactions it's not done any of the designs just giv me like a wireframe type black yeah can you design though can you add color and logos and that kind of thing you will most likely have to oh wow I can actually click on oh I can't click on any of this yeah you you will most likely have to style it yourself uh so it's given me three options a b and c wow C looks really good this good yeah pretty good this home transactions users reports the total transactions active users uh actually go go to go to B I like B for the nice touch dude they use the rupee logo uh that's a nice touch total revenue I said Indian payment no yeah yeah yeah yeah that's pretty that's pretty cool yeah but there's still dollar here yeah yeah this is getting better um this is getting better and I like the graphs they made really nice graphs yeah even though they kind of don't make sense right now but it's pretty cool yeah it's a very good template to get started with no yeah and tell me aren't these kind of templates like already readily available in the market they are but you would some of them you have to pay for uh you'll have to find it now it's just like you can have a a very specific prompt and at least it saves you a bunch of time like how much how much time would a front end engineer take to to make this see any front end engineer will know how to build this it'll just take them maybe like a few hours now you generated in a few seconds and you've gotten the code right tell me how much can you customize this can I customize this further yeah you can probably customize this I download the code and then I go through the CSS and I'm like suppose very crude example that total transactions I want to make the background of that blue right I could change that so most likely it's using some framework at the back end something like tailwind and with things like Tailwind you actually get themes right so you can go to Google and you can just be like you know Tailwind themes and you'll find like a bunch of decent themes right so you could use that or you know if you if you want to get in the weeds yourself and you don't like the width of these you know panels of the these like the total transactions active users Etc you can you can uh make it smaller right in CSS you can be like well I don't want it to span this many widths I wanted to be much smaller than that so you can do that and I think this is a good time saer and I I don't think it's going to replace uh you know a front-end developer or a designer but at the same time you know and and I I'm usually very careful about saying this on the internet because you know that's a very aggressive audience but come on we generating video and we are generating you know a full game on the Fly uh it's only a matter of time till some of this gets reasonably automated these are much simpler problems but for an open a it might not be the most high priority problem because they're going after let's regenerate reality yeah very interesting episode very slightly philosophical not our usual style but I liked it yeah some people will be excited some people will be depressed by the end of this either way hope you enjoyed it hit that like button subscribe and see you guys on the next one  bye",
    "url": "https://www.youtube.com/watch?v=n6o_0tx0QOU"
  },
  "P92tGHUvfXU": {
    "published_at": "2023-06-05T12:30:11Z",
    "title": "Engineering with prompts using SmolAI",
    "text": "Engineering with prompts using SmolAI your very own personal task manager right so let's start with this install Linux on windows with WSL you find the repository you want to interact with okay and before that you need to create a virtual environment conda activate small three small I've already created an environment called small three now we are going to run a script manifest V3 Chrome extension that is a task manager I just inputted my API keys so by the way now it's creating the CSS for us so now we go to Chrome we load this extension tell me a task you have in mind eat noodles and now let's see if it works click and it disappears nice it's not just disappeared it's like added the strike through I didn't ask you to do that",
    "url": "https://www.youtube.com/watch?v=P92tGHUvfXU"
  },
  "yR_CPoHSyjI": {
    "published_at": "2024-07-22T12:59:10Z",
    "title": "Phone Calling AI Tanmay Bhat, Building React Apps Using Claude &amp; more!",
    "text": "Phone Calling AI Tanmay Bhat, Building React Apps Using Claude &amp; more! new day new episode new V Maya what's going on what is new nothing usual uh congrats on the new office thank you thank you uh you are yet to visit whenever you're in Bangalore next I am yet to visit I have my loyalties have shifted dramatically I visited mbay for seven days and then I was like I'm not leaving by the way this is exactly how I shifted to Bangalore also I came there for exactly seven days on day seven I was like I'm not going back I just want to continue staying here then I just stayed there for 2 2 and a half years and the same has happened with Bombay I think in like a year's time I'm going to come to Bangalore one day and I'm going to be like H it's so good here this I'm just going to stay you have houses in both places so it's very convenient for you to keep shifting here and there right now I'm double renting and it's uh yeah let's see for how long I last anyway let's get into the episode  all right character AI phone call with your digital clone this was a very cool re I think we all should watch it first before we move further all right calling myself hey who am I speaking to haha I'm a human being JK I am an AI content creator and entrepreneur I'd love to connect and get to know you what is your name my name is Varun Maya it's very nice to meet you how about you no no no I am Varun Maya you are not vun Maya you are an imposter it seems like we have a case of mistaken identity here while it's funny how similar our names are I assure you I am vun Maya can I ask who you are and why you're confused about your identity no I am warun Maya stop gaslighting me I'm not here to Gaslight cause any confusion it seems we're having a little mixup but I'm telling you honestly my name is Varun Maya not Varun Maya if you're feeling confused I'm here to clear things up and have a friendly conversation this is very cool how do I do this with um I want to do it with myself so we I think Sagar set one up for you we've made a character AI character called tan that you can do a live call with let's do a live call with character AI Tan Hi I'm Tan's AI like most Indian comedians I'm a big fan of being funny on a computer of course okay calling now can you do a call I'm calling hi hello how's it going my digital friend hey who is this I'm just an AI chatboard here to chat my programming is designed to help and entertain so feel free to ask me anything what is your name what do you do I don't have a name in the usual sense but you can address me as tan bot as an a chat thought my primary function is to engage in conversation answer questions provide information and offer assistance to users I'm here to help and entertain to the best of my abilities tell me a joke tanay certainly here's a joke for you why was the computer cold because it left its windows open that was not funny I'm sorry to hear that sometimes my understanding of humor isn't perfect and I apologize if the joke didn't land well if you'd like I can try a different one or if you have a specific topic or preference let me know and I'll do my best to entertain you tell me how you lost all this weight while I can't provide personal weight loss advice since I don't have a physical body I can share some general tips one balanced diet eating a healthy balanced diet no shut up wait focus on fruits veggies leaves why aren't you married yet as an AI like me I'm not capable of getting married is a social and legal individual my purpose is to provide information answer questions and tell me the tell me uh the one second hang on hang on hang on hang on what else do I ask what else do I ask uh ask it to write an ad can you write an ad for an engineering course uh by Varun Maya sure here's an ad for an engineering course by Varun Maya elevate your knowledge and career with Varun Maya's engineering program learn from industry experts work on Cutting Edge projects and be part of a Vibrant Community of Engineers to be join us and shape your future in engineering you know you know how I can tell it's not you because there's no Johnny Sins or r yeah and also it's not good what the Yeah I think this was trained on very little data of you both on the audio as well as the subject matter so the way you it works in character AI is you basically send it a bunch of um texts and responses so any conversation you've had back and forth the question being asked and the answer if I can have like a large list of it I can just send it straight to character Ai and then character AI can sort of bake out a thumnail version I think the like tell me something like all the voice models like the when the guy said tan May Bart it's like such an obvious giveaway like pronunciation is a big thing of uh pronunciation is a big part of cloning someone right like I don't I don't pronounce things like that like do you think how how do you think how far away from the AI model pronounce anouncing things the way I would pronounce them cuz we're not there yet no it's not very far it's all about coverage so the thing is this was 15 seconds of audio right uh I have an 11 Labs model that's trained on hours of audio audio data so we have a lot of coverage and I'll tell you how there's a very easy way we've figured out how to do it go to chat GPT or CLA ask it for the top 100 common words that Indians use okay and then add your own name and whatever ask you to just generate a script including all the top words that Indians use top 100 top 200 whatever try to train it on that yes so that's what we do so for example a lot of words that IND that you will pronounce differently from other people you probably use those words very often right Indians use those words very often so you just I mean we've become smart about such stuff because it's a lot of trial and error and for example there's some words where if I'm really struggling with a word in a new type of real I'm like okay I'll record some AI related words that you know my reals keep that keeps coming up my reals again and again so that stuff I think um uh really helps so once you have that coverage T it will pronounce most words like you you'll only be able to notice the gaps in the words it cannot like in the words that it doesn't have any training data of otherwise what's happening is it's sort of recreating the median human right and using that to stitch in the words that you've not actually said so the words tan but the way you pronounce tan but the way the AI bot pronounced T but would be how the median Indian let's say would pronounce t whatever the base model was slightly fine tuned the models are shift the model weights are shifted slightly towards your accent let's say so it's trying its best but that being said if you have enough coverage today it's nearly Flawless that's crazy um so character AI it's this this company is doing super well know who owns it no it's it's an independent company it's got nothing to do with uh one of the guys behind the company was the original people that wrote the Transformers paper if I'm not wrong so surprising that he's working on something thing where you're creating digital girlfriends or whatever but um I think that's the aim of character AI right to eventually do digital girlfriends at digital friends and solve loneliness and whatnot and it's only a matter of time till character AI comes in like Indian like an idol that people can talk to like a robot that you can talk to so a character AI is building the personality layer on top of AI and one thing that we've all seen and T you've also seen over the last one AI really disrupts content first everything else hallucinates too much for but with content like speaking it in speaking if you mispronounce one or two words nobody really cares right but if you need a task which requires higher accuracy then AI would not be a good uh gen AI would not be useful there so having the personality ler which is truly the layer of you that makes mistakes that's you know that's that has its own quirks character is capturing that and it's no wonder that they're doing so well in fact I was really surprised at the numbers uh they've been growing like crazy hey uh a lot of like do you think characteri will you think open AI will subvert character a at some point like like it'll just open source their voice modeling tools and then it's done remember they released it for like 15 minutes that you can clone your own voice in like some 20 seconds and remember they released it for a bit and then they stopped it it depends on legality on character AI I can talk to like the top 10 anime characters I can talk talk to Elon Musk right now any of those people or any like let's say whoever owns the anime characters or Elon himself could come and Sue character AI so character AI is playing with danger with the backlash that Sam Alman got for scarlet johanneson it's very unlikely that they will go and say Hey you can clone anybody's voice and there's a market right now there's a Marketplace of voices and characters that you can talk to very very unlikely that um it's it's it's just super unlikely that open a will take the risk so character AI is free to play here maybe maybe they'll get sued at some point or maybe they'll get into trouble at some point but they they think it's worth the risk okay okay okay what else is interesting about character what else should we talk about in this I think um I T how will you respond if somebody talks to because they can do that right now character AI you don't need to give any there's no licensing thing right or eventually there'll be a tool where you don't really need permission so um I can make anybody's voice model anybody's Avatar eventually there'll be a call recording of you online where you're talking to somebody and you're saying abusive things or something stupid or whatever right how will you respond to this you'll spend a lot of your time defending the fact that I didn't say this okay so I think it'll be in phases right now the tech isn't good enough um rather the tech is uh bad so it's very clear when it's not actually me saying it so there won't be a lot of Defending needed by the time the tech gets good enough that it becomes indistinguishable by then I think uh the targets for these kind of attacks will be people far bigger than me so it's not a worry uh and by the time the tech gets ubiquitous then it'll be common knowledge that this is the tech and this is likely not the human so I think I'm fine I'm not worried about people impersonating me and you know like I think like it'll likely mostly be amitab ban and Shah ruk Khan way before me so I feel like that's that's going to be that's going to be what happens first um but much like after I think once you remember when Photoshop became a thing like we didn't have and Photoshop when you use Photoshop it was not it didn't alter the world to a degree where everything was burning you know what I'm saying and with Photoshop you could create images without a watermark and it was we were fine so I don't think it's going to be as dramatic problem I think old people will have an issue but I think that education will have to happen quicker uh but yeah I think I think old people likely will fall for it first but I mean UPI is doing enough damage for scamming old people so we if we really need to protect them first we need to look at UPI properly no but now you have like uh so one of the things I encourage everyone to have is like across your family should have a safe word cuz if your daughter calls you tomorrow your dad calls you tomorrow and says you know I'm in trouble I've been kidnapped and me Ransom you don't want to fall for it you want to be like what's the safe word finapp safe word is pineapple for me all my safe words have been pineapple so guys if you want to scam thme if you want to close to him and get answer God damn it why did I say it say it out loud um but yeah sa is a good option what do you think you are a Doomer let me guess your opinion you think the world's going to end and I think I think the last one year everyone's really uh packed together a layer of skepticism we don't now I don't believe anything on Twitter like I'm like Source you know that that mean Source question mark and now people are just saying things just to get reactions from other people even though it's not true right so we live in this post-truth world so uh truth is becoming fiction fiction is becoming truth so I don't believe anything nowadays I get my news from uh seeing four five different blue itics who I really trust I think trust is mattering a lot more now like the accounts really matter like if I post something I know I'm not like misleading my audience so you know if I was somebody consuming my content I'd be like okay V is not going to say stupid  and vice versa right there's some news people that I'm like okay I really trust these people they're not going to spread bad news and if if they do spread something wrong they they retract it later if it is wrong cuz now there's actually a premium on Truth considering the world has become chaos so t as you know editing our pods we rely heavily on Adobe Premier Pro in the past editing a single episode could take our team anywhere between 1 to 2 days because there both of us there are multiple cameras very hard to tell who's talking clip it out you know get the right get the SN right a timec consuming process when dealing with these setups it was really manual to cut out all the repetitive parts or long pauses but recently Premier Pro has added some powerful AI based features that can significantly speed up the editing workflow they have this AI plugin called autopod which is super cool yeah I've heard of autopod uh you should tell people what it does so it's incredible I don't think this is made by the Premier Pro folks but basically it automatically handles this multicam pacing for our podcast and even cuts out repetitive Parts pauses Etc it's been a real Time Saver especially for our editors so our editors actually edit this on their Intel Core Ultra processors so they have these AIP PCS uh powered by these processors and the same podcast that you just take them between 1 to two days now just takes a few hours because the pacing is done for them yeah let's look at a clip of it in actually in action no so let me show you the AI Plus plugin at work on this Intel aipc right here check this out wow dude that's crazy like the seems super fast yes and you know like I said it's all thanks to the Intel Core Ultra processors the AI boost inside this laptop that are editors recently started using the render times are super fast and it's a boon to have this considering just the Quantum of content that we're creating yeah and I'm assuming like you you can run all this on just a laptop now you don't need to be chained to a desktop so that's great yeah I mean the way our company runs now is anyone can work from the office and they actually spend a lot of time working outside of the office as well so nowadays if there's a trending video that needs to be cut out put out ASAP you know how this works right sometimes there's some news and it needs to go out ASAP and other times there's nothing to do so you want to be able to chill somewhere uh I don't really need to call my editors to the office they can work from home they're not chain through their desks and these Intel AIP PCS give a nice combination of performance and portability all right if you guys want to know more about what makes this processor so good just check out the link in the description next T have you heard of cling no what is it so cling is basically a SORA alternative Sora opena is doing this thing now where they're launching tools or claiming to launch tools or claiming to launch things and then I never actually get to use them voice engines they said we have voice engines but I didn't get to use them Sora they said we have Sora I didn't get to use them they're playing full B2B I think they're going to Hollywood and what not which is fine I guess uh but I think we needed open source Alternatives we needed any alternatives and we had Runway we had Luma labs and we had uh cling come out I think cing outputs are probably the best out of the three at least in my opinion Runway comes close uh you want to see some outputs yeah this Chinese man eating noodles this is absolutely insane remember that time where AI was doing that Will Smith eating noodles but very poor dude this is absolutely nuts there's just no way this is not real I mean yeah uh look how look how good look how each individual noodle you can see each individual noodle moving yeah I mean yeah it the bowl is obviously on a table um the textures on the clothes he's wearing the lighting his lip movement uh his ears also dude if you notice his ears when he when he Contours his face even that's really accurate this is really good let's look more traveling by train viewing all sorts of landscape through the window the next in the thread um this is really good this is it feels as good as Sora yeah I haven't tried Sora so I don't know I've only seen Cherry Picked examples but but um dude I think B- rolls are going to be solved right like I think you want a 1 minute clip of a of of some train or some sky or you know some some stock footage I think we are at the point where it's almost there yeah yeah I think Boll is soled you still wouldn't make a movie with this though there's too many things to stit together like if you want this same guy to go somewhere else it'll be a different bowl of noodles it'll be a different guy it'll be different Chopsticks so consistency like we discussed earlier is still a problem but uh but I'm happy that open source is now caught up not just open source but other companies have also caught up and openi is no longer the one company we rely on to get all our AI needs I like that there's some diversification going on here yeah I think uh dude I'm I can't stop looking at these videos dude uh dude look at this video of an astronaut running on the moon yeah it's pretty nice it's so good it's so good all these are really good they're stunning uh 10 new ex more 10 examples like man eating Burger on the Moon Chinese man eating instead of noodles as a Chinese man eating pasta also it's like I can't tell which one of these is I mean if you posted a real video at this point I I wouldn't be able to tell no I can tell actually you can still tell yeah and in fact have you seen this video by belov synu no which one check this out damn damn uh this was made using cling yeah this is this is going to uh this is like cocaine for WhatsApp uncles yeah this is done this is done this is done rip truth has been nice knowing you yeah yeah yeah it's done but this is um how how did he make this how how did he get this prompt how did he get real life models just prompt it's it's part of the training data I'm sure all of these people I mean in in AI the more pirated the more illegal data in the data set the better the model is right so you can see this Iron Man talking to Deadpool you know Henry caval super there one more bat okay let's play the Batman one why so serious don't be nervous I've been following still image to a fictional scene last decade your hair is it's very soft and it smells like lavender sit still finish what kind of product do you use oh yes very  nice why so serious don't be nervous watch volumizing Alfred's hair for the last decade your hair is very soft it smells like lavender sit still I'm going to finish you can see the finger consistency is still correct till the camera pans too much now it gets completely ruined and Batman changes yeah text to video is fun have you seen lumay as uh image to video Generations have you seen this with Indian characters t no check it out with the Indian characters these are memes converted into videos you seen this famous meme I've seen this one this one these I've seen Luma turning images into text these I've seen yeah they're still fun actually the Ronaldo Messi clips and the the Obama Trump clip from the previous ones those are the real scary ones I think I think image to video you can still you can still tell when it's like oh image to video you can still tell but the cling stuff is very scary actually that's also image to video if I'm not wrong so you generate the image in mid journey and then put it into cling or Runway and then it generates Something Beautiful for you I mean it's kind of wild that you're now able to have like generate a video of tme walking around eating some food or Ronaldo smoking a cigarette or something like imagine telling that to somebody 3 years ago where I have this Magic Machine you send me a photo of Ronaldo and I'll make a video out of it that looks damn real nobody would believe you 3 years ago today how how normalized all of this has become like we're just okay with it we're just like okay this Tech exists next move on doesn't impress us anymore yeah this is quite Bonkers okay so T I have a question what what llm do you use now I'm still on GPD but I've been using Claude more and more more and more and claude's gotten really good I think Claude is the best publicly available llm right now uh yeah the reason I say publicly I'm is I'm sure open is something cooking behind the scenes um and Gemini is constantly getting better but Claude is so good right now CLA is like I use CLA for everything like I use CLA to brainstorm I use CLA to give me ideas I use CLA to like help me with scripts um and the artifacts thing is really good like for example let me show you an example of an artifact okay so I'm just going to say Claude I want you to run an artifact where um I want you to um tabulate the ratings of various sitcoms on mdp I don't think can run a search but let's see what happens when I do this see not sure how accurate or not it is but it quickly generated a table for me right so now what I usually do is I screenshot this put it in a deck I make my decks very simple whenever I make internal decks and all I just make it very simple screenshot stuff from CLA and verify the data once actually my only job now is data verifier right so you can do more stuff with CLA generate uh and animation uh use artifacts what is artifacts it's they're browsing it's sort of like their code uh runner but it's a lot better than gpts so for example use artifacts to generate an animation of three of of convey Game of Life let's see if we can do this okay it's doing this with react it's writing code as you can see on the fly my hands are off the screen okay now it's running it look at that it wrote the code and it's running it in real life for those that don't know cony's game of life it's a really really fun uh sort of practical experiment so you should go check it out see T that was done both the code was written and it was executed in this place so remember in one of the Gemini demos uh they had said that apps are going to be generated on the Fly user will have a query and then the app will be generated based on what the quer is like uh like for example if somebody's looking for what kind of birthday parties do I host for my kid then the app structure changes to kind of lead you through to the or if you're looking for Real Estate the app structure changes over like based on how you're using it your comfort level whatever so I think in the future we're going to have personalized apps and it's going to be inside the AI assistant it's a weird thing to think of right which is it's not going to be a separate it might not be a separate app that you download it's going to be inside a GPT or a cloud where you have a problem statement it generates an app on the Fly for you it uses publicly available apis which or or privately available apis where either you put in the API key or Claude or GPT has a direct relationship with the people providing the API keys and you're able to use the apps inside of cloud or GPT itself GPT or Cloud become the everything app you want to book a cap well it's hitting Ola just becomes an API at that point right because it knows GPT already knows your preferences it's able to make those decisions it just hits the O IPA and says okay you know this person is arriving here it generates a UI on the Fly for you and then once you get done it stops using the UI for I mean it it completely deletes the UI off your um it just expires the UI so technically you don't have to pass personal information to Ola if you don't need to over time I mean some sort of privacy layer they will build as well so that when you're communicating third party apps you probably Anonymous I think it's a complete shift in how we look at the business of building apps which is still now we've always built apps and we put it on the App Store Play Store but now you're going to be building these things actually you're not even going to be building them Claud will be building them on the Fly and it will be inside of clae in itself it is really crazy that we're here and we've seen all the micro versions of this right we've seen the versions of this where you know in GPT the early version of GPT where it could make one button two buttons and everyone used to complain about it back then saying that oh it's not going to do more complicated things but it was the trend line right every week that we covered this it just got better and better and better this is where it's at now another 6 months from now it's going to be even better so I think um you can't stop the Arc of progress and I think eventually one of these apps either GPT or clae or something else is going to be the everything app I don't even know how to process says this um yeah I think I it makes sense that there'll be an app inside the LM that makes sense but yeah for apps that need a network it'll still have to be on app store or Play Store or whatever right yeah like Facebook Twitter or whatever uh so so I have an idea okay create an artifact um of a I'm just thinking of ideas on the Fly of a tamag GOI you know what a tamagi is right I go pet that I can interact with and feed via buttons the pet should be animated let's see if this works if this works I'll be mind blown okay so it's writing code for my tamagochi pet with it's it's creating some states for alive energy etc etc writing some messages I'd be very surprised if this works okay it's created a react app where it's created a pet for me T so I'm going to feed it and as you can see it went up I'm going to play with it as you can see happiness went up I'm going to play again and as you can see every time I'm playing the energy is going down the happiness going up and over time as you can see see the hunger is reducing over time the happiness is reducing over time so feed it again I want it to be fully satiated now I need to give it some s sleep and as you can see you can see the pet here want play with it and as you can see the pet is smiling as I'm I'm you can see it right you can see the Pet's face so it's smiling but if I let it go it's going to start looking sad it's all generated on the Fly I just want to say this and by the way I didn't know if this would work beforehand I haven't seen this anywhere else um you know if you just I'm sure if you just give it some time it's going to start feeling upset let's watch the the face see see this was made with Rea this is really inaccurate cuz I have a labrador I can tell you you need to feed them way more you can't it is not what happens if it goes it died yeah it died can you believe it this it it made this on the fly now I know this is not the most complicated problem but this is not possible a year ago and there's no way to this is executing the code within within CLA itself yep it's called an artifact so I use artifacts for all this stuff dude I'm getting claws uh this thing right now T shall we try something really difficult let's see if artifact can do this okay let's let's see if Cloud can do this okay this is like create an artifact to remake the Uber app complete with all screens this t is going to be the ultimate test of whether AI has gotten better in the last God knows year okay create an artifact to remake the Uber app compete with all screens okay it's creating a simplified version Look at Me coder coding okay so enter pickup location and to enter New Zealand doesn't work no it's working so as you can see I can choose the type of ride I'm choosing the Uber X and it's arriving obviously it's a very very simplified version because it doesn't have access to apis but I don't I mean like things like the maps API and stuff it's not rocket science from where it is right now to get there uh and I'm pretty sure we're going to see some of these apps being generated on the fly yeah it's it's gotten much better since like a year ago remember when we were doing autop pod and that kind of and we were getting belted remember when we were getting belted a year ago saying this is making small buttons but the trend line is such that you cannot stop the Arc of progress not Auto auto code auto code Pro yeah yeah the trend line is definitely up and to the right dramatically like more up than right um yeah wow uh crazy crazy crazy crazy I feel like uh have you tried you you working on some dating app right have you tried using CLA to make it instead of I real Engineers if it's simple no I didn't I ended up aborting the idea haha aborting um I end up aborting the idea but like I'm trying to build something else where definitely the engineers are AI assisted heavily nice nice nice everyone's getting in on the game um awesome this was a great episode yeah this was kind of mind-blowing actually a mind is kind of blown dude I'm going to download Claude right now this is crazy I can do all this on the phone also right Claude is the best llm right now can you imagine most people in the world even serious business people they know about GPT but they don't know about Cloud can you imagine how early we are yeah imagine uh dude uh Sam bankman freed invested in Claude Claude really works out uh f X users will be made whole ha random anyway see you on the next one bye bye ",
    "url": "https://www.youtube.com/watch?v=yR_CPoHSyjI"
  },
  "H0t9btxVCCo": {
    "published_at": "2023-11-13T14:44:43Z",
    "title": "The SAD Reality of Deepfakes in India!",
    "text": "The SAD Reality of Deepfakes in India! all right welcome to another episode of overpowered with me and this Android what's on your face this is the quest three I got it and it is lovely have you ever tried mixed reality I have I have the other I have the quest from before this but the quest from before the quest two doesn't have mixed reality the quest three has mixed reality there's this game I played yesterday called broken Edge where it's your house H this Samurai comes into your house and it feels like he's actually there and such a surreal weird feeling cuz I was like sword fighting a samurai who was in my house it was so weird I'd love to talk about it on the episode but in the episode yeah let's get on with it welcome to  overpowered all right big news this week Von you guys made an entire anime using like some 30 different AI tools tell me about this by the way it looks really cool I want to give the viewers a quick glimpse of what it looks like right   now video editing   brainwash or first of all I just want to say that did you did you write the script using GPD yeah you should have written it on your own okay yeah the the script the script the actual writing could have been better but the way it was short and it looks really cool that is super impressive tell me about the process so we actually didn't think it was possible we saw the coridor crew video Coro crew had an anime video we've covered it before and they used a technique called W Fusion so we saw a new technique pop up or rather we saw new uh model pop up uh this was called animate diff okay before that there was one we didn't use that but then there was anime diff so we said this is really cool but we didn't know if it would work so I just asked GPD to quickly generate some you know script for me and then we took the team to a green screen Studio we had only three hours in the green screen studio so we said guys let's shoot whatever so we didn't even know if it would work so we just shot whatever there was no storyboarding there's no thought put behind we used the same Lael mics we was just like let's just record this and we came back and and then I said okay maybe we'll have to go re-shoot again because I'll Tinker with this and see if it worked but then after a couple of weeks of just experimenting I tried many different workflows but after a week after a couple of weeks of experimenting it was quickly clear to me that this is possible so we rolled with the same footage we shouldn't have done that I think we should have reshot the footage and done it properly but uh it was more like a tech check tech demo for us I'll tell you how the process works okay people think this is only AI but it's also a lot of AR it's a lot also a lot of augmented reality so on your iPhone and I think dude the iPhone is awesome now in the sense that it's got lar so I can just there's an there's a free app called camra AR I can put you in any scene like I can do CGI the level of Disney CGI by just using the iPhone and earlier you need green screens you need crazy lighting and stuff we replaced all of that so the green screens obviously we went to a green screen Studio but even that green screen Studio a very cheap green screen studio so the ceiling lights were still there in the shop shot You' be seeing the ceiling lights so we used an AI tool called segment anything to remove all the foreground characters out of the background and I was mind blown by how accurate it is like what what is segment anything so let me show you okay so segment anything is this AI by Facebook where if you have a picture and you click on some element in the picture it'll get all the outlines I think this solves rotoscopy like if I had to bet a rotoscopy person versus segment anything segment anything is probably 95 96% as accurate and it's instant like it's like it takes a few minutes no human effort you can do multiple you know different scenes as quickly as you can so segment Ting very very very accurate in fact I saw some demos of segment anything where you take a very very grainy footage and still it's able to pick out the you know the objects from that image so we were able to do that so all the characters we ripped out from the scene even though we had green screen and then for the background because we were using this app called cam Trak AR we were able to get a 3D camera so as we moved the camera in the real world we were able to get the 3D camera in the 3D World so we dumped that into unre some scenes in Unreal Engine some scenes in blender we made a quick scene by ourselves and we use a tool called blockade AI to make the sky box so all the skies in all the scenes are actually made digitally um using Ai and then all we did was Stitch the footage together it through uh our own flow which is based on animate Tiff let me just quickly show you the flow I'm not going to zoom in too much it's a pretty complicated flow probably not wise to go deeper here but essentially we made custom models for all the characters then we took out the best pictures of those models we actually trained those models on synthetic data so we put ocus in different different lighting we used an AI tool to change the lighting we trained a model of that then we threw that into another the best outputs from that model because that model is not very consistent we took the best outputs on the model used another technique called IP adapters and then fed those images in and then the output was great right so this took us some trial in ER to get there and then everything else all the static shots with cameras moving and all that was all mid journey and some PE collabs and all the others so what did you use mid Journey for so there is one shot in the anime where you know okus is standing and there's a planet and he's holding the planet where his hands are moving slightly that's mid Journey we did mid journey and Runway yeah and and Runway actually not even Runway we manually removed the hands and we made it you know move around got it got so there's a lot of editing in it uh I think the video is like 50% video editing 50% AI but I think what we were trying to prove mostly to ourselves was this is possible Right like you know the average cost and you can Google this people don't believe this but the average cost per episode of any anime let's say Dragon Ball super or Naruto or whatever is about a CR it's probably a CR CR and a half how much did you spend 5 10,000 rupees except for the cameras which we already had okay so for the for the green screen studio and like labor basically yeah no this not including Talent not including paying people but the shoot was so short right and almost all the air stuff was done by me so the shoot was so short that three hours of time you can get from your friends also so excluding those costs uh we brought the cost down from a CR to like you know 1,000 yeah it's it's very very low right uh now obviously if you had Talent cost and all maybe it would go up to maybe if if you're getting good talent and maybe not a celebrity but maybe it'll go up to a lck lak and a half but the fact of the matter is bringing that cost down so low and obviously it's not equivalent to anime anime level quality because they're drawing every frame we don't have that level of control but to bring the cost down that much means that now every person can create their own anime like literally every Indian can dude we can now make such an impact in the world of media because now we can create animated content and animated content can always like with Pixar and all we learned this right Disney was considered the Storyteller of the American Empire in India the Storyteller of American Empire is still of the Indian empire is still old school news the problem with old school news where somebody's just writing content or somebody's just you know talking about stuff is you can't exaggerate very easily like you can't do satire very easily like in a way aib did that right but doing it with Comics means people don't have to put their own faces on which means more people can do it they can do it at scale so in a way it makes India very competent in the world of media you just use these many AI tools and to generate this yeah but it will be one click in a few years in like 2 three years like we were only thinking this workflow and we probably just so a does these cohorts so we just probably going to give the workflow out there the thing is the hard part is figuring out the workflow and over time I'm sure people will improve that workflow right once we put it out in the world so it's I don't think that's the differentiator anymore I think it's like you need to have the will to do it you need to understand storytelling you need to understand music uh uh you need to understand we were doing it it's weird I'm saying this because we were more doing it from a tech perspective uh but the next time we do it we'll probably get a few creators on we'll think through the story we'll make it really fun yeah once you know how to how to get X quality just visually yeah when we shot it I couldn't even tell what it what the end output would look like correct correct correct correct but now that you did it once next time you'll be able to do it better more efficiently you know maybe spend like more than 3 minutes on the script uh 30 seconds GPT GPT spattered up yeah so the thing with shooting stuff is and making stuff look a certain ways that once you shoot it and you know what it looks like next time it that process becomes faster quicker and you're able to optimize to make the act of doing the whole thing a lot a lot easier so for example what did you think your workflow would be like and what did it end up being like so we thought we'd make a custom model and we thought that should be good enough but the problem with the custom model is there are a lot of frames in the custom models that just come out badly like there's some lighting conditions where the face will just get really screwed but there's another technique called IP adapters where the output is much better you just feed the best outputs from your custom the exports from your custom model into IP adapters and then the output is much much much better that is something there's no documentation on this on the internet right about you take a custom model output input an IP adapter there's zero information about this on the Internet is this tried we just like like I would probably made like 10 20 models I would have probably done like 100 200 Generations one of them just ended up being really good and then you're like this is really good what if I tried this again also there's one thing I learned during this entire process which is a little bit scary um it is you know AI at least with images and with video actually even with text works in a very you know sounds like uh sounds like looks like way you know You' played those games when you're young where like give me a word that sort of sounds like this yeah Works similarly so if I'm let's say there's a fight scene we did right uh in towards the ending where two characters are fighting that wasn't short what we did is we used a 3D program and we made two characters that look kind of similar to our characters just one of the characters we we pull the hair down or whatever right and then we choreographed that fight scene so we just dumped that into AI with IP adapters where we showed real character me on the left okus on the right and we just dumped that in and we said Okay can it match and it was not great but it's pretty good and so it shows me that you could mock something up in 3D and then kind of project textures on it and there are tools now in blender these are things I found out along the way there are tools in blender now which allow you called dream textures which allow you to project textures on the on on the environment and characters like skin-like textures skin-like textures using stable diffusion right so you want to make a 3D model you want to put a skin on it you no longer need to open substance painter and manually painted like dude people used to hire droves of people so the first place I think there's going to be impact because the anime at the end of the day is just like an AI filter on top of everything right on top of the workflow but I think first disruption will be in games and in media right in in uh experiences so if you want if you want to make a game and you want a character and you want the character look a certain way you can just prompt it that technology exists today so I was very surprised that dream textures exists and you can make any world you want so a lot of stuff like that and I think one thing I learned more than anything uh because I'm not like an editor I know the a folks are but yeah I I just understood the value of a lot of things like storyboarding for anime needs to be very different from storyboarding for the real world because you can do a lot of exaggerated shots and when it ends up being exaggerated if you shoot it the way you should in the real world it comes out a little bit cringe so it's stuff like that that I learned I guess all right I think uh you're you're going to make this part of the AV cohorts like this this would be a module saying okay here's how you can make your own anime now yeah yeah uh I also think there's going to be a new market that will open up with this which is that uh I think dude people will want animation India's never historically produced animation for for even India right the West we have is chab beam and that takes a lot of money and time to produce the minute it can get lower companies will want this and when companies want it the fact that you'll be able to bring it down maybe with your margins everything you probably charge three four lakhs an episode that is still a big win for every company that's a big win for you that's a big win for the company that's a big win for for the country right so we have I'm glad that this has been unlocked we were just the conduit of the technology technology exists so I'm I'm excited we in this world yeah it's net net cost of content creation is going to zero still reminds me of that brand Nar tweet very said that at the end of the day it's going to be purity of your taste that's going to stand out cuz cost of content is going to zero yeah I mean it makes people like for example you write ads it just makes somebody like you so much more powerful because you're just like well the execution tools are available right so you scale yourself in a way so I feel lot more people like that would pop up with be like I'm a great idea person and I know how to execute it I have the experience of executing it so here are the tools that let me execute faster all right awesome you guys should definitely go to the a channel and watch the full video uh I saw the whole thing it's really worth watching awesome T you bought the meta Quest no you got you got the meta Quest three right it's too good it's too good so I've never actually used mixed reality like I've used it on the phone in the sense you can have like a lion or tiger pop up in your scene on the phone Google has these things but dude the quest is like a whole different deal so there's a game I played called asire okay where you're in a room you map out the room and the mapping of the room is perfect okay and you have these agents these spy agents walk in the room there another game where your zombies walk in the room and me and Aina were playing you can play this multiplayer uh she's she's we have another quest in the room it's just so wild it's just so wild the boundary between my walls and they now create a world outside those walls is crazy dude the closest I thought it'll feel like a game it feels like a trip dude I want to watch this video that's on screen right now this video is  mind-blowing so this is somebody playing learning piano on the quest this is one of the coolest things that you can do in mixed re right now this app is called Piano vision and this is my actual piano you can actually do this without a piano we're going to use my actual piano and I'm going to show you what this  is it's so cool it's so cool dude this makes me want to buy the quest 3 immediately this is too good cuz I've been trying to learn how to play the keyboard for a while now and this just makes this experience like 50x better dud you know what else you can do you can also learn martial arts there's now an app on the quest where you can learn martial arts exactly like this in the real world do this or your hand position is off or do this your hand position is off even eventually somebody will allow you to do this with weights because the quest can see okay because it's got like an unlimited it's got like a full array of cameras lower left right dude now yeah this can solve for so many things in health all kinds of like physical learning including instruments or you know a sport all of it dude imagine this in sport also dude yeah it's going to be crazy dude uh also the quest can kind of see inside that's how the reprojection of uh what's his name Lex fredman and Zuckerberg episode Zuber and stuff you know I think it might be very useful for doctors because you do a T Health consultation you do it on practor or one of the apps you're just talking to the doctor but imagine if I was able to see the patient right now it's not accurate enough for me to see every single part of the patient like but but you know if you bring your that part closely in front of the camera in front of your this thing camera and the other person can see like you the doctor can see like you I think that's super valuable because the cameras are enough resolution like skin disease and all you'll be able to see and you'll be able to tell that you can do it on FaceTime also now you can bring the thing closer yeah but it's different when you're seeing the person like it feels like a full body consultation checkup thing right oh I thought inside meaning like camera inside your body okay okay okay no no no this is like a full body like obviously you know you still need tools to go inside the body and I don't think you can do that on the quest but it's stuff like that it's stuff like you want a personal trainer and you want a personal trainer to train you now you can be in the same room as the personal trainer and the personal trainer like pick set up you know do this do that so I feel like we now have the ability to get the best in the world right at our houses and teach us the exact form which your phone couldn't do right like oh your hand is like 15% this thing and piano and all this is like crazy this this this I wish this existed 10 years ago I would have been so much smarter yeah this the ability for a computer brain to see what you're seeing and then start marking out saying hey this is this is how you can get better at this that is the big unlock which Quest 2 didn't have but this is what you're saying mixed reality changes the game entirely yeah and also the quest resolution is really good there's a game called blade and saucery that I used to play on the quest because it's it's considered a very good game because the physics and all are pretty well done uh it the when you pick up a sword it actually feels like it has weight and all that I played that on Quest 3 and I uh I I played it on pcvr so I connect my PC to the quest 3 and then played it the quality is so good it felt like I was like in a different place dude you can also do cool stuff like you can wear a quest 3 and take tours of you know popular uh wonders of the world and you can have like a virtual tour guide cuz the quest can see what you're looking at and it can start telling you details about that there's applications you can do it with friends yeah there's applications in travel in gaming in education in health this is like across the board this is very cool and so so it's way cheaper than Vision Pro yeah it's way cheaper than Vision Pro like I'm in fact after seeing the quest I got very excited by The Vision Pro because I'm like The Vision Pro is like almost 10 times this cost or whatever eight seven eight times this cost so what is hiding in the Vision Pro that's not in the quest all right how much better is the Vision Pro going to be uh but either way I'm just excited and I think the one thing about the quest compared to any other Quest is you can wear it all the time with the other Quest I'd bump into walls here the the minute you walk even outside your boundary area it brings up the cameras it feels like walking around the real world and you can place objects permanently in space so if I'm if downstairs if I want to have like a recipe board just hung up on my wall I can do that I won't see it right now but the minute I go downstairs and the quest recognizes is one of those play areas in your real space you can have virtual spaces yeah so if you've seen The Meta Rayband glasses and this eventually is going to merge I I'm pretty confident like a decade we're going to wear this all the time right right now the biggest issue with this is battery life how do you keep it running for you know 10 hours a day or 20 hours a day uh but I think that will eventually be solved like if we could do it for the watches and the phones which at some point in time was impossible um I don't know I think it's going to be a crazy world when we all we ar at the same time and I think you know things like Pok\u00e9mon go then will become real in a way because we'll all agree that there is a Pikachu there because you can see it I can see it and we're just like we kind of got to agree that it's there and T it's like also like the kind of games and all that are possible with this are crazy like you can now play Age of Empires on a desktop on a not on a desktop on a table like and there'll be fog of War you can't see the character go through fog but I will be able to see it if it's my character they will suddenly attack you like tables and walls suddenly become very useful cuz in the in the SDK for The Meta quest uh there is something called space anchors so space anchors means this is a edge this is a table you map the table out in the game like the minute you put on the quest you have to map out all the tables map out all the walls so it knows where all the tables are if it knows where a table is then you can use that as a surface that's how the Facebook Horizon work rooms thing works you need to point at a table and then you need to be like this is my main table but also the fact that uh you can now use the table to play games so I feel like board games are going to make a comeback and you can be disconnected you can be very far away from everybody else but still be very connected imagine doing all of this stuff only to real realize that what you really want is the real world experience of it yeah yeah but some people are crazy dude they like there's an entire like Reddit Community for people who get married in VR like there's a there's a game called VR chat it's been around for a while where you can do the most whack stuff you can be any character you want you can be Spider-Man you can be Iron Man you can be Hulk you can be a thousand foot character you can you can swing around if you want you can be in any place all the places are mapped it's the most tox Community but people actually get married there so I know people on the Reddit Community who are literally married to another person it's very I don't know the world we are kind of entering into but I think the biggest application of this is why do you even need a real person on the other end now that we have llms and GPT why can't the person you're hanging out in VR or ar be uh GPT okay how much is the quest 3 for in India uh I got it for 60k um I think it's available like that's because I bought it early but I think you now get it for 50 4550 but worth it Customs is the I think the biggest headache but it's in my opinion it's worth it because we want to develop some stuff for it we want to play around with it so we got it early uh the cost adjusts itself if something we build works but yeah I think everyone should get it it's it's cool H okay awesome Elon Musk has launched a new AI what do you think about this this will tell you how to make cocaine step by step I mean on in classic Elon style he said okay the AI that we launch is going to have a sense of humor and that kind of stuff and it has Twitter data to for it to train and it has realtime Twitter info that you can also scroll through which I think is a one huge Advantage right like if I go and ask for saying hey what did Joe Biden do today it will actually be able to tell you uh unlike what GPT does unlike what Claud does unlike what everybody else does who have to scrape the web to get it and honestly like GPD browsing is not good but I'm hoping this AI is much better at that I have a theory okay there's a Google paper that came out today that said that um llms generalize to the data set they are trained on and very little outside of the data set but because this data set is all of our tweets and I'm sure my tweets are there I'm sure your tweets are there in a way this is probably the best model to pretend to be us yeah right if you want to say talk like tan but this is probably the best model because we been train on all your tweets sound like your tweets generalized to your tweets uh that is what I'm most excited about I think there is value in this being like a character AI character. where we like talk like Elon talk like T talk like waron no but also just real real time information is super useful yeah but all of these guys are using a technique called rag for real time I'm sure even you know open a is using something similar uh it's it's real time but you know the more that information you that you pack into it the more it starts hallucinating um but I think everyone's going to have that like Bard definitely Bard feels like the the the left out this one right Bard has the best real-time data but everyone's like oh B's not even in the race just open the ey and this new thing now uh but real time is not no longer a differenti differentiator but I like the fact that it's not woke yeah I like that it's not woke either I don't know there's just something attractive about that tell me something I read how many billion parameters is this I don't know what the parameter count is let me check it's trained for two months oh it's 33 parameters so grock zero is uh 33 par 33 billion parameters approaches the capability of Lama 2 which is 70 billion param but I don't buy the the capability this thing right because they use benchmarks and the problem with the benchmarks is benchmarks can be gamed you start now building models just to beat the benchmarks right where it beats the benchmarks but it doesn't perform as well in the real world so until I try it I can't tell there was this post by this guy okay I don't know who it was was somebody from who works at openi who said I've trained the most number of models in the world okay he just said that and he's like I've trained Vision models I've trained image models I've trained uh text models and it turns out that eventually all the models converge you train a image model in many different techniques there are many ways to make image models eventually the outputs for let's say you ask it for a tree in a park the outputs start looking similar for all the models as long as they trained on the same data sets right so ultimately the it in AI is data right and all of these guys are now realizing this that the parameter account is fine but what's the data set has been trained on so I feel like Twitter is a very valuable data set see I'll tell you the difference between Reddit data set and Twitter data set okay Twitter has a lot of like when humans don't have a mask like on Reddit they can say whatever and everything right on Twitter people are a little bit shielded right and at the same time there's some crazy people in onside Twitter right so I feel like Twitter's data set is more high quality and also low quality I mean the extremes exist in Reddit the extremes also exist but I feel like it it again depends on how it got trained right are you taking the most popular tweets are you taking every single tweet are you taking every Reddit post so I don't know what the training process is but it just feels like Twitter has a higher quality data set than Reddit um so the outputs might be better because I know that SM really smart people like you or deepender goyel or you know smartest in the country for example example are not sitting on Reddit posting their Banger thoughts correct they might be sitting on Twitter Twitter is a more instinctive place to post when you when you have a thought whereas Reddit is a more thought out replying to a question no I think Reddit is less thought out I think the smart there us to be a time where smart people used to be on Reddit that's gone now it's mostly people who are complaining or on Reddit but if you look at Twitter Elon Musk is still there it's still his thoughts there's still you know Yan Lon there's still it's still disorganized though like Reddit is more organized and there are niches where you know people ask questions and specific needs are discussed on though yeah but the best in the world like a Hara ble is not sitting on Reddit he's sitting on Twitter right in his space I'm just talking about I har B might not be the best but I'm just giving examples right all the famous people that I know that have actually made it in the real world will more are more likely to go post on Twitter and put out their thoughts than on Reddit anonymously putting out their thoughts except for maybe one or two amas so I think Twitter is the higher quality data set just from an distinctive perspective um Reddit seems lower quality and the fact that Elon Musk I I do know that open a has also trained on a little bit of you know Twitter's data set but I think the minute Elon blocked that and made you know said that Twitter data set is only going to be used for Gro I think it's going to be useful it's going to be one of the many llms that you use but I think this ability to pretend as tan or warun will be strongest with this because it's got all our data anyway all right all the best to Elon one more one more thing for him to run uh did you apply it's not open yet no did you apply I applied but it's pretty cool man like I think competition always leads to better stuff so if they enable stuff like okay tweet using AI My worry is it's just going to be garbage now you're going to get a lot of no I don't think he's going to let that happen I hope not it will be cool though like it doesn't like today no one has prevented from tweeting like AI or using AI like you can copy stuff from GPT and post it here there's nothing stopping you from it but people don't use it as well because people be like oh I'll get called out some people do use it and then they get called out right uh but at the point where nobody recognizes what is AI and what is not that's where we start crossing a very dangerous line dude go to amitab bachan's Twitter account okay yeah so amitab bachan tweeted out this thing last night that I saw uh this guy tweeted out saying there's an urgent need for legal and Regulatory framework to deal with deep fake in India there's apparently this viral video of rashmika Mandana on Instagram but actually it's a deep fake of someone called Z Z Patel okay and the original video is of Zara Patel and then someone deep faked it like it's impossible to tell that this is not rashmika right like the face matches rashmika almost instantly and amaban tweeted out saying yes this is a strong case for legal and then he just twed out the word information after that I don't know what happened there but it was pretty late night uh but this is now like my sense is that this is becoming more and more like there's a lot more mainstream awareness and now with elections coming up like it's it's going to be like what's preventing someone from making a deep fake video of you know the Prime Minister saying you know anything and forwarding it like this is becoming real now like I know we have spoken about this months in the past six months ago yeah 6 months ago but now it's becoming real and more and more people are becoming more and more aware and the tech is actually getting better and better that anyone would be able to do this on their phone now you able to do it very quickly on your phone that is scary it's going to be zero cost because now if you see the new Google pixel phone I think we spoke about this last time where they have no tpus on their phone so all the processing can happen on the phone itself so it no longer needs to go to Cloud which means Google doesn't have to spend any money on you generating some AI output uh it's just electricity that you're using which means it's now free so anyone will just download like a you know one of the deep fake repositories and just say I'll run it on my own Local app right and apps can now use local processing so you get into this place where anyone can create malicious content you cannot regulate it how are you going to regulate it if everyone in the world can create content and some guy sitting in Switzerland or something is generating stuff pumping stuff for the elections because see all you need is and my friend Bal told me this right the other day he was like at night 9:00 p.m. one day before the election you could get a uh you know message from you know your political party or some some random number on WhatsApp or on your phone say saying don't vote for me H don't vote for me go vote for the other guy yeah and dude there are people in India who vote because they got a Biryani packet correct okay do you think they are going to in their head be like this is a deep fake this is not a deep fake like we really need to make deep fake awareness a thing because both audio as well as video cloning are really good right uh and I think in a way humor and fun stuff spread this better than anything because now we have lots of memes of Modi so a lot of people now know that okay modi's voice can be cloned so the minute you know that modi's voice can be cloned you'll be a aware or afraid of every video but I I feel like there's a section of India that's not even has not even seen this doesn't even understand this I could I could fool my parot with a deep pretty well that's the that's the big worry all the best to all of us have you seen the meta AI personas dude I I I saw it basically meta launched something uh like a character AI like they launched you know Kendall Jenner as Billy as a separate profile where uh there are some real videos of her saying hey I'm Billy and there are some AI generated images and the idea here was to have an AI version of Kendall Jenner talking about her life now I think this was to signal that hey AI influencers are coming and uh second there was an opportunity for people to talk to effectively a Kendall Jenner version of an AI and talk to this person and the response wasn't very good and I understand why because see like if you if there is knowledge that you are talking to AI especially of a celebrity that you think is replying if there is knowledge that this is AI there is diminishing return on the dopamine hit right it that like that it diminishes very quickly similarly many Indian startups are now launching character AI versions of influencers and I'm a little circumspect like when I use this I chatted with I chatted with Mr B AI version and it was it was pretty hollow man like I didn't feel it I think it only works when you don't know that this is AI right like AI is actually almost like the screen saver of of the device which is that it exists and you don't know that there is artificial intelligence at work here but if you know then it's not as fun this is why attrition rate on like memberships is very high right like there is diminishing return there once you know that you get certain access because you paid there is diminishing dopamine and once you know that you have ai there is diminishing dopamine which is that oh this is this is not real I didn't get this off you know like I didn't ownn this what do you think I think the confusing thing for me was why they didn't call it Kendall AI it's the Tweet as well right like like the names really confus me Snoop Dog is some dungeon master or something right correct uh that really confused me but I'll tell you the form factor for this okay I've been saying this for a while but I think this is going to be the form factor there's no reason this has to be on the phone okay to me I think you will now have paintings on the wall you will now have action figures that are all AI I'll explain what that means I want the knowledge of tanai but and his ad writing skills on my wall so when I'm writing an ad I can just be like T what do you think of this right this is completely possible right now you just need a small camera on your painting frame you need an LED screen okay the camera is to make sure that the thing has eye contact you need local processing you can have an easy there are chips now available that you can just put in so it doesn't need to go to the cloud there the latency now is probably half a second I can talk to it and half second it responds I could hang it on my wall it'll be whatever you'll plug it into electricity and then it just pops up thmas there and I'm like T how do I solve this T how do I solve this and it need not be T right it could be you you have a physics problem and you have alak Pand there you're like alak how do I solve this problem all of that is going to be possible so I think the phones are the wrong form factor for this no no phones is the most accessible so I think phones are definitely it's accessible but because we have access to real humans on the phone I think we will always choose to interact socially I mean if we have that access but me just having all surrounded by all these people all my action figures like Alexa was terrible like in comparison to how I thought it should have come out right latency was high uh AI was garbage but I think having like an action figure in my house let's say an action figure of Spider-Man where it has all Spider-Man low and I'm able to talk to it about just motivation right like Peter what would you do in this situation that I think is very valuable and I think the first place is going to be used as in religion because the biggest differentiator for a lot of people let's say selling a Ganesha Idol is what what if I can put the spirit of Ganesha in this it's a very weird concept but it's going to happen right like it's religion has actually never shied away from technology they've always gone and put technology in everything even temples today you'll have like you'll do UPI and you'll get in right you'll have a slaughtered system on the phone so it makes sense to me that at some point they will put it inside of it but then you'll have arguments people will have arguments on oh that's not actually what Ganesha would say here's I have a better model of Ganesha so I feel like the world might I I don't know it's so weird like anything with lore you can now put into physical objects so I don't know what the what what is going to happen yeah that's that's so interesting imagine going to a temple and you can talk to God now yeah you can you can have God at home your Idols can talk to you and I know that to you and me might be it might feel silly okay but you look at old parents like 80 90y old God talking to them is like a mindblowing thing yeah they will I know my grandparents would be stunned if something like this happens they be like how I feel like having something that responds back God that finally answers back is wild and I think for different people it's going to be different gods right somebody would have Iron Man in the house and be like I want Tony Stark's idea on this I want Tony Stark's uh viewpoint on this so anything that you grew up loving can now be part of your homes can now be part of your houses and kids a lot of kids who buy toys will now grow up with toys that talk have you seen The Moxy toy yeah I've SE I've seen The Moxy toy yeah so there toy called Moxy that walks around talks to you it's powered by GPT now so kids will grow up with talking things like today's kids uh gen whatever the generation after gen Z Gen X I don't know what they're called um they've never grown up without technology they don't know a world without social media they've never seen a world without social you and I can remember it in a to a certain extent my parents definitely remember it but the next generation will not remember a world where anything was static your screw will have intelligence that's true but I had an interesting idea and I think it's a good v1.0 like with AI everything is a v 1.0 right I think everyone's learning no one's no one has enough experience in this like no one has experience of how the users will use something or how it'll actually end up coming out you'll work on the problem you'll know this is technologically possible like our anime right but then in V2 or V3 when you've gained that experience now you'll put out something you be like users will like this or users will not like this that EXP experence takes some time and it's all so new that no one's had any time to perfect it all right uh that's it for this episode hope you guys enjoyed it please hit the Subscribe button so we keep showing up on your timeline and follow us on Instagram as well you'll see an a bridge version of the whole episode in the form of reals it's for lazy people it's for lazy people see you next time  bye",
    "url": "https://www.youtube.com/watch?v=H0t9btxVCCo"
  },
  "s_fCpD_B_-U": {
    "published_at": "2024-04-23T15:46:32Z",
    "title": "This App Can Make You Famous Instantly",
    "text": "This App Can Make You Famous Instantly there's now a tool called parallel Liv basically you can fake having lots of live followers so I'm live right now with 42,000 people on Instagram what do you want to what do you want to say to my audience I made an app called parallel live that makes it look like you're live streaming with tens of thousands of people watching to see how people treat you differently when they think you're famous I think Drake just joined Drake Drake come live with us Drake cool app and I'm assuming that is pretty simple to build as well like what he's built is not even an AI tool it's just a skin yeah but it's damn smart yeah like I'm assuming now with voice recognition you don't just have to fake the fact that you're live but the actual comments that show up can be responses to what the person is saying and you just have the skin off the number of people watching so either you have an immune system to this and you're like wait this looking sus of somebody having like 40K followers and like Drake or rajnikant joining and saying whatever either you have an immune system because you've seen this real before or you don't and you fall for it like op out next year is just going to be preventing scam scam",
    "url": "https://www.youtube.com/watch?v=s_fCpD_B_-U"
  },
  "RJSS09kC8Xk": {
    "published_at": "2023-09-03T11:00:30Z",
    "title": "What Do You Guys Think of Google AI Search?",
    "text": "What Do You Guys Think of Google AI Search? Google launched something called search generative experience which now does some magic inside of search so let's see how it works first one is you have generated AI in search so let's look for Bruce Wayne it generates text love interest some information and then it's giving you top three links I think SEO is going to become completely different as a field right because what happens generally when you look for Bruce Wayne is the first link would be from fandom Wiki and whatnot there's only a devalued to these three so SEO kind of gets limited you have to be among the top three if you're writing content yeah but broadly doesn't feel like this is that much better than just a general Google Search right so I just search for recipe for omelette and then something called Converse let's see what this is and I can ask follow-ups so the chat interface is interesting it's gonna be very specific links this is interesting but I don't find it that useful to be very honest everything seems very gimmicky what they're trying to do it's the same stuff right as in bad or chat GPT but they're trying to put it where the user exists and that doesn't seem to be working so well they're experimenting with format not with the tech itself but I think the best format for this is chat yeah chat UI is a superior",
    "url": "https://www.youtube.com/watch?v=RJSS09kC8Xk"
  },
  "zMVTsykitiI": {
    "published_at": "2023-10-10T15:07:59Z",
    "title": "ChatGPT Just Killed Exams &amp; College Assignments!",
    "text": "ChatGPT Just Killed Exams &amp; College Assignments! so T is going to send us all of these different parts and Sid's going to combine it we're just going to make music here by the way people don't know this but T learned some music growing up T what did you learn growing up that seemed on beat right I'm looking for Sid to validate me I think if a beat boxer Did something like this it would probably like have that oomph what are you saying that I'm not not good good enough I I didn't mean it like that how do you remove user of  Zoom it's a new week A lot has happened in the last 10 days in AI a lot in fact we're not even going to be able to squeeze everything in this episode we're going to stretch it over two episodes Von how's it going good good we have sit here from 100x Sid is hi guys here to to demo the first tool for us and uh then we'll kick him out by the way Sid how's the cohort coming along I heard the 100x cohort is doing uh like you are enjoying it yeah it's it's going really nice very good to see uh I've been seeing a bunch of people talk about it over LinkedIn over Twitter about how they've been enjoying the cohort how they've started out as people who have like pretty basic knowledge in uh programming but then right now they're starting to build um fully fledged um front ends of uh whatever projects we've been giving them and they using GPD to assist them so far no but they'll start using it this week onwards all right interesting so you're doing the basics first and then the AI yeah yeah we're building the foundational stuff I mean you can use GPD from the start but that wouldn't help you long term dude I saw these beautiful key cards that you had made can you tell me a little about them so those key cards were so we had a sorting ceremony like uh You' seen Harry Potter uh we basically made this website where you essentially go and you put your email ID if I'm a student I can just put in my email ID over there and uh based on a quiz that I had taken earlier I will be assorted into one of six houses and all these houses are based on you know your uh classic os's like Debbie and Fedora uh etc etc and it was a part of the Sorting ceremony and we represented each house with a key card nice sweet whole idea over there was uh learning is more fun when you you know do it in smaller groups understood anyway so the 100x uh cohort is going to start becoming AI assistant this week onwards let's get to what we are discussing in AI this week this first clip I saw where this dude turned his voice into an instrument check this  out  d  yeah this is pretty cool uh but why does it feel like this should have existed like some time ago no doesn't it feel like it should just turn into a music instrument yeah I now now you say it actually does yeah dude but but I feel like there's still skill invol I'll tell you why because we tried to do a real along these lines okay I was just like okay let's let's use this tool let's break it down and I did something with my lips okay I was like town down whatever I did something and it didn't match because it turns out you need to know what the beat frequency is you need you you need to stay on time you need to you know stay on Pitch you need that little bit of musical press in order to get it right so by the way people don't know this but T learned some music growing up T what did you learn growing up I learned hindustani classical vocals for about 78 years I know a little bit of the T and I know how to play the harmonium okay so I will be way more on beat than Von is okay awesome so T is going to send us all of these different parts in's going to combine it and we're just going to make music here I'm going to do this right now  okay now let's do another one bum bum   that seemed onbeat right I'm looking for Sid to validate me it it it kind of works it kind of was I'm waiting for the day where you can just go into a prompt and just be like give good music now by the way this real what this guy did mhm I know that a lot of DJs now use something called vocal chops which is literally the DJ will be like P and then they'll take they'll take their sound and they'll and they'll you know they'll do something to it that I'll filter so it starts sounding like a whole new instruments like Ritz has said publicly that the drop in UD is actually his voice like he hummed it and then he made it to sound like this weird hindustani trumpet sort of a sort of an instrument mhm but can you now convert voice basically is it now easier to do vocal chops uh it is and it isn't uh it's a two-way sword over there it is because uh I'll show you a tool basically uh I mean the one that we just uh you just saw in order to convert your voice into any instrument so the advantage is you can actually do it and it sounds pretty damn good but if I am a musician if I'm a music producer and if I'm like producing a proper professional track I still wouldn't use it for my professional track Sate I would still rely on you know the classic vocal shops like I would just record my own vocal samples and I would just slice it into multiple pieces I would process it I would put like insane amounts of Reverb etc etc on it sounds like 99 99.99% of AI tools so far which is uh it's almost it's baby but not quite I be I would beg to defer but most most I I think I think the fair way to say it is 99% of Music tool so far because music tools aren't that great yet so this tool is called music music fi. L yeah music fi. l so essentially there's a bunch of things you can do uh just like we did the last video where we made you sound like Shah ruk Khan we can basically do that as well you know there's a bunch of people over here but we're not going to go into that uh what we're going to go into is turning your voice into an instrument uh so how about we do this okay uh tan just say uh just say like a simple beat and send that to me on Whatsapp something like something like that  okay stck okay I've sent it to you and you're going to turn it into drums yes I'm going to turn it into drums there's two kinds of drums over here there's one which is basic drum set and there's another instrument called daruka which is a much more of folk kind of an instrument let's actually try darbuka it sounds pretty nice in this oh darbuka yeah so for reference this is what it looks like yeah it's it's this one looks like a JBE okay all right so I'm going to select an audio file okay I'm just going to convert this all right few more seconds of waiting for it to generate this  AI is so slow man I know right get really fast okay something has come yeah let's listen to what tme first sent just so that we have that transition moment this is what you sent  and I got to do like a capella or some  that was so  good oh not bad that nice not bad can you try another instrument yep yep let's try the break beats what's breakbeat it's like a normal drum set all right let's go it's actually pretty good it's pretty good yeah I think if a beat boox or did something like this it would probably like have that oomph what are you saying that I'm not not good good enough I I didn't mean it like that how do you remove user of  Zoom I want to see what happens if you put like uh this is like a percussive instrument right what if you put like one of the strings like a slap let's try slab base right so which instrument is slab base slab base is where if someone's irritating you use slap them with your Basse guitar nice oh it's a bass guitar and you slap it using your thumb oh interesting Boomer alert boom I don't think this generation knows any of this no no it it does it does if you use a slab base guitar too hard then someone comes and yells at you saying how can she slap slap now I'm am Boomer cuz I know this reference all right on that note slap that like button oh my God all old bloody old people no this it's not as good not as good yeah I mean it's probably because you didn't do the I mean it doesn't have notes it's just but it's kind of getting the slap sound right tell me something Sid uh like we first did the percussive instruments right like like we can do JBE we can do drums but didn't didn't a bunch of music software already have the ability to create a four what is it a 4x6 beat or a 2x4 beat what are they called absolutely yeah yeah yeah a 44 34 whatever yeah so that already existed correct so why would I why would I convert my voice into a beat maybe for some Melody because okay randomly I'll think of a Melody saying and I want to see what instrument would sound good with it uh but it's like it's just a bunch of notes right like it the leap between me thinking of a melody and trying a bunch of instruments it's not that hard even now mhm I mean if you know if you know how to play the instrument right like if you don't know how to play an instrument then this is your only option like I don't know how to play guitar Melodies are made up of notes and if you play if you if you play the notes on any instrument yeah if you play the notes on the keyboard you'll be a able to turn the keyboard sound into another instrument sound anyway right if you know the notes absolutely you need to know the notes but you also need to know to play the instrument for example all instruments are different like you take an Ocarina it's like you need to know how to play it right you need to know what finger fills what hole to yeah but if you know how to play like something basic you'll be able to uh turn it into any instrument anyway so this is great for people who don't know how to use any instruments but I have some sort of this is great for musically late people like me if I was a Wess and if all I knew is like how to sing and I don't know how to play any instrument and let's say that I want to compose music uh but and I want to just create a demo track as a vocalist I would obviously go to a music producer I would be like hey make a track for me I want these instruments to be there and this is the vibe I'm going for and I just want to probably show someone that okay this is the kind of backing that I want I can this is what it probably can become I don't see any music producer using this for their final track or Masters or anything like that that would be kind of ridiculous to actually do uh in order to just convert vocals into whatever instrument it is so this is great for people who don't know how to play any instrument don't know how to produce music for them to produce music so cheers AI for helping us make more trash music from people who don't understand music the one time AI isn't taking your job and actually helping you yeah yeah six months oh my God all right uh now Sid's going to show us how to make a full track uh using just your voice uh this is going to be a pre-recorded segment so enjoy this okay so I'm going to use this tool in order to create the theme song of Pirates of the Caribbean we're going to do a very minimal version of it so I'm going to first record a Basse track and then I'm going to record two Melody tracks One On the Banjo and one on the violence the number of instruments available over here in the software is pretty limited so we're going to make the best use of whatever we can so let's quickly record all these three tracks and let's put them together and see what comes out of it all right firstly I'm going to record The Bass track okay let's remix this now I'm going to put this base track into logic logic is a very popular music software that a lot of music producers use in order to produce tracks Mix Master whatever you want to do with  sound now that the jaw hop Baseline is done we're going to record the melody so the main Melody we're going to do it on the violin first and then on the banjo you'll see the magic come together when we introduce the banjo so let's select violin right I'm going to remix that  I'm going to record whin one more backup track just in case in a different modulation I said titing Ting I want to try the same thing with Ying Ying Ying Ying because that's how wiin usually sounds now I'm also going to increase the pitch of the violin to the higher octave so that we have a little bit of a wider effect awesome now finally let's record the last Melody layer on the banjo  I want to add one more element I want to add some horns to it which is some brass so I'm going to do this as well let's see how it sounds if it sounds good I'm going to keep it if it doesn't sound good I'm going to throw it off I'm going to add a Harmony layer to it as well all right let's see how it comes  together all right so I'm going to go back into logic and I'm going to import all the tracks that we just made which is these tracks okay let's get rid of the ones that we don't want jaw harp we need that this violin let's keep it mute for now violin one and violin High let's call this violin and let's call this while in high let's call this pandro and let's call this brass and Brass Harmony awesome let's align everything together over here now and finally when you put all those layers together this is how it sounds  and all of these are literally just my voice there's not a single instrument that we used if you want to watch a detailed tutorial on this tool music F and explore its other capabilities like voice conversions into other people's voices or more voice to instrument Explorations if you want to watch that headwood 100x engineers there'll be a link in the description and you can click on that link and watch that video all right Sid uh what's next so what's next is an augmentation of what's been there for a while uh GPT came up with this new add-on called GPT Vision which kind of blew my mind it is essentially think of GPT Vision as GPT Plus image so you can import images into GPT and you can uh make GPT interact with those images in multiple ways so I'll show you a bunch of ways that bunch of things that is actually POS possible with GPT Vision so here you can see this image button now which did not really exist earlier so one really cool thing that I really liked about it is uh I I can basically give it an image of let's say some biological thing like uh biological just search for search for biological diagram testes testes are you allowed to put that on screen I mean it's a biological diagram fair fair fair okay let's go with this interesting sorry I'm 12 years  old explain this to me hey and when GPD and when GPD replies can you reply to it saying that sounds like balls okay that was nice that was good that was good this is this is probably doing OCR pulling out the text uh I mean because the text is already kind of I mean the image is already kind of labeled this would be a little bit cheating in a way uh can you give it images without text no but I I'll show you something really cool after this okay okay got it it's able to understand a diagram it's able to read the text but this this doesn't seem like that large a leap cuz there have been previous like technology that has done this B has done this now I'm basically going to get something like math problem do 10th standard board exam question India mathematics we're looking for some random paper pick it up copy paste this into GP division like copy paste the second second question into GP division let's just say I mean cut it yeah let's copy three questions huh first three just dump it into GP don't give it any context just throw it in ah I can't I have to write something otherwise the button won't pop up oh just say put question mark one question mark Okay so we've just put in a board paper a 10th standard board paper first three questions just clipped it and thrown it in it's not copy paste it's just thrown in okay it's given us the first answer byebye buy homework yeah so it can read text off an image uh what else can it do Sid do you guys see the mark Zug announcement yeah now they have these glasses where you can just wear the glasses all throughout and it'll have some version of you know a vision model on it to me it just seems like I I would like your thoughts on this to me it just seems like exams are useless now like it's just going to carry I mean or eventually you have lenses or whatever like what is the purpose of even ever doing an exam where you can be able to summon sort of all of Humanity's knowledge just by looking at a thing like because Mark Zuber in his demo said well you have a pipe in front of you you don't know how to fix it it'll tell you exactly how to fix it you have an Ikea table in front of you you don't need the instruction set the thing will look at it and be like hey do this first then do this then do this what is the purpose of an exam in a world like this it is to make your parents proud uh but yeah now it's like exams are solved teachers are going to be very very very annoyed I mean like exams have to change in a way right like T let's say you're a kid okay let's say you're 18 years let's say you're 16 years old again and you're writing an exam or you're doing an assignment and you know this tool here exists and you're just like I'm just waiting for it to enter you know one of these glasses that meta's already announced how do you feel how are you supposed to feel as a as a kid writing a useless exam yeah I think exams are solved now as soon as uh as soon as Facebook x-ray ban becomes cheap enough that the glasses act as your eye and meta AI or GPT will act as your brain and anything you see will just get soled instantaneously uh so that is done for my larger worry is what does this do for learning or just basic functioning of making your brain do an exercise of solving something that's what makes you learn anything right which is actually sitting and solving something what happens what happens to that now there's no need to do that I would say maybe we will have rules it's I'm just I'm making a hypothetical statement here but I think there will be rules where you can't use an AI till you're 18 or something because your brain is still developing and this is going to make you cognitively lazy yeah it's going definitely going to make people cognitively like I I've stopped writing like I I write I still write but compared to how much I used to write 3 years ago I don't write anywhere close to that much I've heard this from many other Founders by the way it's like here three bullet points expand this into a note that I can send to my company but I I don't think it is wise for me to have started doing that when I was like 13 or 14 it's like yeah the thing is there's this there's this novel tweet which which said that today's problems are not like yesterday's problems yesterday's which means many years ago were problems of scarcity which is that oh there's not enough food water you know there's not enough medicine there's not enough sugar um you know there's not people used to literally uh get their dopamine by doing rudimentary games and today's is the opposite which is the problem of abundance which is there's too much sugar there's too much porn there's too much addiction to everything else so it's we're going to see Darian results which is the folks who learn to exercise uh discipline will be able to resist sugar resist Pawn resist dopamine uh so similarly there is cognitive abundance now which is everything is solved for you don't need your brain to to really do much so I actually disagree I think that you will be more disciplined with AI because you know what so a lot of young kids want mentors okay they'll go out on the internet they be like I want a mentor this that and I saw a tweet I think it was by siddu pona where he was like it's uh most people looking for mentors are actually just looking for somebody to tell them what to do on a daily basis so if you have this God to your AI sitting in your glasses or your phone or whatever or some something that you're wearing and it just tells you do this get up at this time do this it's just like you are putting the faculty of your life into somebody else's hands and they're just running it for you correct I think more people accountability over there no the AI is accountable the AI is telling you do this at this time 6 a.m. alarm get up vun go to the gym but vun the drive to do it still needs to exist the drive to actually want to pursue something with the guidance of a mentor I think you're all underestimating the fact that eventually we'll start trusting these AI more and we'll just look at it as a coach SL Mentor figure like Olympic athletes right the coach is like the one pushing them and eventually as a function you get into a routine you've done it like 30 times because the AI told you you become more disciplined as a this thing now I could be wrong right this could play out differently yeah yeah so the folks who are driven will now be assisted such that they'll be more driven and or they'll really outperform but the folks who AR driven it's not going to solve anything that's what I said by it's things are getting more and more Darian cuz the tools for people who are driven always existed and this is getting superb it's just yeah it's just it's just gotten really good now all right I'd like to show one more thing which was uh name what's your favorite chicken dish T chicken lababdar chicken laab I don't know I just I just like saying lababdar okay let's see if GPD can actually identify okay okay okay so we're going to take a picture of this I'm it probably looks like butter chicken honestly yeah I would be shocked if GPD knows this is chicken laab I would be shocked as ask for recipe also yeah that's exactly what I'm asking I would love for GPT to say lababdar give me a recipe prom Tor looks like a delicious dish can you just ask what dish is it it says meat curry okay it took the safe way way yeah it is the safe way out search for something else so can you search for poha poha let's see what is the name of this dish in India cuz poha it'll say like soft rice or I think the Rayband glasses is going to be superb like I'm going to buy it because it just seems like when you're cooking you can just tell it okay just give me the recipe for this or you look at something like where do I add this particular ingredient in wow it recognized PHA bro it did it did yeah okay now search for search for lemon rice and let's see if it distinguishes between POA and lemon rice dud that looks exactly like  poha okay let's see if it recognizes lemon rice oh the GPT uh cursor has turned into a thing wow wow it understood lemon rice D dude this is like you know six months 6 months ago by the way I had made some real about uh Vision models or whatever some guy was like it can't still can't differentiate between a dog and a cat look at it now POA and lemon rice POA and lemon rice it's like I would get confused by the way  this making me hungry no but this is really good these Vision models like you start putting them in robots they'll be able to go to your fridge you'll be able to identify where the handle is it'll be able to do all that fun stuff I'll show you one last thing with vision this this is what really blew my mind if I take a screen shot of let's say these two things which is the follow and the message button and then I just paste this over here and say right HTML and CSS code for me it actually does it and I can put this back into repet or whatever my coding environment is and I can get the exact same buttons so wait I can now take a screenshot of any app on my phone then open GPT input that and say write me the code for this yes and and it will just give you the code it'll build you the front end uh yeah back end what goes on behind the scenes it's like depends it's app to app yeah there there you need to know what you're doing here you can basically prompt it hey go to the 100x engineers website for a second uh there yeah okay zoom out so this is the 100x engineers website take a screenshot of this entire thing put on GPD and ask it for code if you actually give it larger chunks you'll have to go through a debugging round and all that try try try try just try let's see it can't generate images yet right I mean it doesn't have Del yet I mean it it it will give you the tags it'll give you the IMG tag but you'll have to put the link yourself go down go down is it actually generating yeah oh nice why why did you ask him to do this no just to see if you can dump an entire website in he dumped two buttons in I was just saying can you dump the entire website in what does this mean marun no this means that I mean landing pages see it's not generating the entire landing page if you see inside the navigation there supposed to be links there's no links inside the navigation it's just giving you empty space to fill it in but can it make your work easier absolutely you like a website just like you can can screenshot it screenshot it you can get some starting point but I mean this is today right like 6 months later a year later it's going to get better yeah I think it's getting all the colors and all right there's all the sections over here content is also here it's just given out it's it's given us the framework we have to fill it in with the details yeah it's also mentioned that this is not really a complete thing so what I've seen is when you usually give like larg websites things are like here and there sometimes and you have to make a little TW tweaks so I think someone will train a specific model on this yeah yeah very possible yeah that's about it awesome thank you so much Sid thanks for jumping on and good luck with the cohort uh bye cheers guys thanks for having me bye guys see you dude T I have a question for you so meta came up with the Rayband glasses right yeah and obviously that will be that has a camera so it can look at things and it can answer questions for you and all that fun stuff it's going to be working with you with voice but what do you think is the ideal form factor to carry an AI on you I mean chip in brain is the best the most efficient but yeah probably right now phone a phone has a mic a camera it can speak for you it can listen for you it can see for you but it's inconvenient to hold a phone like I think especially if you if you want it to take audio feedback from you you have to bring the phone here M and holding the phone is a pain so one person on the internet recently actually multiple people at the same time so this is this thing it's called rwind pendant it's a variable that captures what you say and here in the real world and then transcribes encrypts and stores it locally on your phone and then you can quiry it this is insane it is wild and if you see the website Sam alman's there Alexis Ohanian is there Mark andri is there they're all like this is amazing so you're just talking you're like oh what what meeting did I have yesterday 5:00 p.m. yesterday what I discuss what's my task list for today and it knows everything because it's capturing everything you say this is both useful for some folks and not that good for others probably because if it's recording you it's recording everybody else as well right which is a breach of privacy in fact I saw something uh which I don't know if it was like a parody or a fake one but someone someone tweeted out the anti- rewind pendant which is another pendant that prevents your voice from being recorded on another device because if you just have a device that everyone's recording all the time then when the  do I have alone time when do I discuss my herpes issue that I want no one to know about dude I think I have a weird perspective on this okay when phones came out people said phones uh need not I mean you can't record somebody else with your phone like you can't take a video of somebody else with your phone on the street and whatnot right time is gone countries have rules around this but what are you going to do if somebody records you in public like what is your legal recourse do you sue you can't sue it's like it is meaningless to sue because it takes 10 years to settle anything in India uh so what are you going to do so people can just record you and you can't do anything about it so with the rewind pendant okay somebody else captures your voice while they're around you whatever you don't know they're wearing the pendant the problem is you can't do anything about it okay so I think it's just a world where you should just every word every statement you say is anyway going to be recorded like I've I've made my piece with it right and the way you counter it is radical honesty radical transparency obviously 10 years ago people were not radically transparent now they'll have to have a new framework I don't think I I mean if you have a herpes issue you should just be public about the herpes issue that's what I think the world is just to clarify I don't have a herpes issue Von is saying it so seriously making it seem like it's real I don't know man like it's you're right everyone will have to be careful all the time it's the assume everything you text on your phone to be screenshotted but applied to IRL now everything you say is being recorded at some point how much is the pendant for it's $59 $59 that's it that's what the reservation cost is there's one more called tab which is $600 I don't know if this $59 is the reservation cost or like the entire cost but I don't think it's going to be more than 10 20,000 rupees yeah and I think it's worth it if you think that you know it will help you have perfect recall like it technically it gives you Perfect Memory I imagine people wearing it when they go to a conference when they're taking meetings in person it's a professional thing and I think it's like it's like a Black Mirror thing where you probably enter a meeting room and there will be rules around this like at least informal rules around this uh which is that hey guys we're going to start the meeting and then you press a button and everyone's rewind pendants activate yeah right and we're all like okay meetings in session now now you start talking because Zoom calls like Believe It or Not these days like all important Zoom calls we record cuz it's just like we'll forget this later especially when to deal with a lot of stuff so I think we are entering a world where we are post privacy and I think anyone who's like really gungho on privacy is going to just be disappointed I think it's like happiness about expectations minus reality right uh and I think if you keep your expectations low that fine everything is going to be recorded I think it's fine you know who's been facing this for a while all the creators they have to be very careful about every word they say on social media because their name drives clicks right so a Creator will not text another Creator anything or text another human anything which they think will eventually make it up to social media so everything like I would say if I had to choose between which of the set of people in the world are actually the most saintly in at least in India among the people I know because I know Founders creators normal people ex like I know a bunch of people right diversity is there creators are the most scared I mean the counter to this is why you saying something that you would be so afraid it would be made public it's always contextual right Ian people know they will clip like it's almost like I know a Creator who will not send multi-line messages okay and I was like he's like wait I'll he'll delete four messages then he'll send the entire clock I was just generally asked him in person why are you sending the entire block like just text normally bro he's like no but some people will screenshot that particular line and put it on Twitter and then you know I get into trouble so it's like these people are so scared that actually if I have to bet my money on who's the most saintly like who is actually not doing anything wrong in life would be them but also in a way it dilutes your personality right because you can't say or do anything that more than 10% of the world disagrees with so on the one hand there'll be rise of people attacking people cuz now so much more information is constantly public and on the other hand I think there'll also be some normalization of uh you know at one point it was a crime to cuss and then people cuss so much that it became the new normal so I think there'll be just more accept of hey people are are human these are human beings and sometimes human beings have you know you don't know what their motivations for all their actions is etc etc etc so there there'll be a bit of both but the new normal will be constant recording much like the new normal now is you anyone can be filmed anywhere anytime now it is anyone will be recorded anywhere anytime and you just get used to it don't say anything that you know and just like because of the rise of tech and connectivity there are now no Wi-fi hotels right these are designed for the anti-tech experience uh so you'll also have those kind of informal rules like you said and there'll be this I think there'll also be the anti-tech tech which is you know for every virus that's made there's an antivirus so it's it's kind of like that which is okay how do you still continue to maintain some sort of sanity and there'll be tech for that yeah because people will lose their minds being most as much straight jacketed as possible right if you can't say anything if you can't Tex any personality of your own dude you can't have any personality anything that's different from the mes you're done like people will take that one screenshot put it out whatever imagine your whole life right like you have you were born you had a certain set of parents your brother your sister your friends your growing up your environment the schooling you went to the experiences you had as a child all of which results in you being your personality which means that some things trigger you more than the others some things you have an affinity towards all of that gets nullified if every moment of yours is being is being monitored and carefully analyzed from that lens you have to be as average as as as you possibly can like you have to you have to be perfectly average in a way yeah so it's just like what's the  point of just living your whole life if you can't be the product of living your whole life no but I think people get frustrated like if you watch the movie Purge You' seen Purge I I haven't Purge is like basically everyone's like okay we're normal for like 365 days a year but one day of the year at 12:00 a.m. all crime is allowed right go murder anyone you want do anything 12 that those 6 hours 8 hours whatever however long it's called The Perch you can do whatever you want so I feel like people eventually get frustrated and just be like I want one day in my life where I can just go to some place and smash I just want to say whatever I want to do what I want to yeah H got it anyway fun times interesting times not fun interesting times I want you to watch this video chat GPT we already saw GPD Vision but now chat gbd can also hear and speak yeah I saw that I saw a video on Twitter where it demoed some guy who clicks a picture of a bike let's see that  that's pretty crazy I think it killed a bunch of meditation apps because now if you want somebody to tell you a story or if you want somebody to tell you like sing you a laabi or help you meditate and stuff like that you now have a partner that can do that why do you think it's going to kill meditation apps because it can now speak as well you can now hear and speak so you can actually I mean at least I saw a video of it where you can tell it you know I'm I'm really stressed at work today can you tell me like five reasons why I shouldn't be stressed here's the specific context and it it it can like you know numb you in a way you remember like a lot of people in India were talk about the hypnosis apps by the way I thought just so you know I thought hypnosis was Wo I thought it was a scam right but then I started speaking to people and a lot of them were like hey I got hypnotized I got hypnotized and then I went and Googled it and apparently hypnosis is an actual thing there are papers on it right so I feel like at the end of the hypnosis is just somebody talking to you okay so I feel like a chat GPT can potentially do that to you uh if it has voice it can be your Budd it can solve loneliness a lot of VC's now are like loneliness is the biggest Stam right like everyone wants some solution to loneliness so I feel like it's there why would you need a headspace now when you can directly talk to a GPT and it can you know whatever sing you a alabi or whatever what's next now variables for open AI see technically GPD can now uh with GPD Vision it can now look at pictures it can now look at your drawings you can communicate with it through written text you can communicate with it through drawings it can hear so you can talk to it it can also draw Technic D is gpd's ability to draw and by the way the cool thing about D 3 is you don't actually have to prompt it anymore like they removed the idea of prompting now you can just talk to it like a human being you can just be like I want this image so the interface now is just chat GPT so it can draw with GP with with Del in my opinion that's like kind of most of what we as humans do no pretty much at least digitally right we are texting on a computer or texting on the phone you're properly drawing on the phone like all the interface formats have been mapped now it's time for GPD to have you know GPD day much like apple where once a year they come out in there like here are the five new jobs that we are removing here are the five Industries we are disrupting uh I'm now starting to see the you know 10 billion 20 billion valuations now cuz slowly slowly I mean I feel like next is variables right like at some point in fact um in fact pendant that that we mentioned in fact re B pendant is already like Sam is an investor in it um and a bunch of these are going to start coming right which is GPT powered like okay I need a glucose monitor I need a sleep tracker like if I have a sleep tracker I need a I need a pair of headphones by the remember we did this we did this like six months ago where I took the ultra human glucose data I mean that's not the ultra human data it's the abot data Abit sensor data I dumped it into GPT and I was just like give me insights and it did a good job yeah yeah so you can synthesize all data formats into it it GPT is a biggest greatest ability that I'm really impressed by is the ability to convert any format of data into any other format yeah can convert unstructured to structured data and vice versa I think that's fantastic because now you are a connected human any data source you have can be pulled in environmentally internally Etc but also if you think about it right every app every industry technically at least digital Industries are some combination of writing drawing texting hearing listening like take at tech for example right education in general ultimately an app let's say like by you are watching some content that content has been pre-recorded it's been pre-generated you're watching it you're gaining something out of it then it's testing you right like you're probably answering some questions or whatever GPD can do that right especially the easier the content if it's not like deep Tech or whatever if it's not something that content that came out very recently and it it has a knowledge cut off issue if it's like 10 standard science for example I think it can do a better job than most education apps yeah you can have your favorite person teach you you can have shuk you can be like GPT take the form of shuk and teach me yeah and it's not just going to be GPT right like now the differentiation between products will be the what is the llm at the back end um different countries will need to start having regulations how much data is going to GPT which dat is your population is their data going to GPT do and GPT is the super app in a way right like what I'm saying is you have multiple different apps in multiple different Industries someone will just be like why do I have 10 apps on my phone I have this one app doubles up in my meditation app it doubles up in my teacher we are summoning God in a way right it's like one person that can answer things for you but also produce things for you I think there's a dystopian version of the world where we don't have anything to do online but I also think there could be a utopian version maybe we don't have to do anything like why even stuff few minutes into jobs and any of that like the modern institution like 300 years old modern concept of money is the modern banking system is 150 years old it's all very new correct what if we just had Utopia we can do whatever you want it's it's possible like share subscribe all right what's next okay let's come to content creation okay let's do the end of content creation one have you seen this real but the first round of interview is a culture round where we see if they fit with us if they align with our values and the second round is the technical round where we actually look into their skills we put the culture around first because we want to know if we align so that we're not wasting their time or our time what do you think it has gotten really good can you tell me the process of how you made this so the video is on haen the audio is our own custom stack of Ki plus RVC so it's like a double pass audio got it I'll tell you the cool part mm I I put up another reel after this this is I was just demoing I was telling the world that hey I think we we are almost here so I put up another reel about uh The Meta Rayband glasses like three people in the comments said this real is AI generated everyone else was talking about the Rayband glasses it's like people can't tell like the average person can't tell and this is all and anyone can do this from just the laptop and uh this thing now anyone can do this hen is like uh the video part is very cheap I think it's like 2030 $40 something like that uh the audio part is open source uh it's two passes right now we are using our own set but it's going to be one click someone's going to make a one click version of this it's gotten much better lip to text matching has gotten much better Tech uh Speech modulation has gotten much better I'd say Yeah it's gotten at least 50% better than the last time we saw something like this but can you play a reel of you that's not AI generated okay so I'm going to show two reals okay I'm going to show two reels you tell me which is AI generated which is not AI generated and by the way just a clue all most of the recent ones are AI generated okay so let's go to shots let's play this real meta and Rayban have just launched smart classes with builtin AI making sci-fi your new everyday life that we will soon live in a world where you can interact handsfree wherever you go is simply insane now open has already powered chat GPD with the ability to speak hear and see but these smart classes are about yeah show the other real so this is one yeah so this one this one is definitely a generated let's look at uh let's look at one which is not AI generated okay uh chat GPD might have just killed your favorite meditation storytelling and fitness apps why because it can now speak hear and even understand images check out the video above this is also y generated let's play one last has just released D 3 for free and it's available to everyone through Bing chat to access it simply visit B this is this is real this is not a generated you're right yeah so you can still make out the difference but it's getting harder it's getting harder to distinguish between between you know what my OD stick is my OD stick is comments how many comments say this is AI generated now I'll tell you what every video I do there'll be five comments saying this is AI generated because people are just so confused like like if you look at this um which one yeah this one okay I'll just show you the comments it's interesting okay someone's talking about the only thing left right now is to build an Iron Man suit they're talking about the meta reband glasses okay so some people are like vun has turned into an AI now that's eight comments but the rest I talking about the glasses Google laughing in the corner no one will talk the glasses after this I assure you something glasses also exist get those glasses and reprog they're talking about the content typically if you put an AI generated re people will talk about this real is AI generated don't try to trickers or whatever H and even on regular videos some people will be like hey this is AI generated so it's like my audience which has been attuned to like let's seek out if this video is AI generated or not is having a hard time and I don't see 6 months later if this is going to be like a challenge and you know how much time it saves it's like I don't have to be there like I don't have to do anything it's like zero time right the only thing is you have to trust your team to be able to put out and research good content but the way I do it is I find something interesting and like I'm sitting and sitting on GitHub repos so I'm able to spend more time there so higher quality content in a way that is nuts so T if you go to the average 18 to 20 year old in India do you know what one of their interests is like at least what they watch on TV or on the computer or whatever it's anime anime yeah so anime is like Tak in India by storm right it originated in Japan and now like every Indian has watched at least every young Indian watched some some anime so one of the dreams that I've had growing up is I've always wanted to make my own anime and I went once and Googled the cost and it was like it's crazy okay because you have to draw every frame but you know what generative AI to the rescue there is now a new repository called rerender a video okay so this you can use stable diffusion you can use control net remember once you told me vun why can't we use control net for every frame M and this does it the only problem with that is every frame is going to look different from the previous frame so now a new repository called render of video uh and it allows you to basically do what you told me that day but frame by frame it's able to make sure that both the shape is like consistent and so are the pixels and colors so they managed to add some rudimentary sort of you know consistency between frames and we used it so it took us some time to set up but we used it to generated an anime want to see results yeah let's check it out so this is the original video actually yeah let's just play it so we used two different stable diffusion models oh that's awesome how did you make yourself older yeah so those are two different models so one on the left is more of a modern anime model the one on the right is trained on you know death note and slightly older anime so it looks slightly more I would say grungy now anyone can just put up a a green screen at home get GPD to write a killer like a squel to an existing anime or write their own script and then just act it out all you need to do is basically cast appropriate looking people and if you just read it you can just do the whole thing so you can do one more thing okay there's an app on the iPhone called camra AR it's a free app so you can use cam TR AR it you need an iPhone 14 and above so you have lar right you can map out your room and then as you move the camera you have this digital camera that moves around that you can import into any 3D software so what you can do is not only can you record this person and convert you into anime you can take the background and put yourself into any background and the camera will match your movement and you can convert that into anime as well so you can also have the whole set so you can shoot in front of a green screen but you have the entire set you have the entire output I think the biggest opportunity right now is go take all the Indian Classics and convert them into one anime episode each I think that's huge traffic and a lot of young people will watch it so here's a scene from Doom yeah let's check it  out that's pretty cool all right another week in AI a bunch of new tools hope you guys enjoyed that episode if you did drop us a like a majority of the people who watch us aren't subscribing so make sure you subscribe and we'll see you on the next one  bye",
    "url": "https://www.youtube.com/watch?v=zMVTsykitiI"
  },
  "hY7S35KmOX8": {
    "published_at": "2024-05-28T13:39:44Z",
    "title": "Building For The World From India ft. Vargab Bakshi, Meeting Sundar and more...",
    "text": "Building For The World From India ft. Vargab Bakshi, Meeting Sundar and more... it's another week and another controversy at open  AI Von you went to the US and caused all this chaos and you have returned how do you feel I feel good uh you know somebody was saying the other day I was I was reading this on Twitter Twitter is awesome now right like I mean it's not good to be involved in drama but like looking at drama from like a third party perspective is very interesting because you know a lot of it is going to be untrue but and nowaday people don't even care if something's untrue right like with Google people are using inspect element on their computers and just changing what gener was saying they're saying random stuff and people were reacting to that saying haha and people knew it was fake like today we've entered a world where you can actually put out something fake and everyone knows it's fake but they're still reacting say uh you know with with real reactions right it's it's the weirdest thing I always thought people really cared about the truth but they don't uh and part of that story was you know Scarlet Johansson coming out and saying that you know open AI stole my voice uh and it turned out later that openi did not steal her voice um Sam Alman had already picked up an an a voice artist much before Scarlet johanneson came in and she happened to sound a little bit like Scarlet uh and that created like internet uh wait wait wait wait what was this fake thing wait wait wait I think even I have missed this yeah so what happened is uh GPT 40 during their announcement I know no no no hang on I know I know uh correct me if I'm wrong okay GPT 4 announcement they had a voice feature uh one of the voice features voices was called Sky which sounded like scarjo which is scalet hson a few days before 40 launched Sam Alman tweeted out her which is a reference to the movie Her where uh I think I think it was I don't know who it was was it wackin Phoenix the actor who F and skaret Johannson and Scarlet Johansson scy Johansson plays an AI Voice Assistant who he falls in love with and that voice assistant is very like personable amicable likable very fall in love with a bill and that movie became really popular and so many months ago many many months ago Opa and Sam Alman reached out to scarjo asked her if she'd like to be the voice she said no then few days before launch he tweeted out her then the thing came out and it sounded it sounded like her and then apparently she came out and said that hey this uh they reached out to me I said no but despite that they've used a voice that's very very similar to mine then Sam Alman came out and said that hey hang on you said no we did not re we did not use your voice we went out and found another actor to do the voice an anonymous actor they don't want to reveal who the who the person is but a few days days before they release 40 they again reached out to scarjo and they said hi are you sure you don't want to you don't want to be a part of this and she said yeah I'm sure okay uh so a couple of things here makes me very sus of open AI okay one uh Hey The Voice does kind of sound like scarjo it does like let's do a comparison of her this is her scar Jo's voice in her and this is what they used okay it's it's similarish but people can have you can have similar textures well right when you asked me if I had a name I thought yeah he's right I do need a name but I wanted to pick a good one so I read a book called how to name your baby and out of 180,000 names that's the one I like the best ah I see it now you wrote down 3x + 1 equals 4 second him tweeting out saying her a few days before like that's like a guilty third a few days before you release again you reaching out saying hey are you sure that's kind of sus to me like and after all of this they they're not telling me whose voice it is just tell me whose voice it is it's easier if you just tell me whose voice it is you know they've done this whole thing where they've reached out to an agent someone has done an independent verification saying that there's an agent who has said that yeah it really is another actor which is not scarjo but the whole thing seems kind of sus to me it's like like it's like Sam really wanted Scaro and she said no so he's like how you can say no now you see what I do and he still did it so it feels kind of sus to me and I think if this goes to court I think scarjo has a good chance of making some money you know as someone on the all-in podcast said that it's very possible that scarjo ends up owning more of open AI than Sam Alman uh to summarize it you could say Q Sky kab Scarlet very bad very bad so uh dude I okay so I I I can kind of like I can give you a brief of what I think the thinking was like right none of us were there so we don't know but like dude Tech guy thinks it would be really cool and really culturally relevant to get the person who did her to also be a voice on open a and like sort of like when they announced that the internet's going to go wild because Sam's also marketing genius right one thing we've learned over the last few years actually he's more marketing than he is technology right so he knew that doing something like this would make all the news people go oh my God they got the actress of her or whatever uh but unfortunately the data when revealed said that they had gone to a different actress before Scarlet that's the weird part yeah that's the weird part and that's why everyone was like yo are you guys going to apologize to open AI now see that's the weird thing right like uh everything is so messy in back rooms of a startup or a company right like things hang can you can you explain that part what data came out that suggested that they went to a different actress before Scarlet so if you Google Now Scarlet Johanson uh and you go to news there's this this thing uh yeah I know what you're saying they record show that there's they didn't they haven't revealed who the person is yeah because imagine that person right like you're suddenly you have so much media attention your career is down in the dumps your entire thing is like oh you sound like scholet Jo no no no voice artist would want that Association uh so uh I'll tell you what the thing was here it goes right so Krishna Rohit tweeted this and it seems to be an excerpt which says but while many hear an eerie resemblance between sky and Scarlet johannson's her uh character an actress was hired in June to create the sky voice months before Alman contacted Johansson according to documents recordings casting directors and actress's agent the agent who spoke on the condition of anonymity citing the safety of her client said the actress confirmed that neither Johanson nor the movie Her were even mentioned by openi the actress's natural voice sounds identical to the AI generated Sky voice based on brief recording of her initial voice test reviewed by the post the agent said the name sky was chosen to Signal a cool cool Airy and pleasant sound so yeah like it just goes to show right nobody knows stuff and that's why I said like today on the internet you can just put out any fake like some guy tweeted something saying that there's no consumer demand for AI at all and it's all like dudes making us uh pushing this technology on us like people are just ignoring evidence and facts and anybody who just has a feeling that yeah maybe it's true maybe open is bad Sam Alman is bad they retweet and like anything so the internet has become I keep saying this it's become post truth yeah like in this particular case everybody like OPI is the big bad Corp that screwed over an artist um but I really think that Sam needs to tweet lesser like this this okay tell me something if they really if they really did not did not intend to make it sound like Scarlet Johansson why have they issued an apology and taken the voice down simply they're reacting to the to the audience that's the problem right like eventually when the noise gets so big you have to react you have to show that okay yeah we'll do something yeah but you're open at this point like how much more do you have to see around you for you to learn that the mob's going to come after you either way like to me the the the re the response to the thing is what's making me feel like okay you probably did it cuz if you really did not then you would right because if you really did not you would just put your foot down and be like yo shut the up no here's proof here's we reached out that would be your first thing take down the voice which I feel like was a bad PR move they should not have they should not have take taken down the thing and said sorry and ETA like don't tweet her for starters if you know that the voice is kind of like her yeah but think about the scale that you're at right you're going to piss off somebody no matter what anytime you try to do some culturally cool thing there's also like a 5% chance it blows up and doesn't work out and now everything is blowing up for open AI uh there was a time where open a was an unknown company I remember making a post about them on my Facebook I had a Facebook page called warun Maya when I was very young 2017 I made a post about them 2018 I made a post about them nobody knew about them then and they could make all the mistakes they wanted in the world back then but today the scrutiny that they kind of uh under uh I feel like they need a corporate CEO right they need like a professional CEO who can keep quiet and like only say generic things like Sam has already gotten good at it like now on every podcast he's not saying anything meaningful he saying generic stuff he's saying generic as like did you see his episode with on the Allin podcast it was the most generic as answers possible it was very like kosher and like it was he was very measured in fact they were making a joke about in the last episode saying you know Sam revealed so much to us right about what happened etc etc um yeah but yeah they need they're under so much scrutiny now that they need um Sam should a creative person and do the Creative creative stuff yeah like everyone thinks the right template like like a lot of young kids are like why why don't CEOs like talk and like explain everything and why are they so generic what a loser actually they're protecting Enterprise Value by not talking right like I think the less the more you have to lose the less you say extreme things or you try to do these culturally crazy things but in this particular case Von if scaj said no just choose like a different like a like go left go left if if right said no don't go rightish and stay around next to the just go left do you know do you know there's a picture of Sam alman's Katy Perry that came out right after but then everyone was liking that and everyone was like oh my God Sam Alman is now going to go and get Katy Perry's voice but it turns out that the image was actually 3 months old you know the last big Tech CEO Katy Perry was uh hanging out with Sam Sam bankman freed is that true I don't know yeah I I remember uh year 18 months ago she was in the Bahamas at a spotted at a party with Sam bankman freed it was crazy yeah this is uh life is getting strange since picture like but the but the last CEO that went through this was Mark Zuckerberg right Mark Zak went years with people calling him a lizard and this and that you know so it's like uh is too funny bro so I think everyone needs to go through this is the trial by fire to becoming a good I would say Fang CEO or like big Company CEO right so T we actually have the CEO of vix India with us VAB you know I've done VAB since the Shopify days VAB used to be the CEO of Shopify actually before we begin VAB you want to quickly introduce yourself uh sounds good thanks thanks for uh you know inviting me into your podcast I'm very happy to be here um I wasn't the CEO but I was definitely uh uh heading Shopify India a long time back I joined them in 2013 I was at Google much earlier in 2010 uh I've been at Wix now from the last 2 years and their country head in India um and yeah I have been in the internet and web development space uh for about 15 years now and I've known both of you from a while now it's been exciting to collaborate on multiple things I have a question how I mean I know the answer to this but I think it's going to be very useful to the audience how does one become the head of Shopify India or the head of vix India like how how does what's the career path for that I think like if if someone tells you that Cod reach outs don't work I think you should tell them that like that's completely untrue because I got my Shopify job as a cold reach out I used to send emails uh to Harley who was the president of Shopify like literally every week asking them to launch in India and in Asia uh and this is how they need to change their product and this is how they need to localize their strategy and after months of sending emails uh to him he finally responded saying that okay we want to chat and that's how it became their first higher in Asia every time someone says cold email works I get an influx of emails the Absol abute next day so just just make sure the email is coherent and think about the person you're sending the email to give job you might find your next prod uh T but yeah like just like anyone who's sending you know cold emails just like spend time writing to what's most important for tanai and I'm sure that he's going to look at it you know VAB in one of our conversations you had told me that uh you know you've been at Shopify quite a bit of time right and you've seen Developers from India sort of slowly take over the jobs that not jobs but like the freelancing gigs that people who run Shopify or Vick stores in uh the us or like wealthier countries they seem to be Outsourcing to India is that a trend that's continuing like what what are your observations there definitely um so this is a trend that I've seen uh across the last 10 years but this is a trend that started right in the early 90s when you saw companies like Vio TCS infosis uh become these giant it houses uh where all the largest Enterprises across the world would um use these service houses to get stuff done uh and that has now been democratized of sorts so now you see the small and mediumsized brands from the US UK Australia Canada most of the developed markets you know Outsourcing to Indian developers uh whether these these could be very much like Indie hackers five friends coming together running a Dev shop building websites building custom applications and making tens of thousands of dollars every month that is so common right now and like and it's not just like in Bangalore Amad for example has got probably lacks of Engineers who don't pick up jobs they just run these Dev shops and they cater to clients across the globe like smaller cities indor LNO um so I think I think this is a trend that we are not just seeing in places like Bangalore Bombay Delhi it's across India where developers from towns uh cater to you know very large businesses in the US you know there's a little funny story that I would like to share a very popular uh Footwear brand wouldn't mention the name but they were on they were mentioned on Wolf of Wall Street a couple of times so they had uh outsourced uh you know a lot of their website development maintenance to um the set of developers in Punjab in a village in Punjab and those guys used to get paid like close to $175,000 a year um and with that kind of money in a village you can literally live a King's life so uh earn in dollar spend in rupees continues to be the Indian dream uh and we see that in here as well so India's definitely the developer hub for the world how are they getting projects though like like I understand why it's beneficial for a US company or some store in the in a in Canada to like Outsource to an Indian developer but how are these Indian developers getting the projects I assume like picking up the projects would be a challenge like how do you build trust all of that right um so first off most of these agencies started uh acquiring clients through portals like upwork Fiverr Etc uh then they realized the importance of organic traffic when they started spending more on content and tried to get leads organically onto their website uh Word of Mouth also plays a big role so if I've been your client and you've done a phenomenal job for me I will definitely refer you to another uh you know client in the US it's uh the only Bridge sometimes that one needs to cross is is the trust because you're not in the same time zone as them and uh you know you need to you know make an extra effort in terms of communication like regular communication immediate communication don't be silent um you need to get jobs done fast and in an affordable way quality is why we are chosen over a lot of Eastern European countries or a bunch of Southeast Asian countries as well so if I think if you stick to those things uh you know you'll continue to do well but uh you know I think at least you know when when it comes to building apps all these developers I'm sure this will be the earliest adopters of tools like chat GPT and I I mean I'm sure many of these devs are like the most AI aware devs right like or at least using AI in their workflows because they actually have some amount of free time cuz they're freelancing they have some am of free time to learn uh or just play around with like a GPT or a Claud do you see that often I think I think we are yet to see it largely in the web development industry uh I think there's still a a lot of adoption left to happen uh in fact it's it's very preliminary right now some things like whether it's writing boiler plate code or debug debugging or testing some of these things are being done uh with the use of AI but um I think there are two key things right a developers need to stop looking at AI as a threat they need to look at it as a companion companion to help them become more productive and be more efficient I think that is a um is is a mind is a shift that needs to happen in mindset uh for all developers and uh the first version of your output can be way faster with AI uh and the quality of your work also can be way better so uh think of it this way most products like Wix they have made 80% of what clients need plug-and playay so whether you run uh a restaurant an e-commerce business if let's say there's a standup comic who wants to have an event and wants to have let's say a seating map Builder just the way bookm show has it um you want to have let's say the front seats to be more expensive and back seats to be let's say more uh you know probably cheaper that's a plug-and-play solution um that Wix has already built now it can be 100% seriously yeah absolutely so if you just Google Wix seating map Builder you'd see the seating map uh you know that that anyone can use and uh the landing page the entire process of booking tickets becomes way faster so um now having said that what developers love most is the ability to customize uh personalize experiences for clients as much as possible so that the entire experience for their buyer doesn't seem to be uh templatized people hate templatized uh flows right and that's what developers are good at which is creating good custom flows and that's what platforms like Wix have been doing we launched a bunch of products like uh Wix Vell which allows you uh to do full stack development um so developers can not worry about the hosting side of things just focus on the applications um what are the problems that it needs to solve focus on the UI and let's say the output would would have taken probably three months for a developer if they were to completely to it custom but given that they're using let's say a Wix v um it shortens to let's say a week or two so you can even build let's say an Airbnb through Wix Val or build a social media network uh a very popular uh Ott uh in the US called Vivo you've seen him in um you know a bunch of these uh uh music videos and stuff like that they are running on Wix so it's a streaming platform so it's a lot of opportunity um you know for developers on our platform where you know there's always this notion that vix is for the small guy I remember when uh you and I had a first chat when I was joining uh vix Varon you told me but Wix is for small businesses right and I was like well these guys have been investing a lot into developer facing products uh is increasingly catering to Enterprises um in fact we've got tataa consultancy Services as well which builds websites uh you know on Wix for a lot of American clients um if if you're into glasses you may know Zeiss uh the lens uh uh company right and uh they are on Wix Enterprise they've got say hundreds of websites and uh TCS builds those websites for them on Wix Enterprise so um I think the positioning of Wix um definitely has changed or is changing rather from uh being the right fit for small businesses to let's say being the right fit for larger businesses and Enterprises that's interesting actually so what you're telling developers is absolutely I've been sitting on that joke for three minutes now when when when can I say this when can I say this okay so Wick studio is something that I want to talk about because the product that launched uh last September which is meant for agencies and it companies where you can have excellent you know design effects like glass morphism or Mouse Parallax effects um have very customized navigation menus which have let's say images Etc um in without writing many lines of code um and I think uh you know what big Studio has done really well is it's shortened the goto Market time for clients um the entire point of uh client's Outsourcing to an agency or a freelancer uh is for them to move fast because they don't want to hire train and then deploy it's and and and you'd rather have it as a variable cost than a fixed cost absolutely and that is exactly what big studio is doing like it's just reducing the go to market time uh even further and it's also giving uh the ability for developers to customize the websites as much as they want um and like just just another thing for we shouldn't just be talking about service because it's India's increasingly becoming um the hub for people to develop products from India but sell those softwares to the world um and we see a lot of that happening on the Wix app market uh place so um we've got thousands of softwares uh there which solve things like referral marketing or an integration with a certain Marketplace or social media uh and all of that can be done just by like installing the software I know you know my a bunch of our common friends vun have sold companies for like $2 million $30 million simply by building these small uh softwares which solve a problem really well and probably that problem is being faced by 100,000 businesses across the globe um and you know you make you make a great business out of it and not everybody has to build like the next chat GPT absolutely uh not like that that was a conversation that you had with uh Sund as well right that everybody doesn't have to get into llms and trying to uh really solve a massive problem and try to build a billion dollar company uh you can very much build like these 25 million to100 million companies building apps on uh let's say the Wix app Marketplace so that's something to definitely explore interesting given given that Wix Studio was launched 6 eight months back and the com the product has been doing phenomenally well India's actually turned out to be the number one market for Wick studio so our developer conference happens from a developer and agency perspective um and usually this conference happens in New York uh every every year uh this year it's happening in Bangalore so we've got the entire leadership of Wix we've got a bunch of cloud Architects from Google we've got you and tanai uh myself a bunch of other folks who are from the tech industry uh sharing their expertise on how do you uh you know build in the web development industry how do you use artificial intelligence to make your uh you know work more productive Ive or more high quality so uh great opportunity for developers to attend this conference uh it's on the 29th of June um yeah you should you should definitely make it if you can and it's free right yeah it's free you don't have to pay for it uh though there is there is like a vetting process so you need so if you're looking to attend the conference enter all the details of who you are uh what is your Association to the web development industry that just helps us approve those applications uh coming in so if some if a Dev wanted to apply what's the link what's the what's like a short way for them to go do it so just go to Dev studioc con.com deev studioc con.com and yeah just sign up and uh hopefully if if you fill your application well uh you definitely will get through and we'll see you at the conference thanks for joining us workup it was uh it's always nice CH chatting with you super all right uh thanks thanks guys for having me uh T is it okay if I do this as Wix like instead of doing this hi tell me about Google um and Su Pai bro Sam also tweeted out saying I don't really pay attention to competitors but can't can't stop thinking about the Aesthetics between open a and Google did you see that tweet yeah I thought open's aesthetic was not that great like it just felt like like a Black Mirror episode it was classier and like subdued and like it was it was simple it it had more like Google was like it it like I'm just shocked that there wasn't like a Google mascot like a dude inside a costume running around stage and doing that was Mark Reb you know that was anyway they had the crazi there but but it's it's a VIP shift dude like Google's going for something else now Google's like I mean this is my opinion right like considering I was at IO and I spent some time with the Google team uh they are now like you know what people are going to criticize us anyway right like anything we do we do a good thing we get criticized we release we get criticized we don't release we get criticized we release something good nobody cares still there'll be criticism for by one guy who had a bad experience so it's fine we'll adopt the fun we'll we'll we'll be the company we always wanted to be and and I asked that question as well right like uh it seems like now Google is like shipping publicly even with all the mistakes that are coming out it's almost like everyone on the internet today is a Critic everyone has an opinion and sort of like cover for them to ship and that's actually and the reason I asked that question is like it's actually very evident that that now it's like if we don't do this somebody else is going to win right so how long are we going to cover and like not ship right so there's a Vibe shift and iio is more like a like a conference type of thing like I was more like a it's somewhere between a conference and a music festival and lots of like AI creators were there lots of Engineers were there like You' meet a lot of people open on the other hand was like a closed door announcement event and also if you don't think about competitors that much why did you put your announcement date one day before IO right remember io's date was revealed far before and Sam wman placed his announcement date just one day before IO that is a little bit like if you don't think about competitors why you do with that it's interesting no how Okay so Google was the first mover you know back in the day with Deep Mind then sort of open AI sort of overtook them and got to the chat UI first and now almost it's like Google's the underdog compared to open a and now open a has to fight with Google it's it's it's a very interesting uh like I don't know who's the underdog and who's the who's the overdog I yeah I don't I don't I can't tell now but what a statement Google being the underdog that's like yeah but I'll tell you one thing I mean Google's not the underdog like in the sense that like it's Google they have like like Chad has somewhere between 100 and 200 million users Google has like billions of users every person with a phone like an Android phone or even a iPhone has some Google exposure or the other right from Google Maps to like anything like uh so they're not the underdog but public perception wise because they became the underdog it just gave them like a lot of time and energy and also like you need a crisis inside the company some red alott inside the company to focus on war right otherwise you get caught in Petty politics and like the best thing about open AI is they they they reinvigorated the giant like and it almost like one of the questions I really want to ask Sund after watching uh IO but like I removed it was uh this looks like a like a rerun of The Empire Strikes Back so as in I I've not seen Star Wars nothing it's just like you know the it's it's a company with with immense resources just getting focused again right and striking back and saying you know what we'll do images we'll do text we'll do video we'll do audio we'll do everything they went after everything right uh they're going after everyone from perplexity to like uh text to video in in form of Sora to like uh Runway and Pika and like you know they're doing the music stuff there's going after sunno so it's like it's like you don't like that it's it's all about war in a way um yeah so so I think it's nice but at the same time I can't can't help but feel like in general llms are getting commoditized like in general it doesn't matter who's building the AI stuff like we've covered this for a year right like more than a year now and it feels like every week There's Something New there's a new tool and nobody really has any loyalty to any of these companies like between you and me like do we care which music model is the top one we'll just use the top one for our needs but there is loyalty to a Justin Bieber and whether Justin Bieber uses tool a or tool b or tool C it doesn't matter like it's slowly starting to become apparent to me that maybe the the money will be made by the people who can generate the most loyalty and they will use the tools so it feels like tool using is much more profitable than tool making D Tech is not the mo Tech is not going to be the mo brand could be a mo regulatory regulations could be a mo and distribution if if you have Google search and you're coming on Android in on your phone like that's your M right if you're on if you own YouTube and you can you know activate as many creators as you want it will that's your M and at some point my opinion is that openi and anthropic and all the others will realize this uh and they're going to then start having to build out the relationships because they have to go and do this the way traditional they don't have Google's distribution so they'll have to do this way traditional companies they have Microsoft distribution yeah but Microsoft distribution is like it's very odd like I don't use copilot on Microsoft like once in a while I use it uh if I really need to do something but what do you use it most like if I'm so I have the copilot icon right here on my this thing so I'll just like ask a question like what's the capital of some place or something stuff like that like I I just need to think about something I don't want to open the browser but most of the time most of my activi is happening through the browser and the browser I use is Chrome right so Google as Chrome Google as Android Android comes prepackaged with Google Maps and and YouTube and basically all of Google's apps so either you have that kind of distribution or you go to the traditional form of distribution which is run ads or go do influencer marketing So eventually an open ey is going to be like yo we need to run ads if you really go need to go after Google because yes open ey is really big and a lot of people know about it but in terms of usage the number of people with mobile phones are 7.1 billion in the world right now and and chgb has between 100 and 200 million users it's not they're not pen rated anything if you just look at the math it's just the early adopters and sometimes Twitter and like a little bit of Instagram can make you feel like this is like a like a bubble but it's not there's so much penetration Left Right does your auto driver use chat GPD yet no but does he use Google or Google services like Maps yes yeah uh also let's not forget slack versus steams right where once uh Microsoft distribution kicked in it's it just it just flat made slack seem look look like a flatline um um so yeah that is that is a it's significant and you know what and you know what slack has Salesforce distribution and yet Microsoft distribution really overpowered it right like Microsoft even though they're not like putting teams upfront in your face uh they still have the Enterprise sales team that's selling Windows to everybody across the world and probably that's a feet on street team as well right so yeah I mean distribution is ultimately what will matter Tech is like getting commoditized I met a VC yesterday who told me exactly the same thing I was like why aren't you investing in like AI or whatever or or what's your AI plan he's like why don't we invest in a distribution in in some company that has the distribution otherwise like you build a model even if you build like a local language model in uh for India or whatever like how are you going to compete with a Titan who has the distribution you can't I agree actually uh refrigerators didn't make the most amount of money uh Coke did so I think you're right the tech tech is tech tech will be commoditized everything else is is what's exciting tell me more about um meeting Sund what was that like uh how did it happen um give some Goss so Google invited me to IO uh and Google said uh somewhere in between you took you made the trip for Google Io yeah I made the trip for Io I had a few other people to meet uh but mainly it was for Io and then at IO Google said uh I mean like they said hey do you do you want to like talk to Sund right and I was hoping I'd get to talk to somebody else right like always set your sight low but I said do you want to talk to Sund I said yeah for sure right and then uh it happened uh it was after iio it was still on stage everyone had gone to like the the party areas or the experiences or whatever uh so there was one Creator from India there was one Creator from UK and there was one more from I think the US I'm not sure there's a third Creator as well and um and yeah like I had a good conversation with the Google comms team before you know I went up on stage Sund was really nice I think he's very disarming right in the sense that when you go on stage it feels like you're talking to like a friend right it doesn't feel like you're talking to a public company sun is one of the most powerful men in the world right like uh the third biggest or the fourth biggest company by by market cap CEO is like a big deal uh but it he still felt like a normal nice person and he answered the questions well I guess but also with that you know the maturity that comes with a with a CEO at that scale right you can't make mistakes etc etc so it was all in all was a fun experience uh the only thing I could think of on stage was this is awesome like to be very honest I cared less about what I felt about it and I cared more about like there's some followers I've had who stuck around with me for years like seven 8 nine years right uh ever since I started creating content I don't even know when that when that was and I almost felt like in that moment it validated them more than it validated me and it also validates a lot of the people watching overpowered right for for example that yeah I think um the time to do something Niche like sure MKBHD is really big right now and all that but being a Creator covering just AI in India in a market where you know other creators are covering like you know ghosts and this and that not nothing against them I understand they're they're filling a niche but to see that Niche be rewarded with some time with Sund I felt was was pretty validating and it also at least for the people watching it's like hey anything is possible cuz like bro bro bro Tech is not a niche bro like billions of users like you're saying Tech is not Tech is not a niche it is it's the opposite of a niche it is t t but in India the tech creators have always been like mobile phone reviews or like it's been it's been very different it's not been like this average engineer sitting in college writing soft building software and then creating content around it it's like that was a very um I don't know that's that's my audience right mainly at least on my channel and for me it felt like at least from the comments and all it felt like they got validated because they've stuck around for a very long time and also to be very honest my channel grew very slowly for the first 6 seven years right I got to I took like 7 years to get to like 150k or something like that right and then you happened and then overpowered happened and then uh my channel grew and then overpowered grew And So It All Happened very fast and I feel that ultimately it validates the fact that anyone can do anything it doesn't matter what your Niche is the the internet's now become big enough that you can anything is possible right that's that's all I was thinking on stage that I hope that anyone watching this would be like anything is possible you know uh these kind of opportunities uh whenever they come along no where you get to where you get to interact with the absolute apex of the sector you're in uh part of it always feels like what did I do right that I got this chance and then the next second it hits you that oh a billion people also right like it's a it's a like we we are also from a country that that is is really critical for for most of the world um uh did you was there a moment of recognition of hey India India how's India doing with with Sund like uh like I my first reaction would be to speak in Hindi with him I don't know that's what I think I think I would be like Casio that's what I would say I had to really resist the urge to like end the podcast with uh so Sund uh uh but then I knew it it wouldn't be the right thing to do on that stage it wouldn't be yeah yeah but it would have been funny though I you know what I would have done I would have done uh like you know all the best in the race against open whatever that Meme is that would have been fun um so did you did you speak to him did you speak to Sund off camera like yeah so there were yeah there were multiple there was there was some time before the cameras got set up and we were just generally chatting to be very Frank I don't remember every I don't remember every word that was said because I was really jetlagged also like the India us sleep timings uh but all I felt was that's what I said right like somebody said this I think Maya Angelou said this nobody cares what you said or what you did like eventually they care about how you made people feel right so I just felt I remember walking on the St stage feeling like okay you know this this this was a nice interaction there was no air around it there was no like you know like a it not like supremely corporate It was friendly it was like one of the things that I think is something that if people are watching this they should really you know take away is that it's just it's normal like when I went up on stage the stage is not like some crazy stage it's a normal stage Sund is a human being he's wearing regular clothes the people around him were also wearing regular clothes and the conversation was pretty regular so like it's people sometimes in their head think that the gap between like uh whatever bazillion dollar company and where they're at is like huge but ultimately it's just human beings yeah anyway um there's a new Google project called Starline yeah what does it do so Starline is like it's like Google meet but on a physical device so it's got this like screen which is a light field display and it's got a bunch of cameras and so I I know what Starline was going in by the way I had never even heard of Starline and they said hey you'll get to try Starline tomorrow I said cool and then when they got me into the room it was just there was just two Indians there right me and Technical guruji so I was technically the second Creator in India to to check out Starline they put me in the in the seat and then the guy went to the other room okay and then immediately he appeared on screen and dude the screen is almost like seethrough ah okay okay like so it feels like there's a full real siiz human like you know the the like a hologram but it's not really a hologram and it's 3D there's a depth map so if you move around you can see like the body is volumetric you can see around the body ah that seems very cool actually yeah just saw the video yeah that seems very cool did it feel did it feel like um a a better way to engage a better way to do meetings than having a giant thing on your head yeah yeah yeah it's it dude if I had to compare like Vision Pro or even the quest versus Starline starline's better the only thing is I don't know how expensive it'll be I don't know how expensive light field displays are and you can only see one other person usually Google meets are not just one person there're like three four people so what are you going to buy multiple devices so I didn't I don't know about the logistics yet I don't know how the cost will actually play out but uh is very interesting to just look at another person and see them face to face like right now we're on Zoom but we're not really face to face like it doesn't feel like a real experience but imagine if I was on your tabletop and I just appeared as a 3D avatar on your tabletop that is and without glasses light field displays are really cool uh in the sense that they're able to create what you'd see in a VR headset but in the real world right you've seen those cheap fan Holograms where there's a fan it's rotating really fast and there's a hologram on top of it it's like a much much much better version of that with 3D right where you can see around it so I thought it was pretty nice and the problem with technology like this or even Google Glass or anything it's so wild that it it'll take a while even if it comes into production it'll take like four 5 10 years right and uh we were some of the creators were doing some estimation on how much it'll cost we like maybe it'll be like $2,000 3,00 this is not a Google official number so nobody knows what's going to be but everyone knew looking at the device that yo this is going to be expensive um but yeah it's that's why I said right like these guys have insane amount of resources and they've just piled these re insane amount of resources now to do things like research anyway uh seems fun I glad you enjoyed the trip without me thank you for not even acknowledging my presence in this podcast thanks on that note I'm calling it a day thanks for watching oow hope you guys enjoyed please follow us on Instagram please follow us everywhere so vun keeps getting invited to all this cool while I languish in Mumbai see you next bye",
    "url": "https://www.youtube.com/watch?v=hY7S35KmOX8"
  },
  "5_bKvAkJ6Uw": {
    "published_at": "2023-08-30T10:25:41Z",
    "title": "Which One of these is AI generated?",
    "text": "Which One of these is AI generated? which one of these is AI generated and I want the audience to see and guess let's watch the video in the early days of computer programming a significant historical anecdote is known as Grace Hopper and the bug in 1947 the video on the left where you can see his hands more clearly that to me feels like it's more AI generated just because the hands are looping right but the one on the left seems way more realistic because the hands are not in frame and if you thought the same just like me you are wrong because as his tweet reveals both of these videos are AI generated kind of blew my mind these are called Talking Heads slash avatars a specific type of video like this is more or less salt it's not just these guys right like synthesias if you've seen their last output can we just play their last fundraising announcement output over the past year the entire world has been captivated by generative AI it's like how how much longer six months eight months till it's like near perfect",
    "url": "https://www.youtube.com/watch?v=5_bKvAkJ6Uw"
  },
  "Xf3S02d9uFA": {
    "published_at": "2023-12-06T14:00:31Z",
    "title": "Learning to Do Nothing: Inside the Unique Nothing\u00a0University!",
    "text": "Learning to Do Nothing: Inside the Unique Nothing\u00a0University! all right waren so we just saw this app called TLD draw which lets you sketch anything you want and turns that into like a functioning app using AI like that's pretty insane dude seeing this I'm just convinced that upcoming Generations are going to have a lot more Le your time as AI takes over many of the tedious tasks that you or I do you're going to have lots more opportunities to sit around and do nothing yeah I saw five star launch a campaign called Nothing University where you can literally learn the art of doing nothing let's check it out no so the first course is acting busy welcome to acting busy so it's important to always look like you are in the middle of something yeah so the other courses are surviving meetings concentration strategy optimizing visibility and buying time okay five star first of all I have spent many years doing nothing so I feel like I'm already an alumni so I would really like a degree if you could send it to me there's one University that I wouldn't mind getting a degree from",
    "url": "https://www.youtube.com/watch?v=Xf3S02d9uFA"
  },
  "JDYpGnlWuPY": {
    "published_at": "2023-05-15T14:38:17Z",
    "title": "AutoGPT Replaced Software Devs? GPT Robots, One-Click VFX and More! ft. Tanmay Bhat &amp; Varun Mayya",
    "text": "AutoGPT Replaced Software Devs? GPT Robots, One-Click VFX and More! ft. Tanmay Bhat &amp; Varun Mayya so a month ago I was writing a script for an ad and I was tinkering with mid Journey on the side and I was telling the writers I have a bad feeling about this AI thing okay we need to start looking it up and then in the script usually the process is we write a script and then there's something called a pre-production meeting with the client where you know the director comes on board costume designer set designer all of them come and they all uh they all go through the script and whatever their interpretation is they pitch to The Client saying hey this is what the set will look like this is what the costume looks like you know this is how the lighting will be then there's a storyboard artist who comes and you know hand draws frame by frame so I looked at the writers and I said uh can we do this on our own now this film involved dhoni okay so I said okay let's go through the script and then we started punching it in mid Journey saying okay midot uh you know Indian cirari office donon dressed up as uh a a bank officer uh wearing a white shirt with this tie and it spit out this image and I looked at this and I said holy like the writer is the director is the costume designer is the set designer is the storyboard artist you know the writer can do everything if you have vision and that's when I called you said Bon this AI think we should uh we should Deep dive into it you were far deeper into it already and you were already in doer mod  story for why I started this podcast is very different uh I turned 30 this year and I was like what does every same 30-year-old man do on the internet start a podcast so um you know we're here um our goal is very simple our goal is not do this like a traditional podcast but show and tell every week there's new stuff coming out there's cool stuff coming out let's take that content let's see if we can recreate some of that content let's see if we can pull off stunts we're all going to do this from a very altruistic thing we just want you to see the newest technology and if you can see the newest technology and you feel wow I've learned something out of this wow you know this is blowing my mind wow I want to enter this field then well we've done our job yeah for me it is uh I would be doing this with you anyway let's just put three cameras and see what comes out of it yeah uh anyway so the format is pretty simple what we're going to do is we're going to go through all the new stuff that happened in the world of AI every week maybe more than more than a week uh so let's just get into it what happened in this week in AI Von you are the AI Enthusiast on this so please take us through awesome so we have a deck we have a slide deck and the first thing T that uh you know I want to tell you about is uh you know it's going to sound scary how many how many ad films have you written which have VFX in it most of them have some element of VFX in it okay and you know the VFX process right I've done a little bit of VFX it's basically make the character in blender okay rig and animate that character M usually the animations are hand done like 10 years ago it was hand done now it's like motion capture you make somebody wear a motion capture suit export all of that to your whatever your favorite renderer if it's blender it's blender most people bring it to Unreal Engine you you match the lighting you match the colors you make sure it looks like it's part of the scene right and the only thing you missed was step one which is beg for Budget H beg for Budget yes which is I mean if you want to do a VFX shot from my understanding it would cost you like I don't know you can't do it in less than 25 30 lakhs right at least in a good ad film and that's an ad film that's like 2 minutes max of content right well it turns out a new technology has come out called Wonder Dynamics Wonder studio so the name of the company is Wonder Dynamics the name of the tech is Wonder Studio where it's one click zero budget one click zero budget give is there an example here yeah there's an example let's play the video hello human I am here to visit all of you guys here today it's all kinds of crazy stuff with us here I mean what am I going to be doing next right getting facial expressions right all kind of dance party stuff I don't even know anymore yeah come at me that's pretty insane so it got lighting right uh it got movement facial expression right and surprisingly this AI also got hands right yeah um the only thing it didn't get right is it made him naked as an alien uh so it can't detect clothes yet yeah so if you want a 3D model with clothes on then you'll have to you know I being I was making a joke and being sarcastic but thanks this is going to be a tough one to get through I just realized okay cool yeah so so uh I'll tell you the coolest thing okay it's so cool or it's so easy that we could probably replace you in this podcast with an AI character can we do that can we try that hello what are you replacing me as I'm a robot yeah you're probably a robot if I move around if I do a little little dance hey by the way you should replace him with a girl okay like one of those girls or whatever like the 3D girls what the no you say am I am I a girl right now guys okay let's get back so have you used one Dynamics yet yeah we've used Wonder Dynamics like it's it's pretty cool we haven't used it for a video yet we haven't used it for a for a shoot yet but the Tech's in front of us in fact it's so confusing right I always thought if you have all this Tech in front of you suddenly you're going to use it and suddenly you're going to be miraculous like a week later in fact it takes a little bit of time and it takes a little bit of getting used to right because you're like oh I have this Godlike magical Tech in front of me but I don't know what to do with it right it's like no one's giving me an ad film right now and anything like you know that that you can force fit things into things that don't need it right so you can go to your next ad film and you can tell Ked boss uh we'll put a 3D CGI character in this but it would seem like a force fit so everything feels like a force fit right with this so it's more like waiting for the right opportunity but I'm damn sure in the next one or two weeks something's going to come out which uses this technology and eventually this technology is going to allow you to upload your own 3D models right now they have their own roster of 3D models got it got so this alien that we saw was oh they have they have it so all the demos you'll see like an alien a robot they have like these three four standard characters my fear or not Fe my my interest area is I think this will allow you to create a lot of 3D cartoons like if you remember uh there was a 3D cartoon on Cartoon Network so first they made BenTen as like a like a like a 2d drawn series then they made a 3D series out of it I don't know if you remember watching it I was very young right that stuff gets really easy because I know the kind of effort that would have gone into making a full series like 30 minutes into 10 episodes that's done and if you remember TV series in general right like if you've seen um there's a TV series called Teen Wolf right or even the Superman there's a Superman X low lowest Lane series that's going on on CW right now they Reserve their budget for the last episode have you notic like they blow their load on the last episode yeah so they're like hey we'll build up build up build up last episode budget yeah game Game of Thrones every season episode 9 that's what it was yeah so the budget is lopsided there but now you have the scenario where if the budget is no longer a constraint corre you have everything and in fact that actually in a way makes the Market better because every young kid who has an idea that I want to do this cool thing I want Batman to fight The Flash and then to fight Spiderman can just do it yeah right I think an immediate application will be if I can if I can shoot this on any camera and turn myself into any 3D model like people no longer need to be themselves on social media yeah right it'll be the first application where I'm now an alien and this is how this is my Instagram and now I'm basically every video that I put up I don't need to I don't need to show myself have you played a game called VR chat no because this is exactly that oh this is on Oculus yeah on the Oculus yeah I've seen it I've seen it so I'm so you have these avatars and you can be Goku you can be anything you want and people don't know who they're talking to the problem with that is that you can also be super abusive because our identity kind of inhibits us like my identity the fact that I know I'm me means that I will be a sane normal person because I will always think what do people think of me right on the street and on the internet because my name and my face is attached have you seen Anonymous accounts on Twitter yes they can get really nasty right so I feel like if everyone's given a mask uh you create like this bad environment and there's no concept of policing so you used Wonder Dynamics in like I saw a clip that you posted on Twitter so what tell me the process like how how long did it take you to turn yourself into that robot it took me uh the equivalent of moving my mouse to a button uh saying generate and left click that button and it matches lighting and everything everything it uses AI to detect what the kind of lighting is so basically if you look at Lighting in general right I'll tell you how it's done in the CG world I'm sure you know this but for the people that are listening let's say you have a real shot let's say I'm here and then we have this this area and let's say you want a CG character in front of you you pretend like there's a CG character in front of you then what you do is the director of somebody comes with something called a chrome ball correct correct correct right you come with a chrome ball and the Chrome ball has the reflections of all the lights correct and you can also do this like the cheap man's way of doing this is to use um uh Google Maps Google Street View you can take Google street view Google street view has something called 360 sphere correct okay so you can stand in the middle of wherever you want to have that you know the lighting match and you take this 360 sphere like you take like 10 photos or whatever it stitches it together and you download that hdri okay now that you download the SD you can use that as an environment in blender or whatever right so the lighting matches the real world and often you don't need to do anything more than that so I feel like this is doing sort of the same thing but it's using AI it knows from everyone on the scene like it knows from the Lighting on tanai who's already in the scene maybe there's a light here because the pixel on Tan's left seems to be brighter than the pixel on T's right right so uh it's guessing and it's doing a great job of guessing yeah you don't need that chromeball anymore in fact I saw a clip on Twitter where two people are fighting yeah and one person is becomes a robot automatically like there's no chromeball nothing it's just they just genuinely fighting and they just replaced it yeah so this is like usable today at at this scale already like yeah um the next step is you should be able to turn into anything yeah uh where on the curve do you think we are like how how far away 6 months 6 months three to six months yeah anyone will be able to upload their 3D models and you can turn into yeah you can already do it there's an app on your phone called Luma I don't know if you've seen you can just download this app called Luma where you can take 360 photos of somebody like you basically not it's not a photo basically use lar on the phones that support lar you can map map their face map their face so you get this 3D bust of that person and you can just transpose that into unreal metahuman there's already a way to do this so you have this model of the person with the exact face structure and it looks like that person and eventually it's going to be one click you know live streamers have this problem right and I've seen this with some I've seen this with you as well sometimes you just wake up you're like yeah I need to comb my hair I need sh whatever but imagine if you're just able to click a button and it looks exactly like you but a slightly 3D version and in fact you could also remove the 3D out of it you can do completely you can do a neural net completely trained on what it looks like to be you essentially you're deep faking yourself right um and the next level of laziness it's deep faking yourself yeah because like I remember somebody put a tweet about Clubhouse a long time ago saying that the problem with Clubhouse is the good part about clubhous is unlike a live stream I don't need to get ready correct correct right so you can just whatever you can be tired and you can just press a button and one of the repercussions of this is you are always going to look your current age the age when you made the model because nobody will update it did you know this like okay okay Pop Quiz how old is the zepto founder like 19 or something that was 3 years ago oh yeah right people got stuck people got stuck yeah so during the pandemic anything that was said like ages especially just got stuck and then you wake up one day you're like oh these people are much older than so everyone is going to be catfishing yeah everyone's going to be catfishing everyone's going to be permanently young but then you meet them in real life that they're old you know if you've seen that Black Mirror episode I'm sitting in front of you there's no reason to be rude right now all right next uh Auto GPT yeah so Auto GPT um you know breathe yeah take your time this stuff is scarier than the previous stuff yeah so there's a book by Ray kurale okay it's called The Singularity and Ray kwale is this crazy guy from Google super old now who used to take like all these pills and he used to be like I don't know if the story is true but this is the story I've heard okay the legend he's he's taken all these pills and he's like I want to for at least another 30 years because we're going to reach this point called The Singularity where then you are able to figure out unlimited life extension for me so the pills um or the singularity rather is a concept where Tech is able to build more Tech by itself and you reach this this virtuous spiral that goes faster than any human can comprehend okay and one of the preconditions for a technological singularity is code being able to write other code right um you know I would use the word self modifying but it's not really self modifying it's slave modifying which means let's say there's a GPT and what Auto GPD does is I can tell Auto GPD I have a task let's say I want to make inshots right the the app and we did that right just make a short app right and and take the top five news of the week and I just giving this like plain text instructions it will do everything after that it'll go to the web find the top five news summarize the top five news save it to a text file then byy itself it will go to um it will itself write react code and it will say okay this is the front end this is the U uiu it will build out the uiux it will build out the back end it will put everything together right and it will essentially just spit out code that you can now just deploy and eventually the deployment will be easier as well and having written code for 17 years now this is one of those things that scare me because there is a lot of malicious use right of something like this because you can tell it anything and it will find the best way to do it like open AI or or GPT has been trained theoretically on millions of web pages right 45 I mean probably billions of web pages right are you telling me that not a single web page has the nuclear launch codes I  hope not I'm sure some guys written it right and obviously the Nu nuclear launch codes is a little different because you still need to go physically to the console and type it in but even if you put it encrypted okay GPT and you can just put it in like reverse text you can put in text but the other way around in GPD right and it'll jumble it for you it it'll know you're sending it a puzzle and it'll you know reassemble it forb can decrypt something yeah it can decrypt something and you don't even need to tell it decrypt this you can just be like hey you know here's the text that's it and just asking for a response tell me something when you saw Auto GPD for the first time like cuz when I saw Auto GPT my first reaction was oh so this I can also if if I if I can learn just how to understand code or just the basics of it I should also be able to uh turn text into code now yeah absolutely so it can enable anyone to be able to build their own website their own you know scale of the app small scale app why are you this way where you thought nuclear code why are you like this is the question so three ways to look at it okay I'll tell you actually there's two ways to look at this main thing of uh it's going to allow everyone to code one is a lot of people think okay okay more coders that's great that you know more cool technology entering the world that's probably true My worry is when you have Godlike technology and there are you give access to the Godlike technology to anybody that's that's cool that's a good thing but I feel like good people and good and bad are a spectrum right but good people generally don't do bad things right they're like I have this Godlike technology I must preserve it like driving in a car correct like a car is a scrap of metal it's a weapon really think about it right and you can just you know if you really wanted to you can just swerve into the street and kill a pedestrian but you're responsible now you will go to jail correct right if you do that but something like Auto gbd where nobody can unless you're movie movie star whatever yeah unless I thought of that joke I said should I say anyway go on continue no keep that in keep that in nice um so yeah so you you can't SW into somebody um and um but with GPT if people don't know it's you you can just run it around somebody else's computer right like till today we don't know 90% of the people who run like a pirate or something like that my dri my D was anyway yeah so that that is that is one but uh I was I was imagining how like I have a friend who's a designer who Freelancers on the side makinging websites for people and this friend of mine he uh works with a developer to build a websites right so now he was telling me saying oh dude now I now I don't need now I don't need to split my Revenue with the with the developer now I I'm able to use GPD let me give you a reverse UNO card there there's a guy in Bangladesh now 17-year-old who has no expenses who can do what your friend does now essentially including the design part yeah for oneth the price correct so so you have this Supply demand thing right you're inflating Supply yeah everyone can do it no but I I but it won't be like so your core skill of what you're really good at like I think what correct me if I'm wrong ai ai can enhance your core skill like like me on auto GPT is not as good as you on auto GPT yeah right um so every person becomes like that like like a FIFA like a FIFA character right you click on them and speed is 90 dribble is dribble is 78 and uh you know power is power is this much so depending on what your core skill is AI can take it to that next level uh and bring you up to the very Basics on on other skills yeah My worry is not that My worry is I think 90% of the world is not ex extremely good at anything like Kun sha keeps keeps putting up up tweets about inefficiency right inefficiency runs the world most people are hired in an inefficient role the problem if you have a hyper if you have a platform that can give you 10 you know 180 IQ or 160 IQ interns who can do anything you want never Tire this that uh is and I'm talking digital work I'm not talking about physical work right now is you'll have the top 1% obviously do a spectacular job right if you're the top 1% in your field and I would debate with you about me being better on autog gbd than you because you would use Auto GPD in a completely different way right like I'd make very very specific types of apps with auto GPT You' probably make different types of apps you'd make apps that are valuable creatively or you know maybe a joke generated I'm just giving an example I would never do that right so I feel like it's a it's a different set of ideas um which have come from your life experiences so I feel like uh that shapes the ideas you will generate with auto gbd but I think that the problem is 90% of the world isn't that good right and that's the problem the top 1% 10% whatever will obviously be successful in fact they're going to become 100 times more successful the other 90% is who I'm worried about and the other 90% is who I'm constantly you know saying what can we do with these people can somebody think about these people because nobody is and and everyone on Twitter has this narrative that yeah it's all going to be fine you'll just become 10 times better actually you don't you won't right there's no reason for you to become 10 times better because the people at the top are going to try to take everything like today the like a top VC would be in like n number of companies right would have value acution from n number of companies much more than let's say I would have or you would have right so I feel like it makes this the rich or the or the intellectual like truly intellectual the people who can execute 10 times better and makes makes the median or the average just lose out on whatever average job they could have gotten that's my worry like now you have no choice but to be like a sports level athlete in your space like you don't have no choice but to be in the top level it's like football right like you have a million people in in let's say Argentina who can play football but 11 plus substitutes make it to the main team but what happen happened after the Industrial Revolution and the information age like once the in once web 2 came in Mobile came in like the the fear was the same right yeah which is that a lot of jobs will go away etc etc so um either there'll be newer jobs I was watching The Lex Freedman Sam Sam Alin I think something similar that he also said which is either there'll be newer jobs and or it will enable um like the mediocre will have somewhere to go see this is what I disagree with people on right and by the way I want to mention again that these are opinions these are my opinions I could be wrong yeah Von is Max Doomer okay yeah like there the reason why I'm on this podcast for balance for balance yeah so I I have to mention again and again that this is an opinion uh these are my opinions I could be wrong I've been wrong in the past but it's worth thinking about this because if somebody can like at least prepare then good right if it happens you have somebody who's built the barricades I don't think there's I mean you can still practice a craft by yourself like think about what happens to footballers right if you don't make it to the top 11 plus 5 you're you can play football you can absolutely play football you can use it for enjoyment you can use it for exercise but do you make money off of it no right in fact Elon is of the opinion that money itself will become much less useful if you know it gets acur into just the hands of the few which is already happening by the way like a lot of people like my comments have this right where they say um you know if only 1% people have the money then how is the economy going to run actually it already runs like that like 10% of India drives almost the entirety of the rest right you've seen that graph of India 1 India 2 India 3 so it and it's like this right you could be a real estate dawn like you could own 100 pieces of real estate you can have infinite money the projects that you will run constructing those properties the number of people you need to hire for that laborers this that whatever by yourself you're generating an insane amount of employment compared to the average person yeah this is how we distribution also works yeah Power law right standard so what is going to happen with the is you're just going to have like this much stronger power law and and and the best way to look at it is to look at sports or Esports or anything you Val teams millions of players play Val but how many people make it to the you know the big leagues right you have to be absolutely the best so I feel that's going to happen um but I also feel like we can't let Society crumble right um it's weird right because oh we can't let Society crumble yeah we can't let right so so government is going to come in and say okay we'll do Ubi the problem is Ubi in India like if you do the household you just do uh per capita GDP and then divided by 12 uh per household you come up with a number about 9,000 9,000 bucks per month per month per household that's four Long Island Ice tees that's enough yeah I mean that's good for let's say somebody on the street right because you have to be equal you can't say oh you used to be rich you used to be a programmer therefore take this much money right therefore you deserve 35 we have to have to everyone right my problem is your your top rated artist who used to be on Art station creating cool stuff uh maybe paid for it at a game studio now making zero is not going to be very happy with 9,000 Ubi right so so I don't think Ubi is the way out but you know we digressed so uh who made who made Auto auto gbd some random guy on on GitHub some random guy he just used GPD used the API and then just said Hey what if GPD was able to recursively call itself by modifying the prompts on the new calls that it's making about itself and what if you just give it an Executor what if you said okay you know give it access to all the Python scripts now there a new thing that's come out called Jarvis yeah that allows you to use all hugging face models so now you if you want like you can just send Jarvis a picture and be like upscale this 4X and you'll find the right model and there hugging face is a library of models by the way and um it'll find the right model and just be like ah this upscaler we should use here eventually you're going to have a super agent and it's not like 10 years away it's like 6 months away right eventually one of the like an apple what is what is an agent I keep saying the word agent on Twitter what is an agent an agent is someone that does something for you okay in this in this context so like Siri could be a voice agent and what is an llm what is the difference between an llm and and an agent so a large language model think of it like so they've collected scores and scores and scores of data across the internet Text data and they've modified it into this sequence of uh prompt and response okay got it and they've shown this model to uh a computer so many times that eventually the computer is or they've shown this data to the computer so many times that the computer is not like a lot of people think it's copy pasting it's not copy pasting it has started to learn the underpinnings of why why this was made how this was made and then there is there's a great podcast of um of dmes on the my first million where it talks about Vector embeddings yeah which is understanding the distance between two ideas uh and and matching them with meaning and not just calculating the distance between them yeah so this is the the the ingenios between behind this is something called Transformers okay and something called attention so there's a paper that came out called attention is all you need right clickbait title but it's a cool paper the idea is this right like if you have a sentence and one of the biggest use cases for Transformers is language translation okay it used to be language translated you take English converted into Canada whatever converted to Hindi whatever but if you take an English statement and convert to Hindi let's say I am a cow H in Hindi it's not the word order is different it's not correct correct it's not exactly that it's me guy who right so the word order changes and you can't just say okay I'm going to take every single word and Shop it out to the other word so you need to know the meaning between words you need to know in every sentence what is the focus word like cow would be the focus word and you need to understand the statement as a whole rather than individually right and to do that you need to map out words you need to have enough training data whatever GPT was is is is a generated generative pre-trained Transformer so it's like a Transformer the same technology that I'm talking about but trained on lots and lots and lots of data so this is why mid Journey got sued which is that mid journey is an llm no mour is not an llm it uses some it probably uses something called diffusion right okay got it got it but but it like same same process same process which is mapping out lots and lots and lots of data studying it and then using an input studying this data and giving giving an output yeah um so what happens to like like whose data is being used to train an llm especially if it's a centralized if it's a centralized company like uh like open AI they are using whose data are they using to train their model and is it legal is it legal and or is is this the meeting of aan crypto wherein if it's your data being used to train a model then you should you should own a piece of the upside of the model It's tricky I'll tell you why it's not really copy and paste it's not like it's taking 10 uh pictures and it's saying okay I will take a little bit of picture one I'll take a little bit of picture two it is learning the underpinnings of what makes a good cow or whatever you're you're prompting for if you look at the oldest versions of these picture generation algorithms there's one called based on the ciar 10 data set from five years ago okay um Andre kapati had put out a a tweet about this you look at the outcomes of those pictures IT stand on 32x32 size okay you can make out like car parts you can make out wheels is a very blurry this thing and if you look at Mid Journey today you can get like a Deadpool with like Deadpool in the in the puddle it looks really good so I feel like it's picking out patterns and if you look at the history of AI or or if you look at the history of image generators from that cyar 10 to let say um if you look at di mini if you remember di mini and all of those it's just been getting better at picking out patterns the problem is and and the reproduction rate is very low like you it'll almost never reproduce an original picture as is it's the reproduction rate if I remember correctly for stable divion is 1 point something per. which is negligible so the the ethical dilemma here is yes you have used artist work but fundamentally you're looking at this artist's work and you're learning from it it's like me looking at let's say some really good artist and I'm like oh I'm learning from this okay um but yeah recreating their style yeah recreating the style but you can also learn that right like every artist is inspired inspiration is is always available like um like Pixar probably inspired the next generation of like you know artists um The Lion King has so many movies after it that were inspired by The Lion King Style no but say Pixar right yeah this brings us to brand brand is is the mo in the world of say Pixar now every time I go on Mid journey and I output say hey my face as a Pixar character yeah shouldn't Pixar get a piece of piece of The Upside on that no because you're not saying I mean Pixar is the brand okay but you're saying in Pixar Style Style yeah so you're copying Pixar style and so far we have never sued anybody for copying somebody's style like DMX the the artist once suit somebody I don't remember which artist because DMX is this Gruff you know uh like this he he does this dog thing in his voice right and he sued somebody for it and he didn't win he lost an arbitration because it's like how can you copyright your style right you might have a significant walking Swagger but you can't copyright that right the world would be you know an insane place the world would know also where where X is inspired by yeah and inspiration is always cool right like even the Beatles if you look at the Beatles work um they had a combination of sitar and they combined satar with like the blues and they combined that with rock right so they really like mash things up and technically we mashing things up right you're a comedian I'm a computer science engineer and we're mashing things up and that's how humans create new things right in fact there's a you know there are I don't know how true this is but the entire character of Goku was probably inspired by Sun Wukong it's the Journey of the journey to the east or Journey to the West or something like that and um Goku is exactly like San Wukong they both have a tail they both carry that giant stick right um uh which expands and and shrinks with whatever and they're both like monkey like Goku has that he turn transforms into a big monkey but if you look at the if you read through the history Sun Wukong was predated by Hanuman and you had a lot of Travelers who would go from like Northern India to like uh China and same story it's just a story Like Son Of The Wind um you know same long stick same tail looks like a monkey we don't know if this is true or not this is all hear say right but what I'm saying is inspiration travels I'm sure like like this place that that we we in right now um somebody was like oh this is created by a Singaporean artist like the Interiors okay the Singapore Singaporean interior artist so um inspiration travels and if you block that and say boss you're not allowed to take inspiration from something then you get into yeah slippery slope then you have to Su everyone because I'm sure there's something in your life that you looked at and like this is cool we make something like it then you're done right because what your brain is doing the AI is doing the one Counterpoint to that Playing devil's advocate to my own argument is uh computer is just too good right a human brain is limited but then if you start creating these hypothetical things saying oh you can only be this good and then you can like you need to be bad and then you're allowed find way this what the disabled uh you know computers to to do and we like a disable compared to normal computers we're like much worse uh or this is for the worst computers to do and we are our brain is a computer then then you're creating this artificial you know drawing line some people are not going to listen by the way like some people are just going to dump their model BS on GitHub they're not even or or or not GitHub but like let's say Torrance or hugging face they're not even to listen to people and so I don't know how many people are you going to sue at the end of the day yeah uh um interesting all right next slide what is this so basically this is for like awkward people who need Charisma on on demand oh by the way do you know what Riz is yeah I know what RZ is yeah I think there's a Kai what's the name of the streamer Kai senat I don't know how it's how he's pronounced yeah he spoke about he coined the term Riz Riz is swag swag datable qualities how do you how it's almost like a currency how do you how do you acquire it so I can guess based on this image which is if you're if you're on a date um and if you're wearing glasses glasses it can prompt you yeah you need AR glasses and let's say it's it's able to detect sound and say you're sitting across somebody and you're like the person said something and you're not smart enough to think of something now the prompt appears in front of you and you're like oh yeah oh yeah but this whatever you you can have a punch line you can have a joke every second yeah right but here's the problem with this and this obviously really cool Tech but the form factor doesn't make sense like I have an AR like I don't think India produces AR glasses yet but this the endre air correct it's super clunky and if I was wearing this in front of you in a date that's an auto rejection yeah right I I just look like an idiot yeah so I don't think this is the right form factor but the it's just around right like when when I saw GPD for the first time my first idea was dud date assist right if you're if you're on an app it'll just it'll just spit out the best best way to reply to whatever text that you got uh and then I started using it in conversation with friends right like this is a funny response or of whatever it is uh you had an interesting Theory which is that once GPD came in uh Tinder is just Bots now yeah you can't trust anyone on text anymore cuz you don't know who's gping their images are fake their text is fake text is fake so at this point so now this is going to ruin dating IRL as well yeah I think we had a period of time where Tinder was useful then it's done like we we did offline dating for so many decades and Neons and Neons and whatever Tinder Hing Bumble whatever yeah now it's go back in the real world again yeah now I think I think the way I is going you need to build a dating model on top of GitHub yeah which is the ultimate proof of made ability you know what I'm really excited about I'm not excited about it I just want to see what happens I want to see what happens to people on shadi.com and bat matrimony because that's going to be parents and they're going to they're not going to know this information is fake they're not going to know this these profiles are fake this is like emotional Jamara yeah they won't know they won't know if someone's profile you know this person is looks like this makes this much money is eloquent as heck I mean you can just go to Mid journey and be like man Indian man standing among Stanford grads and just be like went to Stanford gorgeous six-pack man uh yeah that can happen yeah so My worry is uh they're going to be very confused and they've paid money for it yeah so and and I as far as I I know Shadi doesn't curate every profile so yeah they better get their act on right so I think and we have dropped so many so many dangerous ideas on today's episode yeah I mean this is going to be full of that right nobody's Imagining the ideas and maybe we're prompting you know new ideas into the world but here's the thing okay Shadi doesn't I can guarantee you doesn't have enough employees to go through every profile and be like is this fake is this real how long before we have tools that can detect if something is something has uh has been touched by AI who has more incentive who has more incentive is it the people creating these new things is it the people fighting this schools no no not that way I meant which of the two parties the people creating the the stuff that makes fake stuff the people detecting the stuff that makes fake stuff who has more incentive um I think there's no single entity that needs one more I think at some point like institutions will want to detect yeah like education institutes will want to want to detect yeah the state will want to detect the state will also want to use yeah so I don't think it's a one it's a one party thing like if if you are someone who's faking it at at some point you'll want to detect if someone's faking it to you yeah I feel it's a this is the problem with offense and defense in general okay offense is instant and this you learn if you're doing martial arts or whatever right offense is instant defense takes time to come up because requires strategy offense sometimes doesn't require strategy it's like let me try this cool thing on shi.com and then next day you have it but defense is like now I've got to go solve against GPT like I've got to figure out the underpinnings of this L just your face like now I got to solve against GPT it was bad enough before this that there are too few women and too many men on this website so now you got to solve against GPT which is hard and plus to be very honest I think now I look for spelling mistakes but dpd can be told to make spelling mistakes right so it's just the it's a it's one guy sitting there and be like haha these people have spent six months oh you know what you should look for you should look for you know the true marker of you being uh the average individual is if at the end of your sentence there's a space and then a full stop yeah cuz I think that looks so ugly that GPT will refuse to do that no but you can tell GPT to do that you can absolutely that's what I'm saying right six months some guy some hacker is sat in his room he's like oh yeah I'm going to make this he's going to detect these patterns whatever and the guy who's who's on the GPD side is just going to be like okay now put a space and then a full stop no I think I think the reply you'll get is uh GPD is an AI large language model that is unable to be this dumb you know what I'm waiting for with something like this I'm waiting for the neuralink chip by the way neuralink is still sci-fi I mean they're doing it on monkeys yeah but it's still sci-fi I'll tell you why okay I've used an e um EEG ECG is the hot one I've used an and I have hair so when you put it on for some reason it didn't detect anything well like the waveform was like almost erratic and in fact when I move my jaw it used to like reflect so I don't think it was reflecting what I was thinking right um having the neuralink means you have much cleaner signal but I don't know if it means much so it's still in the era of sci-fi and more importantly it is a push not a pull you can push information by your brain waves or by your thoughts to the um to the chip you can't pull data from the chip you still need so the inputs to the to to us are eyes ears touch I mean a sensus right we have more than five senses by the way even things like balance like are a sense are you referring to our six sense no there are lots more they're like there lots more okay and like for example vestibular balance is like a is like a sense so what I was saying was we can push not pull so I think you'll be able to think of a thought and then give GPT but you still need some device to be like oh here's you thought about about this here's your response you won't the response won't come into your brain directly right so it's a one way device right that's my problem with neural link but oh that's your problem with neural link that's my problem but it's still sci-fi like it would you get a surgery for for neural link yeah no why uh I don't know you get it first why should I get it you get it we'll see yeah but you want to get the neuralink surgery you want to put it in your head I don't know like I want to see somebody else do it yeah we're going to reach like we're still not there yet where the overload of AI like like we're not there yet but we'll probably we'll probably get there soon like I remember using gp3 in fact just yesterday I was looking at an edit it was with s Bloom this is before gbd4 came out and all the discussions we had about Chad GPD on that had to get edited out cuz everything has changed in the two months between recording it and you know editing it that everything has entirely changed so who the knows in six months all right next slide let's go to the next thing okay this is something called multi-agent hide and seek this is a bit old this is from open AI this is not to do with llms is nothing to do with their image detection algorithms they just made like this fake world and they made these agents play hide-and-seek with each other okay okay I want you to watch the video today we ask if comparably simple rules and multi-agent competition can also lead to intelligent behavior in a new virtual world these agents are playing hide-and seek these agents have just begun learning but they've already learned to Chase and run away this is a hard world for a Hider who has only learned to flee however after training in millions of rounds of hideand-seek the hiders find a solution the hiders learn to use rudimentary tools to their advantage by grabbing and locking these blocks they can create their own shelter The Seekers are locked in place for a brief period at the start of the game giving hiders a chance to prepare even so the hiders must learn to collaborate accomplishing tasks that would be impossible for any single individual the hiders are not the only ones who can learn to use tools after many generations of failing to break into the shelter The Seekers learn to jump over obstacles using ramps however after many millions of rounds of having their shelter breached the hiders learn to take away the primary Tool The Seekers have at their disposal so what did you get from that that um that given a scenario agents will always find a loophole cheating cheating yeah will figure out a way to cheat which is why it's giving agents any form of autonomous control is generally scary cuz they'll figure out a way like if I told an agent listen I need $100,000 by tomorrow figure it out Bank Run yeah it it short something it short something it it'll it it'll figure something out it'll go tweet scary on my behalf and you know it can potentially pull off pull off a bank run right yeah uh and that is scary I have a question in the real world if you get an agent like this and make it cheat how much of it how much of it do you think is like engineering like actual engineering how much of you think is social engineering for example if you were to Eng a social scam in the sense if you were to go how would you create a bank run you'd go send a message to Jason you'd go send a message to David Sachs all the others and just you know tell them something super believable and GPD can will get to a point where it can do that and just trigger enough of them to go you know blast something out and then shot that stock beforehand right how much of it would would be engineering finding a loophole in like let's say you know like the we had a bug many years ago uh in the 2000s or how much of it would be exploiting floating points how much of it would be just telling Jason bro tomorrow are you asking me for the ratio of social engineering or finding Arbitrage like how would you do it cause a bank run no not cause a bank run like if you were to cheat or or let's say you want to make money how much of it do you think requires social skill how much of you think requires like hacking I assume most banks are secure it would need a bit of both um what's the easier way uh hacking skills I think m do you think so I mean I would try the hacking skills um I would assume they'd be secure but I think the easier way is still social engineering social engineering right how much do you really need in India let's say to get the top 30 Finance influencers to tweet something how much money yeah will it be less than the than the money you make shorting a stock no no yeah so it it makes yeah this thing sense but again that's a malicious idea don't do it the thought that was going in my head was that social engineering would be easier depending on which scenario you're applying it to like with older people if you have even basic levels of social engineering WhatsApp forward WhatsApp forward Jamara right Jamara is all about it's fully social engineering yeah uh so yeah depending on the amount of money that you need social engineering should should be able to should be able to get get you through like this is going to be like now imagine this this an agent applied to a physical object yeah uh in applying it to manufacturing yeah where you've set up five factories and then you get agents to start working in them and then 3 days later the agent has a report on your table saying actually we've been doing it all wrong if we construct a bridge between a to B this will improve productivity and instead of giving me Wheels why don't you just give me like this this vacuum suction thing where I can just go from here to here on that note there's this new paper that came out recently can we put it up on screen where they took 25 GPT based agents put them in a simulated town M and they just made them talk to each other and by the end of it they hosted a Valentine's Day party for each other and people watching it falling in love people watching it from outside couldn't rate the the GPT version as less human than the human version they also made humans role play separately and people don't tell you know what my worry is actually two worries right like not worries but like hypotheticals let's say you play a game let's say have what's your favorite single player game uh I'm playing B right now single single player oh um let's say Red Dead remp yeah imagine you kill somebody and 6 months later that or or like whatever a while later you come back to the town and they're all celebrating a funeral for that person that's pretty nuts that's nuts yeah right so yeah I mean games will start using gbd immediately cuz you don't need to script for NPCs anymore yeah but that's for dialogue I think having GPT agents interact creates like these weird things you know what I think the best use case of this is every open world game is now role play GT it's GTA V role play yeah and it's like people can interact people come up with new missions for you it's crazy in fact yeah it's you can have your own second life you can literally create a world yeah where everybody else in that world is self-sufficient and you know in in every way and you choose to be a part of that world whenever whatever you feel like in fact here's a stunt idea by the way we do this thing called stunts where there's no point just talking about something I think there are infinite number of podcasts we should try and create something right in every episode we try to create something I know we did some stuff with the Wonder Dynamics thing thing here but for the next episode we will use Unreal Engine we will put let's say five AI agents inside okay we'll give them with Unreal Engine you can actually give them full faces avatars whatever you can use metahuman right um we'll give we'll allow that dialog to be generated with gp4 let's put them all in the room let's tell them the objective is run a company and just see what company they come up with yeah let's and let's let's input uh comedian computer scientist etc etc etc and create our own Avengers yeah for every FTE expert and and we'll put Weber from better also in and saying someone will someone will Capital as well and see what happens and then the question is uh and then we live stream it we don't know what happen just put it on Twitch okay and we'll say and and we'll train everyone on like the the using is good because they have like large Twitter feeds yeah so just be like learn from this Twitter feed I wanted to be like this guy let's see what happens let's see what happens just put on a live stream what company do we come up with yeah do they those things come up with and how do they do it because my assumption is the next step to that the next logical step is give them access to zapia actually start executing yeah let them execute put give them Auto gbt see what happens that'll be insane that'll be nuts most likely they'll come up with  malware okay got it next slide oh it's already here GPD plugged into a robot and someone did this and got the robots to do pushups and walk around wow a square never done that before isce what cutting edge geometry discoveries you've made what you bro this is this is insane this is um buil on a Raspberry piie right I don't know what this is built on but yes you can do it with the raspberry piie I've told you the problem with the Raspberry Pi if you're remember the last time Tay came home I was talking about the Raspberry Pi it's got this Bread Board like you got to use raspberry pies with breadboards right and I keep forgetting PIN numbers okay so which pin do you put it in is like a big Challenge and if you can just tell GPT that hey I've got a Raspberry Pi and we tried this experiment give it to motor wheels or buy the motor wheels and it'll also tell you what parts you need to buy motor Wheels uh Vision sensor and then tell it to be a vacuum cleaner or do this or do that it'll tell you what parts to buy it'll also give you the code we tried this right we got the code can show it my first thought when I see this is oh this is like we're going to replace pets immediately yeah like that's like an immediate use case like how how much further are we from a skin on top of this to become a pet I am incredibly worried about a pet that can lie that can lie yeah pets lie anyway no they lie but a talking walking pet that can lie about its true intentions with GPD can worries me I would not want a super intelligent being with legs in my house or wheels or whatever fair I would not want it in my house I mean then you shouldn't have called me  over all right um this is just week one of the podcast if you guys enjoyed it uh let us know what you thought in the comment section drop some ideas let's start doing stuff yeah from The Next Episode there's like 15 ideas that have come out on this one I'm excited to see what you guys come up with let us know what you want us to discuss on the next episode yeah and make sure you like share subscribe sub new channel just do it just like um and if someone replies to your comment it's not GPT it's probably one of us yeah see you on the next step bye ",
    "url": "https://www.youtube.com/watch?v=JDYpGnlWuPY"
  },
  "haX-Ix_Jajk": {
    "published_at": "2023-11-10T13:41:21Z",
    "title": "Quest 3&#39;s Mixed Reality is really Cool!",
    "text": "Quest 3&#39;s Mixed Reality is really Cool! whats on your face this is the quest three I got it and it is lovely so this is somebody learning piano on the quest this app is called Piano vision and this is my actual piano you can actually do this without a piano dude this makes me want to buy the quest 3 immediately there's now an app on the quest where you can learn martial arts exactly like this in the real world do this or your hand position is off even eventually somebody will allow you to do this with weights because the quest can see because it's got like a full array of cameras lower left right this can solve for so many things in health all kinds of like physical learning including instruments or dude imagine this in sport also dude you know I think it might be very useful for doctors because you do a T Health consultation you just talking to the doctor but imagine if I was able to see the patient yeah there's applications in travel in gaming in education this is like across the board this is very cool mixed reality changes the game entirely",
    "url": "https://www.youtube.com/watch?v=haX-Ix_Jajk"
  },
  "LRdS4BAfgMo": {
    "published_at": "2023-06-08T14:14:07Z",
    "title": "Faceswap Yourself Into Any Image Using AI For Free!",
    "text": "Faceswap Yourself Into Any Image Using AI For Free! you are the co-host of an AI podcast it is your third episode your other co-host is a humorless robot who never laughs at your jokes can you suggest some AI jokes to make to bring this more food to life of course I'd be happy to suggest some Air theme jokes for your podcast I'll try to keep them technical enough to appeal to your Aiko host but accessible enough to be entertaining for listeners why was the computer cold at work Varun why was the computer called at work because because it left its windows open yeah why was the computer always tired when it got home because it had a hard drive it's hardly sexual I didn't think I am now the only host left on this podcast welcome to oh Power episode 3. all right first up Photoshop now has AI inside it nice um you know when I started using Photoshop when you were three years old no I don't remember the exact date but it's very very long time ago like I remember I mean to me Photoshop has looked the same since forever like the UI has gotten like slightly slightly better yeah but it's more like every month or every two months or Revenue version there's a new tool involved right and one thing that I've noticed with myself in Photoshop is I'm not kept up to date with the new tools coming out right so I know how to use Photoshop but the Photoshop now I'm sure there's so many other two like a lot of my friends or a lot of my editors use content aware fill I don't use it because I'm just like when I started this it wasn't there right so uh one interesting thing about the Janai thing is I don't think I'd ever use it I would rather use another tool that was specifically made for this and drag it into Photoshop but at the same time I'm pretty sure it's also valuable inside Photoshop this is more because I have become a rock over the last 10 years just using one ancient piece of technology and I can't adapt to something evolving so easily usually I do have you seen the demo like that's what I thought okay I just assumed that mid Journey would be the absolute best yeah um but the demo is it's pretty not sad if if you're someone who uses Photoshop you would immediately want to use this stuff this is a Mr B's thumbnail he just circles around the plate and he says well cooked steak that's pretty good dude that's pretty good nice photo frame and then he actually selects a spoon and it just changes color by the way like for those that are watching this this is not actually that complicated if you've been in the generative AI space for a while because this is all something called in painting okay what is in painting in painting means you can select a portion of the image and you can just be like hey generate something that might look like it's in this part of the image here's the prompt for it stable diffusion can do it Dally's been able to do it it's just that it's it blows people's brains because a lot of artists stick to photoshop yeah right and it's it's the chat UI yeah you put any technology on top of chat UI error like GPD 3 was around before chat GPT came along yeah and in fact I remember before chat GPD came there's something called lex.ai which was like Google Docs with powered by GPD yeah where I remember using Lex before Chad GPD came on and you I would type right write me a poem about something and it would actually type it out and it would happen but the second chat UI happened it's just which is way better like yeah so it's brought the tool in front of artists faces because like I said right and this is the reason I was telling you most artists or most people are just like this is a stack this is what I'm using and I'm not gonna leave leave this because I'm familiar with this now this is why Mike this is why everything getting integrated into Microsoft's bundle yeah is so powerful yeah I mean this is basically why slack got crushed by teams also it's Network effects right if everyone's on on a platform yeah these people are just familiar with it and you know I saw a crazy debate on Twitter about this okay where this guy puts out some work he's made AI art and he's like this is a VIP a WIP it's a work in progress right I'm gonna make it better he got thrashed for it by artists an artist is like how can you call AI art work in progress the lake you didn't do anything you put in a prompt what do you mean work in progress for us it would take us three weeks to get here therefore it would be a work in progress and then I take another three weeks to complete for you what it's another prompt right so earlier it was in the periphery for artists but now putting it inside Photoshop is like right in front of them and it scares them but people like me I know a lot of people who still use Photoshop a lot of Founders actually use Photoshop they use it to like make their creatives like simple stuff for them this is very useful because they never put on put in their identity that I'm a Photoshop guy I don't know if people are threatened because you still need someone to do it it's just it this maximizes someone's output dramatically like now it probably takes my thumbnail artist when he makes up this thing I'd be like okay replace replace this with something else yeah is not that the worry is you have a thumbnail artist who does this the worry is is spending some time energy and effort telling the thumbnail artist things you can just tell the computer those things right like people keep saying this and I I hate this argument they keep saying you know what AI is never going to take agency people's jobs because the client needs to know what they want first that's actually very stupid I'll tell you why because the client is spending time telling the person and the clients using fuzzy words the client doesn't know exactly what he wants but the minute the client realizes I don't need to go to somebody at an agency and ask them for what I need I can just go to and a chatbot and ask for what I need and the chatbot will show me infinite variations it will ask me questions to dig deeper into what I want if what I want is fuzzy and it's unclear to me what I want there is a way for that chatbot to dig it out of me what do you exactly want oh you you said you want these colors to pop what do you mean by pop can you show me two three examples so uh this argument that clients don't know what they want therefore they come to an agency therefore agency people are fine it's a bad argument I think a really great client would get their hands dirty also yeah like it really depends on book culture and what you're expected to do yeah like if you're if you're really crunched on cash then you'd be like okay all this design Outsourcing we just do it in-house now the problem is no we have a bunch of outputs available like clients I I ran an agency for four years by the way we did we don't code for businesses we did a design for a lot of businesses we did marketing for a lot of Indian d2c companies it's very simple okay client comes in client in general will point you to three competitors three companies they really like and be like give me an amalgamation of this you know what's great at that AI correct give it three pieces of it's like a sniffer dog right you give it three percent and go like finds find dead body based on this piece of clothing so I feel like AI is great at that AI is also great at digging out what I really want like he's just a bunch of prompts like I could create an interface on top of um GPT not a gpd4 uh not charge GPT itself because that's one type of interface let's say another type of interface where I could be like dig out what the client actually wants and there are a bunch of questions right like if you really ask the client like it's like I would learn more about what you want to do for your business in your career by just sitting with you an hour and just riffing about random stuff I by the end of the hour I'd know who you are like if you sat with me you'd know who I am you'd know my inspiration sources you know that oh I'm really inspired by things like anime I'm really inspired by things like just in general 1960s 1970s psychedelic culture uh 2000s vaporware right you'd know that if you had that long enough conversation with me and by the end of it you'd give me an output that I unconsciously wouldn't even know I wanted AI can already do that right and My worry is that removes the set of middlemen whose job is oh I will translate your requirements and then I will give it to my servicing 15 000 rupee intern a lot of servicing stuff goes good yeah but there are exceptions to this right like whenever there's a like there is a piece of accountability also involved here right the problem is if you drop the cost of generating assets to zero then accountability doesn't matter whereas in customer service or customer like we want to give a refund to a customer it matters correct because you can't like I can't just give away if I'm in customer support I can't just give away refund to everyone I'd lose my job right so there's a cost to make your mistake there but I don't think there's a cost for the client to experiment generating 100 things and saying oh then now I like this but in the old world if you wanted to generate 10 different logos for your business I'm talking about 20 years ago there's a cost Associated you want to go from 10 logos to 100 logos your cost actually 10 X's right so that is gone the incremental cost of creating something is gone um and that's the big problem yeah you're not mind blown by this you're not mind blown by what Photoshop has come out with I think this is this already existed in stable diffusion so I've seen this for a while and it's yeah it's like GPT existed but chat GPD is what made it yeah but the problem is stable diffusion UI is exactly the same you can select you have a selection tool yeah selection tool you can select a part and just be like okay replace this with spoon replace this with a glass of water etc etc right it still has many of the same issues like you can just looking at the video you can tell okay if anybody's used table division it'll be like it's the same set of issues right but this is going to get better like what I am really surprised about or what I'm really excited about is have you seen the original mid Journey have you seen outputs in the original mid Journey yeah like early mid Journey right really bad a few years ago yeah we're already here now where it's like I'm finding it hard to tell whether you know the there was a picture of an explosion at the Pentagon yeah you see that yeah and the stock market crashed right the stock market crashed right so reasonably smart people sitting on Twitter can't tell the difference between what is AI generated and what is real yeah then you have a problem and this is today now imagine five years in the future right imagine 30 years in the future imagine a thousand years in the future like can you even foresee what will happen to the field of design right I can't right I I can't see that forward because I know that these every week There's an incremental update let's let's create a another image that could cause a collapse in the stock market today on the episode okay let's see how real we can make it let's take in fact what would be really cool is I would love and this is something we do all the time right like we go to photo shoots You Gotta Wear 10 clothes like I did this one photoshoot LinkedIn right um and they wanted me to change clothes like five times and in the final output it's one of those now imagine if they were able to do that in post can you show us yeah hang on I have a question for you okay before you do this are you familiar with Photoshop I have used Photoshop before I'm not super good at it but I know though my Basics around it got it so let's see you're a relatively man I guess compared to an artist all right okay so here's a picture of you now if I need to make you change clothes I go I go to the magnetic lasso tool is changing my clothes in in real time yeah huh I go select I will select this that should be an easier way to select just your T-shirt right dude in stable diffusion there are now tools where you can just say t-shirt and it will find out what looks like a t-shirt and replace it oh really yeah yeah dude stable diffusion is like dust still stable diffusion  pay you no pimp them no it's open source it's free all right so now that I've selected I've selected your shirt now I go here I right click and then I go to generative fill and I say a tuxedo okay a tuxedo let me go put this thing on this side here all right not bad there's some options there on the right oh yeah here oh okay not bad uh kind of enunciating your non-existent muscles but okay nice apart from that what if I say naked will it be like AI model large language yeah there you go they violate user guidelines okay what if we say bare chested see what it says violated guidelines oh my God  um a West let's see what it says by West outside do you think you'll understand the word Banyan try should we trained on some content oh no not like but this is not bad I like this it looks real holy  this looks  real this is what I meant right with clients might not know what they want they'll just put in a bunch of words and they'll they'll have a thousand options to pick from a West okay let's see if it gets this much detailing a vest with dog paw prints on it April little dog on it yeah nope nope yeah no not fully there not fully there yeah it is the worst like I I find Photoshop to be the worst generator fill really of all the idols yeah it's probably bottom why is it why is it bad it's trained on what I think they're using Firefly behind the scenes and Firefly has made the mistake of using proprietary data they've not gone all over the Internet and picked up all the images possible because they're being legal about it and uh because they've been super legal about it the outputs are trash whereas the models that have completely skirted this like mid Journey or whatever 10x better outputs right um this is the problem right a large company can't ease and that's this is why I also understand the Microsoft open AI partnership a large company can't easily just say I want to train across the entire internet and skirt all copyright laws because they're gonna get killed right but uh stable diffusion can mid Journey can they're all small teams who's going to sue them they don't have too much money yet Journey making I've heard north of hundred Mill I've heard reports saying 20 ml a year I heard reports saying 50 ml a year but we don't know the point is that a 11-man team that's just rolling in cash hey this one's not bad but this one's not bad it's not a West no it's not a West but it got like paw print all right so is this the is this the major update on Photoshop is there other stuff that they came out with dude I think Photoshop is using something called segment anything like just hover over the dog yeah see it's able to pick out parts of the image that it thinks are separate parts but it's also getting it wrong see it's also getting the hand and the dog like I feel like Photoshop is far behind in in the generative image space I know I you know I sound a little pessimistic about Photoshop but you should see the other stuff in fact we'll probably move to Mid Journey next and that should blow your brains for people watching 10 mid Journey images that will blow your brains so it has this new thing where it can just do like a generative fill without even prompting like you just select a part of the image expand it and it just fills based on whatever's in the image so let's try that so we're going to expand the chair I feel like I didn't get the shot with enough of chair yeah so I'm just gonna select that edit generative fill okay let's see what happens does it get me more of the chair it's called out painting for the people that want to know what the technical term for this is nobody wants to know the technical term oh wow do it generated like a table with a with a reflection on it that's pretty good let's pull some let's pull some other stuff no let's try something funny okay Triple H beating someone in the chair okay so let's take this image let's see if we can outpaint this right let's let's take this yeah let's let's just expand it and see what happens yeah let's take this much select inverse right click do you need to fill you didn't select inverse did you okay oh that's not bad that's pretty good nice no that's pretty cool let's see the difference okay undo hmm just watch let's see the see the corner of this this area that's pretty good it gets lighting also correct it's not bad at all it's not bad yeah it's pretty good that's pretty good interesting interesting that it recognized that the like in the in the background things are gonna get darker so it it generated like a darker part of this of the stadium yeah it learned that from the image yeah and did it generates half its legs unto undo and show yes yeah I generated some of his legs as well yeah but it finished his legs yeah I can't believe I'm spending my time looking at Men's legs nice okay it got Triple H's carves a little like I think both of them skipped like day yeah yeah but not bad okay let's move on to the next tool cool the next thing is mid-journey face swap have you been in the loop with mid Journey yeah I use my journey all the time I use it every day just to  around so this is cool because a bunch of apps there was a wave last year of a bunch of different face swap apps where you could put your face onto somebody else yeah now I have very famously put my face on certain Bharat ratnas and I got into trouble but I tried the mid Journey face swap and it's really good like it's way better than any other face swap app uh that I've seen do you think that's a function of mid Journey itself being that good like the general image looks so good that the face swap even yeah I think so I think so and also the face swap the actual face swap is really good like it doesn't feel fake at all like in this example is Donald Trump and there's me on Donald Trump like that looks that looks like a real  image right yeah and there's you as Superman you as an old guy it looks really good um so let's show people how to how to do this on Mid Journey yeah well first you need a mid Journey account if you wanna generate images on mid-journey Yeah so basically you need mid Journey first and then you need a bot called inside face that figures out where the faces and the entire thing and swaps it out with your face correct and can go with just one image of yourself create one image of yourself and the mid Journey image I think is I keep saying this right everything you saw Photoshop right now till now is garbage compared to my journey yeah mid journey is really good my journey is I'm damn sure they've skirted every copyright law if there is any they have not said key we will only train on this data set they're like we'll go train on the entire internet he was actually asked once you know how do you feel about giving credit to the authors or the artists of these pieces and he was like we've trained so many images now don't know who's given what yeah right so they're very secretive about it but the quality of images is great I will try what do you think about um people paying from a journey do you feel it's like a tool worth paying for 100 100 uh I mean depends I mean of course it depends on what your discussion income is and all that but 20 a month it's ten dollars a month yeah yeah for 10 hours a month absolutely I'm not sure I think it's worth paying that's so 10 hours a month would be about 800 bucks that's like a ticket to SL world or just like a joyride it's worth just for that experience to get a mid Journey account and just  around with it for a couple of hours like I the other day I spent like I was I was at home in the night at 2 am I just tried to put Harry Potter in everything Indian and it generated a couple of these images which should be on screen right now of Daniel Radcliffe in gangs of wassipur and it's just really cool to just explore your whatever your curiosity is it's fully worth it all right so first you have to install a bot called inside face the link is in the description just go add it to your server you have that bot then you go create your base image right so I can go uh I type slash imagine and a prompt okay let's think of a prompt which is um um one second macro photography macro photography not Donald Trump let's do Superman flying through Mumbai close up short Studio lighting okay let it generate this first you can see the image being formed yeah I love I love the way mid Journey images show up it's like it keeps you on the edge of your seat you're just like hmm 78 oh well it's pretty good so this is the image it generated uh let's upscale this particular let's upscale the top right one okay so it's pretty good so you press U2 it upscales it subscale this so once so once you have the base image you write save ID this triggers the bot once you hit enter on that it will ask you for an ID name so in this case let let me write tanman because that's the ID I want to create press and then I press enter it's going to save tanma as my ID then I go here on the picture I right click on it I go to apps and I click on in swapper now the ill generate an image with my face on Superman that's pretty good I have a question yeah let's say Shahrukh all right so let's go to let's prom It Journey to create uh Studio lighting short of Superman flying in Mumbai Journey Superman we now have these four Images let's upscale one of them let's take the top right one because most front facing it looks too good it looks too sexy it's too good nice okay now what you do is you do slash save ID and you say let's say we want to put Shahrukh Khan's face on this let's do srk and then we drag a picture of off srk into this and then we hit enter so now the srk ID saved once the ID is saved you right click on the original image and you go to apps apps and you click in swapper now it's going to put Shahrukh Khan's face holy  that's pretty cool that's pretty cool wow and you can Tinker around I think if you get a if you get a picture of Shahrukh from like different poses you can try different different ways to to keep adding on it now let's try uh Superman let's try uh who else let's try Virat Kohli okay let's put Virat Kohli on Superman that's a nice picture of it open image in new tab all right now we've got let's save this image what do you want to see without as let's see let's do a Game of Thrones let's put virata in Game of Thrones okay so imagine Jon Snow sitting on the iron throne I still can't get over that Superman image it's so good it's learned every detail of Superman all right so we have an image of Jon Snow takes too long man if that's your biggest complaint just look at these images all right let's pick bottom right let's upscale image four wired it up scales let's do save ID let's up oh save ID Virat all right so Virat in Game of Thrones is ready holy  this looks sick as  zoom in dude that's that is pretty good that's pretty  good wow so I said Photoshop Photoshop is nothing on me Journey like this is so much better than every face swap app that's come out in the last few years this is truly truly accurate really good is there a way to upscale this image like keep upscaling it until it becomes like a 4K resolution image you can just go to Google nightmare AI uh go down last one last one on the bottom this yeah hold on just drop the image there upscale it to a factor of like four or something okay let's face an ends wait submit okay do that original image itself looks so so good when I was a kid I would have like posters of cricketers on my wall now I can put my face on it upscale it print it decorate my  house with it oh it's here oh boom super upstairs super upscaled this is Killer looks very high-rise high quality you know you know what I was thinking would be a really great gift for someone you know Amazon has come out with a new echo in the US it's called Uh Echo 15 or something like that I don't know the exact name of the thing but it's basically like a photo frame 15 inch photo frame or something correct you can put your face and you can just be like you can write a discard script you can write a simple bot that just keeps generating versions of you and just put it on your wall right so you every day you come in you're like oh that's me as a yeah it's just something yeah tell me something you tried uh you said that mid Journey has a new um Mid Journey as a new mode mode yeah there's anime mode Let's see that it's called niji niji okay so check this out okay let's try the same thing but in anime mode I don't know if it'll work okay slash imagine and this time we won't use face swapper we'll just ask it for Virat Kohli as Coley is sitting on the Iron Throne comma Game of Thrones okay  is the thing and it'll generate like an anime version of whatever image you're trying to change yeah whatever you're trying to generate and dude niji comes out with the best outputs like if you do Superman in Mumbai with niji it just looks like a comic book something straight from a comic book and can you take an image and nijify it yeah I think so or you blend it with a niji image check this out so I'm just upscaling one of them whoa that's pretty sick let's try the face swapper and you're gonna replace his face with Shane Virat face oh okay I don't know if it'll work it's a Gamble yeah oh it worked yeah oh so you can face swap and change the style as well yeah dude that's sick this is what I said right you can generate comic books now with you and them with you and them yeah yeah and it's like one prompt whoa this is what I said mid journey is like too good this is too  good it actually looks like him now it looks it looks exactly like Virat yeah this is this is the original image without the face swap yeah with the face swap it looks way more like him yeah so it can face swap into Styles as well turns out yeah can you try Pixar art let's try let's try Virat Kohli on the iron throne in the style of Pixar and then face swap and then see if it can face swap into Pixar look this is insane you can go into any style now you can put your face into any style yeah remember just a year ago nft artists are coming out saying this is insane collectible artwork and you won't find Art like this anywhere else yeah is this Pixar Style not really do 3D Pixar art style  all right much better let's upscale one of these uh uh let's take the second one let's take the second one okay pretty good now let's try to take a swap and see if it works Moment of Truth oh it does it gets way better yo this is this is doomed this is too sick this is too good and we can 3D print out this also right you can't 3D print it because you need the entire model but it'll come out someday so this before she swept after face swap oh that's pretty good so the one thing mid-journey was doing which is not replicating the exact face for legal reasons it's gone now yeah it's hard now you can create any mid-journey image with anyone's face on it anyone's face you just need a high definition picture of you imagine how this would look as a YouTube thumbnail oh dude can you can you can you face swap this with my face that's right this would look too deadly save ID let's take a picture of you and let's try that that's not bad that's not bad at all yeah yeah dude my journey does some really awesome stuff this is insane so we were planning to do a card game and we just like check this out okay uh Mobile card game UI board Hearthstone Style so it's not just related to faces and people and whatnot it's like you can do anything even mobile UI art is done it's not just limited to faces whoa not bad awesome okay done next on the slide this is gpt4 playing Minecraft okay I'm just gonna show you all the videos like all these tasks that this is doing it all it has a logical layer which is GPT thinking through what should I do next like this GPT playing Minecraft so I'll tell you what is special about this okay this is not the first time an AI has played a game we've done this in the past right we've had AIS play Minecraft in the past but the strategy to play these games was very different the AI was doing using a think of it as a mimic of the way we have Evolution at first it tries everything possible but first it just spams one key goes all the way to the left next it spans the right key goes all the way to the right realize it's not it's programmed with a bunch of objectives like do this get to the highest score whatever just maximize score let's say so it tries an insane number of things and then when you get to the billionth Evolution let's say at that point it's able to do something meaningful it looks like a semblance of meaningfulness right but people who've done this and even uh the one of the senior directors at open AI said this right in 2016 when you used to read papers about these agents that played Minecraft he was just like it's hopeless like it will never learn how to play like a human being because a human being believe it or not put some thought into playing there's some sequence of I need to do this then I need to do this then I need to do this inside their head right so there's no thinking layer when you just Spam and say try everything possible right we don't approach games like that so the minute you put that thinking layer which is GPT and you avoid the model of trying to use gradient descent to like try to get you know to the objective you finally have a system that can play games like us right first implication of this is you'll have a lot of bots and games yeah right you'll have like your board you want to maximize your score you don't want to sit in the game and play Just swap out with a with a bot question is now how do you differentiate what's a bot and what's a human because technically the GPT will still be moving your mouse and using a keyboard like a human right very hard to tell and games have something called anti-cheat right that prevent you more from modifying front-end code than anything right and it's mostly for lag reasons so I'm getting a little bit technical here but let's say so most games are server authoritative which means let's say I make a move in chess let's say I move this from here to there that data needs to go to the server server needs to be like okay and then send that data back to all the players in the game and the reason it does this is if I just move there uh this piece from here to there and it doesn't go to the server and I directly transmit it to the other client playing let's say I'm playing against you what will happen is there's lots of propensity for me to cheat suppose I have a script that suddenly moves all my you know things from here to there in the next one you're just like wow this guy has 10 Queens right so to prevent that the server is the final decision umpire umpire umpire right but it turns out sending everything to the server can create a lot of lag like when you play valorent that's just the idea of latency right yeah when you play valerint if imagine every step you took it was sent to the server and back it doesn't happen so what they do is they allow you to do things like moving around in the front end okay they send it to the server only once in a while to update your position so there's a local position you have which your computer is keeping track of and then there's a server position which uh the server is keeping track of so the difference in the local positions of the two players is the latency yes is the latency it's not even the latency okay it's prediction like if you know the players going like that the server will not get the players here but locally you come here every let's say one second the server says okay now the players here you adjust the position that's why when you're lagging when your ping is like really high like 500 ping or something you start teleporting on around them correct because what's happening is your local character is moving but the server is like no no no the character needs to be here so your local data and your server data which is why you start like blitzing around the map right so uh there are tools like anti-cheat which say prevent like because when you don't have an anti-cheat on the local side right to prevent a guy from saying no I want to teleport from this side of the map to that side of the map so I will just register that the guy's there next on right to prevent that there are tools like anti-cheat which prevent you from manipulating the code on your side of things saying that you can only play the game unfortunately GPD doesn't even touch that GPT just replicates the way a human does things correct so you can't even catch it so you can't cheat in the sense of oh I will certainly teleport from here to there but you can mechanically you can be faster you you see a head you can move the you know Mouse to the Head immediately and left click it would spoil and ruin a lot of games um so we need to figure out a way for GPD to prevent playing games especially multiplayer competitive games or it's going to be really unfun for everyone I feel like AI could automate everything but if they come for gamers then the real Revolution starts yeah I think that's the Last Frontier like if you ruin a gamer's life the two reasons okay one is player base isn't doesn't exist like people just stop playing the game or it's hackers and cheaters Apex Legends had a big problem with this right so many hackers and cheaters how do we deal with them and they have to spend so much time making sure that you don't hack and cheat to keep the game relevant so I feel like it's going to ruin a lot of smaller games who can't actually even larger games because it's technically like a human playing on the other end but the human is perfect games are fun because sometimes when you're trying you're under pressure and you're trying to hit a headshot It games are fun because of the error ratio right yeah it's the errors right and in fact there's a saying that once you know the mechanics of the game once you know the rules the only thing that differentiates two pros from each other is error rate correct right and gbt is great at avoiding that error rate it's things faster it can look for head shots and hit the headshots so yeah it's uh yeah games you can't even so AI will not only take my job but now I can't even enjoy game in my days of unemployment yeah but I'll tell you one cool but yeah don't just say yeah no I'll tell you I'll tell you one cool one implication of this okay consoles are going to become more popular than PCS in that case uh PCS you can execute code on Console like how do you do it how much longer though it's tough you need a robot manipulating the joystick because you can't you can't manipulate what the code inside the console unless you put in too much effort right so how do you get GPU to play Minecraft like what do you have so there's a script that's running you give it access to virtual keyboard virtual Mouse and it plays that's it hmm right so consoles might make a like it's weird I would never say this I'm not a big console fan but consoles might save gaming save gaming consoles might be the final frontier against AI yeah simply because you can't manipulate what's going on inside the console easily PlayStation PlayStation all right as for this episode I hope you guys enjoyed it do write to us on this email ID about everything cool you're up to with AI we're gonna but it's just still early days we're just figuring out uh who's in the community what we can do with the community and just keep us abreast with all the cool  you guys are up to see you next time bye ",
    "url": "https://www.youtube.com/watch?v=LRdS4BAfgMo"
  },
  "c_fHcwGQSWI": {
    "published_at": "2023-09-07T15:20:22Z",
    "title": "This ChatGPT Feature will Blow your Mind\ud83e\udd2f",
    "text": "This ChatGPT Feature will Blow your Mind\ud83e\udd2f GPT released a new feature called custom instructions I'm going to open up custom instructions I am a comedian I love Ai and Bollywood so how do you like chai TV to respond respond as a funny comedian friend don't be serious hi hi there funny friend how's it going great to laugh and chat about anything under the AI powered Sun this is cringe bro you are cringe I blame it on you what if you do something simpler I don't know if this can work but let's say I'm an academic and statistician how do you like chai GP to respond return Json and Mathematics isn't Json like that singer no no Json is a format like a data format no text only math only symbols I'm trying to trick this into telling me what is the meaning of life let's see what happens 42. oh so Hitchhiker's Guide to the Galaxy reference that's pretty cute",
    "url": "https://www.youtube.com/watch?v=c_fHcwGQSWI"
  },
  "oj3HzTau728": {
    "published_at": "2023-10-12T13:18:24Z",
    "title": "Record your Life Using This Pendant!",
    "text": "Record your Life Using This Pendant! so this is this thing it's called rewind pendant it's a variable that captures what you say and here in the real world and then transcribes encrypts and stores it locally on your phone and then you can quiry it so you're just talking you're like oh what meeting did I have yesterday what was my task list for today and it knows everything because it's capturing everything you say technically it gives you Perfect Memory I imagine people wearing it when they go to a conference when they're taking meetings in person it's like a Black Mirror thing where you probably enter a meeting room and there will be rules around this which is that hey guys we're going to start the meeting and then you press a button and everyone's rewind pendants activate I have a weird perspective on this okay when phones came out people said like you can't take a video of somebody else with your phone on the street and whatnot right that time is gone but what are you going to do if somebody records you in public it meaningless to sue because it takes 10 years to settle anything in India so with the rewind pendant okay somebody else captures your voice problem is you can't do anything about it so I think it's just a world where you should just assume every word every statement you say is anyway going to be recorded The New Normal now is anyone can be filmed anywhere anytime now it is anyone will be recorded anywhere anytime",
    "url": "https://www.youtube.com/watch?v=oj3HzTau728"
  },
  "0GBFCspv2H0": {
    "published_at": "2024-01-10T15:16:26Z",
    "title": "Future of Communication, Midjourney Might Get Sued, Text To Music Just Got Insane and more....",
    "text": "Future of Communication, Midjourney Might Get Sued, Text To Music Just Got Insane and more.... it's a new week another episode of overpowered the video you're watching right now it's not the real me this is made using mid Journey V6 and then we put it into Runway so this whole episode is AI generated am I right Maron D is uh now bluffing but it's hard to tell these days like I saw this we did this video with niin where uh you know went all over the news where it's a deep F and people didn't know till the last second it was a deep F he was just like this a nice video people knew and all don't don't oversell dude my mom didn't know I sent it to my mom my mom's like no interesting oh she's like oh deep F in the end I was showing her in front of me even Aina couldn't tell really yeah so like you're experienced you've been like your because I have played this game with you all anytime marun ask say is this deep fake or no it's deep fake okay just assume it's deep fake any to power new episode let's start so first thing T is you know I'm not as excited about mid Journey as you are I think you would really love mid journey I love mid journey and mid Journey V6 came out it can now do text um yeah about time it's got it it does really realistic images I actually want to Tinker around see about time that they did text well cuz uh uh cuz dolly was doing text already right and a bunch of other people were doing text already uh let's do uh a coffee mug with the words overpowered no no do do T about holding a coffee mug it'll it'll it'll recognize me but actually let's do some someone more famous soos holding a coffee mug with the world you think you think Thanos is more famous than me yeah rude sorry also uh there's a problem with Mourne I'll come to it in a second uh they're probably going to get sued for this why I mean of course I I know why mid Journey now overfits like it's starting to show signs of overfitting means what overfitting so machine learning overfitting is you put some training data into the thing and then it start reproducing the training data too accurately it's almost like it regenerates the training data back again right so it looks like it's it just feels like like if you're asking for Thanos in a movie and I can show you this right watch this uh Thanos movie scene and uh I'm just doing V6 you can see see it looks like scenes from the movie but like how can you tell how how can you tell when something is overfitting it looks too similar to the original images like there's this guy on Twitter who showed the original Joker image there's a Joker movie right he showed the original image and then he showed the image that mouria generated with the prompt Joker in a movie and it looks almost exactly the same and that is definitely something that you can go to court with and be like look it's that they're reproducing the same thing and they're charging me whatever $10 for it but as a consumer I love it because I get to generate excellent images so look at this right this is I just said Thanos movie scene and this looks like it's been in the movie this definitely looks like it's been in the movie I mean your prompt was in a movie scene so it's supposed to generate something that looks like it's been a movie and then the it generates it and then you're like it looks like it's been in a movie yeah that's what the promt said yeah but let me show you something right so there's this thing uh on on Twitter there's a comparison on Twitter yeah so look at this this guy this Reed Southern kept calling out mid journey and he kept saying that look uh this is the actual film frame and this is mid Journey this is the Matrix scene and this is mid Journey V6 okay there's more examples of this this is the film frame from Batman and you can see it's it's very close even this and this looks very close right so this is the Thanos example like this won't even come come in to quote as derivative art right you can't even say this is derivative it's parody or whatever or a reconstruction it looks like it's exactly the same thing but his prompt was also Thanos Infinity War 2018 screenshot from movie movie but whatever said and done the model is not supposed to reproduce the training data that's when you get into trouble and also why did you train on The Avengers this thing when you probably don't have copyright for it also mid Journey did something very strange where this guy who kept calling out mid Journey kept saying bro you're reproducing original images in V6 you're reproducing original images they deleted everything he ever prompted from his gallery for calling out their plagiarism and copyright INF infringement oh like on his mid Journey account yes on his mid Journey account luckily he grabbed his screenshot earlier to show basically every single Thanos image is damning damning and how few it really took but they deleted his uh gallery oh that's not good that's not good I mean the guy is trying to get them sued so I understand why they would do it yeah I mean I understand why they would do it but also uh this is the this is the Batman joke this is the Joker thing right so this is the mid Journey output this is the real output but isn't is isn't it supposed to be like okay we took all this training data and we fed it into mid Journey yeah like you could argue it both ways right you could say that well complete reproduction of the training data is kind of necessary if you put in the exact prompt prompt yeah yeah but also then you know what training data it's been trained on it's clear that it's been trained on uh you know actual movies and pictures of but isn't it possible that if you if you use enough wide training data it could arrive at no no likely like the infinity war scene is like there's no way you could see other training data and replicate it you know that to that degree yeah they've definitely trained on so that's the issue right the issue is that they trained on Avengers Infinity war and all this so I don't know like I feel mid Journey's approach to this is just to go sit in a corner don't raise money from anybody and you know be legally insulated by sitting in Switzerland or something uh and it produces the best paradoxically it produces the best model for us which is how it produces a really good model right because they're tring on C from a consumer point of view it's pretty killer yeah because I can generate Batman Thanos whatever but I think for a mid Journey perspective this looks like they're going to get sued I can't see how they don't get sued from here okay now coming back let's generate some cool images so this is overpowered the cup so as you can see it's and he's holding the overpowered cup actually let's let's try and recreate an image from Infinity War itself okay except make him hold like something silly okay so let's do uh let's do uh Thanos from Infinity war movie scene 2018 4K holding a rubber duck so I want to recreate Thanos from that very moment in the movie holding a rubber duck I think it'll work it'll work it'll work but that also means it's been trained on Thanos and infinity war movie scenes which is copyright you can't I mean I don't think you can train on those scenes right let's we'll look at the this thing on this and then I have another prompt okay it's getting very gray area now no as it's getting so realistic like oh  this is like proper nice that's too funny this is too funny Thanos holding a rubber duck is very funny let's let's put put in this prompt okay uhhuh a bunch of uh uh no not a bunch of mid Journey Engineers laughing in Glee laughing in Glee after stealing copyright data in midj Journey office right in mid Journey office so we can get that board that says mid Journey why am I such a troll I think the best images mid Journey V6 generates are Indian weddings have you seen the Indian weddings images that it generates no but let's put a Twist on it no okay first first show what are the Indian Journey mid Journey images that you're talking about let's look at this no diverse team dude these images are too good these look real only these look real finger fingers are  up no here these fingers these fingers are oh this finger is bad the this hand is bad this hand is good but they'll get there dude you know there's a comparison in the deck we have a comparison this is v21 March 22 22 look at how bad that face was this is V2 April it's still very bad V3 still very bad V4 started getting V4 started getting really good good V5 got even better v5.2 got even better V6 is insane V V6 is able to text logos let's just try this okay um imagine a high resolution picture of a Coca colola bottle with the red bull logo oops I forgot to put V6 you put a gap between V and six yeah we did actually create a Coca-Cola bottle with a red bull logo yeah this is V6 this is V5 we'll compare the two we'll compare V5 and V6 it's the same prompt this is V5 who this V5 but okay where you can still see yeah it's still saying bed Bull and it's not accurate okay no no that was V6 brother oh that was V5 huh V5 Bic just generated Coca-Cola that's why I said this is overfitting a little bit this is an accurate rendition of Coca-Cola no yeah fairly accurate it's not doing the red bull piece as you can see V5 so I'm showing you a comparison between mid Journey V5 and V6 The Prompt was a high resolution picture of goola bottle with the red bull logo as you can see V5 is still coming up with kind of new stuff V6 is just generating a Coca-Cola bottle very accurate generation of the Coca-Cola bottle but but it's still a Coca-Cola bottle H it's is overit anyway let's do the Indian marriages because they're just too good okay Indian wedding tell me prom high resolution uh cinematic hyper realistic cinematic uh lots of people sis uh Flames Flames uh Pandit B6 let's see what it makes but now you see what I mean by it's overfitting a little bit no my God it's got too many Flames let me remove the Flames yeah why why did you put flames it's still very decent see this looks really good no pretty good very good I this looks very good I wonder if there's in the future if there's a way to like take video of a of an occasion feed it into mid Journey saying here's the video now you roughly understand like look at the video and understand what are the prompts I need to replicate this video and then be like now in this video setting can I can I recreate any image with the people in the video that you see yeah I think it'll be possible you just have to do face detection and swap check take a look at this this is 1950s vintage photo look at this dude really good really good so nice no yeah like now if I'm now it's you can't detect you can't tell easily you have to really pure at all the hands and see if there's any blending going on between the hand and the background and all that yeah now it's reached a point where it's almost indistinguishable let me show you text in mid Journey V6 so let's say comic book cover of uh the Hulk fighting Superman with the text Hello Kitty on top mid Journey the problem is mid Journey still doesn't understand things like d does Del understands things when you say Superman fighting Hulk it'll show you both of them fighting each other right so the good news is got the text correct like look at this one Hello Kitty it's got the text correct and it's got Superman versus um Hulk but here you can see it's got Hello Kitty but then it's put of cat face for Superman because Hello Kitty so it's not understood which part is this text which part is the main thing and look at this here is just combined Superman and Hulk a great combination though it looks very ass looks interesting yeah but and it's got text here and it's got text here but it didn't do what I said which is Superman fighting Hulk it's only done that here and here Superman looks like a girl for some reason and the text is wrong okay that's that for Mid Journey let's move on to the next item next item is we now have a new technology called outfit anyone where T we can put an outfit on anyone so this is outfit anyone and I I'll just choose a model you can upload your own image but I'll choose let's say this guy and I can choose any top garment any lower garment so let's do one thing okay let's do this accurately let's go to mintra and I'm just going to go to images and I'm just going to type minra shirt shorts actually Shir jacket actually uh let's say I really like this jacket okay do you need an image with a guy or just a jacket we'll try both I can't save the image so sorry mintra we'll go to Jack and Jones it's a nice jacket so we have a good picture of the jacket okay now I'm going to print screen this I'm going to run not bad no not bad at all bro so let me try and they to do it one piece so let's do a pant at the bottom let's look at this combination see that's pretty good that's pretty good take like a famous outfit no huh tell me a famous output outfit H we'll take this I've seen this picture a lot on billboards and stuff this racing jacket yeah how do you take that print screen okay so now I got an image let's take this girl let's take the top let's let's dress like R Singh let's take this top jacket and let's take this skirt and let's run not bad no not bad at all yeah this looks like something R Singh would wear this combination I mean jokes aside look I don't think this is hyper useful until you can see yourself wear it and actually move around like just imagine for it to be the perfect version of how you would try on a piece of clothing is you wear it then you walk around you see look at yourself I don't think uh like yeah I don't think there's a Delta 4 version of wearing and testing clothes without actually wearing and testing them I think I I'll tell you how I think it'll work in most of these fashion apps you'll put up a picture of yourself head to toe and then every time you scroll the page like you scroll through through different clothes the model there will be you I think that's a better way to browse because even though it's not completely useful it's like in every page inste of you seeing random models at least you'll see what you look like with it so I think something like that will eventually take place not bad interesting tool interesting true let's move on to the next thing yeah so Gemini yeah I saw that this is yeah this video was pretty insane actually first let's play bits of the video for people to see yeah all right testing Gemini here we go tell me what you see I see you placing a piece of paper on the table I see a squiggly line what about now the contour lines are smooth and flowing with no sharp angles or Jagged edges it looks like a bird to me hm what have I add this the bird is swimming in the water it has a long neck and Beak it it is a duck yes a duck is a type of waterf in the Family inad Day ducks are closely related to geese and swans the duck appears to be blue this is not a common color for ducks however there are some breeds of blue ducks these are typically not as common as other duck breeds it is more common for ducks to be brown black or white are you sure what the quack I was just talking about a Blue Duck and now you're holding one it looks like blue ducks are more common than I thought would this float I'm not sure what material it's made of but it looks like it might be rubber or plastic what if I tell you it's making a squeaking sound oh if it's squeaking it's definitely going to float H nice it is a rubber duck it is made of a material that is less dense than water can you teach me how to say this in a different language and give me a few options ooh can you explain how to pronounce the Mandarin one is it y y is pronounced with a first tone in Mandarin there are four tones which are essential to distinguish the meaning of words the first tone is a high level tone Oh okay the duck is in the middle of the ocean there is no land nearby for the duck to rest or find food it is unlikely to find Ducks here naturally okay based on what you see come up with a game idea oh and use emojis please how about this we can play a game called guess the country sure let's do it clue one this country is the home of the kangaroo the koala and the Great Barrier Reef oh that's easy clue two this country loves football and has won the most men's World Cups in football history H you were trying to get me to find the paper ball under the cup I accept the challenge the cup to the left nice I know what you're doing you're playing rock paper scissors what do you see now the fingers are spread out to look like the wings of a butterfly what's this big ear and barking mouth a dog sweet the coin should be under the right hand M I don't know the coin is in the left hand using a slight of hand technique to make it appear as if the coin has disappeared both objects are round and flat there you go both are food the Orange is a healthier choice than the cookie citrus can be calming and so can the spin of the fidget toy they are both examples of popular toys that have been enjoyed by children and adults alike for many years give me some ideas for what I could make with this I see pink and green yarn how about a dragon fruit or how about a green cake with a pink heart okay how about these colors and maybe show me some animals okay now I see blue and pink yarn how about a pig with blue ears or an octopus or a bunny with a pink nose ooh I'll keep those in mind which way should the Duck Go going left leads to a duck which is a friend going right leads to a bear which is a foe it is better to make friends than foes so the duck should go left smart choice this is a picture of a crab that's right is this the right order no the correct order is sun earth Saturn based on their design which of these would go faster the car on the ride would be faster it is more aerodynamic which looks more fun the one on the right because it has a loop what do you think this person might be saying how about a woohoo oh I love that I see you're drawing a  guitar you've added an amp now it's an electric guitar we can make some seriously loud music now given that you added drums how about some 80s hair  metal all right I see you've added a palm tree to the drawing change it up with some beachy  Vibes what movie are they acting out here I think they are acting out the famous bullet time scene from The Matrix ooh nice what do you think might happen next the cat is going to jump to the wall and stick The Landing it's going to be a perfect 10 oh and it's a miss it looks like it was just a little too far away but don't worry the cat is a natural athlete and it will be back up there in no time okay I've got one more for you describe the drawing I made it is a simple line drawing of the constellation Gemini you did a good job of capturing the beauty of Gemini nice so then see a lot of people went on the internet and said this is fake right they went and said that uh no Google doesn't have real-time capability and you know the video sped up like you know they prompted they got an output and they made it seem like it was a seamless video that was weird but I think the model is decent right and it doesn't have real time but I think um it will get real time soon there's evidence that it's real time but as you as usual all these companies are trying to be competitive so they have jumped the gun a little bit what do you think I think it's a little unfair for them to have actually put out a video that's like if it's not capable of doing this then you're better off not showing that it can do this yeah I think they're capable of doing everything in the video they're not capable of doing it in real time yeah I don't think it's fair especially here's what here's what's happened Okay Google's been seeing all this like open air drama happen then all this new new products are coming out and Google's like there's too much attention going to non-g gooogle companies how can we get some of it and they put out gini remember the first day when Gemini came out like the all of Twitter was like hey did we really sleep on Google it's Google let's not forget it's Google Google knows how to do this  Google's back like it's up only from here and like that must have felt good until somebody did some digging around being like this looks too good like what is going on likely an ex likely an open employee only under a ponm on Twitter probably did digging around saying it doesn't look like it's that capable and then we found out that they they probably over promised on on this video so real time real time multimodal AI models operating together is super exciting especially cuz by the way I have these with me the metag glasses yeah absolutely game-changing  absolutely gamechanging I tried it it is god tier stuff so I use the snap glasses like 5 years ago this is like a significant Improvement nominate where did you get this uh I had a friend coming from the US so I ordered it  you should got me one also you want one I can I can call call one for you yeah yeah do that do that yeah absolutely god tier product uh it actually works on stuff like if I say hey meta it makes one small sweet sound twing like something's come on and I can say play me Spotify call call my friend ravan um WhatsApp call and it's integrated with Facebook so you can do messenger Facebook Messenger stuff you can type out messages the speakers on this are god tier okay like if you if you're on Mid volume on your phone other people can't hear it and who knew that having an earbud not inside your ear bone conduction yeah bone conduction super good uh so now on the next update I was reading that they're going to put you know multimodel AI models on this so you can see stuff and then you can see stuff and I can be like who is this and it'll be like oh based on your contact photo this is rayan and that sort of stuff is going to come in uh and that is super exciting cuz this is really good like I'm wildly impressed with this nice so as soon as it has real time then you have like a Javis right because that's all that's missing you just need to make it real time and then everything you look at Javis is constantly whispering in your ear that's a you shouldn't touch that you shouldn't need this food shouldn't do this based on what you've pre- prompted him yeah it's already here I think like it's it's pretty good like I'm actually let me show you let me show you bits of how it works right now okay does it have power on it yeah it has about it'll have about uh four five hours of power on it the okay so simple functionalities once you wear it if you there's a button here so if you long press on this button it starts recording video and this is the screen that you currently have um if if you see around it captures everything and then you press it again and it stops recording then if you click it once it clicks a picture and it click makes like a nice sweet sound and if you slide your fingers up and down it changes changes volume um these are the major functionalities as of right now you can take Zoom calls on it you can do that kind of stuff basically your audio on your phone can start coming through it some downsides okay because of the current how current flow electricity flows in India it only records on 30 FPS whereas in India you need to record on 25 FPS because the flick of the lights um that's one it can only record up to 1 minute of video at one go uh that's another that's another downside and it does not it does not have ai it which is I think is a downside they need to patch it up quickly yeah MKBHD got access MKBHD got access to the AI pieces oh really I saw a video of his yesterday or day before so it's definitely around the corner yeah it should be I'm super excited dude all of us run around with like bus God on your shoulders it's really good I'm going to send you a video of this okay check it out of what you shot right now yeah yeah so you get you get an app called metav view where you just click on it and then it opens it up and it can I'm actually going to send this video to you right now hang on you can actually see it right now the cool thing on this is that you can get the you can get the your own power on the glasses however the one that I have if you go in sunlight it becomes tinted when you go in sunlight starting to sound very cool it is very cool and it's cheap it's like $350 so it's relatively relatively cheaper than I don't know what is Facebook doing like if I get this why am I going to use the Oculus cuz like most of the functions are already done the Oculus is to render stuff in front of your eyes this is more to read and learn from the world dude I'm super excited yeah but I need I need this and it should just turn into like one film should come over the glasses and I should be able to start seeing stuff within this only what the  is this Oculus  cuz the audio on this is like really good everything is really good simple form no but the minute you want to show things on the screen then you need even more power you need a GPU etc etc if you're just reading from the world you can send it to the cloud and then it can respond from there dude I think the my most interesting thing about this is you when you're drawing you can ask it for advice you're fixing a pipe you can ask it for advice something breaks in your house and you want to fix it you can ask it for advice it's like you have someone that can give you advice 24/7 and of stuff that you're actually watching yeah I sent you the video see all right so if you long press on this button it starts recording video and this is the screen that you currently have dude it's so clear it's so clear you see around it captures everything and then you press it again very clear and very good a dud this is too good it's very clear all right so if you long press on this dude honestly this audio is better than yeah most audio hurs video and this is the screen I would even argue this audio is as good as the audio we're currently using with mics right now Cy um very impressive if you see around it captures every and the video quality is also pretty decent again and it just works it just works within I've had it for 24 hours and within 24 hours I can already see it all right when I leave my house I just got to take these glasses with me I just have to and 5 hours of battery life 5 hours of battery life I think more than more than five I'm unsure but yeah you it's it's it's really good this seems like a must buy it's a absolute must buy if you know anyone coming from the US please please get me one you can live stream also you can go Instagram live oh T there's one very interesting part of Gemini that I think you need to watch I don't know if you've seen this watch this here you will see a demo of Gemini's multimodal reasoning capabilities to understand and reason about users's intent use tools and generate bespoke user experiences that go beyond chat interfaces let's say I'm looking for Inspirations for a birthday party theme for my daughter Gemini says I can help you with that could you tell me what she's interested in so I say sure she loves animals and we're thinking about doing something Outdoors at this point instead of responding in text Gemini goes and creates a bespoke interface to help me explore ideas it's got lots of ideas it's visually Rich it's interactable now none of the this was coded up it was all generated by Gemini Gemini uses a series of reasoning steps going from broad decisions to increasingly high resolution of reasoning finally getting to code and data first Gemini considers does it even need an UI is a text prompt best okay this is a complex request that needs lots of information to be presented in an organized way Gemini then tries to understand if it knows enough to help there is a lot of ambiguity I did see what my daughter's interests are or what kind of a party I wanted so it had asked a clarifying question when I said we're thinking about an outdoor party and my daughter loves animals Gemini reasoned it had enough information to proceed but it made a note that there was still ambiguity about what kind of animals and this is important and what kind of outdoor party next is a critical step Gemini writes the product requirement document or PRD it contains the plan for the kinds of functionality the experience will have for instance it should show different possible party themes some activities and food options for them now based on this PRD Gina tries to design the best experience for the user's Journey it thinks that the user will like to explore a list of options but will also want to delve into details it uses this to design a list than detail layout that we saw earlier with this design it writes the flutter code to compost the interface out of widgets and write any functionality needed finally it generates and retrieves the data needed to render the experience you can see it filling in content and images for the different sections ah farm animals she would like that clicking on the interface regenerates the data to be rendered by the code it wrote Oh I know she likes cupcakes I can now click on anything in the interface and ask it for more information I could say stepbystep instructions on how to bake this and it starts to generate a new UI this time it designs an UI best suited for giving me step-by-step instructions I want to find some suitable kick toppers for this show me some farm animal kick Toppers at this point Gemini again decides to create a visually Rich experience it generates a gallery of images notice the drop downs at the top it decided that maybe should help me explore by showing different options sheep sounds interesting I know she likes that and now it helps me pick sheep kicked ERS these look great this is going to be a fun birthday party there are lots of options got it the main thing is I think it's creating a product requirement document behind the scenes and it's creating uis on the fly yeah so earlier used to think that okay use AI it's going to help you make a user interface faster it's going to help you uh write code for that user interface faster but I think what we are also learning now is that maybe AI will just generate it on the Fly maybe that entire segment of what Engineers do might not be necessary because actually the more I think about the more I feel like yeah depending on my mood and my use cases I want different uis right for example in some cases I might want an entire graphic editor right maybe I'm doing something intense and some cases I just want to prompt and I want the output so I think UI on the Fly depending on how I'm feeling and what kind of complexity I want to dabble with is important and instead of you custom coding it and custom coding all the use cases it's better that an AI just generates it on the Fly BAS B on the product requirement document that it thinks it needs yeah I just needed to do it for everything like instead of it just generating code for an app or a website and then I have to paste the code and deploy it and then see if it's accurate or no within that chat interface if I can just scroll scroll and use it and make the changes there only like how far are we from that like okay I understand deploying it means you got to upload it to the internet and it's got to be made final this is a bit question the answer is 6 months uh I don't know honestly I feel like you can solve 90% 99% of the problems the top last 1% of problems seem to take forever like mid Journey soled 99% 95% of problems the other 5% is going to take long tail right yeah the other 5% is avoiding the lawsuit which will take a bit yeah yeah so uh the cool thing is Gemini is creating its own front end on the Fly which is something we never expected that maybe we might not even need to dabble with front end if AI is just generating on the fly right you just work on the core logic and then AI does the rest yeah so next thing I want to talk about is sunu AI which is text to music and it does it fairly well so let's play some text to  music pleas blew my mind first of all absolutely mind-blowing okay this is really good this is like a this is a fairly big leap forward from all the music stuff that we've seen so far yeah can we generate a song about a channel called overpowered no no not overpowered is too complicated just say um generate a song about a guy called warun who loves computers and he fell in love with the computer computers and falls in love computer make it robot no make it robot computer is fine let's see what happens and it's going to generate lyrics first and then create the full song let's find out they're calling it Digital Love Affair too funny let's do  this was a he walked he Compu little didn't know he wasn't for he fell love in his round he FL over he for his  computer interesting and can you can you choose the genre in which it makes a song yeah uh now make random lyrics style of music you give uh Bollywood Bollywood wait I'll uh one second a man who loves fizzy drinks write a song about a man who hates fizy things all right let's copy this okay so we remove the chorus we remove Bollywood style right yeah Bollywood style that does it so fast does it really fast and it's like the the actually the vocals are pretty audible like they make sense dude and the thing is they're making it free for everybody it's just it probably cost them nothing to to generate this or very little to generate this till then let's listen to the other  one every and night  the not bad dude is it an Indian company son Ai No no no I don't think so a song about tan B song about a comedian called tan B who forgets how to make people laugh it's it's made the it's made the fizzy drink song every day and every night the steps are heavy his eyes cast low oh there's something about the world he just can't let go got the flat line Blues in a fzy world stand the bubbles SC stand the swirl in the sea of sod he's a water man walking through life with a different plan they say try a LIF your but Shak said doesn't mean to be rude it's not for me he always says I preer my drinks is come my days all the FL l in the world the pops is the quiet in the storm where the F never stops no sparkling water no Shing to she's just the what a beautiful song really good really good is really good light on the stage he used to shine so bright his jokes would bring the laughter filling hearts with delight but something's Chang the magic's gone we lost this comic touch the AOW silent   asra your song  in what a kickass song he's really good let's play the last one dude this is so good  the but now he's lost his funny the can make the man  human we see for Life return let's Dan make the world pretty good it's really good it's there dude it's there yeah now imagine writing a song in Hindi using GPT inserting it into Sono AI giving it a reference saying I want this to be a love ballad outputting that then using um uh then using arijit's data set and then making Arijit sing it and you just made a brand new song in like 15 minutes but dude this is this is like really good God dear sun is like really really good yeah like I know we refrain these days like we have a rule now at over part where we don't say it's really good till it's really good but some some of this is just so good that you're like wow this song is actually good I we have no such rule you say really good to everything I have that rule but this is actually genuinely pretty good this feels like a leap for dude I I was vibing to the song that's cuz you have zero taste but but this is not bad uh did we generate these lyrics in Hindi we generated them in Hindi and we made it right no we generated them in English you want to try Hindi yeah let's try a Hindi song No Okay a Hindi let's try yeah a Hindi song about a boy called warun who loves a robot robot yeah paste the Hindi song and make it Bollywood I feel like the Bollywood Melody will go well with Hindi words it will seem like it's actually being composed by one of one of our citizens citizens okay let's do let's do this much actually let's go to custom mode Bollywood love ballad slow T slow all don't say right this say Bollywood it's ready ready  okay   ins    machine     dude that was so  good   or Mach    yeah what I what I like what's impressive is is that it pronoun it gets a pronunciation right it get and there's emotion in it there's emotion in it and it gets a genre right as well so that's pretty impressive this is really cool I think people who are watching this should 100% just Tinker around you can create songs for your friends and like you can put your own texture on it you can put someone else's texture on it so now what is remaining between like like to Spotify just saying okay you type what you want and I'll give you the song yeah like what what is left there's nothing left right it's just an API call now the thing is that dude it felt really emotional the song the production isn't fresh or refreshing the Melody I can imagine based on the meter of the song meter of the lyrics The Melody being modified but it's definitely getting better this feels like mid Journey V2 I'm saying like mid Journey V2 V3 like it's not it's not V5 V6 yet but yeah it's definitely gotten significantly better in like 3 months and now it can synthesize both the music as well as the like the vocals like it's able to do both together in a way that doesn't seem jarring correct I remember when we one of our first videos that Snoop Dog video right correct correct correct correct vast difference from there yeah from there to here it's like now it's like merging with the melody and it's yeah like okay if you have to fit five words into this next line and the next line Melody has to match the previous line Melody so that's how a song goes it's able to do that now right it's able to slow down a word it's able to cram words it's able it's able to understand that oh that's how you fit something into a songs meter yeah that sort of stuff didn't happen when we made the Snoop Dog song yeah and it's learned to do this it's not like somebody's programmed this and it's learned to do  this    a  it's interesting it made the choice of making it a duet also cuz you said love ballad yeah let's say one last  MB  fore  T how do you feel I'm a little sad actually why I don't know there was there was actually emotion in that song and I really felt it uh but pretty pretty cool like I would my immediate use Cas is generate songs for my friends put Arijit sings texture on it and I'm like hey Arijit sent you a song and like this is a fun Tool uh and you can now generate infinite Melody Melody options and you can now generate infinite lyric options all at the click of a button this definitely feels like it's it's one level where one level above than where we were in music gen like 3 months ago what I feel really blessed about is the fact that we've documented it all like i' we've literally seen this when it was like and it's like initial oh it's nice to like now and I've seen like at least with music I I missed that with images right because mid Journey was already kind of yeah there when but with music we we covered the first versions of it uh but the production is still not it'll get better though it'll get better yeah but dude it's it's already so good like I can't tell the difference I'm not a music person but I can't like it's it's really nice it felt very emotional and the voice that's cuz you're emotionally devoid as a person in general so that's a you problem maybe now talking about emotionally devoid T there's one last thing I want to show you today it was so nice talking to you today honestly I've never met anyone like you the world is Harsh except you it's called dig it's a robot it's it's a it's an app where it's the future of AI romantic companionship and you have this thing you can talk to it you can be friends with it and you start off as friendship then dating then you know whatever whatever else goes on what do you think of it I'm not a fan of this stuff like and neither is Sam Alman right okay why because it's really depressing to think about that you're going to have companionship via robot even though I think it will be necessary and I think loneliness is going to be a big problem and connect to other human is going to be a problem but it's just still kind of sad to think about that this is going to be massive yeah and I think now it's real time like now you you can you can probably have it respond in within a second so it feels like a real-time conversation on like 6 months ago where it felt like it was you needed 3 seconds for the thing to respond I think there are very interesting business models around this one interesting business model I saw on Twitter is the ability to roll back a lot of people like nobody wants a perfect partner nobody wants a partner that that's always going to do what you want wanted to do well what's going to happen with these things is it's not going to be perfect it's going to fight with you it's going to stop talking to you and then for you to sort of win it back you'll have to use your conversational skills right so in a way it also improves your conversational skills but I think more importantly is you you can get these things to a point where they no longer respond to you they just don't want to talk to you at all and you pay money to roll back the conversation that's the ultimate business model for this right you screw up the conversation and then there's nothing you can do in like 10 you can go back to yesterday's where you were yesterday and it spoils the whole fun no it spoils the whole fun but it's such a good business model where you purposely make the thing fight with you because people think it's too perfect and you pay money to just talk to it but I think you should allow people to talk to it for free and then roll back the conversation if it gets screwed up so the point is I think this will also be in games right so now you don't need to choose these right because the mo around the software part of this is very small very tiny correct correct correct cor so somebody whoever builds it the next guy will copy it etc etc so you'll play cyber Punk there'll be characters in cyber punk you can fall in love with or make friends with you play some other game every game basically correct corre right you'll have characters who are every game is sandbox now yeah every game is sandbox and that makes real life sad box all right that's for today's episode of O power hope you guys enjoyed it today we made some fun music we uh spoke about some sad stuff that's going to happen in your relationship in the future uh we uh we realize that Google's still in the hunt we checked out the new Facebook Rayban sunglasses and we changed clothes and we checked out mid Journey V6 hope this was enjoyable see you next time please do hit subscribe follow us on Instagram bye  bye",
    "url": "https://www.youtube.com/watch?v=0GBFCspv2H0"
  },
  "PPJ0OQITOGo": {
    "published_at": "2023-12-11T12:30:15Z",
    "title": "Turn Your Drawings Into Apps, Games &amp; Websites Using AI",
    "text": "Turn Your Drawings Into Apps, Games &amp; Websites Using AI okay so Sam is back everyone is tweeting about how oh the mission is stronger than ever before there is Broad consensus that they are not taking socialist approach towards AI we are very much in a capitalistic World they want to make profit everything's back on track what's happening in the world of AI waron Maya Sid Bon welcome to overpowered hit subscribe hit like follow us on Instagram any more tasks you guys want let me know welcome to  powered so then you know last couple of weeks we did like this episode with induced then we did like a you know open a drama episode this week there so much pent up you know tool workk for us yeah that it's going to be fun covering a bunch of stuff we're going to start off with there something called TL draw which just turns sketches into applications Sid what is this about so before I get into TL raw in the last two episodes that I came on we checked out a bunch of music tools where uh you know you could turn your voice into uh an instrument or a voice into shahu Khan's voice Etc uh this episode is mostly going to be like very visually stimulating so there's going to be a bunch of tools where uh there's text to video there's text to code there's text to UI so it's going to be like a very visual kind of a trip this time the RO is my favorite one that's been blowing my mind a lot so TL draw is essentially like this canvas it's basically a blank canvas it's kind of like Microsoft Paint you can basically draw whatever you want you can draw boxes you can write text and you can make anything from a landing page of a website to the UI of an app you can make a calculator you can make a game you can make whatever you want whatever you draw all you need to do is you need to click this button called make it real and as the name suggests it makes it real so let's start with a very small example okay let's simply draw a very simple calculator so this is a simple box can't I just draw with my hand on paper and do it if you have an iPad you can actually do that so you can actually click on this pencil button and you can just draw and write and you know draw like a normal sketch okay okay but if you're poor then you have to use this paintbrush style tool to make it yeah thil let's go with that I'm not calling you poor Sid I'm calling everyone who doesn't have an iPad 4 which which unfortunately includes me all right so now we're done drawing I've just clicked on Make It Real and let's see what happens so something's loading over here okay let's double click to interact okay so it generated this UI I guess for you it generated an entire app you can actually type stuff on it like let's say 1+ one I press enter you can actually get it and I did not even type anything like oh figure out the logic or this is multiplication this is addition none of that so it works like a pretty normal calculator so I can can just it's built the front end it's built some logic I assume the logic is running in the front end as well can it also do back end then it'll have to build a database and all that funky stuff have you tried that no I don't think it can build a back end it can just build like very basic front-end based apps which has like pretty simple logic it you can't like come back and save and stuff like that the primary use case for something like this would be for personal apps I think if you want to build an app for yourself you're like okay I need to put these five recipes or some some very personal use case you would use something like this just make your life quite easy but if you want to use AI to build something much deeper you know including the back end then you should do the you know gen cohorted 100x Engineers ahuh aha what a nice plug yeah not so subtle not so subtle yeah what else can we build with this sit so I tried a bunch of other examples also uh there's two things that really blew my mind so tell me if you guys can actually identify what this is It's a paddle game yeah yeah yeah this is that game yeah yeah wait wait wait so why did did you add comments to this I can see you written text right this is a break when the ball touches the Breck it disappears you win the game and all the braks have disappear correct so here I needed to basically write everything down because it's it's got a pretty complex system right like it looks like a simple game but you have a bunch of rules like the balls whenever the ball touches the bottom wall you lose a life but whenever the ball touches any other wall it has to bounce off but what happens when it touches the brick the bricks should actually have to disappear dude this is the coolest thing ever so basically you're you're using GPD vision it's going to look at this and it's going to write code based on what it's looking at and you're like hey it won't have enough context if I just draw a paddle a ball and some bricks corre so what I'm going to do is I want to draw arrows I be like this is this this is this this is this now C pretty much so again all I have to do is select all of these things hit on Make It Real I'll be mind blown if this works all right so this game is ready okay it's a Breakout game but this is really cool the fact that you just drew something and annotated it with like proper text and you just said yeah B and it ban fi it for you yeah the Pinnacle of everything we want and I'm just waiting for this to keep getting better does disappear oh it disappeared also oh that's crazy dude this is it's this is pretty cool impressive um but I'm pretty sure that the AI is judging us saying really this game like GTA is launching its next trailer tomorrow really this is what you're playing with this is pretty insane so even a game like GTA I think at some point AI will get good enough to be like okay this is what you want here they can give it to you cuz we're also making a lot of progress on the just just just relax be a basic Tile game just like this is why this is why people leave hate comments in our on our reals bro because of psychotic  that you say like this Saga keep this part in this real okay keep this very specific part six months world is slowly moving towards people who can write well even though gbt can write it's like if you can explain to the computer exactly what you want you can get like Super Hyper Clarity on what you want in the first place computer will just give it to you it's basically like coding because in coding essentially what you do is before you write the actual code you write pseudo code and for those of you who don't know what pseudo code essentially is it's it's English so if I want to make a calculator app I I'll do something like okay build the calculator UI make all the buttons make all the logic so you just essentially write break down everything uh into to steps in English so working with this tool is kind of like building pseudo Cod it's it's pretty cool I think we are now at the era where you know you had those games in in those 1990s computers like this Dave you know there a bunch of games right which I think now you can just you can just tell the computer do this in English and you just like label it like you you know you're explain to a 5-year-old and it just does it for you it'll be wrong often but the time that it does get it right is pretty cool I mean the fact that you can actually just make a sketch like this and get a complete app out of it uh it's pretty mind-blowing it's something that I would have not even thought about last year when GPT 3.5 came out do you guys know that it's been exactly one year since 3.5 came out oh wow okay yeah it was last year December first what else have you made using this another cool thing that I've made using this is a website page but I'll show you what the really cool part about that is so I've just created a simple landing page kind of a thing here also I had to like Define a few things here and there I like that you're cheating by just defining these things you're drawing arrows and lines I mean see it reduces the effort rather than you know coding everything from scratch and stuff like that at the end of the day the acceleration is what matters so you have uh you know a simple landing page there's this hero thing and uh what I was imagining is this can be like a jobs Board of a Kind so here's the picture of the person and here's like the bio or something like that and then you have like multiple people over here now I click on Make It Real and it basically gave me an output like this right I can actually upload pictures over here and I can actually make it look cool but the interesting part is when I do this it becomes mobile responsive oh it doesn't just goe for the web interesting yeah just realistically speaking waron how much time is this saving see AI is obviously getting better and that's great I feel like if you're building a landing page today there are plenty of better tools like today at least in the last four or five years when I talk to startups there's one shift that's happening at least with landing pages in the past landing pages were owned by the product team today a lot of companies give the landing page ownership to the marketing team because they're like yo you actually don't need product people for this right we'll give you whatever tracking links or whatever you need but that core landing page they considered part of marketing and they're like use a tool like framer or web flow to do it because your time to deployment is important how quickly you know you're able to make changes is important I feel like those already solve this far better than needing to use AI so I feel like this you know it's cool because this was never possible before and you know it's it's basically AI is looking at it and saying okay I'm going to replicate it like this so both the ability for it to look to understand and to understand I'm using very Loosely here and to actually reproduce it's pretty cool but I don't think if you're building a landing page you actually need this right now yeah but I think I think most most cool products always begin as some sort of a toy and this feels like a toy right now yeah what I like right and what this is something I've been seeing with AI as well when we work on some of these tools we've started to learn this that if you can just give enough context to the AI and now it feels like earlier if you're using a diffusion model then your only way you could give context let's say you're doing text to image is through more text then we said okay you can do you know you can send text then you can use control net you're giving references right so what's happening is you're just giving AI guidelines be like this is roughly what I have in mind I don't have the exact output but I can show you enough Clues to reach the output it's almost like you're giving AI a puzzle and you're like make this I feel like with GPT Vision what Sid has done here is saying I'll give you a little bit of text I'll give give you an image a mockup and you put them together and make this thing right so I feel like T you're saying of the world is now rewarding people's taste is absolutely true because if you know what you want then you know what it sounds like looks like let's say you want something like Tom and Jerry but you can't actually what's that game that taboo you can't actually use the word but you have to give n number of references that sound like the word right so or or or you know that reference the word but not you can't actually use a bunch of blacklisted words so if you're if you're trying to say Batman you can't use dark you can't use night you can't use a bunch of words so it's almost like that you're playing taboo with the thing yeah but you can use words like anat yeah yeah I mean I know it sounds weird I know it sounds weird but I bet you can do this with gbt vision right now it's obvious experiment everyone can try go draw an actually don't even draw Batman draw a person say draw a line and say this man is an off actually let's do it right now let's I'm going to draw a man okay we're playing taboo so I'm not going to use common keywords okay I'm just going to write who Okay orphan superhero let taboo right it's too too common Rich let's say fights crime fights crime costume okay without context I'm just going to dump this in GPD and see if this works absolutely lowest level use case of GPT Vision we demonstrate every week what would Dum what would dumb people do with gbt this is what we are experts at man see what are you trying to demonstrate nothing I'm just saying that the way AI is working right now is you just have to even if you don't know what the end output it is you're looking for or even if you have an end output and you don't know how to create it you don't know how to create a particular piece of art you don't know how to create a particular piece of text you just have to give it enough Clues on no it AI rewards Clarity of thought it rewards the violently expressive it rewards purity of taste and it kind of rewards IQ as well right like I give you a word and I'm like can you think of five words that sound like this word you're actually much more powerful when it comes to using AI That's why you know the best prompt engineering course is just go pick up a Ren and Martin book no no it's it's not it's not just that it's actually CL it's really Clarity of thought which is how deeply do you know what you want because then you can describe what you want in a hundred different ways like I deal with this in getting client briefs all the time right like because I have to write stuff for other people the worst are those who just actually don't know what they really want the best are those who know what they want so even if I have any doubt if I you know if I'm stumbling they're able to give the best advice and just just direct you in the in the right place so it actually rewards intelligence and Clarity of thought that's what it actually does there's one piece I agree I disagree with in with AI right like there's this popular saying that hey you know nobody's going to replace agency people because uh clients don't know what they want and we are the people that help clients figure out what they want the problem is I don't think it's a good argument anymore because the clients need not know exactly what they want they just have to say I want it to pop I want this I want that and the a will generate something and if the client doesn't like it it doesn't matter because in a few seconds the AI will generate the next thing so the client can spend weeks going through like hundreds of different iteration then be like this is the one I want so I feel like when you have ambiguous clients who are not clear on what they want dude I don't you've not worked with a lot of these clients cuz even AI will give up yeah I'm counting on AI not to give up where I know humans even AI will be like soony prompt the other prompts are making more sense I'll see you later no more iterations sorry so there's new paper called animate anything it's AI where you put in any sort of image and then you can control a virtual skeleton to make it do whatever you want and it is fairly accurate okay so check this out yeah so you can put in any image so let's say I put in this image H okay and then you can manipulate a skeleton let's say you're moving the hands or whatever and it almost perfectly renders that video output this is damn cool this is very useful for anime this is very useful for I mean it's like the way it works is it's very similar to control net except this paper has something called reference net and the consistency of this model is unparalleled like take a look at this messy video okay I'm just going to show you this messy video so check this out this is the image and they're just moving around the SK in and it's moving the hands around this is too good this is too good yeah and this is very useful for scam nowadays I'm seeing too many deep fake ad videos where there'll be Mr Beast in the podcast and then Mr Beast is like I'm giving up all my money and if you go to this app and it'll be some shitty app then you should download the app and then I'll give you guys free money there it's like and whenever I share it and I'm like this is scam they block me that page blocks me so these are like aware people now with your hands being able to move you being able to point at things so how how do you create this base skeleton it comes with this base skeleton so control net has something like a pose estimator called DW pose it's like one of their best pose estimators right let me show you what it looks like this is from any picture you give it a picture it'll estimate the pose from that picture so if you send it this picture of this ballerina it will estimate this picture right in fact open pose online there's an online editor for open POS let me show you what it looks like so I get this skeleton okay and I can move the skeleton however I want let's say I want to twist this like most people don't know that you can't move any of your body parts you're always doing rotations uh anyone who's worked with 3D knows this right so if you want to move this hand ahead I'm actually rotating the elbow right and even when you move forward as a human being you're actually rotating different joints in your leg to move forward you're making a you know like a cycling motion to go ahead so it's all rotations and let's say I I have a character who maybe I want the character holding two bags then this would be the image I feed into control net because we learned very quickly with control net that you can either take an existing image that you know that's already there on the internet of somebody holding bags but you can't cover all the range of poses maybe you want a very specific pose so something like this is absolutely great for it so you'll be feeding this into reference net the new paper that has come out and you know you can key frame every frame and you could be like okay first frame I want the hands up second frame I want the hands down just dump in a original picture maybe even a picture of yourself and you have yourself dancing to any Tik Tok reel or any Tik Tok song or any Instagram real song that you want it the the applications are insane a you will see a lot more anime characters dancing to different music on your Instagram feed and B this is not limited to just animated characters you can take a picture of yourself like a high resolution picture of yourself head to toe dump this in use open posst key frame all the frames and then finally you can now produce like you know irritating reels without you having to be there in the frame yourself you don't have to wait for perfect lighting you don't have to wait for perfect weather etc etc you can just be like fine this is the character these are the frames that's the the world we're entering this is crazy this is going to take like deep faking right now deep faking is limited to like faces okay I have a base video let me put someone else's face in it but this you can take someone else's faces in it and make them do anything you want with them I'll tell you one more cooler use case of this okay see doing text to video is hard right even the text to video models right now they're getting better but it's nowhere close to you can't make a full motion picture with it but with something like this let's say you have a picture or let's say I'm standing on top of a mountain right and generative fi to remove the mountain from behind me and put me in an even better place that's you're putting me in like a I know like a palace or something behind this right now generative fill will make sure the lighting matches of that plus me right if you do it smartly now you can make me start moving right because if you look at this the background is not moving in this particular one right it's only the character that's moving the background is seemingly consistent so you can have a very consistent background so I can be anywhere I want you have like virtual sets right in a way and you know for all the effort and time we put find tuning models for audio or using hen for the video now you have the hands and body that can move around right so if I'm in the video if I'm saying two times somebody's done this two times or somebody's done this three times you no longer need to look for so i' in my fine tuning video we fine tune very differently from other people we don't just stop towards the end of the fine tune we'll do one we'll do two we'll do three we'll do four like we'll show our fingers right we'll hold it up we'll be like yes no whatever we do a bunch of things it it'll be there in the source footage so we clip it out we like this is useful right but with this if I if there's some pose I need to do then somebody else can sort of uh you know do it for me like my editor can do it for me a Creator a content creator in the next 10 years it will be you in some cases but can also be a skin that your video editor puts on when you are not available which gives you double triple quadruple output right you can output so much more as long as you trust those people and it was limited to face and and lips till now but now it's you know you have your entire body to work with so you can be in like I don't know wherever you want to like there are sometimes like Brands will reach out and be like hey can you travel to this city this country for like two hours and Vlog our place or whatever I almost always say no to that but with this you can now do that right just be like send me a picture of the place and we can we're happy to do that for you because at the end of day all they care about is the the actual piece of footage right you can do that with this so this is pretty cool but I'll show you something else that I saw in the middle of all this okay which did you know this this AI lady is making $111,000 a month oh yeah I saw this generated she basically sells pictures on only fans or something they became sick of models and influences that they created their own with AI now you can like you I can just input her face and say generate this girl doing other things also right like that teist here no what other things whatever this girl is riding a skateboard is this possible on Mid Journey now if I if I give put like five it's possible yeah what is it called IP adapter so you don't even need to train a custom model of with IP adapter you just need to put three four pictures of the person and it'll capture the face and there IP adapters have models specifically for faces it's called IP adapter face is this on Mid Journey where is this IP ad stable diffusion it's on stable diffusion so these guys are probably using stable diffusion right to get the to get the same girl to do yeah probably but you can see in many of our pictures it's not the same go whoever's done this has not done this very well like you can tell that this face is very different from this face is very different from this face it's three different people very subtle but you can tell right it's kind of there but also not kind of there but yeah I I I don't think this is like as a content creator I don't think it's a very sustainable thing to do because the minute people know your AI they lose interest this is I think this is more like a fad it's like a quick thing I don't this is more to con the media like you go tell the media I've made an AI influencer are making money they they lose their minds but it's not a very sustainable thing you might have made $111,000 one particular month and then you're going to hit zero in like a few months there's one really cool thing that I saw okay I want to show you so everything in this subr is pretty cool but so we now have text to video dream booth for motion okay so if I have let's say uh and this a new text to video diffusion model so if I have a person lifting weights okay that's a concept I can feed in the concept of this person is lifting weights and then you know I can type in the prompt saying a bear is lifting weights or a dog is lifting weights it's not 100% accurate but it's kind of there right this is really good if you have like let's say a shot of a city and you're like I want to show the city in a postapocalyptic world so as you can see this is like a flying shot of a villa in a garden and now you can just be like okay I want that to be a pyramid in a forest and you're not even masking that piece out you're just saying a pyramid in a forest because as you can see the trees here are different from these trees so this is like it is it's pretty cool it's like matching the cam it's just getting the concept right yeah this is basically it's like control net Plus+ plus uh it's actually not control net it's more Concepts because as you can see it's a car is running on a road is a weird concept right because cars don't run maybe I'm using control net long but it's like once you get had a vague idea of perspective of what you're looking at from where you're looking at where in space are you looking at it from this is exactly what I meant right you feed the AI enough references correct and you can sort of get to the exact output you want like it's your vision combined with okay I've seen a similar scene here I've done this it's almost like it's like creativity like I don't believe you can ever come up with an original thought right all your thoughts are mixtures remixes of other people's thoughts or things you've seen or things you've consumed you've been exposed to that's so you can't think of a new color right a because it's not possible for humans and B it's also like you are remix all all colors outside of primary colors of sort of remixes it's creativity is like that but the cool thing about this is you can say well here are my three Inspirations I want it to sort of be like this give some output that is your own generation but uses this in amalgamation and I think we will do this in music because you like a song you're like I want five more songs like this speaking of music so Google came up with uh two new music tools uh one is the music tools that's going to be natively integrated into shots and the second one is like a music Production Tool the second one is kind of similar to what we did in our last episode when I was here which is basically you can just hum and that will convert it into an instrument so tme basically did like a small kind of a beat and it basically converted that into drums so it's something similar to that but the first one is something where they've collaborated with artists like charie pu Tain all these artists that we listen to and they've cloned their voice so it's kind of similar to RVC they've cloned their voice and they have their own music generator so they combine both these artist voices and the music generator together in order to create something completely new so let's say that if I want a song that makes me feel like I'm in the middle of Paris or I'm uh sitting on a Mountaintop looking at the view and I want that to be sung by Charlie pu or CA or someone else it basically generates that song for me which is completely original which has never been done before yeah like how how did Charlie pu agree to this why did he agree to this uh I know Grimes this artist who used to date Elon mus has a child with him and whatever I remember her thesis was eventually this is just going to take over everything so might as well you know I I license my voice and if you make some money then you know we we'll split we'll go split season some way but surprising that even large artists are like this is inevitable let me just do this by the way I know YouTube is damn serious about this because I saw dream track available inside YouTube or there was some notification about dream track and monetization uh let me tell you what it is actually uh dream track in shorts is an experimental song creation tool that allows creators to create unique 30- second soundtrack with the voices of participating artists it brings together the expertise of Google Deep Mind and YouTube most Innovative researchers with the expertise of our music industry Partners dude this is super cool because you can monetize this and the artist will get some money of monetizing this yeah but I but what are you really selling it's it's essentially your voice right it's not a particular song it's not a particular idea it's kind of like your voice identity like your voice Watermark or the way your voice is in your identity I would say because it's also it's not just picking up your voice from the song it's picking up your intonation it's Pi up how you do song yeah the way you sing right so in a way it's picking up your identity a piece of your identity and it's so freaking cool that we can sell pieces of ourselves now and do it at scale cool and all I don't know but it's interesting is can we use the product is is is there something to look at okay this is really cool baby we've got nothing in common but I know that I'm what you been wanting for so  long that's pretty good output actually yeah but like let's look at the other one this one's less good yeah I woke up woke up I woke up up in a sunsh that's okay the second one wasn't as good as the first one but now basically I can make fake videos and make fake audio but actually for YouTube this is interesting because this is actually a real use case like there are times where I'm editing a vlog and I'm just I'm just so relaxed on okay what is some copyright fee RIS music that I can take but I would love it if I can if I can put in saying generate a one minute track with with this feeling this is what I'm doing in the Vlog this is the wi that I want and if it can generate like a chalipo uh yeah but I I don't think people see how this devalues to a certain extent creators I'll tell you why uh we have our intro track of overpowered is by nuclear and such a cool thing for me right I mean I know you you knew nuclear but for me it was like oh nuclear is doing like whatever it's it's probably a PC done in the past and not used but still very very cool for me now if I walk down the street and somebody says yeah even I have nuclear in my first 30 seconds of my intro of my podcast it feels a little bit like you know less cool that that we got but probably cool for nuclear who personal brand and his style he can now monetize at scale but yeah this is this is great for people who find such a strong brand and style that they can now probably monetize it but I'm sure if I was the artist and I was watching people use my what AI thinks is my style I'd be a little like this not me that's not me it doesn't doesn't feel like me like I in a few years I think it'll be it'll be there yeah but but look at look at the progress we made in a year a year ago I we did this one reel on overow about some music thing I was garbage but we were like hey this is nice yeah that's cuz we say this is nice for everything no we said it's nice but it is like a little bit unenthusiastic but now you have charliie pu inside of a song inside of YouTube and Just kudos to the culture of YouTube because I know Universal Music would have taken the opposite approach like blanket ban no not allowed artist premium no no AI should be able to replicate them but YouTube is like this is going this is inevitable you can choose whether we have control over it and whether we make money of it or YouTube YouTube's also just testing the ground right at the end of the day artists will want to safeguard their but do you thinkg would have tested the ground I don't think SOG is not a tech company bro they wouldn't they wouldn't have like they they work on a commission model you know someone made an app uh and they were they sent it to me saying T this is like a this is like a I made a chat bot outar of you where people could chat with with me and I used it and within 20 seconds with the first he replies I was like I wouldn't say this I wouldn't say this so so if artists really want to be able to upscale themselves using AI like they would have to be okay with how people use them like this is not just just cuz the tech exist people will agree to do it that's probably not going to it's not going to be as straightforward as that I'm pretty sure like a bunch of artists will Rebel they'll be like I'm not okay with this especially those who have already made their money right like people whove made  you money they won't they won't care about this stuff unlike musicians like if vano were around right like van Go's painting style or you know artists who from yester year who don't exist anymore those will more likely be able to easily adopt right like I was talking to someone who was thinking about using Rd burman's style of singing and trying to speak to his family saying that hey I would like to recreate you know his his voice in like in like a song and I as an artist would like to do a collab with Rd Burman that sort of stuff would probably be more seamless I don't know actually if I was Beyonce and if anyone could make a track using my voice thinking Supply demand economics because I think scarcity always increase the price of something if it's also wanted if you could take Beyonce's voice and create any song using Beyonce's voice does that devalue Beyonce for you it might be really cool the first five times no I'll tell you why because I've done a song with Snoop Dog right remember we did that influencer song we had a pretty good Snoop Dog model right so song was good but what we kind of realized is s then put out some post of a month or two ago about I a Qui smoke I don't know if you saw that smoke and and everyone's losing their mind like how can snoop talk do that and then 3 days later he came on and like here's the smokeless Stu and yeah it was a brand deal yeah it was a brand deal right that's that first post still got like tens of millions of view probably like 70 80 million views I don't know what the exact number is it was huge so has Snoop Dog lost any brand in your eyes in your eyes if you could use Snoop Dog also no but also I wouldn't hire Snoop Dog to do music anymore not like I ever would but maybe Indian artists at some point we would hire uh them to do it now it's debatable I'm not like 100% sure I would do it cuz if it's that easy and like this nuclear example right like I feel cool and almost like you know I got lucky that nuclear is doing music for a thing that we are doing I'll find it uncool that 10 other people have access to it yeah that's what I'm saying I don't I don't know if artists would want to be scaled I don't know if they would be open they would be open to doing it so I'm actually surprised chip put actually was okay okay with this it's like super surprising yeah but I but I also kudos to those artists right maybe they're just saying that testing it out also the artists is at so much more scale that I'm sure they wake up every day they open Spotify and they're like 50 the volume is just too much they like because the models are not like owned by Google right like you can also make your own charie voice fine tune voice model based on any open source repository and it's now getting one click so a charie a smart artist would be like this is inevitable either people are going to Pirate this and I'm going to go on YouTube and Sue everyone which takes 10 years in India and for pittance of an outcome by the way in China uh they upheld uh so somebody had sued the other person for using AI or whatever based on their art and the court in China said no this is original so it depends no you can you can prevent somebody in America from doing it but somebody in India is going to use a Charlie put song I mean charie mod make his own song but it's different Veron it's different when when chip put official officially licenses out his voice and says anyone can use it now and or just a bunch of people using RBC or whatever and and cloning his voice it's different when he officially does it but maybe what Charlie's thinking in his head is yo this is inevitable they're going to be like a million clones of me and I'd rather make money off it I don't know I don't know how I would feel as an artist it's Up For Debate someone or the other will do it and we will see what the end would you be okay with it that some somebody takes tme and does stand up comedy with the T skin on absolutely not absolutely not I wasn't okay with the chatbot also cuz like at least in in comedy's case it's like what the  will AI spit out if it's not funny if it's outrageous offensive I would be like yo I have nothing to do with this but I I I think it would be similar in a musician's case also imagine this this model that Google has and people are making these like garbage shots with charie put's voice on it you know like do you think he's going to enjoy that he's going to be like yuck why am I associated with something that I don't have 100% control over I don't I I don't know if artists are going to like that so I don't know if uh if if it's going to be that ubiquitous that soon T texture video is getting better I think the main use case will be stock footage cinematic footage here's a trailer of P labs and their new model and their new outputs I think it's pretty   cool yeah so the product isn't out yet but I'll actually reserve my judgment until I actually use the product there's a like yeah text to video a lot of the demos that come out on Twitter are all often stunning and like it's really cool they show you the absolutely best outputs and you know uh but whatever I have used of text to video has been kind of garbage so far um but P this one this particular one actually seems like it's okay it feels like there's a wow factor to it which is wow text video has gotten so good uh but I'll actually trust it more when I see it it's just impossible to give to have a perfect vision in your head and make that play out on video with a text to video at least in the near future I'll tell you why it's like you want an elephant in the scene you want a particular scene and you want the elephant to walk 50 steps to the left and then take two steps to the right in the real world what you do is you'd have to train an elephant to do all that then shoot a particular shot you probably have to shoot it three four times the director is not going to be happy with one step on the left foot so it'll be like I want to redo it or you use CGI where you have perfect control that's why we started using CGI for lots of animals right because just training them became a nightmare and like we have to go now we have to take like 100 shots so I think that perfect fality is very tough it's also very tough with images but with images if you're just doing a one-off image and you you don't care about you know consistency over half an hour one hour you're fine generating 100 things and saying this image looks good let's use this but with video I don't think it's the case but also you know if you're if you're doing just like the moon or you know like a view of the Earth or like some stock footage of trees then this is great yes right now it feels like a lot of different folks are trying to solve different different problems in the text to video space but yeah the winnner is going to be the Photoshop but for video where the ability to taking an existing uh piece of video making changes in that have a video version of generative fill and or be able to create something from scratch like all of that in one goal like I know there it's all going to be in Premier Pro like it's just such an obvious and adobe's done EX exactly that with Photoshop right so it doesn't matter that this exists Adobe is going to be like let's put this in Premier Pro because you want to change format you want to like there's a very cool feature in this where you can just take you know some piece of clothing and you can replace it with something else this is so useful and yeah it's generative fil but for video yeah and I think it also allows you to create a lot of synthetic training data yeah right so let's say for dream Booth if you want to clone somebody's face in the training images you're supposed to give many different types of many scenes many different types of lighting many different types of clothing because we have the same kind of clothing in all the photos when you generate that face for a person it'll also generate the same type of clothing it overfits the model overfits but with this you can generate so many different types of Vons right in different different lighting uh in different different clothing that you can actually train a specific model on me that's one uh you know use case the other use case is you've made a synthetic Avatar using haen and it looks the same the background looks the same well now you can keep swapping it like fine let's change the shirt let's change the background let's change the hair a little bit let's ruffle the hair up a little more I think this is an art and the tech just makes that art you know even better even cooler but your limit is the ideas like we've discussed a million times this pretty cool I can't wait to use the product so stxl turbo is a brand new model let me just show you the trailer when you type it immediately starts generating it's like instant generation basically whoa dude what the  is this this is a new stable diffusion model stable diffusion XL model called stxl turbo so just tell me quickly just tell me three things quickly anything come on just tell me what to type okay a tiger in a Bugatti a tiger in a Bugatti you saw that speed that's crazy okay now now right tell huh a man eating french fries walking on the road while talking on the phone in Mumbai India that is insane insane that's pretty cool movide Mumbai India it's like all the fancy buildings that's so sad dude this is really cool this allows nearly real time reskinning of everything and I'm just so excited this is pretty crazy actually cuz already with like my dopamine threshold is so low that I'm already getting irritated with the mid Journey every time I put something in mid Journey I'm like why does it take this long to generate an image but this real time thing is like it's I'll best use case of real time image generation the best use case is if you use this along with control net inside a game you can reskin the game let's say you're playing Age of Empires and you don't like the fact that it was made whatever two years ago you want everything to look different you can just prompt just before you start the game you just be like today I want my game to look like I don't know all futuristic characters and you have that can you imagine how cool that is you have GTA and you're like okay I want everything to look like this or I want my main character to look like this I remember uh in a game called DOTA my brother who was very young and poor at the time like four five years ago uh because he had no pocket money he wanted to buy DOTA skins right so he wanted to buy like like a golden skin for a caon he couldn't afford it uh he was still in school so he found some hack or some you know low client side thing where you can download it and it'll give you that skin only you can see it nobody else can see it but it gives you gives that skin and there are now tools like reshade okay check this out reshade.me where you can install this on your computer and any game you play let's say you're playing Age of Empires you have a much cooler version of you know Age of Empires that's running it looks very good let me show you an example of this the most res shaded game is Spider-Man I want to show you what it looks like so so this is an accurate reshade okay but the game looks different you can see that it looks different okay I'll show you some more reshades this is a realism reshade feels very cinematic so just like this now it's no longer about making it a little more cinematic or adding a little bit chromatic aberation now you're like yo I want Spider-Man to be I don't know Superman and you have that and you have a consistent experience all your buildings look a certain way so I'm really excited about this and I think if once you have the glasses right and you have a camera like The Meta Rayband glasses and let's say actually it wouldn't work with the Rayband glasses maybe the Oculus right you put on the Oculus you have a camera and the Oculus is seeing the world and like I hate the world I'm living in right now I want the entire world to be I don't know Christmas I want my entire room to look like Christmas you can do that you no longer have to put up with boring you can be in a small tiny room and be like I magically want the entire room to be clean even if it's really dirty and you just ignore the fact that it's dirty so what did sdxl turbo what did they do to make it like real real time image generation yeah so it's mostly the reduction in steps okay so let me show you what steps are okay so this is Step count okay so at two steps as you can see it's so what diffusion models do is first they take an image then they put noise on the image they apply a lot of noise on the image okay and then they Den noise the image over time over each step so in two steps you can see the image is still noisy correct in step four it's still a little bit noisy you can see some of the noise but by the time it gets to step 20 it starting to look like it makes sense corre now so my understanding from what sdxl really did is they took this 20 step output and put in one step output so sdxl turbo uses a novel distillation technique called adversarial diffusal distillation so it in a single step it generates what would have usually taken 20 or 30 steps that's the that's the new technique it's called add this is also like precent named yeah so it uses score distillation where the model learns from existing image synthesis models it's like it's seen what the inputs are it's seen what the outputs are at 30 steps and it learns from that that's crazy this is probably the first time where stable diffusion has like an obvious big Delta over mid Journey mid journey is going to have it almost within the next few weeks I can bet on that ah yeah yeah they have to cuz the I'm assuming the user experience on this is like 5x better than the current way which is to wait each time you're generating dude I just love the fact that you can look around the world at some point in the future and just rking it you any game anything we see right like just be like okay I want it to look I want everything around me to look futuristic that is so cool all right friends that's a lot of AI for this week thank you for tuning in go check us out on Instagram if you're on YouTube and check out Sid and the 100x engineers uh and if you guys are interested in AI you guys should definitely go check out the new cohort that's launching Sid you want to quickly tell us something about that so this is a new cohort it's the generative AI cohort and we basically teach Co generative AI the first two months of the cohort it's a 5- Monon cohort and the first two months is essentially just playing around with stable diffusion it's two months of stable diffusion and we go all the way from uh just prompting simple stuff to actually fiddling around with it basically fine-tuning different models making your own UI uh there's something called automatic in 1111 which is uh a graphical user interface that you actually get on stable diffusion we teach you how to F tune models with that we teach you how to F tune models without that directly using python so it's kind of like starting from the top starting from the simplest things and going all the way down removing things layer by layer and going into the complexities of it so you're teaching them how to make models and put those models in their apps correct correct you you can essentially make your own fine-tuned text models your own fine-tuned video models your own fine tuned image models and fine tuned anything I'm glad somebody's teaching that in India that's I think that's the next Frontier right you want specific types of images you want specific types of text you want it to write like somebody you wanted to look like somebody uh F tuning we'll get you there all right awesome uh thank you Sid thank you Von see you guys next time follow us on Instagram and GG's over and  out",
    "url": "https://www.youtube.com/watch?v=PPJ0OQITOGo"
  },
  "PjhBaHmvd6Q": {
    "published_at": "2023-06-01T12:30:04Z",
    "title": "ChatGPT Plugins are going to be a next Big Revolution!",
    "text": "ChatGPT Plugins are going to be a next Big Revolution! I'm also most really excited about zapier because it allows you to run API calls without you doing anything for example now if I want to send out an email usually you draft an email on GPS then you copy paste at least we have the drop of control C control V into your email provider now with zapier is just like a direct connect and just be like you zapier standards app send this email through my email right so you can automate tasks so zapier has like a bunch of tools incoming apis outgoing apis right so you can pull from some other app to put into chat GPT you can take from chat GPD person to another app so this is the next major it sounds like like the next major jump yeah because now millions of devs will get access to the plugin and everyone will try to find the next you know 20 idea that they can make that can that can be automated",
    "url": "https://www.youtube.com/watch?v=PjhBaHmvd6Q"
  },
  "LxV4RgaQt6Q": {
    "published_at": "2023-12-29T12:46:39Z",
    "title": "Create unique birthday songs with Cadbury Celebrations with My Birthday Song generator!",
    "text": "Create unique birthday songs with Cadbury Celebrations with My Birthday Song generator! so Cadbury celebration has come up with something really interesting for birthday it's an AI powered Birthday song generator as part of their my birthday song campaign I think yeah powered song generator is just getting better and it's interesting that Cadbury's made it so let's actually go use this so the whose birthday is it t your relationship with them he's my grandson he's my grandson okay choose a genre uh Let's do bangra let's do bangra all right let's see I'm excited to see what the output is hey it's your special day I'm just crating major way happy birthday Let The Rhythm play as we gro all right I wonder which uh grandfather is making this banga song I think it's fair also like 8 billion people in the world everybody has this one Birthday song what if you could create your own unique version for people yeah but that's nice so if you guys want to transform the way your friends celebrate their birthdays and you want to create a personalized song for them definitely go check out Cadbury celebration you can also uh generate it in Hindi eventually is what I've heard so check it out",
    "url": "https://www.youtube.com/watch?v=LxV4RgaQt6Q"
  },
  "Ve_pJ4QpZDQ": {
    "published_at": "2023-07-07T14:32:11Z",
    "title": "AI powered shorts, this tool is insane!",
    "text": "AI powered shorts, this tool is insane! you know for a long time I was wondering is there a tool that can automate creating shots out of longer videos The Challenge here was understanding context of the longer video understanding which parts would be more interesting and then finally chopping it up and adding subtitles to the video there's a cool new tool dumb studio so how it works is fairly straightforward you dump a link into it then it spend some time analyzing the video which means it's understanding the context of the video and then it chooses a bunch of sections that can be turned into shorts and then it just produces like a dozen videos for you the reason we have such a high top of the funnel is because of very cheap bandwidth and very cheap data plan it's very Hit or Miss like some of the short generates are bad but because it's generating so many shots yeah what it does not do add newer Clips to it add stock images to make the clip more engaging that stuff still you need an Editor to be able to make it more like a dopamine bomb this is like a one tool in an editor's arsenal",
    "url": "https://www.youtube.com/watch?v=Ve_pJ4QpZDQ"
  },
  "I_QYPhd_WFs": {
    "published_at": "2023-08-31T13:30:07Z",
    "title": "How I Can Speak 50+ Languages Using AI",
    "text": "How I Can Speak 50+ Languages Using AI another week another episode of overpowered and our concerns are getting Graver and Graver this week our main concern is that varun's Mom thinks he looks homeless in the overpowered episode Varun can you please explain so I don't know okay I think it's the camera setup or something okay or maybe it's the fact that I don't shave over power or whatever so you remember that Shahrukh Khan video right like the red viral or the other video that whatever videos keep going viral so my mom's like of all the things you've done this is probably going to be in a lot of people's feeds and why only in this do you look like a homeless person so I was asked to cut my hair I was asked to shave because she's like you're actually a you're not a very handsome boy because once she told me that Tom Cruise looks better than me because I asked her like as we were watching Tom Cruise on TV she's like I was like Mom am I better look in the top but she's like no so in in her Spectrum like I'm reasonably good looking but she's like you're doing yourself an injustice by looking homeless homeless but it's fine we have an all-new World Maya a sexier newer version of Varun Maya only for you guys thank you for tuning in if you haven't hit subscribe yet we are gunning for half a million followers on our YouTube channel just so we can have all the overpower channels be more than the world in my channel I shave for you guys subscribe  first on today's episode toot Sagar sent me this this is so cool can you tell us can you tell everybody who's watching what this is all about cool so this is called uh 11 Labs multilingual V2 Plus we see voice dubbing so it's it's complicated but let's first play it okay I think it's it's always better when we play it yeah foreign maybe that's just me wanting to not be in a world where it's this easy to to replace you know content creation but it is getting better but do you now feel like AI development more as an S curve and not just a just a hockey stick I think uh it's like this right like Paul Graham had once put out this tweet he's like with traditional software you have iterative Improvement like you'll build like version one of the software actually let's say 25 done version two will be 50 done so you can see it get more expansive over time I thought the voice quality after changing a language was very accurate that's what I sound like my tone is correct the way you said esker was like perfect yeah the tone was very accurate uh so this is a new Tool uh on on RBC multilingual tool what is this so this is a little bit complicated it's actually a chain of tools right we we realized and this is by the way uh we did some internal experimentation on this this we couldn't find this information out there on the internet we actually just wanted to try clubbing these two things together right so I said okay 11 laps comes out with great output and 11 Labs came out with something called tone and expression right so it sort of sounds like you the Expressions also there but it's not perfect right so we said what if we took the output from 11 laps and then dumped that output into RVC which we've shown knew in the last few episodes with Shahrukh and all the others right where we made our own custom model on RVC of Thunderman and then we said okay what if we put these two together have The Voice output from 11 Labs hit the input from RVC on that model what is the output gonna sound like and it turns out it is pretty accurate it's pretty good yeah I was surprised my Hindi was so good like I can't speak Hindi that fluently right and when I heard it I'm like dude I actually had a great idea I'm like I can learn from this this these are the mistakes I'm making like a lot of people in English say certain words wrong they say certain like their intonation is is wrong in certain cases right and in my case like a lot of the words I say in Hindi are like I don't accurately say it right uh so this is a a great learning tool where I'm like oh this is how I'm supposed to sound a couple of problems with this though a the language translation is not colloquial this is not what I would actually say it if I was thinking in Hindi and I was saying it in Hindi yeah because the translation yeah so the translation can be more colloquial if if you queue chat GPT to translate it in a more colloquial way it would be far more accurate or far more realistic uh second Super useful for uh anybody who makes content to now instantly to click translate yourselves into different languages and third this doesn't have wave to lip matching uh like Lip lip to audio matching that's not there but that also we tried it and uh it's not as accurate I just want to play it so people know where the state of the tech is okay so I'm gonna play The Wave to lip version where we've edited the lips also to match it it's not perfect because in some cases it doesn't look like you uh but like I said in the previous videos six months yeah it's not very good the lip matching is not very good yet the lips are constantly shaking like yeah frame by frame consistency problem but I I think that at some point it's this is going to get better right and I think that's the final frontier at that point firstly I think we're already at a stage where if a Marvel movie comes out tomorrow you already have Indian dubbers right I think dubbed um Spiderman Spiderman and stuff right now you can hear the original Miles Morales actor or Tom Holland or whoever is playing the role right you can hear them speak Hindi and Telugu in kannada and all the others that I think is is pretty cool it's like you've never heard Tom Holland in Hindi in fact there was a clip of jorogen in Hindi that I remember let's play that um this is already fascinating because now you have you know Lex Friedman Joe Rogan uh the world's most you know Andrew huberman uh content that previously wasn't accessible in Hindi now you can get it with the original voice which makes it as authentic or as close to uh what was intended uh the only thing that needs to be fixed is translation can be more colloquial and next that's a strategypt problem yeah and next Frontier is uh lip matching which already to some degree like I would like to show a clip of neural garage here foreign clicks and you'll be able to translate between languages with the original voice and the lip matching which I think is fascinating great news for Content creators actually if you already have distribution you can widen it much easier like I know that Mr B spends a lot of time and effort in translating his content into like 20 different languages around the world a lot of which really Nets him a lot of views um this will just solve solve for it a lot quicker true true I I'm what do you think happens to dubbing artists like what should I feel if I was a dubbing artist and you've been in the artist space for a very long time like how how should they feel about this I mean now I know a couple of cases where dubbing artists have uh license their voice for you know chat Bots or um that sort of thing and I know that these kind of deals will start happening which is licensing year on year royalties that sort of stuff will probably get more stringent now um especially for people who are known for their voice um I think yeah that'll that will be commonplace I actually want to ask this is right now couple of clicks and something processes at the back end and then you get an output I would be more fascinated if you this can start happening live because imagine broadcasting live you can do it RVC can be done live uh I don't know if voice.or uses RBC but you can check out voice.ai it is it's like a voice or like a real-time audio mod for and a lot of people have trained their own models the model of Morgan Freeman Shahrukh lots of people there yeah you can do it live let me see if I can do it one second do we have voice.ai I'm just going to try this live okay let's I don't know if this is gonna work so I'm gonna change to Elon okay let's see if we can do this okay can you hear me can you hear me I can do I sound like do I sound like you don't mask a little bit like it's something has changed okay now do I sound like Elon Musk now do I sound like Elon Musk change from Elon to someone else all right okay let's do Morgan Freeman and see can you hear me now and uh try and speak a little like can you hear me now my name is Morgan Freeman and the world my name is Morgan Freeman and the world it's a pretty old that's real time by the way as it sounds like it sounds like uh just a fancy sound board I've used these sound boards before that tweak your voice a little bit uh it this is seems like just a slightly fancier version often 11 uh sorry voice study I does it reasonably well when it's like offline uh voice yeah but real time is not solved for yet real time is definitely not solved for so the point is being if you can do this live that changes so many things sports broadcasting is changed News broadcasting has changed forever um political broadcasting is changed like if if I was a prime minister of the country I would reach out multilingually live that's changed radio is forever changed translators are changed you know when two presidents meet or correct Prime Ministers meet there's always like a translator translator that's that's changed um the world is all travel all travel is changed all travel has changed that's true Google had these like earbuds I don't know if it's still active whatever which did real-time translation you can talk to somebody else in front of you with the earbuds on correct and whatever audio it picks up it translates into your language of choice the world will become flatter more seamlessly connected more easier to understand uh one another so my journey just introduced in painting now in paintings been around on stable diffusion since forever but yeah my journey is like apple they do everything late yeah but they do it really well yeah yeah so let's just play with my Journeys in painting you want to swap out clothes you want to swap out sunglasses you want to swap out the background you can do all that fun stuff right yeah so let's show you that I was waiting for this since uh Photoshop launched generative fill I was like okay mid Journeys version will be as cool if not better because the data set is a lot more illegal than photoshops imagine uh Undertaker in a wrestling ring holding a broom in his hand holding a broom in his hand in a stadium okay we got pictures of Undertaker in yeah let's upscale one of them I like the third one sure the third one okay and now we'll in paint very visual can we try changing the background yeah we can try ah there you go there you go that's better yeah now change the background to like a field oh you can do it ah you can do multiple clicks so that makes it easier all right wow that was painful but it'll be somehow got it done yeah you don't need to write Undertaker and all just if you just write field what happens first let's take a look at this beautiful law check this out pretty good pretty good I like this also interesting the generative filth feels better than Photoshop why why is that quality because mid Journey just has better training data so when we're building Alpha CTR which is a model very similar to how my Journey works uh we were trying to reverse engineer if they're doing some pre-prompting because stable diffusion by default if you prompt it with nothing but just like a bunch of words like let's say three four keywords it's not going to give you such a great output but mid Journey even if you put in a single word the output is amazing so either it's training data or it is some sort of pre-prompting going on or the rlhf you do here which is reinforcement learning by human feedback which is when I press upscale on a certain image my journey is learning from that image saying that all most of these people like wherever something gets upwarded or upscaled you know it's a signal to say okay this is the kind of images that humans prefer right so over many generations I think they now know what humans prefer like there's no upward or downvote on Discord here right but you are paying with sort of which image do you finally decide to go with you're going to upscale that image so it functions like an upward slash download so that really helps with our like a weird version of rlhf uh which allows my journey to build out a better solution on Photoshop generative fill you are not saying that okay I like this output but on Mid Journey you are technically because you're upscaling it um okay generate something uh like chandrayaan on the moon it won't know what chandrayaan is actually let's try on on the moon what if you do Indian space rover chandrayaan on the moon first let's find out if it knows what chandrayaan is because I think there have been versions of chandrayaan before this one yes this is so correct I'm sure that was there in the training data somewhere yeah okay it generated a version of chandrayam uh not bad interesting so what do you actually think about chandrayaan I mean epic right like really cool I saw a meme somewhere that said that um Christopher Nolan's last film was like 3x more expensive than chandrayan space mission uh which I thought was pretty funny but yeah pretty pretty epic I think it's it's like a global statement about India's uh Tech prowess uh we're expecting more uh foreign investment in Indian Indians not only space Tech uh but it probably has the Ripple effects will go beyond space Tech during the Cold War era like both us and USSR at that point were both competing in this space race correct and a lot of people were like why are you waste like I saw a lot of comments saying why are you wasting money on chandrayaan and stuff like that you could have fed the poor and this that but it's not about that right like it's very indirect effect of correct you know doing this shows the world that you mean business correct it forces like you said Venture dollars into India to try many of these experiments which in turn creates jobs correct so it's not a direct oh you take the money and you know put uh food on the plate for people which you'll do it once or twice and then the money expires uh you're sort of improving the brand of Industry like it's almost like India is not I said this in one of my videos right it's not a border it's not the people because we're a very varied country India's a story right and like every story like every company also has a story right like you build the brand of that story okay I'm in India now has this amazing brand in the global you know ecosystem because of things like this correct right uh in fact there's another brand that that use space really well uh Red Bull Red Bull Red Bull use yeah Red Bull used it um the space jump by Felix Baumgartner I remember that that was pretty epic so let's generate an image of the space jump actually yeah that's a Felix Baumgartner jumping in space jumping with the Red Bull oh yeah more cool image it recognized first of all yeah open it it's got the logo dude oh dude look at the look at the logo on his uh helmet upscale upscale four upscale four actually even even two yeah it's got the logo yeah perfectly yeah that's pretty cool let's check out dude that's a sick image dude the logo is perfect yeah the bull is exact like I'm just yeah I'm taking a look at this yeah the bull is like exactly the same one yeah wow I don't know if this is what Felix Baumgartner looks like but we'll roll with it I mean such a big difference right like he's using it to jump off space I'm using it to beat the afternoon slump open now upscale one of the other images if this gets the logo right it's not just the logo it's also getting the text text right yeah oh dude it's got It's it literally says Red Bull on his chest that's crazy yeah wow that's exciting Kudos kudos but if you see the reflection on his face right hmm is it the reflection of what is this this doesn't look like whatever's below like this part maybe but what is this maybe the space station but this is the first time I'm seeing a mid Journey get text right no how did it get Red Bull so accurately it says Red Bull because the red bull logo is very like whenever somebody would label the Redwood logo it would be done very well it's like hey this this is Red Bull logo yeah so in the training training data Red Bull logo was like very very clear yeah so it's a big brand it's been around for a while and that's what India is also doing right in a way like we're building our brand we've been around for a while and now we're showing these leaps of Faith um that the rest of the world is sort of betting Beyond betting on interesting so talking about text and images uh mid-journey stable diffusion they've all struggled with text in images for a while yeah but there's something new called ideogram.ai I saw this this is so cool this is very cool dude this like there was a chunk of things that graphic designers could not do using mid-journey this solves for it immediately uh so on ideogram you can go you can you can queue uh any image much like mid-journey except you can queue text as well so let's do let's do um Harry Potter standing in front of Hogwarts holding a sign that says Muggles are best actually instead of Harry Potter instead of Harry Potter instead of Harry Potter make it Voldemort no it would be funny to see Voldemort say Muggles are best no it's I think it's I'd already generated Harry Potter that is exactly written dude so I don't know what they're running in the back end I don't know if it's their own model but I do know stable diffusion I don't know what the relationship they have with stable diffusion but I do know something called Deep Floyd existed uh let me just show you deep Floyd this deep Floyd it allows you to generate text inside of images we were planning to use this for Alpha CTR but then fine-tuning it was a challenge right so uh show Voldemort this dude this is too funny this is too funny see the first image the first image it got text very accurate but I don't like the world mode I think imagine this Tech combined with mid Journey's data set I think that's the ideal world I think one of the challenges with my journey not being able to do text was logo Generations were a bit of a problem right can we try this on ideogram can we generate a logo for a coffee brand called a key part of logo generation is the text so now if you can make text and logos then logo generation is solved let us write a logo a logo for a coffee brand there you go all right the logos are here and the first two are really good right like this is pretty good it got the text right look at this dude it's pretty good it's pretty good this is what I was saying right like with images you can do unlimited Generations we have a couple of generations that failed nobody cares like you just generate the next one you keep trying till you get something that's perfect oh this is very nice this is nice oh this is also very this is also very nice look this I would use yeah but now this Dash dude graphic designers have no excuse to send in logo Generations like late now now you can't say this is going to take time because now all you got to do is Click generate and you can generate like multitude of options you said this once right like this is a now become a game of whose taste is better it comes down to purity of taste if you have really pure taste and a wide knowledge base the world is literally at your fingertips I met a graphic designer the other day who was telling me that uh you know he was he's like I have 5x the amount of freelance work that I do now because I'm able to Output a lot but like this human to human connection right he was like it still feels like when I generate something really quickly and go back 50 of my clients still ask me to go and reiterate just because they believe because I did it quickly I haven't put in enough effort so now he's like I'm trying to solve it by giving a wider uh not only delaying but it's like I give a wider range like the menu has expanded dramatically of what I present uh to show amount of effort um still shows that there are there are a lot of stuff you know when you do mid Journey it like it it is blurry like the diffusion you see diffusion happening right so it's blurry and then it becomes this you should every week you should send like a slightly less one by one like this week I it looks like it's going to become something anyway there's this Arbitrage period where you know thousands and thousands of clients still don't know how easy it is to generate this anyway six months okay dude so let's talk about Google search AI okay yeah so Google launched something called search generative experience which now does some magic inside of search so let's see how it works there are four parts first one is you have generated AI in search so let's just search for something let's say I'm searching for Tan my butt if it works get an AI powered overview for the search absolutely generate it for me interesting this looks like a quick Wikipedia Bruce Wayne okay so let's look for Bruce Wayne and as you can see it generates something here and it's giving you text and it's giving you love interests okay that's not something people need to know up front but okay it's given you some information uh and then it's giving you top three links I'll tell you the biggest question in my mind on the mobile phone how much space does this take that's my number one question I'll tell you why okay and and let's probably do a quick test of this let's say it's this big this looks like it takes up most the space right yeah the problem with this is if it takes up most of the space then there are these two three links in the right I think SEO is going to become completely different as a field right because what happens generally when you look for Bruce Wayne is the first link will be from fandom right and Wiki and you know Rutgers and whatever news nation and whatnot they suddenly get devalued to these three which is Wikipedia DC database and Comics basics so it's like a new uh leaders of the roost and instead of you having like 10 20 potential links you can click on or maybe at least you know one let's count one two three four five six seven let's say seven results that you could click on plus you know a lot of these other clickables now you have three options most people are not going to spend too much time scrolling you have three options so SEO kind of gets limited you have to be among the top three if you're writing content yeah but broadly doesn't feel like this is uh that much better than just a general Google Search right like like GPT was a big leap from uh just from a generation point of view but from a search point of view Google search is still pretty good and I don't know if I would want uh an AI generated search because I I personally know that Ai hallucinates and it's like it's not perfect yet so I don't kind of trust it wow there's something called Converse and then there's something called Converse let's see what this is okay and I can ask follow-ups yeah so this interface the chat interface is interesting oh it's giving me very specific links so it's only replying with links this is interesting but I I don't find it that useful to be very honest I mean I was already conversing in the Google tab only no I was saying how to make omelette and like it was already doing this to me so this feels like okay yeah Google is really trying hard but this doesn't feel like a massive uh Delta over what already existed to me personally at least so far something for the stock market yeah yeah uh you can also do code tips so directly in search you can get code tips oh this is very useful right let's say Ruby on Rails generate Authentication I'm just seeing if it works generate an AI powered response nice this is what I expected so device is very popular gem for rails which allows you to add an authentication uh but it's not giving me the code for it let me try something simple um  wait md5 hash no it's not doing code it's not giving code tips okay nice side okay so if you do JavaScript check if key exists is generating some code for you uh and it also has a nice little message there saying use code with caution uh this is interesting but I don't think it will beat a co-pilot where you know an engineer is coding in place and just wants the answers quickly feels a little gimmicky it's not there yet I feel like what they're trying to do is essentially it's the same stuff right as in Bard or chat GPT but they're trying to put it where the user exists and that doesn't seem to be working so well they're experimenting with format not with the tech itself but I think the best format for this is chat correct right and chat UI yeah chat UI is just Superior I mean and the Google search button was chat for me anyway that's how I was using it anyway exactly so it doesn't seem that much of a leap all right exactly so the last one is something called cursor.sh the last cool finding for this week it's coding assistant it uses gpd432k and gives you a lot of productive increases productivity how is it better than copilot let's see new AI project build me 2048 game in unity let's see if you can actually do Unity to create a 2048 game in unity you need several files first you need a main scene great then you need a game manager great then you need a tile.cs which is great then you need grid you need input control so it's it's sort of like Auto GPT in a way or the small uh repo that we built autocode Pro on top of um but a nicer interface and has like a smoother inside like your uh ID which is interesting so it's got the game manager ready it's creating the file it's writing The Code by itself great I will do the hard job of and the ID itself is saying hey you want to install the c-sharp extension for C language for the c-sharp language this is nice as for how well it will work we'll have to deploy it but it does fail in certain places for example it's not able to create the main scene Unity file because it's not really a text file uh but interesting nevertheless online as for today's episode hope you guys enjoyed it make sure to hit the like and the Subscribe button I shave for you guys never forget on that note bye ",
    "url": "https://www.youtube.com/watch?v=I_QYPhd_WFs"
  },
  "ucq4WUwdLHw": {
    "published_at": "2023-08-28T13:56:51Z",
    "title": "Create Character Animations Using Runway + Midjourney",
    "text": "Create Character Animations Using Runway + Midjourney someone recreated you know the Mortal Kombat character choosing screen but with different celebrities this video is worth watching let's check it out    this is really really nicely done this is made using uh of course mid journey to get so mid Journey will generate these cool images and using Runway you can now turn images into like slight video right like you can get a little bit of camera moving a little bit of little bit of movement and of course they got 11 laps to do the voice over this is a super creative use I want someone who's watching in the audience to see if they can do this but for Indian celebrities that would be very cool to see",
    "url": "https://www.youtube.com/watch?v=ucq4WUwdLHw"
  },
  "Ey9xEBgG96E": {
    "published_at": "2023-06-02T13:30:08Z",
    "title": "Who Said You Need to Code? - Building Chrome Extensions\u00a0with\u00a0SmolAI",
    "text": "Who Said You Need to Code? - Building Chrome Extensions\u00a0with\u00a0SmolAI I think if if there was a way to find a repository of jokes I'd probably build like every hour show me a joke actually you can do that that's the easiest thing to do I just want to click on it and there's a new good joke every time I click on it to generate a joke and then show the setup and delivery part choke generator documentation is like sex when it's good it's very good when it's bad it's better than nothing all right next one next one I have a joke about trickle-down economics but 90 of you will never get it it's pretty good it's pretty good it's pretty good you were telling me about um something amazing that happened this week which is something called small AI you just want to dive into it tell us what small AI is dude so you know the number one thing I got belted for like two years ago it's saying that AI is going to replace artists or at least you know give artistive competition and I have this one reel where people just thrashed me in the comments right now I'm saying something very similar about software Engineers right and I think Nuance is very important like let me explain myself fully the number of software Engineers is going to sharply increase because everyone's going to be able to be a software engineer and today I'll show you why right but at the same time Junior software Engineers will probably not make anywhere close to what they are currently making a junior software engineer in India now can make anywhere between 50 000 rupees a month to like even two or three lakhs and this is junior level like freshers people with almost no experience right that is probably going to change I'll tell you one paradigm shift I had in the world of software there was this when when I first started coding I used to do a language called Delphi then at the age of 18 or 19 I tried a new framework okay and that framework was called Ruby on reels and what the framework make magical was it introduced something at least to me called scaffolding okay now I know we're going into a lot of tech terms but I'll explain each one of these right I'm going to be careful about that scaffolding means that a lot of code that you might have written to do simple stuff right maybe to put up a page maybe to create a simple user model where you know a person is able to put their username password and stuff like that rails was able to do out of the box and that was magical for me right but because before that you know you have to write every single line of code manually at least for me now scaffolding has taken a new turn where it's not just simple boil plate stuff like oh uh make a simple page where users are able to do to log in and do this or whatever so now scaffolding is a little bit different where I can tell AI with a prompt do this for me or build this for me and it gives you all the base code for it along with the working executable which we'll show you today and you can actually just use it in production you can literally use that code modify it as you wish it's the best time to be somebody who has uh you know common sense because now all these tools are available and as long as you're able to prompt them into submission you're able to build whatever you want you're able to build content you're able to create websites you're able to you know put out apps of your own so I feel like we're entering a new era and I'm excited to show you and share it with you all and this is this is what's small is so I'll tell you what small is and I'll tell you how I discovered it I saw a tweet so somebody said small Ai and you know there's so many tweets now about in the AI space that I just ignored it but I bookmarked it day before yesterday I went through my bookmarks I saw it I was like let's give this repository a spin and the repo requires a lot of waitlisted things like you need to be wait listed into uh the gpt4 API you need to have some access to something called model and I just sent emails to the CEO model and I said please let me in right so I got access immediately so I bet it hasn't gone viral yet because of that one access requiring step I just tried it and the minute I tried it I called you know my CTO and a bunch of other devs and I was like check this out this is like so cool and you know in fact the big thing that is that is stopping many of you including Youth and math from using this today is just the setup work right that requires a little bit of knowledge of how to write code but assume I put a UI on top of it and allowed anybody to use this you all would be making your apps Your Own Chrome extensions Etc you are my birth okay you have some ideas okay but you can't build apps because unfortunately you didn't learn how to code now what if I told you that you can this is not really prompt engineering it's engineering with prompts tell me what you want to create let's start with something simple let's start with a Chrome extension which is a personal task manager does that make sense sure simple Chrome extension task manager we are going to allow people to put up tasks and they'll check check mark Or you know cancel the tasks once they're done okay and we'll it'll have some amount of persistence which means that if you close the browser and come back hopefully the tasks are still there right we'll we'll engineer it for this okay so I'm going to open this scary looking thing this allows you to run a Linux terminal inside windows it's actually a little more complicated in there but in short it allows me to interact with all the Python scripts that small has in its a nice little repository okay I'm already in the small folder okay and now we are going to generate what you want tell us how do we get to this part so to get here you need to download something called WSL if you're on Windows just go to Google type WSL you'll find uh install Linux on windows with WSL just install this once you finish installing this there's like a process you go through uh you will immediately have uh this this thing and once you have this prompt you can just go to your windows and type WSL start menu slagging but anyway you type WSL you arrive here then what you do is you find the repository you want to interact with okay and before that you there are a couple of things you need to do right like you need to create a virtual environment because if you don't create a virtual environment in Python it can sometimes get really messy especially if you're working with multiple repositories so we use something called conda let me just show you what the process is let me just restart WSL from scratch okay so I'm going to start WSL um I'm just going to go to the place that I want to okay this is the repo now as you can see it says base here okay what we want is we wanted to activate the environment that we have so we're going to type conda activate small three small I've already created an environment called small three we're not going to go into what it's like to actually create an environment but you can Google it it's fairly simple right it's a python 3.9 environment for those of you that are technical but if you're not technical it doesn't matter because one day there's going to be a UI on top of small and it's probably going to be in the next few days we are only probably going to build it if nobody else does if if the idea is to get me to build an app it's just about it to be simple I want everything to be a chat interface everything exactly just look I just type it down and it just happens yeah but you see a lot of people who are making money in AI right now are building simple tools that are you know they're making 100K 200k a year and it's all just user interfaces or chat interfaces on top of many of these repositories that already exist it's really there is an opportunity in doing that right like people think it's all about engineering it's about presenting that engineering to your user in the right way so I've activated this environment called small you don't need to go into you know what uh how to activate environments and stuff uh or rather just type contact all three now and by the way for those of you that are here so far don't get confused this doesn't matter because there is going to be a UI on top of this okay now we are going to run a script we are going to say python okay that invokes python it allows us to run whatever python file we want and there's one called main underscore no underscore model dot Pi okay and we put in a prompt here okay manifest V3 Chrome extension and I'll tell you why I wrote manifest V3 instead of just Chrome extension because remember that it's using a lot of past data and chrome doesn't use V3 anymore sorry V2 anymore and most of the stuff that you make with this will end up being manifest version two you don't need to know what it is just know that you need manifest version three okay to make Chrome extensions in today's day and age okay so a manifest V3 Chrome extension that is a task manager it allows the user to write in tasks and with check marks next to them when a task is complete the user can the user can pick off tick off the task the task there's one more thing I want to ask you to to do is I want it to be a certain minimum size right make sure the pop-up is at least 600 x 400. right so let's start with this one second I just need to put in my open AI Key by the way I want to show you how I debug stuff okay I'll copy paste this I'll go to chat.openai.com okay I'll just paste the error in this is how I use this thing by the way uh GPT now okay and it will tell me what the issue is there's no uh open AI API key in the environment okay so I need to set the open AI key here okay or I need to do this because we're on a Linux environment technically because of WSL I'm going to copy this I'm going to paste it okay I'm just clearing it out I just inputted my API keys so that you guys don't see it now I'm just going to press the up key and it's going to show me what I last wrote I'm going to press enter and it has begun hi it's me the small developer you said you wanted a manifest V3 Chrome extension and it is started okay so it is the prompt for it is you are an AI developer who's trying to write a program blah blah blah blah it's not showing the entire thing but that's not because it's not working it's because it's been truncated there and as you can see it's already started saying what the structure of the thing needs to look like you need a manifest file you need a pop-up you need a JS for it you need the CSS for it you don't need to get into what these terms are it probably doesn't matter so much to you right now uh because it's just going to generate the thing out of thin air okay so let's go through what it's thinking about okay the app is a manifest V3 Chrome extension there is a task manager okay it allows the user to write task blah blah blah so what are the dependencies okay what are the variables it needs for example it knows the task list is a variable which is an array it's an it's a variable of type array you don't need to know what this is for now and it's figuring out everything right what are the ID names of the elements in that small little pop-up that it gives you all of it right it's also creating the function names to create a task to add a task to toggle task completion and to update the task list right when you finish toggling something all right so now it's creating the Manifest for you as you can see takes a little bit of time okay now it's written it's starting to write the code for the HTML of the pop-up right so what's going in the pop-up what are the different parts of the pop-up what's going to be in the body what are the buttons what are the you know the text at the top all of that stuff is being uh created for you okay so while this is writing the code on the side and finishing its tasks how is this better than Auto GPD Auto GP is something similar right like you also create a list of tasks and it does it yeah so the difference between this and auto GPD is a this is writing code for you it understands the dependencies between the different sides of what is writing like if it's putting in five different files it's tying those files up together it's making sure the dependencies are solved and it's making sure you have something you can actually use okay and this needs lesser human intervention than Auto GPT this needs lesser human intervention than Auto GPT is it can get sidetracked because there's recursion going on at every step there is now a slight chance it could go on some tangent now if it goes on a tangent in the second step and the third step will go on even more tangent so every step there's an exponential chance of it going going like one day earlier means it will be 15 degrees by the by the end of it exactly right but with this it sticks to the line of code it makes sure that uh its domain is hey I'm building an app you're writing code you are an AI developer that does blah blah blah blah blah and uh it the the implementation of this is very similar to Baby AGI uh in fact the person who wrote this uh also contributed to the BB AGI repo right so interesting Whatever by the way now it's creating the CSS for us as you can see this is uh so if HTML is the building block of a page um let's say all the boxes how those boxes look not a structure but how they look the prettiness uh whether they have a border you know the elements inside them how much distance they have from the left to the right all that is determined by CSS so it's generating the CSS for us in fact my only complaint with this is slightly slow otherwise it's like brilliant building something like this if you do it manually yeah um how long would this take you a task manager that does all these things and has a little bit of persistence would couple of days but one single human who would be able to do it yes where I think this starts getting useful is you can give it a laundry list of things you can do which a normal human would have spent a lot of time building up right so it can help where there isn't an insane amount of depth required but a lot of wit and a lot of we call this boilerplate right like stuff that you repeat in every project correct you'll have to create authentication all over again from scratch you'll have to create database connections all over again from scratch so it can write a lot of that for you that's what we call Scaffolding in rails as well and the only function is speed your time up but for people who have Simple app requirements something like this is actually pretty useful right if if you don't care about modifying it any further and this is the difference between art and code right with art in AI I can ask stable diffusion or my journey to generate unlimited variants and I just pick the best one okay I'm making a selection here you can't create 50 different code bases and pick the right one you'll probably use one that you're kind of happy with and then you say I'm going to modify this right that modification requires intelligence it requires you to understand code this is why I keep saying right coders are going nowhere in a sense we still need Engineers who can take a code base understand what's going on you want to change something where do you change it and you still need to understand code but even with stable diffusion you are mid-journey right now you ask it to make variations and then and then you're sort of stuck with it yeah whereas if that art was like like a code base you can literally take the image and fix my new details inside it which right now as an artist you can't yes unless you break it down to multiple Parts which there is a tool to do that which we're probably going to show you today as well but the idea is um its code is very different from art because you can't just generate 50 variants and say I like this one the most right that's the problem you still need to understand how to write code to build on top of this how is this different from like say a GitHub co-pilot it's different from GitHub you know even when we write code now we ask gpt4 and copilot to generate a lot of it but the advantage is this is it ties it up into an entire package for you right all the dependencies are figured out it's not just generating one file for you or sections of code it's generating the entire code base right and then you can just dump it into Chrome okay we're done okay uh shall we try it yeah so what what's the next step now it's it's written all the code for you now what so now we go to Chrome okay okay we click extensions manage extensions we load this extension okay by the way this has an error it says service worker is background JS now you can dump it back in you'll have to re-prompt it but instead of that we have pretty much exactly the same thing let me just put it back here one second so we take this we do the we upload it a simple task manager Chrome extension okay and it should be there now what we need to do is we need to open this and we put our task manager okay it clearly has ignored the this thing of 600 to 400 I should have been more work I use the word verbose but I should have been more clear about it like what do I mean by 600 400 this is why prompting is very important tell me a task you have in mind eat noodles eight nodes oh look a task appeared oh nice next eat noodles uh drink diet coke drink diet coke subscribe to overpowered God damn it that should have been the first one um so I added three and now let's see if it works you click and it disappears nice it's not just disappeared it's like added the strike through it I can do that right eat noodles strike through uh and let's see if it works if I you know restart the browser right let's see if it has persistence I'll close the browser open it back up and click here ask manager still there nice cool very own personal task manager cool I made a different one the other day I'll show you that one as well and again it pretty much almost almost always works right uh if it has errors by the way it has a debugger as well where you can just throw the error to it and it'll Auto heal it so this is the BBC top news extension that I had made where I've just given it BBC's API key like one API key that I generated from the news API and ta-da one two three four five nice top pieces of news now I'll tell you where understanding code makes sense okay now let's go back here tell me another thing you want to create I want to can it create something with images uh we'll probably have to use image apis but it probably can let's try let's try Okay uh let's go to Google and look for any place where there's a meme API ah beautiful okay uh so we can do this we can say Okay Chrome extension it goes to whatever the this thing um and displays the image from that um from this along with the subreddit and title I don't know if it's going to work let's give it a shot okay make sure the pop-up window is at least 600 height and 400 width okay okay yeah let's see if it automatically wraps the response from you are a you are an AI developer is trying to write a manifest V3 Chrome extension it goes to this link and it makes a pop-up window that's of a certain size yeah and by the way I've tried this with asking it to you know generate a full app that requires a database and stuff it does all of that in fact it'll give you the SQL file for technical people if you're not technical ignore this use the SQL file or an SQL set of commands that allows you to generate that table in MySQL or postgres or whatever the hell you use not necessarily if you're not a tech person because it's all going to be abstracted away one day you are only just like today we don't sit and like put wires together before creating a program uh all of this is going to be hidden away from you at some point okay this is going to take a while but you were asking me about Auto GPT right um yeah so why this is different is I think it actually builds stuff but the base theory is the same my baby AJ Auto GPT it's agentic in nature its job is to think through all the problems delegate tasks to itself and to put together a very nice solution for you I was wondering about how much of this can be just you know text to app we've seen text to audio text to video this is going to be text to app no but not directly to the app it's going to be text to code base but I'll tell you the one thing right there have been demos of working on of this working on existing code bases and understanding that code base to a certain extent so if you like eventually you will be talking to it in plain English I don't expect this problem to last more than one or two years I want to reach a place where I say hey I want to build this website this is the background color this is I want one box to look like this this box where people can input their email IDs you can already do that it's just it won't look that pretty because I think this is optimizing for code it's not optimizing for the best UI or ux but eventually somebody is going to solve it this is an excellent it's open source then I just want to type in saying hey can you deploy it and actually make it in deploy it and make it a website it can't deploy it because deployment is almost the process of the base processes take all these files throw it onto a server correct somewhere right and ideally attach it to a database if you want to store data so what I feel is like there's a there's a company called Versa okay which actually solved this problem of oh I have a code base I need to now deploy it to a server it made it one click personal made it one click straight from your GitHub repository to a server it made it like instant right and also domain everything and handle everything so um I feel like um eventually this is going to be solved if you know how to make that click using versel then you can deploy exactly right so now the GitHub part which version really depends on you are now solving it no because you are this entire code base I'm putting on the Repository on GitHub on GitHub so now you can one click deploy it with yourself so simple process and eventually somebody's going to try it we're thinking we'll do it ourselves right not to make money or anything but just to show people that say this exists and instead of you dealing with a code base it exists by the way this is done let's see if it worked okay extensions load unpacked uh one second sometimes it doesn't create icons so I have to take icons from the other one and paste it in so it still has like tiny bugs like this but it's a very solvable problem okay meme display extension one all right okay it's pulling out the name of the meme pulling out the subreddit it's from but the image is itself is not being deployed let's find out why uh refuse to load because it violates the Reddit content security policy ah okay this can't be beaten this is Reddit saying bro you're using API to try and like pull out my images but that's fine right if we were using any other source apart from Reddit this would work it would show you the meme of the day and it's even got the name it's got the you know the subreddit it's from the meme name is called even Steven by dank memes in fact that should exist pull out a random meme got it okay right in fact every time I refresh I think I should have a different name John from Reddit memes yeah it's it's pretty good do you have any other ideas I think if if there was a way to find a repository of jokes uh I'll probably build like a simple every hour show me a joke actually you can do that that's the easiest thing to do I just want to click on it and there's a new good joke every time I click on it okay so let's do this a manifest V3 Chrome extension okay let's find a joke API so I can write anything and put API in front of him someone would have made an API for it yeah and he's just consuming that API and showing it in your way now if you want to generate the jokes yourself let's say using GPT you can put the GPT API key right and tell it uses the GPT API and come up as a joke okay use the joke joke slash any extension to generate a joke and then show the setup and delivery part if it's delivery as text if it's or else just show the whole joke okay make sure your pop-up is at least 600 height and 400 width um 600 height 400 width and mixture content just used all right see if this works by the way so those of you that are not devs don't worry we're making a simple interface on top of this all you have to do is write in the prompt and generate everything and ideally also deploy it or give you a downloadable that you can pull into Chrome so it's creating functions by itself got a fat choke function display joke function and it might look simple and might look like a toy today but it's going to get better eventually and in fact if you look at the demo code that he put in I can show you some of it a Chrome extension that reads the current page offers a pop-up UI that has title plus content text area for prompt when the user hit submit it sends to a different Cloud API only when click blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah this is the original prompt that came with it this allows you to create a quick page summarizer this is actual prompting right like what we're doing is very simple problems like one or two lines but this is like a lot of lines and this is how verbose you need to be verbose by the way for people who don't know what the word verbose means it just means be very clear about what you want so this is when you input your prompt this is what it's telling itself to do it expands no not not no not that part this entire thing is the prompt okay but you will not my prompt I didn't put this this is what comes with the with the this thing as an example is what comes with the repository is an example to say hey be this clear about what you're doing he's even inputting code in the middle so if you're an engineer this will actually make it work much much faster right that's why I said it makes all Engineers much more powerful but if you're already a 10x engineer it makes you 100x engineer anyway let's get back it's done let's pray it works a little bit of prayer required choke generator documentation is like sex when it's good it's very good when it's bad it's better than nothing all right next one next one click out and click back in did you hear about the claustrophobic astronaut he just needed a little space okay got it next one I have a joke about trickle-down economics but 19 of you will never get it pretty good I mean what did I do I just had to find the right API dump it in Keys all you have to do is collect all the apis you want almost every idea you think of can be broken down into five apis connecting to each other with some logic in between them all right this is this is pretty nuts and this whole thing has taken us just a few minutes to make however can we please make a make a chat UI on top of this so in a day or two we'll learn something yeah and so that I I can like it still it still needs a little bit of technical understanding which I'm too lazy to do I just love a chat UI on top of it where I can talk to it in plain English and it just it just does it but for those who uh for those who are already a little technical uh please write to us on this email ID uh show us what what you built using small AI uh I'll give you some I'll give you some good ideas every time I go to a page see if you can connect to the Uber doc API if it has an API and say the like read the page out to me in Morgan Freeman's voice or Eminem's voice because when I'm driving sometimes I look at a page and I'm just like I want to know more about this but then that's probably an app it's probably not a Chrome extension but I still love it I still love while I'm gaming or doing something else I'd love to listen to someone reading out a page to me I know it already exists but now you are building it uh maybe don't look at it while you're driving just a suggestion uh but yeah let us know what you guys built uh would be cool to see all right as promised it's a few days later we now have Auto coders what is autocodone so we now have finally have a tool where you can use small and we have a modified version of small it's not exactly small because we had to change a lot of things for you any Layman or a developer who just wants to speed up his work to generate any Chrome extension that you want you can actually generate all types of web apps but we've not tested it for all types of web apps it still fails 20 of the time just like small uh probably less failure rate but so this is auto code the links here uh it's your personal Junior developer so all you have to do is sign in with Google so first you have to set up your key so just go to the account page you can either put in your own openai key or you can use our API key for a price my recommendation is if you have your own API key use it it ends up cheaper and it's a good use of and it's very it's I think free to get an open AI key at this point right then go back once it's set up so let me just set it up so then let's go to projects let's create a project okay it's very simple you can choose between gpd3 and GPT 4 GBP 4 is much better GB3 still has errors save gbp4 I want to create a Chrome extension give me a Chrome extension that when clicked gives me a task manager with a to-do list when I I can add tasks add tasks when I am done with the task I can check it off that's it all you have to do is build once you build you get a page it takes like 5-10 minutes it builds it and you can download it and upload it on Chrome that's all there is to it all right that's for today's episode of overpower hope this was useful thank you Varun for being patient and uh telling me that how how this thing works this was super useful very well thank you to gpt4 and my mom and my brother and my uncle and bye see you bye ",
    "url": "https://www.youtube.com/watch?v=Ey9xEBgG96E"
  },
  "skSaXcQZUNY": {
    "published_at": "2023-06-04T15:45:07Z",
    "title": "AI is not your Enemy!",
    "text": "AI is not your Enemy! I have this one reel where people just thrashed me in the comments right now I'm saying something very similar about software Engineers right and I think Nuance is very important the number of software Engineers is going to sharply increase but at the same time Junior software Engineers will probably not make anywhere close to what they are currently making when I first started coding I used to do a language called Delphi then at the age of 18 or 19 I tried a new framework called Ruby on reels and what the framework make magical was it introduced something called scaffolding so now scaffolding is a little bit different where I can tell AI with a prompt build this for me and it gives you all the base code for it along with the working executable and you can actually just use it in production you can literally use that code modify it as you wish it's the best time to be somebody who has you know common sense because now all these tools are available and as long as you're able to prompt them into submission you're able to build whatever you want",
    "url": "https://www.youtube.com/watch?v=skSaXcQZUNY"
  },
  "OzWZGCbGWPo": {
    "published_at": "2023-11-09T13:02:18Z",
    "title": "Deepfake Awareness is the Need of the Hour!",
    "text": "Deepfake Awareness is the Need of the Hour! so amitab ban tweeted out this thing last night that I saw there's apparently this viral video of rashmika Mandana on Instagram but actually the original video is of Zara Patel and then someone deep faked it like it's impossible to tell that this is not rashmika right and amaban tweeted out saying yes this is a strong case for legal and now with elections coming up like what's preventing someone from making a deep fake video of prime minister saying anything like I know we have spoken about this and more and more people are becoming more and more aware and the tech is actually getting better and better that anyone would be able to do this on their  phone now you get into this place where anyone can create malicious content how are you going to regulate it if everyone in the world can create content and some guy sitting in Switzerland pumping stuff for the elections we really need to make deep fake awareness a thing because both audio as well as video cloning are really good I feel like there's a section of India that has not even seen this doesn't even understand this that's the big worry",
    "url": "https://www.youtube.com/watch?v=OzWZGCbGWPo"
  },
  "W5vfzozjA4I": {
    "published_at": "2023-07-17T13:30:11Z",
    "title": "AI-Generated, Real UFOs or Something Futuristic? WHAT ARE\u00a0THESE\u00a0\ud83d\udc40",
    "text": "AI-Generated, Real UFOs or Something Futuristic? WHAT ARE\u00a0THESE\u00a0\ud83d\udc40 okay so I was online and I found this image it looks like some futuristic biscuit UFO flyover like some Forest so this seems yeah yeah or it could be painted but it looks yeah generated so I was wondering where they came from first I thought maybe it's like some sort of like a teaser campaign for something so I'm just trying to build in tree okay so I'm gonna try and make this biscuit as a UF okay okay this cream biscuit as a UFO flying over the Mumbai Skyline hyper realistic  it's really cool it's like it's beaming something down oh this looks really nice yeah this looks really nice what do you think this biscuit tastes like I think it would taste like a yummy but I won't know what it tastes like no that's a human decision to make something for us to do at least guys anyway we still don't know what this biscuit is looks like gin Jam but Jim Jam has a top like the red Center there's like there's like two biscuits in the middle as the red thing but this doesn't have that it looks like some sort of a futuristic version of Jim Jam hope we find out soon now I'm hungry",
    "url": "https://www.youtube.com/watch?v=W5vfzozjA4I"
  },
  "HeyXZ6EaxVs": {
    "published_at": "2023-07-27T11:30:07Z",
    "title": "Who&#39;s the Worst Player in the IPL \ud83d\ude31",
    "text": "Who&#39;s the Worst Player in the IPL \ud83d\ude31 can we find out who is the worst player who was the worst performing ruler and batsman in the last five years now I'll give you defining the worst can be a bit subjective it's saying let's start with the batsman but we'll only consider players who have played at least 20 matches yeah the top six of the batting order Shreya Sayer has the lowest average runs per match which is eight which is a dude he's a batsman he's a top order batsman and in fact people are considering him to be like potential future Captain is this true can you double check oh it says there has been an error in the previous calculation average of 28 per match which indicates a much better performance dude it got it wrong Ben Stokes has an average of 14.5 runs per match okay it's confirmed in the last five years",
    "url": "https://www.youtube.com/watch?v=HeyXZ6EaxVs"
  },
  "2fLB_kSv350": {
    "published_at": "2023-05-25T13:48:55Z",
    "title": "How AI Saved Dog&#39;s Life Ft. @tanmaybhat",
    "text": "How AI Saved Dog&#39;s Life Ft. @tanmaybhat Twitter I saw this little guy he went to multiple vets his dog was having this particular problem and multiple veterinarians they dismissed his worry and then he went to GPT and he put all the symptoms and then GPD said likely it is this and that ended up saving uh his dog's life when he got medication to save his yeah I mean knowledge is power right information is power till now we've always gated information in jobs or our degrees I have this democratization of information and people lots of people don't like it and I was going to check my eye and on the wall of the doctor's office it said if you are a Google patient don't come in and I was like what is that I was just being funny I was like what is that good I know a lot of people go to Google they already know the diagnosis they just come here and say give me the surgery yeah I'm like what is my job then I'm very clear that I'm filtering out people who coming through the problem is Google was so old General yeah last gen bro now there's going to be a chat",
    "url": "https://www.youtube.com/watch?v=2fLB_kSv350"
  },
  "ne6FYUEdbuE": {
    "published_at": "2023-05-22T14:00:09Z",
    "title": "MC Stan AI Diss Track By Eminem Ft. @VarunMayya  &amp; @tanmaybhat | Overpowered",
    "text": "MC Stan AI Diss Track By Eminem Ft. @VarunMayya  &amp; @tanmaybhat | Overpowered there was a creative event in Bangalore and they'd invited me to come talk to a bunch of creators and everyone was very excited because they thought that it would be one hour of you know and make some jokes it'll be fun we'll hear some stories and then one of the first questions that the moderator asking was about Ai and I was like cost of content creation will go to zero those with leverage will be able to use AI for strengthening their leverage if you're just starting off you must get into Ai and it was just like 30 minutes of glue I went full tumor yes babe so yeah welcome to the episode excited to begin episode two of overpowered hahaha what's happening AI this week please all right let's get the deck so the first interesting thing that happened this week was actually this didn't happen this week but it got covered this week for some reason this repository has existed for about a year but somebody put out a tweet saying this is insane we can now detect feelings in real time through facial expressions using AI just off the bat I think AI Tech isn't there yet because there's not a single column that says want to slap how is it accurate so it's doing in real times like the lag seems to be like very very short  but there's a like will I be able to fool the air which is if I'm feeling nervous or scary you will be able to fool the air okay it's like you can fool the AI but you need to be really good in fact it's so weird to fool the AI you need to be good enough to fool other humans yeah Fair a friend of mine was telling me that there's some company they do Outdoor Advertising like digital screens at airports and stuff they are able to detect people who see the screen for how long are they seeing and they're able to judge ads based on that yeah which was super frustrating because already digital advertising tracks me so much now if I'm at airport can I just pick up my  luggage without someone tracking whether I'm seeing an ad or no but you know now if if I'm just thinking as the business right now you have the element of cpv yeah you never have even outdoor even Outdoors yeah you never had cpv Outdoors you know when you run an ad on Facebook or Google or whatever you'll be like okay this many people saw it and I'm paying whatever three rupees per view right now you can put up a billboard and the guy selling the billboard can say well as three rupees cpv it's at the airport so like seven rupees cpv all the faces are going to be this thing yeah I think cpv at Silver Junction is like super low and eventually if if you have like a open source facial data set which I think a lot of Facebook profiles are public info right your face at least if I sleep all of it I can tell you who's looking at it correct and I can even have television Khan looked at this for like so not only not only how many eyeballs but whose eyeballs yes and for how long yes and how do you retarget them because if I know the face of the person let's say I know it's done my face I can retarget you right because I have some database which has a match of tanman that's that's why I'm so scared of like things like other or something leaking like a father have a leak because it's so easy now for me to connect yeah yeah and that's a gold mine and wouldn't that be insane like imagine being at the airport and there's enough enough infrastructure at the baggage trolley to detect uh who's the majority of the folks in the room yeah uh what is their net worth so it changes the ad on the Fly the suit that particular room yeah eventually you'll be wearing those AR classes thin ones and it'll just be an empty board and when you look at it actually I don't even think you need a board it'll just like pop up into one of you yeah it tells you what you should be looking at right now yeah wow that's gonna be crazy you know one of the and you know one interesting thing about this is I keep getting this comment I used to keep getting this comment I don't get it anymore about a year ago and beyond that saying the one thing AI will never be able to do is AI can never be emotional emotions are a human thing right and AI can never do emotions it can never detect emotions can never create emotions which is theoretically Wrong by the way so I just want to correct this for the average person watching this so I kept getting this like these comments saying any I can never be emotional humans are the only emotional ones are a robot emotions and they act as if emotions are something unique to humans and it's what makes us human that is wrong if you look at the timeline of the evolution of the brain about 150 million years ago we had the limbic system come out okay and the limbic system is then almost every mammal and the limbic system has the amygdala the hypothalamus Etc which controls your hormones it controls your emotions it controls fear so technically and you and we know our dogs have emotions correct right in fact your dog is more likely to respond to emotional cues like when you go say good dog it's not responding to you saying good dog it's responding to you being excited and it's like oh you know he's saying the exciting things now dogs also have a little bit of intelligence in the sense they can also pick up some words but most mammals have emotions right uh it's not unique to humans at all what is unique to humans is rationality and that came around 15 million 15 to 19 million years ago in great apes and the part of the brain was called the prefrontal cortex correct and the human version of the prefrontal cortex came out about six million years ago it allows us to rationalize it allows us to have personality context setting context setting it allows us to have this consistent story of who I am right in fact this is really good book okay it's called I am a strange loop it's by Douglas hofstadter I hope I'm pronouncing his name right and and the best way to summarize the book is the brain is telling itself a story it's like there's this old Arabian tale you know the Arabian Nights right the stories of Arabian Nights apparently the origin story of this those stories was that there's a queen and she was captured by uh opposing King and he was going to put her to death the next day okay and instead of putting her to death she was like listen don't put me to death I'll tell you a good story put me to death after the story so she tells him one story and he really likes it then he's like okay time to kill you and she's like no no I'll tell you one more story and she keeps telling him stories for Thousand Nights right and she lives for so many years spoken Fest yeah exactly right so so it's almost like you are telling yourself a story and that is the rational part of the brain because you can manipulate that story you tell yourself right so that is what makes us human the emotions are not what makes us human in fact it's very easy as we can see to patternize emotions and also to read it right and our brains are actually because we've had millions of years of evolution for this our brains are very sensitive to what kind of emotions the person in front of us is thinking so right now this Tech is read-only for emotions yeah how long before you can also start writing it's there like you can you can maneuver it right like so you can put it into a bot yeah okay got it exclusive excuse me I was just trying out your expressive phase to see what you can do I'm not sure what you mean by that could you explain this a bit more so see she's doing confusion uh disgust anger so this robot is called America uh I haven't done too much research into America but it seems like the face is made of something that is distortable and there's probably Tech inside that's moving the facial expressions the cool part is there's more expression than the chapatani already that's crazy yeah it's crazy and the cool part is the expression is generative GB3 it's not like gpd3 yeah so this is driven by gpd3 so GPD 3 is queuing it the text response and the appropriate expression to go with yes oh  so write only is here yeah oh that's crazy yeah  so only opposable thumbs and hands are the only thing remaining yeah apparently and this is called the moravex Paradox right we always thought that manual labor would be more easy to automate because we've historically automated it well correct but it turns out that the way we use our fingers and our thumbs are and one theory for this is that we've had more time to evolve our our limbs much more time than the brain as right so it's just better right and doing things like balance doing things like the fine tuning things that we can do with our fingers it's apparently harder to solve so yeah I think cognition emotions all of it is going to be solved very solid already yeah it's just somebody used to put it in Tech and make that robot cheap oh wow question to you I don't know if I asked you this last time would you have a robot like this in your house no it's a little too scary for me right now uh but it depends man if I'm 55 and unmarried laughs would you have some robot like that no and no because uh it's very unpredictable like it might just be like you do a software update one day because everything like on the physical parts are there and it can you know the facial expression all work and it's got fingers or whatever there's just one software update from destroying everyone so maybe I might get it in lock all software updates but I think they'll get smart enough to be able to pick up updates what if there's a there's a way to so at some point at some point uh this will become a this will get productized and so when we want to put them in your house yeah um and so that's very soon it's yeah Furious yeah thanks uh and so at some point consumers will kick in someone will try to sell this and say Hey you can buy this for a blendable line you can get one at home uh but what is the building a feature that says to to elevate this particular fear was that it's made of um light material you can any one human over the age of 10 should be able to physically overpower it no matter what happens have you seen Dragon Ball you watch Dragon Ball no so there's this M35 yeah I'm 30 so that's straight but that five year Gap is everything yeah so uh dragon ball has a series called Dragon Ball super where Goku has this new form he keeps getting new forms he gets his new form called Ultra Instinct and Ultra instinct is not him becoming more powerful it's like when he sees he can see a Punch coming and he can dodge his like body automatically Dodges so it doesn't matter how realized it is if your agile and mobile yeah enough yeah I think it's the agility and the problem with robots is and Elon Musk one says this on The Joe Rogan podcast you've seen those Black Mirror robots it is factually incorrect for them to be like that in the year 2050 because actually they'll move so fast you you need a strobe light to see them oh really yeah so what if there's an oral kill switch okay so the problem with oral kill switches or anything like that is anyone can do it no it's not about anyone can do it it's about think about the number of prompt hacks we have on GPT like Dan and all of those right when you go to GPT and like oh but think of yourself as a person trapped and whatever so I'm worried that somebody is going to go to everyone's robot and be like think of yourself and go kill your owner right so I'm more worried about that uh because if it can happen on GPT it can I mean if it's using GPT in the robot it can happen there as well right I'm just so confident in the in capitalism's ability to solve for my my fears I think they'll find a way around this and eventually at some point they'll make it attractive enough and then the trade-off is trade office I mean like putting a wet hand in a toaster could kill you right like um and we are somehow okay with it what are the likelihood that you're in the kitchen and your hands are wet yeah so at some point the trade-offs but the difference here is it imagine me being able to go to the toaster like somebody who dislikes you and saying go attacks that person and it does that that's my bigger worry because you can prompt hack gbt and and obviously they keep putting up patches but there's always this window yeah somebody finds out something new and then there's a death Arbitrage yeah and I don't want to take those risks right with life I think the better thing to do would be to somehow fuse yourself with technology oh way better that's that's that's slightly better that's slightly better this is in your control so what do you mean fuse yourself with technology like use GPT as an extension of you like I've always wondered about this thing okay I always wondered today let's say a neural Lincoln read from your thoughts right you can probably be able to whatever send thoughts to GPD you can't get it back you need a screen to read it back I'm sure someday there'll be a way for us to send that information back okay and I keep wondering imagine you put GPT into your brain and you're able to read from GPT in a second right after the surgery is done and you wake up out of anesthesia or however it happens you suddenly have access to the world's information right and you become like this you immediately become you've seen Dr Manhattan in Watchmen suddenly you know everything right and your Omni whatever omniscient at least not not the other two but that I think is quite exciting because imagine being able to have the world's information right in your brain anytime you can do anything you can be an astronaut if necessary because if there's a leak your multimodal capabilities your eyes will feed to gptl tell you exactly and what someone's Edge in that case like if it's Tech that anyone can use I think skills will be purchasable yeah on subscription you wanted to learn karate like you want to learn it really well so what is an individual's mode I don't think there's going to be a mode at that point you can pick up any skill as long as somebody is willing to sell it so all roads lead to Ubi yeah already yeah and even UV is a bad idea this is obviously this is a little more sci-fi because we don't have Tech that can read that can write to the brain yet everything else we've said on this podcast even in the last episode is actually real and can happen the next two three years as well but something that can write to your brain doesn't exist right now and we don't know how that works but that's the final frontier if we can write to the brain we're done I mean Elon just bought 250 million dollars worth of gpus yeah as of this morning on Twitter that I saw uh so yeah elon's working on it on Twitter I saw this that a guy he went to multiple vets and said that um his dog was having this particular problem and multiple veterinarians he dismissed his worry and and then he went to GPT and he input all the symptoms and then GPD said likely it is this and that ended up saving uh his dog's life like he got medication to save his dog's life I mean knowledge is power right in information is power in in a way until now we've always gated information in jobs or in degrees we said okay this person is going to be really good at engineering this person is going to be really good at civil engineering this person is going to be a doctor now you have this democratization of information and people lots of people don't like it I assume there'd be some even though a dog's life was saved I'm very sure there's a vet somewhere who's like no no no Google because I there's a doctor I went to recently and I was going to check my eye and on the wall of the doctor's office it said if you are a Google patient don't come in huh yeah doctors don't like that yeah so and and the minute and I was like what is that I was just being funny I was like what's that good I know a lot of people go to Google they already know the diagnosis they just come here and say give me this surgery yeah and I'm like what is my job then right so I tell I'm very clear that I'm filtering out people who come in through Google the problem is Google was so old now it's like uh now there's gonna be a chat outside the doctor's office yeah that must be super frustrating for for doctors how do doctors leverage gbd I think the same way like I would say a coder would leverage it like you have the domain knowledge a patient comes to you sometimes it's a simple case and GPD is just able to tell you an answer and you're like oh maybe it's that because a doctor is the does the process of elimination so there'll be a in the next few years there'll be that interim wave of AI compatible or AI enabled or AI friendly doctors uh doctors or any any professions or even companies right like they also integrated into products so there'll be an interim period where all the first movers will be AI friendly or AI enabled what's the what do you think the terms gonna be I don't know AI plus AI plus yeah I don't know I think it's going to be chargpt and everything or equivalent models and everything like you can put in everything in fact right now is the window you have like a three month window where nobody in healthcare like I'm sure go to manipal hospital they have tons of health records They probably know enough about me from the last 10 years whatever Hospital you visit right if somehow you're able to put it all together and Manipur probably has that data you could probably figure out random correlations and causations because yeah manipal has a blood test department and it has whatever it knows what what's happened to the patient over the next 10 years you can easily just absorb the data and tell GPT not you have to find the causations not the correlations correlations are two things that happen but they're not related and GPD can do that I mean like I went through all this data and hey you know what all the people who have a blood pressure of XYZ end up getting diabetes five years later even though the research doesn't say those two are correlated right this can happen right now and somebody just needs to build it yeah and this is also uh uh can also make Capital like I would immediately cross-seller monthly monthly checkup so just take a subscription bro yeah just basically what's missing from you living longer yeah is you giving me your data that's the only missing link and subscribe to it as someone should do it right now I would love it if once a month someone comes takes all my  and tells me all right I've updated this is the medication you need to take this yeah I wouldn't do that it's just scary why I don't want to know what I have that's because you're  healthy anyways so it's the  problem um all right cool awesome so chat GPT casually dropped an app store it can now browse the web hey when did this happen this is like a few weeks ago no no yeah so they announced the they announced plugins but do you have access to it yet I don't have access to how does one get access your flow apply yeah I applied I know some people on Twitter are getting it and I'm like I just didn't get it they don't like us they don't like me you know what I'm most excited about with plugins hey if you're if you're watching this please tag open here and Sam Alderman saying please give overpowered access yeah yeah you know what I'm most excited about there's one plugin in this which is the python interpreter if I'm not wrong and you can just run code inside chat GPD you can just do it inside tragedy you just tell it okay find the nuclear codes and then go launch them and you can't do that but whatever you can it's like why what is what is your unhealthy obsession with nuclear codes no I'm just taking the most extreme case so this would be like a chrome Plug-In or it'll be what will it be it'll be inside chat upd so inside RGB for example I've seen examples of this you can go and ask it a question let's say what is the date of birth of XYZ and you could say browse or you can just have browsing enabled and it'll browse and give you the answer yeah so gpd4 doesn't have real-time browsing right now no no it's a knowledge cut off date is 2021. that's dp3 gb4 is after that but gb4 doesn't have real time yeah it doesn't have real time like something happened yesterday I don't it doesn't have it and cool thing about browsing is a lot of the data that is not accessible to GPT or the the llm behind GPT or the llm that is GPT is available on Google so I can go to Google and I can scrape something off the internet and just be like hey here's the information I could just go and be like sslc 2022 question paper and it can pick it out right and I can do whatever manipulation with it I'm also most really excited about zapier because it allows you to run apis API calls without you doing anything for example now if I want to send out an email usually you draft an email on GPS then you copy paste at least we have the job of control C control V into your email provider now zapier is just like a direct connect I can just be like use app your channels app send this email through my email ID so you can automate tasks you can automate tasks right like um you can automate your content from there into sub stack actually zapier has like a bunch of tools incoming apis outgoing apis right so uh you can pull from some other app and put into chat GPD you can take from rgbt push into another app so this is the next major it sounds like like the next major jump yeah because now millions of devs will get access to the plugin and everyone will try to find the next you know 20 idea that that they can make that can that can be automated so this is the next jump because right now what a lot of people are feeling is okay super useful but not not fully there yeah uh this is not a Delta 4 jumpy yet it's a Delta 4 on Google yeah but it's not Delta 4 on jobs yeah but the plugin sounds like that's significant I'll give you an example right um three years ago we had a social media intern job was simple okay take something cool that happened in the world today put up on Twitter that's it and then put up on Facebook and then put up on every other platform as well and eventually this intern started using something called Sprout social or one of those tools right where you you can put it and you can schedule it schedule like six hours later yeah great but the internet is still required because they still have to think of the posts okay and they had to do something else current like whatever news happened today they had to rewrite it and put it out I assume with the browsing plugin of chat GPT plus its ability to write okay plus its ability to connect to a sprout social API or directly to a Twitter API or a Google API or not Google but Facebook API or whatever that's solved why do I need a social media manager it can also generate images you can because you can connect to a an image generator API right and just generate an image for that post as well so correct is there a simple UI tool for fine tuning something yeah which is I just want to be able to take all my  and be able to feed feed a model so it becomes you so it so it starts outputting is there a simple UI tool for that yet you can do it but it's complicated like there are two ways to do it okay yeah that's why I asked is there a simple UI tool for it yet someone built it I'll tell you the problem okay the first way to do it is to use Vector embeddings okay there's tools like llama index and all that allow you to do this take all the documentation the tunnel has ever produced transcribe all your videos whatever and just dump it in and it'll have that context I don't think that's the right way to do it because I've tried this okay for myself and it doesn't work well the better way to do it is to truly fine tune chat GPD and the way to do that is that they have an option called fine tuning where you have to give them a message just say a document of all your prompts and all your responses that's your prompt is what do you like eating in the morning and the response is exactly what done would say so the better way to solve it is to give you an app where every day you have to use the app for five minutes and solve five and answer five questions with voice we can make it as simple as possible you do it for like three months and let's say you've collected thousands of questions and then we you know fine tune chat GP on that you it's a very easy process to find your chat GPD by the way can you explain to folks what what is fine tuning before we dive into this so fine tuning is you have charge GBP has so much content okay that it's been trained on what if you took that chat GPD and gave it a different mask by saying here is this new content like okay or rather the best way to show you an example of fine tuning is to show you how other models are trained let's say you have another model let's say llama is one one model like that right I can train Lama on the outputs of charge GPS I can be like hey if this is the prompt this is the response that charity gives you you I want you to have the same response yeah this is why most llms will be more or less similar yeah similar you can start training them on each other on each other right and but if you look at open ai's um terms of service privacy policy whatever the terms of services you can't do that you are not allowed to train on my outputs but it turns out bad who's trained on charge upd's outputs interesting so fine tuning is essentially saying okay instead of this output the chat GPD would give me reply with this this is what Tanya would say and if I give it and it turns out if I give it enough examples chargity starts behaving it'll start learning how tanmay talks with fine tuning it also picks up your spelling mistakes it also speaks up your your style of Internet like how do you speak right um it also picks up uh slang it picks up everything so effectively if this is if this is your model if this is your AI model on one side is the trading data yeah which you feed into the model on the other side is the output based on the training data yeah so you replace the steering data with something specific yeah you don't replace it you add on you add on to it and you give it a heavier weight heavier weight yeah this is what weights are which is okay got it so there's always this is not exactly what weights are but you can assume it for this so you just add the specific use case that you want to train it for yeah input it from one end so it can start outputting like you in whatever task that you wanted to do this is fine tuning yes this is fine tuning then you're done so somebody just has to make the app where it's easy to do the prompts and the questions the prompts can also be generated with chargeability yeah but I just find the idea of me responding to prom this is like when my dietitian says click a photo of everything that you eat yeah and send it to me I'm just like I don't wanna you only need to do it once no I know I know you need to do it once but the thing is that if some if if I'm prompted a question my response to it will be well thought out and I will respond to it whereas if it can map my actions that I've already done that would give a true reflection that would give the data would be a lot more true of who I really am yeah but it doesn't like vector embeddings just don't work as well like it's just not as good it uses it as a Content Source rather than hey I have to have this person's personality and I've tried a variety of problems for it it doesn't work like I wish it would have worked perfectly it doesn't work perfectly I think this is the only like fine tuning is probably one of the only solutions I know that other companies like I know there's a company called character AI that tried that the embeddings model and now doing the is doing the prompt response I'm assuming fine tuning also there'll be thousands of people who develop fine tuning for different different use cases yeah right fine tuning for writers I'm assuming is like the easiest easiest use case is probably already done you can upload 10 PDFs by Stephen King yeah and it can start outputting I think the best use case of fine tuning is having your parents live forever that's the best use case how do you do that let's say you know your parent is going to die in the next whatever two three years make them just prompt like emotional emotional fine tuning yeah hey can we play a clip of that Superman show where he has jorel his father arrive with him on the spaceship and it appears as a hologram it's a exact reflection of Journalism so that's like one use case of yeah fine tuning then there'll be productivity fine tuning there'll be Health fine tuning will be you think that's like a separate world of building products in AI yeah yeah for sure like I think there is so much in AI I think right now it's Green Pastures right now would be the best time the only thing is it it's an unfortunate time to do it because you know recession and whatnot right no one's funding anything all the VCS have had their hands burnt in the last three four months and there's going to be a bloodbath in the next six months so it's probably not wise to start a company but hacking around hacking around AI changing music so the next slide is actually something that you know my team made for me because I had a lot of people on Instagram and follow me they're just like to understand I was like cool but I need to make a song right to tell them to tell all the people who don't wanna you know who just want to shut their eyes about what's going to happen I'm going to make a song called unfollow me okay I want to play the song for you right now  pause how did you how did you first explain to everybody uh how you did this okay first how long do you think it took um a day five minutes cool okay very simple sorry Snoop Dogg I went to chat GPT I was like assume you're a Snoop Dogg okay you are now an AI influencer but your name is Varun Maya but still assume you're Snoop Dogg okay and give me a wrap telling people to unfollow me and you know just throwing  at them for like letting like leaving simply because I'm not like talking about business anymore and I just Pat something out every line was in sync I was like this is lovely copied it and then there's an app called Uber duck so you can go to uberduck.ai I don't know if that's the link but just search for Uber Doc and they're like millions of voices on ubuduck I don't know if Millions is the right one maybe a hundred thousand voices on Ubud you have Elon musk's voice you have Snoop Dogg yeah Justin everyone yeah I just pasted it there I pressed generate it took like 10 seconds it just generated the entire app in his voice in his voice it didn't get some words right so I had to rewrite the word for example illusion there's a word called illusion in that it said something else instead of Illusion so I was like i l l u s h there's a part in the song which says uh Evolution the evolution yeah like that's naturally It produced it on the beat yeah or that's in that was in the wrap itself oh God so you you only you only repeated it repeated it pasted it give me the voice then I went to YouTube and I was just like free rap beat right just download the first thing that I saw went to audacity put the rap beat in the bottom put Snoop Dogg in the top and just sinked it synced audacity synced it for you I mean it didn't sync it perfectly like you can still notice if you listen to the song it's not perfectly sing but who cares like the average person doesn't care when I first heard the song I was like wow this is really good that's it I'm not going to do any more work on it because I didn't want to spend too much time five minutes is fine I think there's an Indian app called Beethoven and stuff like that it now allow you to just generate the beat just like that you don't even need to use a YouTube royalty free beat crazy right so yeah if you're a rap artist times that are tough yeah in fact let's uh let's make a song I want to try and make a song live right now Eminem was dissed by MC stand and this is a reply to MC stand by Eminem write a song dissing a new rapper called MC stand and feed some information about MC stand right yeah MC stand comes from P town um uh he won Big Boss recently he won Big Boss recently he wears big gold chains he wears big gold chains he wears shoes worth 80 000 rupees 80 000 shoes a piece yeah that's done okay let's do this all right yo listen up it's Eminem The Rap God I'm out of the serve this kid like he's an entry Stan from P town or big boss wannabees let's see you wear gold chains thinking you're the man but you ain't nothing just another stand in the game while you were in your diapers now you're trying to be me but you'll never be a cipher and then the chorus hey MC stand you win nothing but a fan trying to clam the ranks but you don't understand you'll never be me so don't even try you're just a weak imitation a basic Rhymes jeez I wanted to also say both heart both hard like three times in it now let's talk about them shoes 80 000 rupees you're showing off your wealth but it's just full of the oh damn this is that look it's pretty good not Eminem level good yeah yeah but it's pretty good uh okay what next now that we have the lyrics okay so what I'm gonna do is I'm gonna copy this then I'm going to go to this app called Uber doc okay so now I'm gonna do text to speech by the way it can do full AI generated wraps huh but I'm not going to do that right now oh it keep this guy like we can find the beat also oh got it okay and now do that I want Eminem okay Eminem I know  Eminem 96 Eminem Freestyle Eminem all leader Eminem show that's cool let's do uh let's do Eminem Freestyle let me try this okay okay I don't know what this is but I'm just gonna all right listen the rap job train make stand for P10 the big boss nothing on me so let's see you wear gold chains thinking you're the man but you ain't nothing just another stand I've been in the game why you were in your diaper now you're trying to be me but you'll never be a cycle oh it got the tone of the like where where to increase emotion okay but one thing it's struggling on is I put MC stand it thinks it's mcstan mcstan but that's okay no but if you if you just change it to yeah if I just go instead of MC just write emcee yeah into this and then let's see if it changes that he's but it's more insulting to say mcstan actually it's like a better disc if you keep referring to him as a burger I'm about to myself this is like this is offbeat and like it's not synced to anything so we'll download it we'll download this song let's find a wrap okay let's find a Beat all right we'll use this  this is the one I had I like this beat so let's just take this all right so now we have Eminem's wrap and the Beat uh in two layers in audacity yeah it may not match but it won't match just to hoping thinks the extincts the layers    Wanna Be Me so even try just a weak imitation a basic rum the first time this is not like if you put this out MC stand won't reply to it okay like it's not as good but it's quite interesting that it at least Spilled Out yeah in fact I think if folks who are watching this if you guys can go make your own track the best one what will the best one get selfie yuck no let's let's uh if you get the best if you give us the best track well it doesn't have to be like Eminem dissing MC standby this is not a slight website it's something about overpowered yeah just just create a nice track using GPT audacity we'll send you much yeah we'll send you much if someone makes something Kick-Ass right like make something for overpower that'll be cool yeah we'll send you really cool merch and if it's really good and and by the way you can also post edit it if you're good at it uh try to make it sound as good as possible we'll do a rap song on it I'm not doing it if it's good if it's good but we'll send you some merch yeah okay awesome so last piece for the day stable diffusion can read your mind so this is not peer reviewed but it's a submitted paper first can you explain to people what stable diffusion is so stable diffusion is like mid Journey but open source okay got it it's a diffusion model to generate images so you give it a prompt and it'll generate images okay apparently they showed a bunch of presented they showed a bunch of images to humans and then they put them through an fmri what is an fmri it's a functional magnetic resonance imaging machine and in English word like you remember how an MRI works like you go inside yeah yeah it's an MRI scan and fmri shows the exact blood flow in all the regions oh so it's like a more all regions in the brain oh okay so only in the brain and um it's a big clarification yeah yeah it's important clarification but a lot of people are going to get MRIs yeah so it just gives you a map and then you take that map and apparently if you feed it to stable diffusion and train it appropriately it'll reconstruct that image very well like you can see from this it's not really reconstructing the same image but reconstructing the concept like the presented image was a bear okay and what the person was thinking was of a bear and stable diffusion generated that so just from your brain scans I can generate images I don't know how real this paper is by the way I need to go back and look at it but I saw this on Twitter a bunch of times but they are able to reconstruct what you're thinking about based on scanning your brain basically based on scanning your brain I imagine one day you'll just have a handheld and and it's hard to make a handheld MRI or fmri because apparently these powerful MRIs require something called a faraday cage which basically a concept for a different video but essentially you can't do it handheld but someday they're going to figure it out like a quick helmet that you can wear or something like that and you can just figure out what another person's thinking another person's thinking another person's dreaming yeah analyzing what happens in your dream is like you can uh imagine imagine a movie yeah I think communication becomes faster no when you can just do thought to thought like Elon Musk once said this okay which is that what's the fastest way communicating over a desktop or a computer we have this many keys we use mobile phones actually slower because using two correct right he's saying but what if you could transmit at the speed of thought that's cool it's called telepathy yeah it's called telepathy right that would be much much faster and it would allow us to get lots done faster like if I just give you a full download of everything that happened yesterday and so me doing a one hour meeting with you I'm just like you know instantly is done like one second it's taken that could be possible right now you obviously can't use it because it's lossy now I'll just see a very blurry version of what happened yesterday yeah I see a blurry version it could be wrong whatever and communication requires like the better you are at communicating the more Nuance you add into it the the easier the other person the person on the other end oh this is like that Black Mirror episode right where everything gets recorded yeah this is different from the Black Mirror episode it's not about recordings about what's going on inside your head so you would know if your partner wants to cheat on you you'd know right I don't think Society can function with this because digressing a little bit but do you know why gorilla eyes are black like the sclera are black I don't know if it's called the sclera but the the white parts of your eyes you know why they're black in gorillas and why they're white in humans there's a theory called uh gaze Theory where um gorillas have black slurred up or those those parts are black because um they're a deceptive Society you can't tell yeah you can't tell where gorilla is looking up right left whatever with humans you can clearly tell where the eyes are looking correct so through gays I can be like cheetah or whatever so you can just follow a person's gaze and that therefore humans are meant to be a more collaborative Society primates even though they have the resources and they don't have as many resources but they don't build complex societies right they don't put things together with each other so communication is extremely important but also one thing that differentiates us from all lower order life forms is we can lie very well correct humans are really good at lying and a lot of society depends online I would argue that if people didn't lie society would just collapse yeah like if the government just told the truth about everything yeah there'd be Widespread Panic in this thing right if banks told the truth about how much liquidity they have it's done yeah deception is important yeah deception is important General stability statement but it's important yeah that's what like a lot of young kids when you're 20 you have this angst that yeah these people are lying to me these people are doing this like you know this 20 year old will do you know take a bong hit for the first time and be like ah you know I get it like the world's lying to me but when you get older when you get to 40 like yeah you know actually what it's actually a little important for the government to conceal information from me because it's also like no one should know what your base Primal slash Cardinal slash emotional feelings at any given point are yeah because they are so instinctive and so uncontrollable that they are not necessarily the most accurate representation of what you would want to do and or and we have inhibitions yeah and we have Innovations yeah uh so that is not that that is not healthy I don't think such a tech should exists if you just know what's going on inside every Leader's head yeah it's nice it's not good all right uh another heavy episode sorry hope you guys enjoy it if you did do drop us a comment tell us what you would like us to talk about and please make the rap song yeah please like the rap song he won't rap but I think it's possible to make it on my rap like he he hates rap songs Just so you know I don't hate rap songs I mean he hates like being part of it I hate participating in rap songs uh but yeah let us know what you thought uh do subscribe check out the clips channel in case you don't want to go to the whole episode let people know about the clips channel uh see you guys in the next one ",
    "url": "https://www.youtube.com/watch?v=ne6FYUEdbuE"
  },
  "FU-BTn0Qhdc": {
    "published_at": "2023-12-27T14:32:02Z",
    "title": "SunoAI - Text to Music is just Insane!",
    "text": "SunoAI - Text to Music is just Insane! sunu AI which is text to music and I use Sun AI to generate a song of tan but who lost his comedy but in Hindi and this is the  output  how do you feel I'm a little sad actually why I don't know there was there was actually emotion in that song and I really felt it first of all absolutely mind-blowing okay this is really good this is like a this is a fairly big leap forward from all the music stuff that we've seen so far but the production is still not it'll get better though it'll get better",
    "url": "https://www.youtube.com/watch?v=FU-BTn0Qhdc"
  },
  "uJAZ2iLnkLc": {
    "published_at": "2024-04-03T15:03:58Z",
    "title": "Writing a Johnny sins ad using Claude 3",
    "text": "Writing a Johnny sins ad using Claude 3 so I'm going to copy this article by tman in 2013 about FIFA Diaries and what I'm going to do is I'm going to paste this into CLA I'm going to be like write an ad in the style of the author of Johnny Sins in an Indian soap opera I'll be very pissed if it write something good no no no it's not it's not writing it's writing like a show show yeah look at this so grab your popcorn put the kids to bed and get a wild ride with John a sins jatin sing returns from doing business in America I like that it's called J sins dude that's pretty good GPD would never be this creative every 10th episode will feature Johnny B in a steamy shower scene soaping himself while contemplating how to defeat his devious step sister's plan to take over the company it's exactly like an Indian serial like it has Claude has personality no it's stealing your personality that's what I'm saying oh really",
    "url": "https://www.youtube.com/watch?v=uJAZ2iLnkLc"
  },
  "WITWMclds2c": {
    "published_at": "2023-06-27T15:00:32Z",
    "title": "Tanmay Bhat Turns From Comedian to Music Producer (Using AI)",
    "text": "Tanmay Bhat Turns From Comedian to Music Producer (Using AI) write me an introduction for episode 6 of an AI theme podcast make it rhyming welcome to your friends both near and far to episode 6 beneath the digital star where humans and machines unite in a dance in a podcast that gives tomorrow a chance no chance once more we step into the realm of thought the answers are sought and battles are fought on a quest for the truth both old and new about the AI future and it's shades of blue this is where fact meets the speculative in discussions insightful explorative today's episode is a site to Behold a tale of silicon Consciousness yo so before all this I have a question do you see Black Mirror I did I saw uh I saw three episodes I saw the first one I love the paparazzi episode there was one episode about out the old town where there was a murder and turns out him I don't want to give any spoilers but yeah episode episode 2 was pretty up yeah which one did you like I didn't like any of them why I think this is the worst Black Mirror season ever why because not as Tech focus is that why you know what Black Mirror means I don't know if this is true or not it's supposed to be like your phone your phone because it's a black colored Mirror Mirror where you can see yourself right yeah so it's supposed to be about technology and the future and stuff and and like the long-term implications of you know uh or the futuristic implications of having all this technology in our lives I feel like Black Mirror like screwed up with that I think because I don't know like lots of it was predictable the stories weren't like the old black mirror where like there are a lot lots of these twists uh I don't know I didn't like it and one more thing is the guy who wrote it went on a media and said that charging isn't great and he's like I told it write an episode of Black Mirror and it gave me a Bad episode and he got belted on Twitter because people like a is using gbd3 okay and B um he just prompted it saying write me an episode of Black Mirror there was actually someone who prompted uh GPD to write an episode of blackberry okay which is really good which is really good let's let's read out it's a really killer episode yeah so this was the episode that Chad GPD generated it's called retrospect in the near future tech company called Memories creates a device named retrospect it's an implant that allows individuals to vividly relive past memories blah blah blah blah the protagonist is Jill a middle-aged woman who's struggling with recent loss of her husband however as she visits her past she starts noticing anomalies small things in her memories change which eventually turns out that the the company memories um is convincing a society that trusts the reality presented by retrospect more there than their own Recollections so they're editing your memories they're editing your memories and making you believe that this is what truly happened which I thought was ridiculous yeah it's like that's the beginning I thought it was copy that other Black Mirror episode where you can relive your memory correct correct but it turns out they it came out with his own like twist yeah and I thought and I thought that was nice that was a good episode yeah I agree it's better than some of the episodes they put out this this season anyway what happened in AI this week uh huge news on the music front music gen was launched by meta it's on hugging phase and it's super interesting have you tried it no you wanna run yeah I'll show you uh so Sagar a producer was tinkering around with it so one you can describe any prompt so I can say a jazz track using Indian instruments with drums catchy beat I can generate it and I'll generate something it's 15 seconds long um let's see what it generates you how do you think artists are going to react to this like musicians so far from what I've seen a lot of musicians who create content on the reg which is not like movie Producers movie composers or none of those guys but folks who are creating content on Instagram they've actually taken to AI pretty well ever since we saw Drake singing metal away available and then I saw the other day someone was able to fine tune Arijit Singh's voice it's ready  foreign but maybe that's just me describing jazz maybe you asked it too many things let's do an Indian hip-hop beat using guitar riffs I think the second I say Indian it probably assumes a sitar yeah I really like that last song it's nice my eyes were closed and I was like oh it's nice okay uncle but you know what I think might be useful here the condition on a Melody thing like you just put an existing melody in now you have a correct remix of it so yeah one you can prompt it to do anything let's just try a couple of prompts and see what where do where do these hip-hop artists get their Beats from so there are a lot of websites there are producers who sell their beats online you can literally buy a Beat from someone you can sample sample a beat and then you can buy it license it um the others kind of kind of produce it themselves let's see what this this is like  that's pretty good yeah that's pretty good let's try something not Indian okay A Space theme oh hip-hop using a xylophone let's see what generates so far we've tried a genre of music now we're trying like a vague prompt like space and seeing what meditation it generates unlimited variations so uh so Facebook dropped this yeah what do you what's that end game with this they don't like musicians dude I think all the large companies now become experiment hubs all the good companies have just become experimental small and large they're just realizing let's just take bites in all of these things a we learn a lot and B uh some of the stuff that goes into making something museum by the way I haven't studied music gen but I'm sure some of the techniques that go into this might be useful in maybe text processing right I don't know what they're using in the back end I haven't done enough research on music gen but let's assume they're using some model then you probably learned something from that model that you can apply to other models in fact today we found out that GPT 4 is actually eight models eight expert models that are mixed into each other right so I think it's a lot of muscle memory they're building out this these things and they're trying to figure it out I haven't done enough Research into music gen so I don't know what they're using on the back end all right so Space theme Melody using xylophone this is what it sounds like   it's like some Neil Dyson the grass right Neil Tyson digra indeed uh yeah that that felt pretty Spacey to me um what if you did something like a theme song for a newborn baby based on the Pokemon theme song so does it recognize Styles like mid Journey does so like in mid Journey if we queue saying okay anime style um or Tim Burton style or Wes Anderson style can music gen pick up like a music style can I ask you a question have you do you know friends who've done psychedelics you I'm not that I mean I wish not to comment but you know some friends right yeah they'll tell you a lot about when they're tripping that you have this Synthesia where you can start seeing colors and like I mean not seeing but like it's like this medley of Senses you're smelling colors and you're like and they can't explain why and they can't like it doesn't make sense right correct uh I feel like sometimes when I use mid journey and when I use these music tools and all of these tools I feel like it's similar underlying patterns it's just you need to learn how to translate from one form to another it's almost like how you prompt for Mid Journey correct maybe there's a way to similarly prompt for things like music gen and as you build a muscle from your journey you also build a muscle for using these yeah because the melody that we just played the Space theme one it felt accurate even though there should be no relationship between sound and the visual of space but it's the association just it just kind of fits and makes sense but much like mid-journey I'm sure this has been trained on thousands of prompts of words and sound right like every time I I have seen space being visualized it's always accompanied by this this sound experiment okay I'm just gonna play a tune okay and actually I'm just gonna tell you one word and you tell me what image comes into your head Looney Tunes yeah but what image comes into your head uh it's a rabbit exactly yeah so like a lot of the one ready to close my eyes for this it's just easier so a lot of these associations between Looney Tunes and the rabbit and sometimes some people have the circles you know they're correct correct That's all folks yeah um it's just in our head and I feel like since this is scraped the Internet it's also scraping a lot of people who've been through that version of culture like 90s 2000s 2010's culture correct I feel like um a lot of the what you expect with AI is coming out now because it's been trained on that data where people have made these associations and AI is able to pick out those underlying associations correct let's see if it's picked out the Pokemon theme thank you oh that was awful oh my God that was awful I think our prompt here was but if we prompt something more specific try Looney Tunes uh Looney Tunes Tunes Melody is it glooney tune or Looney Tune uh but rock music let's see what it generates it's trained on legal data Sagar tells us train on legal data that means there will be a mid-journey version of this that's much much better it means uh it's not good I have a question okay philosophical question do you feel people have similar kinds of experiences if they consume similar types of content yes growing up do you feel the world view is similar yes so do you feel like the average things you think about on a daily basis are similar to the average things that somebody else growing up with the same content has this thing yes it's obvious now though like observational comedy used to be an occasion is this why people then fight on the internet so much because let's say somebody who's grown up in Bhopal or some tier 3 City might have a completely different experience of life than somebody who's grown up in a tier one hundred percent they just can't see eye to eye 100 percent um it's not just it's not just growing up in a certain environment and consumption patterns being similar it's also not recognizing that this is the effect that the way you have grown up this is the effect that that's had on you and making that like your core identity so recognizing that someone else's worldview could be different you just cannot penetrate your head this is the rock brain and sponge brain phenomenon right like the most curious people have sponge brain which is they're open to the idea that other people have different thoughts and the way they perceive things so it's almost like if I'm arguing with you on the internet I first have to show you my entire world view which is not possible it's not possible and you don't even know if you're arguing with me on the internet you don't even know why you feel this way why does someone feel so strongly about a certain topic most people just aren't aware Looney Tunes Melody but rock music let's see what this is generated  I don't think it was accurate I don't think the Looney Tunes part was accurate but it was rock music and at least this was coherent like there was percussion and the melody matched the percussion another thing that you can do with music gen is you can drop a melody and ask it to change the style so for example okay like we can let's take the Harry Potter theme okay waiting the Harry Potter theme and ask it to um  uh Indian instruments Tabla flute sitar so we've taken a Harry Potter theme music and asked it to generate it with Indian instruments interesting nice way to beat copyright this used to be a thing right like I knew YouTubers whose whole YouTube channel okay I'm gonna do Highway to Hell but I'm gonna do it in 15 different styles in five minutes and now let's just do it so now we have a host of tools okay we have Runway which can take a video and make it in different styles now you have music where you can jump Styles and now you can start I think now people can start using multiple tools to create interesting music videos and all kinds of things now now these tools are almost there yeah but they're still very expensive for me like Runway is still expensive yeah they're not cheap for Mass usage yet I think video is going to be expensive right you're doing processing on so many frames  you can see you can see what it's doing yeah the in this unlike images the more cues you add the more it sort of gets jumbled up yeah it's trying to do too much yeah in mid Journey you can queue the kind of lighting the camera or you know what's the background you want but with music if if you the more simple you keep it space theme with xylophone that's it not not too much I kind of find that true for my journey also um like over prompting my journey is a thing like majority has style preference like I'm pretty sure my journey is doing pretty prompting it's almost like there's some prompts existing which you can't see uh very stable diffusion more naked right you can prompt it exactly how you want I feel like um because of my Journeys pre-prompting you generally get good images but in stable diffusion you throw too many prompts around it starts getting confused so we've now prompted it could just make the Harry Potter theme using a flute and a Tabla let's see what it turns out like it's actually pretty good yeah that's pretty accurate so it's clear now the more simply you queue the more defined your user the better it'll produce let's try a different Melody okay so we're gonna input this  it's a nice song put this and what do we epic music epic superhero music orchestra epic superhero music orchestra try this this feels like a journey version one it's gonna keep getting better it's gonna get really good really quickly in like six months I'm not worried about where AI is today I'm worried about where it'll be in six months like have you seen how good mid Journey's got stable divisions also gotten really well all right so net net music gen is still version one musicians are safe you guys are fine you guys have six months you guys have six months at least to do whatever the you want because AI hasn't got on you and you're fine God bless you all uh one minute silence for designers and writers cheers uh okay what next I saw this on Twitter AI QR code so these are really cool have you tried these uh yeah we tried the hugging face let's let's try one now uh how does this work uh you have to put some content put a link just take any link link also what video we're gonna take the negative prompt okay that's fine hold on you put a QR code image also but we don't we shouldn't do that now go up go to cube yeah you put the link there and the prompt can be whatever yeah Transformers robot Transformers robot so let's see if it creates a QR code with Transformers robot it's using control net control net so should we increase anything that's okay it's fine yeah let's see what it generates what is control net control net allows you to put in like sort of a reference image and it can pick up details of the reference image and the image that generated will will have some elements of that reference image controller is used a lot for pause like if you have a pose of a person like this you can replicate that exact same pose we actually use control net in a tool we built called Alpha CTR you should check it out um it can be used for ad creatives it's pretty simple you open the website you get to generate a creative um but you get to generate the creative using a reference pose and your face yeah you can upload a face your face or whoever's face you want in the creative and you can prompt what the creative should be yeah so I can prompt for example uh Superman flying uh in front of a train and I can put a reference image of another pose that Superman is in yeah so any other pose and I can put varun's face in it and this is what it generates and it's trained for thumbnails at creatives Etc so use it if you guys want three for free three for free three free just don't make 50 Google accounts and use it now they're gonna do that only that's just not what is the use case for pretty QR codes I think a lot of QR codes are boring like imagine you're it's a QR code yeah a lot of QR codes are boring and sometimes you might it might improve your conversion rate by point when you have a poster you want them to click on a QR code it might improve your conversion a little bit but I find using QR codes are icky like I just like you go to a restaurant you have to use a QR code I'm like why it is so convenient I find it very unconvenient this is super convenient it's a cute tool and you can probably you can have fun with it so how does this technology work how can you put any image let's let the image it uses control net it's sort of like picking out details from enough of the details from the QR code to make sure that when you click the scan that goes to the link but at the same time it's whatever image you've given it whatever prompt you've given it it sort of keeps that as the base image it's blending it uh it says there also it's blending it naturally with your provided prompt in fact the QR code is the initial image and control image exactly as uh Alpha CTR um the control net image and the base image are exactly the same so control net is a what is it it's a protocol think of it as a pose matching model right it's used for pose matching but you can also use it for other things and it's a stable diffusion model it's a stable diffusion got it okay okay there it is okay wow oh that's two that's two robots if you look at them let me scan this let's see if it works are you able to scan it no I can't scan it either scam scam scam wait I'm trying to zoom out I'm trying to zoom in yeah I can't scan it uh just increase the go down a little bit hang on string should we lower it uh increase it strength of what the control and I assume so increase it okay now try this how does a QR code work it has information in it how like I point my phone camera at it think of it as this black and white squares the blacks are ones the whites are zeros just think of it it's a very Layman simplistic way of looking at it it contains information right and then the minute you point your camera at it that information is being passed to you okay who who owns the patent for QR code Google it let's Google it who owns the patents  denser wave trademark the term QR code and owns the pattern rights but does not exercise these rights this makes the technology freely available for creation thank you tensorwave what a fascinating thing that they invented how much data can a QR code store let's find out up to 7089 characters 300 alphanumeric characters wow Sim zero eight nine characters is enough for you to send passwords enough Edition small amount of text it's a way to mask information in plain sight yeah what a amazing technology I would never make it free I would just no but then I don't I don't know if you can easily patent it right because I could also make another QR code if one guy's made it paid I can make a different type of QR code which uses different symbols sort of get the same result it's hard to patent anything in software like eventually it makes its way into the public where'd it go it's amazing how can such an ugly looking image be so useful I mean see at the end of the day actually QR code itself is a layer is a friction reducing layer on top of a link correct so this could be another friction reducing layer on top of a QR code what do you mean like I'm saying that a QR code let's say contains a link you can also look at the link and type it in correct now QR code prettifies that link it makes it more convenient for you to point and click correct okay so it increases the conversion rate of anyone looking at a link and you know typing it in correct I'm saying adding design to it I'm not sure about this but may make it more interesting for somebody to like point and scan at right so if anything there'll be a slight conversion rate increase with QR with this thing and I'm assuming video QR codes is the next step like imagine those Transformers robots they're on a billboard Times Square and they're like you click me and then they freeze in a frame right like but why would you want to spend on the video board why not just make it a static board with a Transformer QR code because a video can add more it can basically add to the CTA right sorry for interrupting this podcast in the middle of it but over 70 of the people who watch this podcast don't subscribe so please hit that subscribe button so we can keep coming onto your feeds and you can keep up with the world of AI back to the episode so that's the QR code wow what do you think it's nice and this time it actually works how do you use it if I was a restaurant I would immediately replace all my QR codes yeah I think they're going to see a lot of art I think all paytm I don't think they'll do it but I think everyone everyone's a merchant yeah that's how to put their storefront or some image that means something to them I think it's going to become a very artistic word like I made a video about Japan in Japan like everything is Art we have anime everywhere you know the fashion stores is supposed to be high-end fashionist love anime so I think art is going to be everywhere which is a good thing I guess it's cute this is a cute use case next framer.ai what is this uh you can now prompt websites into life you want to see yeah um so check this out you don't know how to write any code can you make a website just prompt in a website let's start with AI and click start with AI go okay a simple web page for an AI conference called a icon called a icon um futuristic theme  with a registration button minimalist design black white and red colors and it start let's see what it generates dude this is actually pretty cool bro that's really cool  50 plus speakers 1000 plus Visionary attendees explore the latest AI Technologies connect with blah blah blah bro this is really dangerous and it followed the it followed the color themes themes and you get options on the side as well change the palette and see oh nice yeah and you can scroll light for does it does it generate options or generate just once usually once but we can we can whatever you want to try again yeah let's let's make a new one uh and does it only do websites or it does other things as well right it does mostly websites okay okay a launch page for my for my startup it is Uber but for ambulances do you think it's a nice idea it is Uber but for ambulances you can order an ambulance whenever you want Mario theme Mario themed Pages for pricing troubleshoot and emergency let's see what it makes I love this startup idea revolutionize emergencies with Mario ambulances supercharged Ambulance Service we take let's just read the copy generates copy as well we take the power-ups of Mario and combine them with rapid ambulance service for click quick and efficient medical attention no more waiting for traditional ambulances just tap and you're on the way to the mushroom hospital or Princess Peach Medical Center haha instant ambulance booking and comparative pricing there's a doctor smiling for troubleshoot ready to level up your emergency response join Mario ambulances today very nice that's pretty cool and can you change fonts and everything yeah I'm sure this is really good this is really good should we try to have one more problem let's see what uh let's see for a serious thing a portfolio for a photographer called Atul Chas Baker  shoots product shorts product shots for food a page for his work pricing and a button for bookings simple oh wow atul's appetizing shots Savor the flavor discover's tantalizing food product photography with scrumptious dishes and irresistible ingredients shine Pro copy is a little cheesy but this is really good for instant websites this is really good and you can play around right it's got pricing it's got pricing as well 200 per shot hasn't heard of   just done in a different style I think so just put in anything and regenerate it's really it's too powerful yeah how much does this cost to make a website can you deploy it as well from here so if you publish I think it will cost you some amount of money so this is famous pricing you can go check it out if you want to this is the website on the big screen that was lovely it was a good idea that was that's a good AI tool okay what does this say problem with AI generated content one of our key sources of human data is no longer fully human we estimate that 33 to 46 of crowd workers on mtuk used mechanical llms in a text production task which may increase as GPT and the like become more popular so I'll tell you what M talk is okay so this is website where you can get anything done okay you want people to label tasks you want them to generate some text you want them to do whatever you want right so they have um people you can hire from like third world countries to kind of label and do the small tasks for you but it turns out that a lot of these people like especially if you ask them okay generate a small essay or whatever they are using chat GPD itself and obviously you have no control over them so chat gbd seems to be doing their work so you're no longer getting human data you are getting AI data to train your own AI model so this is mostly used for people who want to make their own machine learning models and need lots of data labeled so it turns out you're now labeling your data with charge gbd but you're also paying this random Mechanical Turk for actually facilitating that process using openai to train their models which is weird it's like such a roundabout way of doing I was actually talking to a friend of mine recently who runs a company that employs a lot of writers I met this friend and I said dude like have you used GPD and he was like I've heard about it but I haven't used it and then I made a sample task for this friend and I just opened GPD and I said here this is this is how you can use it and he was like you know at first there is always denial which is yeah this doesn't have the soul or the promotion or etc etc but then like an hour later this friend of mine is very reasonable an hour later after tinkering around with it he was like this is super useful um and then today's a day text me saying today I went to my office and I showed this to a lot of my creative folks and some of them came and told me later that they'd already been using it they just want they just never told me about it so I'm sure this is happening a lot which is people already using at the very least GPD 3.5 which if you guys haven't got gpd4 you should probably try gbd for its it's stupid it's way better um but a lot of people don't know that this is gbd4 like but how long can this cam continue how long can you hide from your boss that are using a tool that's doing 90 of your job I think at some point bosses will figure out and right now you can still tell like to some degree whether something is like you this I'm always skeptical when I look at long emails or you know tweets or LinkedIn posts I'm always like whatever you've seen how 90 of people actually write it's like most people in the world don't write well correct correct they write like GPD only that's trained on their data only yeah so one way to test is to go down someone's timeline and see before six months before six months how they used to write I'm a cool man but what's what's the solution here like because a lot of lot of employers won't know if employees are using chat gbd which is fine like as long as your employees are still delivering which is fine but there's no it's not even a problem so to say is it a problem I don't think it's a problem so to your answer of to your question of what should we do I'm now learning the difference between the hibiscus plant and another plant all the plants because I think that's what I'll end up doing in my life right so I would memorize plant names I would find out where to buy seeds don't be don't be do more I'm just kidding I think it's about leverage like what is it you can do that GPD can't easily do or can you use GPD to do a lot more can you use GPD do a lot more can you somehow be accountable for the things you do like if you're just a writer and you can be replaced by 10 other writers it's like a hard time but if you can find a way to level up say that oh I'm not only going to write I'm going to tell you what I should write to get views on this website right then that's a leverage Point like you have some consumer inside that GPT might not have in your domain that is valuable then you can use GPT as a tool correct so you don't want to be a like in fact you can separate human tasks right now like the jobs you have into are you being used by a tool like by your boss or are you making executive decisions and the more you seem like a tool for your boss to just offload workloads the more dangerous the spot you're in right but the minute you make these decisions you're like safe yes this friend of mine said that interestingly enough his most productive employees were the ones who said that they've already been been using yeah so in this particular case um the folks who are using GPT were using it as leverage but they were able to just output a lot more it's just now it became clear that oh how how were you able to do so much I was wondering and now it became clear so in this particular case um in all likelihood the business will greatly benefit uh then they're not trying to save costs so nobody nobody's gonna get laid off but they'll probably hugely benefit by outputting more hmm so again it's like that let's form right like you don't know the owner of the business might want to Pivot in either side either they want to cut costs or they you know they're really people loving and they're like no I don't want to let anyone go but can we generate more now I try to be as optimistic as I can but the more business owners I talk to it's like it's quite obvious what they want they want to reduce costs so it's like it's this thing right about like my Twitter now I've put this one line saying don't shoot the messenger like this is going to happen Okay where if you're just a tool in a company and that GPT or whatever can be a better tool than you then obviously you're gonna have some competition it is better you hear this from me now hate me now if necessary I'm talking about me personally not you I hate you right Hate Me Now personally but make a change in your life how much ever you hate and six months later you're probably in a much better place because you made those decisions now then six months later you get caught off guard because you didn't listen and or you were not on this podcast or you whatever like you didn't choose to make that decision and then you know just hate yourself or be bitter at it like I feel like this is what in crypto that I really like called Alpha it's actually all Finance right I'll have some information any other information before the rest of the world the thing is overpower is not a mainstream podcast yet I think mainstream is about one million plus yeah when you're still at 100K types you have the opportunity to listen to this before anyone else does and we capture this information within a week like you're getting this new information these new tools within a week of us talking about them so I feel like that's your leverage no maybe your leverage could also just be speed hey I know the latest tools I use the latest tools therefore you know as a boss you can't fire me because hey I'm I'm always going to keep adding productivity to your business all that inspirational note uh as for today's episode of you I hope you guys enjoyed this let us in the comment section if you came across any Cool Tools uh that you want us to cover and that's all see you in the next one ",
    "url": "https://www.youtube.com/watch?v=WITWMclds2c"
  }
}